{"created":"2024-04-22 17:59:57","title":"AutoAD III: The Prequel -- Back to the Pixels","abstract":"Generating Audio Description (AD) for movies is a challenging task that requires fine-grained visual understanding and an awareness of the characters and their names. Currently, visual language models for AD generation are limited by a lack of suitable training data, and also their evaluation is hampered by using performance measures not specialized to the AD domain. In this paper, we make three contributions: (i) We propose two approaches for constructing AD datasets with aligned video data, and build training and evaluation datasets using these. These datasets will be publicly released; (ii) We develop a Q-former-based architecture which ingests raw video and generates AD, using frozen pre-trained visual encoders and large language models; and (iii) We provide new evaluation metrics to benchmark AD quality that are well-matched to human performance. Taken together, we improve the state of the art on AD generation.","sentences":["Generating Audio Description (AD) for movies is a challenging task that requires fine-grained visual understanding and an awareness of the characters and their names.","Currently, visual language models for AD generation are limited by a lack of suitable training data, and also their evaluation is hampered by using performance measures not specialized to the AD domain.","In this paper, we make three contributions: (i) We propose two approaches for constructing AD datasets with aligned video data, and build training and evaluation datasets using these.","These datasets will be publicly released; (ii) We develop a Q-former-based architecture which ingests raw video and generates AD, using frozen pre-trained visual encoders and large language models; and (iii) We provide new evaluation metrics to benchmark AD quality that are well-matched to human performance.","Taken together, we improve the state of the art on AD generation."],"url":"http://arxiv.org/abs/2404.14412v1"}
{"created":"2024-04-22 17:59:36","title":"CrossScore: Towards Multi-View Image Evaluation and Scoring","abstract":"We introduce a novel cross-reference image quality assessment method that effectively fills the gap in the image assessment landscape, complementing the array of established evaluation schemes -- ranging from full-reference metrics like SSIM, no-reference metrics such as NIQE, to general-reference metrics including FID, and Multi-modal-reference metrics, e.g., CLIPScore. Utilising a neural network with the cross-attention mechanism and a unique data collection pipeline from NVS optimisation, our method enables accurate image quality assessment without requiring ground truth references. By comparing a query image against multiple views of the same scene, our method addresses the limitations of existing metrics in novel view synthesis (NVS) and similar tasks where direct reference images are unavailable. Experimental results show that our method is closely correlated to the full-reference metric SSIM, while not requiring ground truth references.","sentences":["We introduce a novel cross-reference image quality assessment method that effectively fills the gap in the image assessment landscape, complementing the array of established evaluation schemes -- ranging from full-reference metrics like SSIM, no-reference metrics such as NIQE, to general-reference metrics including FID, and Multi-modal-reference metrics, e.g., CLIPScore.","Utilising a neural network with the cross-attention mechanism and a unique data collection pipeline from NVS optimisation, our method enables accurate image quality assessment without requiring ground truth references.","By comparing a query image against multiple views of the same scene, our method addresses the limitations of existing metrics in novel view synthesis (NVS) and similar tasks where direct reference images are unavailable.","Experimental results show that our method is closely correlated to the full-reference metric SSIM, while not requiring ground truth references."],"url":"http://arxiv.org/abs/2404.14409v1"}
{"created":"2024-04-22 17:56:09","title":"SEED-X: Multimodal Models with Unified Multi-granularity Comprehension and Generation","abstract":"The rapid evolution of multimodal foundation model has demonstrated significant progresses in vision-language understanding and generation, e.g., our previous work SEED-LLaMA. However, there remains a gap between its capability and the real-world applicability, primarily due to the model's limited capacity to effectively respond to various user instructions and interact with diverse visual data. In this work, we focus on bridging this gap through integrating two enhanced features: (1) comprehending images of arbitrary sizes and ratios, and (2) enabling multi-granularity image generation. We present a unified and versatile foundation model, namely, SEED-X, which is able to model multi-granularity visual semantics for comprehension and generation tasks. Besides the competitive results on public benchmarks, SEED-X demonstrates its effectiveness in handling real-world applications across various domains after instruction tuning. We hope that our work will inspire future research into what can be achieved by versatile multimodal foundation models in real-world applications. The models, codes, and datasets will be released in https://github.com/AILab-CVC/SEED-X.","sentences":["The rapid evolution of multimodal foundation model has demonstrated significant progresses in vision-language understanding and generation, e.g., our previous work SEED-LLaMA.","However, there remains a gap between its capability and the real-world applicability, primarily due to the model's limited capacity to effectively respond to various user instructions and interact with diverse visual data.","In this work, we focus on bridging this gap through integrating two enhanced features: (1) comprehending images of arbitrary sizes and ratios, and (2) enabling multi-granularity image generation.","We present a unified and versatile foundation model, namely, SEED-X, which is able to model multi-granularity visual semantics for comprehension and generation tasks.","Besides the competitive results on public benchmarks, SEED-X demonstrates its effectiveness in handling real-world applications across various domains after instruction tuning.","We hope that our work will inspire future research into what can be achieved by versatile multimodal foundation models in real-world applications.","The models, codes, and datasets will be released in https://github.com/AILab-CVC/SEED-X."],"url":"http://arxiv.org/abs/2404.14396v1"}
{"created":"2024-04-22 17:50:27","title":"Poisoning Attacks on Federated Learning-based Wireless Traffic Prediction","abstract":"Federated Learning (FL) offers a distributed framework to train a global control model across multiple base stations without compromising the privacy of their local network data. This makes it ideal for applications like wireless traffic prediction (WTP), which plays a crucial role in optimizing network resources, enabling proactive traffic flow management, and enhancing the reliability of downstream communication-aided applications, such as IoT devices, autonomous vehicles, and industrial automation systems. Despite its promise, the security aspects of FL-based distributed wireless systems, particularly in regression-based WTP problems, remain inadequately investigated. In this paper, we introduce a novel fake traffic injection (FTI) attack, designed to undermine the FL-based WTP system by injecting fabricated traffic distributions with minimal knowledge. We further propose a defense mechanism, termed global-local inconsistency detection (GLID), which strategically removes abnormal model parameters that deviate beyond a specific percentile range estimated through statistical methods in each dimension. Extensive experimental evaluations, performed on real-world wireless traffic datasets, demonstrate that both our attack and defense strategies significantly outperform existing baselines.","sentences":["Federated Learning (FL) offers a distributed framework to train a global control model across multiple base stations without compromising the privacy of their local network data.","This makes it ideal for applications like wireless traffic prediction (WTP), which plays a crucial role in optimizing network resources, enabling proactive traffic flow management, and enhancing the reliability of downstream communication-aided applications, such as IoT devices, autonomous vehicles, and industrial automation systems.","Despite its promise, the security aspects of FL-based distributed wireless systems, particularly in regression-based WTP problems, remain inadequately investigated.","In this paper, we introduce a novel fake traffic injection (FTI) attack, designed to undermine the FL-based WTP system by injecting fabricated traffic distributions with minimal knowledge.","We further propose a defense mechanism, termed global-local inconsistency detection (GLID), which strategically removes abnormal model parameters that deviate beyond a specific percentile range estimated through statistical methods in each dimension.","Extensive experimental evaluations, performed on real-world wireless traffic datasets, demonstrate that both our attack and defense strategies significantly outperform existing baselines."],"url":"http://arxiv.org/abs/2404.14389v1"}
{"created":"2024-04-22 17:46:29","title":"STROOBnet Optimization via GPU-Accelerated Proximal Recurrence Strategies","abstract":"Spatiotemporal networks' observational capabilities are crucial for accurate data gathering and informed decisions across multiple sectors. This study focuses on the Spatiotemporal Ranged Observer-Observable Bipartite Network (STROOBnet), linking observational nodes (e.g., surveillance cameras) to events within defined geographical regions, enabling efficient monitoring. Using data from Real-Time Crime Camera (RTCC) systems and Calls for Service (CFS) in New Orleans, where RTCC combats rising crime amidst reduced police presence, we address the network's initial observational imbalances. Aiming for uniform observational efficacy, we propose the Proximal Recurrence approach. It outperformed traditional clustering methods like k-means and DBSCAN by offering holistic event frequency and spatial consideration, enhancing observational coverage.","sentences":["Spatiotemporal networks' observational capabilities are crucial for accurate data gathering and informed decisions across multiple sectors.","This study focuses on the Spatiotemporal Ranged Observer-Observable Bipartite Network (STROOBnet), linking observational nodes (e.g., surveillance cameras) to events within defined geographical regions, enabling efficient monitoring.","Using data from Real-Time Crime Camera (RTCC) systems and Calls for Service (CFS) in New Orleans, where RTCC combats rising crime amidst reduced police presence, we address the network's initial observational imbalances.","Aiming for uniform observational efficacy, we propose the Proximal Recurrence approach.","It outperformed traditional clustering methods like k-means and DBSCAN by offering holistic event frequency and spatial consideration, enhancing observational coverage."],"url":"http://arxiv.org/abs/2404.14388v1"}
{"created":"2024-04-22 17:22:31","title":"Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph","abstract":"Model scaling is becoming the default choice for many language tasks due to the success of large language models (LLMs). However, it can fall short in specific scenarios where simple customized methods excel. In this paper, we delve into the patent approval pre-diction task and unveil that simple domain-specific graph methods outperform enlarging the model, using the intrinsic dependencies within the patent data. Specifically, we first extend the embedding-based state-of-the-art (SOTA) by scaling up its backbone model with various sizes of open-source LLMs, then explore prompt-based methods to harness proprietary LLMs' potential, but find the best results close to random guessing, underlining the ineffectiveness of model scaling-up. Hence, we propose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulous patent data analyses, capturing the inherent dependencies across segments of the patent text. As it is model-agnostic, we apply cost-effective graph models to our FLAN Graph to obtain representations for approval prediction. Extensive experiments and detailed analyses prove that incorporating FLAN Graph via various graph models consistently outperforms all LLM baselines significantly. We hope that our observations and analyses in this paper can bring more attention to this challenging task and prompt further research into the limitations of LLMs. Our source code and dataset can be obtained from http://github.com/ShangDataLab/FLAN-Graph.","sentences":["Model scaling is becoming the default choice for many language tasks due to the success of large language models (LLMs).","However, it can fall short in specific scenarios where simple customized methods excel.","In this paper, we delve into the patent approval pre-diction task and unveil that simple domain-specific graph methods outperform enlarging the model, using the intrinsic dependencies within the patent data.","Specifically, we first extend the embedding-based state-of-the-art (SOTA) by scaling up its backbone model with various sizes of open-source LLMs, then explore prompt-based methods to harness proprietary LLMs' potential, but find the best results close to random guessing, underlining the ineffectiveness of model scaling-up.","Hence, we propose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulous patent data analyses, capturing the inherent dependencies across segments of the patent text.","As it is model-agnostic, we apply cost-effective graph models to our FLAN Graph to obtain representations for approval prediction.","Extensive experiments and detailed analyses prove that incorporating FLAN Graph via various graph models consistently outperforms all LLM baselines significantly.","We hope that our observations and analyses in this paper can bring more attention to this challenging task and prompt further research into the limitations of LLMs.","Our source code and dataset can be obtained from http://github.com/ShangDataLab/FLAN-Graph."],"url":"http://arxiv.org/abs/2404.14372v1"}
{"created":"2024-04-22 17:20:18","title":"Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data","abstract":"Learning from preference labels plays a crucial role in fine-tuning large language models. There are several distinct approaches for preference fine-tuning, including supervised learning, on-policy reinforcement learning (RL), and contrastive learning. Different methods come with different implementation tradeoffs and performance differences, and existing empirical findings present different conclusions, for instance, some results show that online RL is quite important to attain good fine-tuning results, while others find (offline) contrastive or even purely supervised methods sufficient. This raises a natural question: what kind of approaches are important for fine-tuning with preference data and why? In this paper, we answer this question by performing a rigorous analysis of a number of fine-tuning techniques on didactic and full-scale LLM problems. Our main finding is that, in general, approaches that use on-policy sampling or attempt to push down the likelihood on certain responses (i.e., employ a \"negative gradient\") outperform offline and maximum likelihood objectives. We conceptualize our insights and unify methods that use on-policy sampling or negative gradient under a notion of mode-seeking objectives for categorical distributions. Mode-seeking objectives are able to alter probability mass on specific bins of a categorical distribution at a fast rate compared to maximum likelihood, allowing them to relocate masses across bins more effectively. Our analysis prescribes actionable insights for preference fine-tuning of LLMs and informs how data should be collected for maximal improvement.","sentences":["Learning from preference labels plays a crucial role in fine-tuning large language models.","There are several distinct approaches for preference fine-tuning, including supervised learning, on-policy reinforcement learning (RL), and contrastive learning.","Different methods come with different implementation tradeoffs and performance differences, and existing empirical findings present different conclusions, for instance, some results show that online RL is quite important to attain good fine-tuning results, while others find (offline) contrastive or even purely supervised methods sufficient.","This raises a natural question: what kind of approaches are important for fine-tuning with preference data and why?","In this paper, we answer this question by performing a rigorous analysis of a number of fine-tuning techniques on didactic and full-scale LLM problems.","Our main finding is that, in general, approaches that use on-policy sampling or attempt to push down the likelihood on certain responses (i.e., employ a \"negative gradient\") outperform offline and maximum likelihood objectives.","We conceptualize our insights and unify methods that use on-policy sampling or negative gradient under a notion of mode-seeking objectives for categorical distributions.","Mode-seeking objectives are able to alter probability mass on specific bins of a categorical distribution at a fast rate compared to maximum likelihood, allowing them to relocate masses across bins more effectively.","Our analysis prescribes actionable insights for preference fine-tuning of LLMs and informs how data should be collected for maximal improvement."],"url":"http://arxiv.org/abs/2404.14367v1"}
{"created":"2024-04-22 17:15:32","title":"Better Synthetic Data by Retrieving and Transforming Existing Datasets","abstract":"Despite recent advances in large language models, building dependable and deployable NLP models typically requires abundant, high-quality training data. However, task-specific data is not available for many use cases, and manually curating task-specific data is labor-intensive. Recent work has studied prompt-driven synthetic data generation using large language models, but these generated datasets tend to lack complexity and diversity. To address these limitations, we introduce a method, \\textit{DataTune}, to make better use of existing, publicly available datasets to improve automatic dataset generation. DataTune performs dataset transformation, enabling the repurposing of publicly available datasets into a format that is directly aligned with the specific requirements of target tasks. On a diverse set of language-based tasks from the BIG-Bench benchmark, we find that finetuning language models via DataTune improves over a few-shot prompting baseline by 49\\% and improves over existing methods that use synthetic or retrieved training data by 34\\%. We find that dataset transformation significantly increases the diversity and difficulty of generated data on many tasks. We integrate DataTune into an open-source repository to make this method accessible to the community: https://github.com/neulab/prompt2model.","sentences":["Despite recent advances in large language models, building dependable and deployable NLP models typically requires abundant, high-quality training data.","However, task-specific data is not available for many use cases, and manually curating task-specific data is labor-intensive.","Recent work has studied prompt-driven synthetic data generation using large language models, but these generated datasets tend to lack complexity and diversity.","To address these limitations, we introduce a method, \\textit{DataTune}, to make better use of existing, publicly available datasets to improve automatic dataset generation.","DataTune performs dataset transformation, enabling the repurposing of publicly available datasets into a format that is directly aligned with the specific requirements of target tasks.","On a diverse set of language-based tasks from the BIG-Bench benchmark, we find that finetuning language models via DataTune improves over a few-shot prompting baseline by 49\\% and improves over existing methods that use synthetic or retrieved training data by 34\\%.","We find that dataset transformation significantly increases the diversity and difficulty of generated data on many tasks.","We integrate DataTune into an open-source repository to make this method accessible to the community: https://github.com/neulab/prompt2model."],"url":"http://arxiv.org/abs/2404.14361v1"}
{"created":"2024-04-22 17:12:06","title":"A Stochastic Geo-spatiotemporal Bipartite Network to Optimize GCOOS Sensor Placement Strategies","abstract":"This paper proposes two new measures applicable in a spatial bipartite network model: coverage and coverage robustness. The bipartite network must consist of observer nodes, observable nodes, and edges that connect observer nodes to observable nodes. The coverage and coverage robustness scores evaluate the effectiveness of the observer node placements. This measure is beneficial for stochastic data as it may be coupled with Monte Carlo simulations to identify optimal placements for new observer nodes. In this paper, we construct a Geo-SpatioTemporal Bipartite Network (GSTBN) within the stochastic and dynamical environment of the Gulf of Mexico. This GSTBN consists of GCOOS sensor nodes and HYCOM Region of Interest (RoI) event nodes. The goal is to identify optimal placements to expand GCOOS to improve the forecasting outcomes by the HYCOM ocean prediction model.","sentences":["This paper proposes two new measures applicable in a spatial bipartite network model: coverage and coverage robustness.","The bipartite network must consist of observer nodes, observable nodes, and edges that connect observer nodes to observable nodes.","The coverage and coverage robustness scores evaluate the effectiveness of the observer node placements.","This measure is beneficial for stochastic data as it may be coupled with Monte Carlo simulations to identify optimal placements for new observer nodes.","In this paper, we construct a Geo-SpatioTemporal Bipartite Network (GSTBN) within the stochastic and dynamical environment of the Gulf of Mexico.","This GSTBN consists of GCOOS sensor nodes and HYCOM Region of Interest (RoI) event nodes.","The goal is to identify optimal placements to expand GCOOS to improve the forecasting outcomes by the HYCOM ocean prediction model."],"url":"http://arxiv.org/abs/2404.14357v1"}
{"created":"2024-04-22 17:10:27","title":"Rethinking Legal Compliance Automation: Opportunities with Large Language Models","abstract":"As software-intensive systems face growing pressure to comply with laws and regulations, providing automated support for compliance analysis has become paramount. Despite advances in the Requirements Engineering (RE) community on legal compliance analysis, important obstacles remain in developing accurate and generalizable compliance automation solutions. This paper highlights some observed limitations of current approaches and examines how adopting new automation strategies that leverage Large Language Models (LLMs) can help address these shortcomings and open up fresh opportunities. Specifically, we argue that the examination of (textual) legal artifacts should, first, employ a broader context than sentences, which have widely been used as the units of analysis in past research. Second, the mode of analysis with legal artifacts needs to shift from classification and information extraction to more end-to-end strategies that are not only accurate but also capable of providing explanation and justification. We present a compliance analysis approach designed to address these limitations. We further outline our evaluation plan for the approach and provide preliminary evaluation results based on data processing agreements (DPAs) that must comply with the General Data Protection Regulation (GDPR). Our initial findings suggest that our approach yields substantial accuracy improvements and, at the same time, provides justification for compliance decisions.","sentences":["As software-intensive systems face growing pressure to comply with laws and regulations, providing automated support for compliance analysis has become paramount.","Despite advances in the Requirements Engineering (RE) community on legal compliance analysis, important obstacles remain in developing accurate and generalizable compliance automation solutions.","This paper highlights some observed limitations of current approaches and examines how adopting new automation strategies that leverage Large Language Models (LLMs) can help address these shortcomings and open up fresh opportunities.","Specifically, we argue that the examination of (textual) legal artifacts should, first, employ a broader context than sentences, which have widely been used as the units of analysis in past research.","Second, the mode of analysis with legal artifacts needs to shift from classification and information extraction to more end-to-end strategies that are not only accurate but also capable of providing explanation and justification.","We present a compliance analysis approach designed to address these limitations.","We further outline our evaluation plan for the approach and provide preliminary evaluation results based on data processing agreements (DPAs) that must comply with the General Data Protection Regulation (GDPR).","Our initial findings suggest that our approach yields substantial accuracy improvements and, at the same time, provides justification for compliance decisions."],"url":"http://arxiv.org/abs/2404.14356v1"}
{"created":"2024-04-22 17:07:25","title":"Calc-CMU at SemEval-2024 Task 7: Pre-Calc -- Learning to Use the Calculator Improves Numeracy in Language Models","abstract":"Quantitative and numerical comprehension in language is an important task in many fields like education and finance, but still remains a challenging task for language models. While tool and calculator usage has shown to be helpful to improve mathematical reasoning in large pretrained decoder-only language models, this remains unexplored for smaller language models with encoders. In this paper, we propose Pre-Calc, a simple pre-finetuning objective of learning to use the calculator for both encoder-only and encoder-decoder architectures, formulated as a discriminative and generative task respectively. We pre-train BERT and RoBERTa for discriminative calculator use and Flan-T5 for generative calculator use on the MAWPS, SVAMP, and AsDiv-A datasets, which improves performance on downstream tasks that require numerical understanding. Our code and data are available at https://github.com/calc-cmu/pre-calc.","sentences":["Quantitative and numerical comprehension in language is an important task in many fields like education and finance, but still remains a challenging task for language models.","While tool and calculator usage has shown to be helpful to improve mathematical reasoning in large pretrained decoder-only language models, this remains unexplored for smaller language models with encoders.","In this paper, we propose Pre-Calc, a simple pre-finetuning objective of learning to use the calculator for both encoder-only and encoder-decoder architectures, formulated as a discriminative and generative task respectively.","We pre-train BERT and RoBERTa for discriminative calculator use and Flan-T5 for generative calculator use on the MAWPS, SVAMP, and AsDiv-A datasets, which improves performance on downstream tasks that require numerical understanding.","Our code and data are available at https://github.com/calc-cmu/pre-calc."],"url":"http://arxiv.org/abs/2404.14355v1"}
{"created":"2024-04-22 16:59:43","title":"On-the-Fly Point Annotation for Fast Medical Video Labeling","abstract":"Purpose: In medical research, deep learning models rely on high-quality annotated data, a process often laborious and timeconsuming. This is particularly true for detection tasks where bounding box annotations are required. The need to adjust two corners makes the process inherently frame-by-frame. Given the scarcity of experts' time, efficient annotation methods suitable for clinicians are needed. Methods: We propose an on-the-fly method for live video annotation to enhance the annotation efficiency. In this approach, a continuous single-point annotation is maintained by keeping the cursor on the object in a live video, mitigating the need for tedious pausing and repetitive navigation inherent in traditional annotation methods. This novel annotation paradigm inherits the point annotation's ability to generate pseudo-labels using a point-to-box teacher model. We empirically evaluate this approach by developing a dataset and comparing on-the-fly annotation time against traditional annotation method. Results: Using our method, annotation speed was 3.2x faster than the traditional annotation technique. We achieved a mean improvement of 6.51 +- 0.98 AP@50 over conventional method at equivalent annotation budgets on the developed dataset. Conclusion: Without bells and whistles, our approach offers a significant speed-up in annotation tasks. It can be easily implemented on any annotation platform to accelerate the integration of deep learning in video-based medical research.","sentences":["Purpose: In medical research, deep learning models rely on high-quality annotated data, a process often laborious and timeconsuming.","This is particularly true for detection tasks where bounding box annotations are required.","The need to adjust two corners makes the process inherently frame-by-frame.","Given the scarcity of experts' time, efficient annotation methods suitable for clinicians are needed.","Methods: We propose an on-the-fly method for live video annotation to enhance the annotation efficiency.","In this approach, a continuous single-point annotation is maintained by keeping the cursor on the object in a live video, mitigating the need for tedious pausing and repetitive navigation inherent in traditional annotation methods.","This novel annotation paradigm inherits the point annotation's ability to generate pseudo-labels using a point-to-box teacher model.","We empirically evaluate this approach by developing a dataset and comparing on-the-fly annotation time against traditional annotation method.","Results: Using our method, annotation speed was 3.2x faster than the traditional annotation technique.","We achieved a mean improvement of 6.51 +- 0.98 AP@50 over conventional method at equivalent annotation budgets on the developed dataset.","Conclusion: Without bells and whistles, our approach offers a significant speed-up in annotation tasks.","It can be easily implemented on any annotation platform to accelerate the integration of deep learning in video-based medical research."],"url":"http://arxiv.org/abs/2404.14344v1"}
{"created":"2024-04-22 16:58:37","title":"Heterogeneous Face Recognition Using Domain Invariant Units","abstract":"Heterogeneous Face Recognition (HFR) aims to expand the applicability of Face Recognition (FR) systems to challenging scenarios, enabling the matching of face images across different domains, such as matching thermal images to visible spectra. However, the development of HFR systems is challenging because of the significant domain gap between modalities and the lack of availability of large-scale paired multi-channel data. In this work, we leverage a pretrained face recognition model as a teacher network to learn domaininvariant network layers called Domain-Invariant Units (DIU) to reduce the domain gap. The proposed DIU can be trained effectively even with a limited amount of paired training data, in a contrastive distillation framework. This proposed approach has the potential to enhance pretrained models, making them more adaptable to a wider range of variations in data. We extensively evaluate our approach on multiple challenging benchmarks, demonstrating superior performance compared to state-of-the-art methods.","sentences":["Heterogeneous Face Recognition (HFR) aims to expand the applicability of Face Recognition (FR) systems to challenging scenarios, enabling the matching of face images across different domains, such as matching thermal images to visible spectra.","However, the development of HFR systems is challenging because of the significant domain gap between modalities and the lack of availability of large-scale paired multi-channel data.","In this work, we leverage a pretrained face recognition model as a teacher network to learn domaininvariant network layers called Domain-Invariant Units (DIU) to reduce the domain gap.","The proposed DIU can be trained effectively even with a limited amount of paired training data, in a contrastive distillation framework.","This proposed approach has the potential to enhance pretrained models, making them more adaptable to a wider range of variations in data.","We extensively evaluate our approach on multiple challenging benchmarks, demonstrating superior performance compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2404.14343v1"}
{"created":"2024-04-22 16:56:43","title":"Zero-shot Cross-lingual Stance Detection via Adversarial Language Adaptation","abstract":"Stance detection has been widely studied as the task of determining if a social media post is positive, negative or neutral towards a specific issue, such as support towards vaccines. Research in stance detection has however often been limited to a single language and, where more than one language has been studied, research has focused on few-shot settings, overlooking the challenges of developing a zero-shot cross-lingual stance detection model. This paper makes the first such effort by introducing a novel approach to zero-shot cross-lingual stance detection, Multilingual Translation-Augmented BERT (MTAB), aiming to enhance the performance of a cross-lingual classifier in the absence of explicit training data for target languages. Our technique employs translation augmentation to improve zero-shot performance and pairs it with adversarial learning to further boost model efficacy. Through experiments on datasets labeled for stance towards vaccines in four languages English, German, French, Italian. We demonstrate the effectiveness of our proposed approach, showcasing improved results in comparison to a strong baseline model as well as ablated versions of our model. Our experiments demonstrate the effectiveness of model components, not least the translation-augmented data as well as the adversarial learning component, to the improved performance of the model. We have made our source code accessible on GitHub.","sentences":["Stance detection has been widely studied as the task of determining if a social media post is positive, negative or neutral towards a specific issue, such as support towards vaccines.","Research in stance detection has however often been limited to a single language and, where more than one language has been studied, research has focused on few-shot settings, overlooking the challenges of developing a zero-shot cross-lingual stance detection model.","This paper makes the first such effort by introducing a novel approach to zero-shot cross-lingual stance detection, Multilingual Translation-Augmented BERT (MTAB), aiming to enhance the performance of a cross-lingual classifier in the absence of explicit training data for target languages.","Our technique employs translation augmentation to improve zero-shot performance and pairs it with adversarial learning to further boost model efficacy.","Through experiments on datasets labeled for stance towards vaccines in four languages English, German, French, Italian.","We demonstrate the effectiveness of our proposed approach, showcasing improved results in comparison to a strong baseline model as well as ablated versions of our model.","Our experiments demonstrate the effectiveness of model components, not least the translation-augmented data as well as the adversarial learning component, to the improved performance of the model.","We have made our source code accessible on GitHub."],"url":"http://arxiv.org/abs/2404.14339v1"}
{"created":"2024-04-22 16:49:34","title":"DE-LIoT: The Data-Energy Networking Paradigm for Sustainable Light-Based Internet of Things","abstract":"The growing demand for Internet of Things (IoT) networks has sparked interest in sustainable, zero-energy designs through Energy Harvesting (EH) to extend the lifespans of IoT sensors. Visible Light Communication (VLC) is particularly promising, integrating signal transmission with optical power harvesting to enable both data exchange and energy transfer in indoor network nodes. VLC indoor channels, however, can be unstable due to their line-of-sight nature and indoor movements. In conventional EH-based IoT networks, maximum Energy Storage (ES) capacity might halt further harvesting or waste excess energy, leading to resource inefficiency. Addressing these issues, this paper proposes a novel VLC-based WPANs concept that enhances both data and energy harvesting efficiency. The architecture employs densely distributed nodes and a central controller for simultaneous data and energy network operation, ensuring efficient energy exchange and resource optimisation. This approach, with centralised control and energy-state-aware nodes, aims for long-term energy autonomy. The feasibility of the Data-Energy Networking-enabled Light-based Internet of Things (DE-LIoT) concept is validated through real hardware implementation, demonstrating its sustainability and practical applicability. Results show significant improvements in the lifetime of resource-limited nodes, confirming the effectiveness of this new data and energy networking model in enhancing sustainability and resource optimisation in VLC-based WPANs.","sentences":["The growing demand for Internet of Things (IoT) networks has sparked interest in sustainable, zero-energy designs through Energy Harvesting (EH) to extend the lifespans of IoT sensors.","Visible Light Communication (VLC) is particularly promising, integrating signal transmission with optical power harvesting to enable both data exchange and energy transfer in indoor network nodes.","VLC indoor channels, however, can be unstable due to their line-of-sight nature and indoor movements.","In conventional EH-based IoT networks, maximum Energy Storage (ES) capacity might halt further harvesting or waste excess energy, leading to resource inefficiency.","Addressing these issues, this paper proposes a novel VLC-based WPANs concept that enhances both data and energy harvesting efficiency.","The architecture employs densely distributed nodes and a central controller for simultaneous data and energy network operation, ensuring efficient energy exchange and resource optimisation.","This approach, with centralised control and energy-state-aware nodes, aims for long-term energy autonomy.","The feasibility of the Data-Energy Networking-enabled Light-based Internet of Things (DE-LIoT) concept is validated through real hardware implementation, demonstrating its sustainability and practical applicability.","Results show significant improvements in the lifetime of resource-limited nodes, confirming the effectiveness of this new data and energy networking model in enhancing sustainability and resource optimisation in VLC-based WPANs."],"url":"http://arxiv.org/abs/2404.14333v1"}
{"created":"2024-04-22 16:38:41","title":"Machine Learning Techniques for MRI Data Processing at Expanding Scale","abstract":"Imaging sites around the world generate growing amounts of medical scan data with ever more versatile and affordable technology. Large-scale studies acquire MRI for tens of thousands of participants, together with metadata ranging from lifestyle questionnaires to biochemical assays, genetic analyses and more. These large datasets encode substantial information about human health and hold considerable potential for machine learning training and analysis. This chapter examines ongoing large-scale studies and the challenge of distribution shifts between them. Transfer learning for overcoming such shifts is discussed, together with federated learning for safe access to distributed training data securely held at multiple institutions. Finally, representation learning is reviewed as a methodology for encoding embeddings that express abstract relationships in multi-modal input formats.","sentences":["Imaging sites around the world generate growing amounts of medical scan data with ever more versatile and affordable technology.","Large-scale studies acquire MRI for tens of thousands of participants, together with metadata ranging from lifestyle questionnaires to biochemical assays, genetic analyses and more.","These large datasets encode substantial information about human health and hold considerable potential for machine learning training and analysis.","This chapter examines ongoing large-scale studies and the challenge of distribution shifts between them.","Transfer learning for overcoming such shifts is discussed, together with federated learning for safe access to distributed training data securely held at multiple institutions.","Finally, representation learning is reviewed as a methodology for encoding embeddings that express abstract relationships in multi-modal input formats."],"url":"http://arxiv.org/abs/2404.14326v1"}
{"created":"2024-04-22 16:38:41","title":"PLUTO: Pushing the Limit of Imitation Learning-based Planning for Autonomous Driving","abstract":"We present PLUTO, a powerful framework that pushes the limit of imitation learning-based planning for autonomous driving. Our improvements stem from three pivotal aspects: a longitudinal-lateral aware model architecture that enables flexible and diverse driving behaviors; An innovative auxiliary loss computation method that is broadly applicable and efficient for batch-wise calculation; A novel training framework that leverages contrastive learning, augmented by a suite of new data augmentations to regulate driving behaviors and facilitate the understanding of underlying interactions. We assessed our framework using the large-scale real-world nuPlan dataset and its associated standardized planning benchmark. Impressively, PLUTO achieves state-of-the-art closed-loop performance, beating other competing learning-based methods and surpassing the current top-performed rule-based planner for the first time. Results and code are available at https://jchengai.github.io/pluto.","sentences":["We present PLUTO, a powerful framework that pushes the limit of imitation learning-based planning for autonomous driving.","Our improvements stem from three pivotal aspects: a longitudinal-lateral aware model architecture that enables flexible and diverse driving behaviors; An innovative auxiliary loss computation method that is broadly applicable and efficient for batch-wise calculation; A novel training framework that leverages contrastive learning, augmented by a suite of new data augmentations to regulate driving behaviors and facilitate the understanding of underlying interactions.","We assessed our framework using the large-scale real-world nuPlan dataset and its associated standardized planning benchmark.","Impressively, PLUTO achieves state-of-the-art closed-loop performance, beating other competing learning-based methods and surpassing the current top-performed rule-based planner for the first time.","Results and code are available at https://jchengai.github.io/pluto."],"url":"http://arxiv.org/abs/2404.14327v1"}
{"created":"2024-04-22 15:54:53","title":"Does Your Neural Code Completion Model Use My Code? A Membership Inference Approach","abstract":"Recent years have witnessed significant progress in developing deep learning-based models for automated code completion. Although using source code in GitHub has been a common practice for training deep-learning-based models for code completion, it may induce some legal and ethical issues such as copyright infringement. In this paper, we investigate the legal and ethical issues of current neural code completion models by answering the following question: Is my code used to train your neural code completion model? To this end, we tailor a membership inference approach (termed CodeMI) that was originally crafted for classification tasks to a more challenging task of code completion. In particular, since the target code completion models perform as opaque black boxes, preventing access to their training data and parameters, we opt to train multiple shadow models to mimic their behavior. The acquired posteriors from these shadow models are subsequently employed to train a membership classifier. Subsequently, the membership classifier can be effectively employed to deduce the membership status of a given code sample based on the output of a target code completion model. We comprehensively evaluate the effectiveness of this adapted approach across a diverse array of neural code completion models, (i.e., LSTM-based, CodeGPT, CodeGen, and StarCoder). Experimental results reveal that the LSTM-based and CodeGPT models suffer the membership leakage issue, which can be easily detected by our proposed membership inference approach with an accuracy of 0.842, and 0.730, respectively. Interestingly, our experiments also show that the data membership of current large language models of code, e.g., CodeGen and StarCoder, is difficult to detect, leaving amper space for further improvement. Finally, we also try to explain the findings from the perspective of model memorization.","sentences":["Recent years have witnessed significant progress in developing deep learning-based models for automated code completion.","Although using source code in GitHub has been a common practice for training deep-learning-based models for code completion, it may induce some legal and ethical issues such as copyright infringement.","In this paper, we investigate the legal and ethical issues of current neural code completion models by answering the following question: Is my code used to train your neural code completion model?","To this end, we tailor a membership inference approach (termed CodeMI) that was originally crafted for classification tasks to a more challenging task of code completion.","In particular, since the target code completion models perform as opaque black boxes, preventing access to their training data and parameters, we opt to train multiple shadow models to mimic their behavior.","The acquired posteriors from these shadow models are subsequently employed to train a membership classifier.","Subsequently, the membership classifier can be effectively employed to deduce the membership status of a given code sample based on the output of a target code completion model.","We comprehensively evaluate the effectiveness of this adapted approach across a diverse array of neural code completion models, (i.e., LSTM-based, CodeGPT, CodeGen, and StarCoder).","Experimental results reveal that the LSTM-based and CodeGPT models suffer the membership leakage issue, which can be easily detected by our proposed membership inference approach with an accuracy of 0.842, and 0.730, respectively.","Interestingly, our experiments also show that the data membership of current large language models of code, e.g., CodeGen and StarCoder, is difficult to detect, leaving amper space for further improvement.","Finally, we also try to explain the findings from the perspective of model memorization."],"url":"http://arxiv.org/abs/2404.14296v1"}
{"created":"2024-04-22 15:53:08","title":"A Survey on Efficient Inference for Large Language Models","abstract":"Large Language Models (LLMs) have attracted extensive attention due to their remarkable performance across various tasks. However, the substantial computational and memory requirements of LLM inference pose challenges for deployment in resource-constrained scenarios. Efforts within the field have been directed towards developing techniques aimed at enhancing the efficiency of LLM inference. This paper presents a comprehensive survey of the existing literature on efficient LLM inference. We start by analyzing the primary causes of the inefficient LLM inference, i.e., the large model size, the quadratic-complexity attention operation, and the auto-regressive decoding approach. Then, we introduce a comprehensive taxonomy that organizes the current literature into data-level, model-level, and system-level optimization. Moreover, the paper includes comparative experiments on representative methods within critical sub-fields to provide quantitative insights. Last but not least, we provide some knowledge summary and discuss future research directions.","sentences":["Large Language Models (LLMs) have attracted extensive attention due to their remarkable performance across various tasks.","However, the substantial computational and memory requirements of LLM inference pose challenges for deployment in resource-constrained scenarios.","Efforts within the field have been directed towards developing techniques aimed at enhancing the efficiency of LLM inference.","This paper presents a comprehensive survey of the existing literature on efficient LLM inference.","We start by analyzing the primary causes of the inefficient LLM inference, i.e., the large model size, the quadratic-complexity attention operation, and the auto-regressive decoding approach.","Then, we introduce a comprehensive taxonomy that organizes the current literature into data-level, model-level, and system-level optimization.","Moreover, the paper includes comparative experiments on representative methods within critical sub-fields to provide quantitative insights.","Last but not least, we provide some knowledge summary and discuss future research directions."],"url":"http://arxiv.org/abs/2404.14294v1"}
{"created":"2024-04-22 15:29:28","title":"Fast and Robust Normal Estimation for Sparse LiDAR Scans","abstract":"Light Detection and Ranging (LiDAR) technology has proven to be an important part of many robotics systems. Surface normals estimated from LiDAR data are commonly used for a variety of tasks in such systems. As most of the today's mechanical LiDAR sensors produce sparse data, estimating normals from a single scan in a robust manner poses difficulties.   In this paper, we address the problem of estimating normals for sparse LiDAR data avoiding the typical issues of smoothing out the normals in high curvature areas.   Mechanical LiDARs rotate a set of rigidly mounted lasers. One firing of such a set of lasers produces an array of points where each point's neighbor is known due to the known firing pattern of the scanner. We use this knowledge to connect these points to their neighbors and label them using the angles of the lines connecting them. When estimating normals at these points, we only consider points with the same label as neighbors. This allows us to avoid estimating normals in high curvature areas.   We evaluate our approach on various data, both self-recorded and publicly available, acquired using various sparse LiDAR sensors. We show that using our method for normal estimation leads to normals that are more robust in areas with high curvature which leads to maps of higher quality. We also show that our method only incurs a constant factor runtime overhead with respect to a lightweight baseline normal estimation procedure and is therefore suited for operation in computationally demanding environments.","sentences":["Light Detection and Ranging (LiDAR) technology has proven to be an important part of many robotics systems.","Surface normals estimated from LiDAR data are commonly used for a variety of tasks in such systems.","As most of the today's mechanical LiDAR sensors produce sparse data, estimating normals from a single scan in a robust manner poses difficulties.   ","In this paper, we address the problem of estimating normals for sparse LiDAR data avoiding the typical issues of smoothing out the normals in high curvature areas.   ","Mechanical LiDARs rotate a set of rigidly mounted lasers.","One firing of such a set of lasers produces an array of points where each point's neighbor is known due to the known firing pattern of the scanner.","We use this knowledge to connect these points to their neighbors and label them using the angles of the lines connecting them.","When estimating normals at these points, we only consider points with the same label as neighbors.","This allows us to avoid estimating normals in high curvature areas.   ","We evaluate our approach on various data, both self-recorded and publicly available, acquired using various sparse LiDAR sensors.","We show that using our method for normal estimation leads to normals that are more robust in areas with high curvature which leads to maps of higher quality.","We also show that our method only incurs a constant factor runtime overhead with respect to a lightweight baseline normal estimation procedure and is therefore suited for operation in computationally demanding environments."],"url":"http://arxiv.org/abs/2404.14281v1"}
{"created":"2024-04-22 15:28:42","title":"Co-designing a Sub-millisecond Latency Event-based Eye Tracking System with Submanifold Sparse CNN","abstract":"Eye-tracking technology is integral to numerous consumer electronics applications, particularly in the realm of virtual and augmented reality (VR/AR). These applications demand solutions that excel in three crucial aspects: low-latency, low-power consumption, and precision. Yet, achieving optimal performance across all these fronts presents a formidable challenge, necessitating a balance between sophisticated algorithms and efficient backend hardware implementations. In this study, we tackle this challenge through a synergistic software/hardware co-design of the system with an event camera. Leveraging the inherent sparsity of event-based input data, we integrate a novel sparse FPGA dataflow accelerator customized for submanifold sparse convolution neural networks (SCNN). The SCNN implemented on the accelerator can efficiently extract the embedding feature vector from each representation of event slices by only processing the non-zero activations. Subsequently, these vectors undergo further processing by a gated recurrent unit (GRU) and a fully connected layer on the host CPU to generate the eye centers. Deployment and evaluation of our system reveal outstanding performance metrics. On the Event-based Eye-Tracking-AIS2024 dataset, our system achieves 81% p5 accuracy, 99.5% p10 accuracy, and 3.71 Mean Euclidean Distance with 0.7 ms latency while only consuming 2.29 mJ per inference. Notably, our solution opens up opportunities for future eye-tracking systems. Code is available at https://github.com/CASR-HKU/ESDA/tree/eye_tracking.","sentences":["Eye-tracking technology is integral to numerous consumer electronics applications, particularly in the realm of virtual and augmented reality (VR/AR).","These applications demand solutions that excel in three crucial aspects: low-latency, low-power consumption, and precision.","Yet, achieving optimal performance across all these fronts presents a formidable challenge, necessitating a balance between sophisticated algorithms and efficient backend hardware implementations.","In this study, we tackle this challenge through a synergistic software/hardware co-design of the system with an event camera.","Leveraging the inherent sparsity of event-based input data, we integrate a novel sparse FPGA dataflow accelerator customized for submanifold sparse convolution neural networks (SCNN).","The SCNN implemented on the accelerator can efficiently extract the embedding feature vector from each representation of event slices by only processing the non-zero activations.","Subsequently, these vectors undergo further processing by a gated recurrent unit (GRU) and a fully connected layer on the host CPU to generate the eye centers.","Deployment and evaluation of our system reveal outstanding performance metrics.","On the Event-based Eye-Tracking-AIS2024 dataset, our system achieves 81% p5 accuracy, 99.5% p10 accuracy, and 3.71 Mean Euclidean Distance with 0.7 ms latency while only consuming 2.29 mJ per inference.","Notably, our solution opens up opportunities for future eye-tracking systems.","Code is available at https://github.com/CASR-HKU/ESDA/tree/eye_tracking."],"url":"http://arxiv.org/abs/2404.14279v1"}
{"created":"2024-04-22 15:16:59","title":"Sparse Explanations of Neural Networks Using Pruned Layer-Wise Relevance Propagation","abstract":"Explainability is a key component in many applications involving deep neural networks (DNNs). However, current explanation methods for DNNs commonly leave it to the human observer to distinguish relevant explanations from spurious noise. This is not feasible anymore when going from easily human-accessible data such as images to more complex data such as genome sequences. To facilitate the accessibility of DNN outputs from such complex data and to increase explainability, we present a modification of the widely used explanation method layer-wise relevance propagation. Our approach enforces sparsity directly by pruning the relevance propagation for the different layers. Thereby, we achieve sparser relevance attributions for the input features as well as for the intermediate layers. As the relevance propagation is input-specific, we aim to prune the relevance propagation rather than the underlying model architecture. This allows to prune different neurons for different inputs and hence, might be more appropriate to the local nature of explanation methods. To demonstrate the efficacy of our method, we evaluate it on two types of data, images and genomic sequences. We show that our modification indeed leads to noise reduction and concentrates relevance on the most important features compared to the baseline.","sentences":["Explainability is a key component in many applications involving deep neural networks (DNNs).","However, current explanation methods for DNNs commonly leave it to the human observer to distinguish relevant explanations from spurious noise.","This is not feasible anymore when going from easily human-accessible data such as images to more complex data such as genome sequences.","To facilitate the accessibility of DNN outputs from such complex data and to increase explainability, we present a modification of the widely used explanation method layer-wise relevance propagation.","Our approach enforces sparsity directly by pruning the relevance propagation for the different layers.","Thereby, we achieve sparser relevance attributions for the input features as well as for the intermediate layers.","As the relevance propagation is input-specific, we aim to prune the relevance propagation rather than the underlying model architecture.","This allows to prune different neurons for different inputs and hence, might be more appropriate to the local nature of explanation methods.","To demonstrate the efficacy of our method, we evaluate it on two types of data, images and genomic sequences.","We show that our modification indeed leads to noise reduction and concentrates relevance on the most important features compared to the baseline."],"url":"http://arxiv.org/abs/2404.14271v1"}
{"created":"2024-04-22 15:15:50","title":"What do Transformers Know about Government?","abstract":"This paper investigates what insights about linguistic features and what knowledge about the structure of natural language can be obtained from the encodings in transformer language models.In particular, we explore how BERT encodes the government relation between constituents in a sentence. We use several probing classifiers, and data from two morphologically rich languages. Our experiments show that information about government is encoded across all transformer layers, but predominantly in the early layers of the model. We find that, for both languages, a small number of attention heads encode enough information about the government relations to enable us to train a classifier capable of discovering new, previously unknown types of government, never seen in the training data. Currently, data is lacking for the research community working on grammatical constructions, and government in particular. We release the Government Bank -- a dataset defining the government relations for thousands of lemmas in the languages in our experiments.","sentences":["This paper investigates what insights about linguistic features and what knowledge about the structure of natural language can be obtained from the encodings in transformer language models.","In particular, we explore how BERT encodes the government relation between constituents in a sentence.","We use several probing classifiers, and data from two morphologically rich languages.","Our experiments show that information about government is encoded across all transformer layers, but predominantly in the early layers of the model.","We find that, for both languages, a small number of attention heads encode enough information about the government relations to enable us to train a classifier capable of discovering new, previously unknown types of government, never seen in the training data.","Currently, data is lacking for the research community working on grammatical constructions, and government in particular.","We release the Government Bank -- a dataset defining the government relations for thousands of lemmas in the languages in our experiments."],"url":"http://arxiv.org/abs/2404.14270v1"}
{"created":"2024-04-22 15:12:47","title":"Deep Learning as Ricci Flow","abstract":"Deep neural networks (DNNs) are powerful tools for approximating the distribution of complex data. It is known that data passing through a trained DNN classifier undergoes a series of geometric and topological simplifications. While some progress has been made toward understanding these transformations in neural networks with smooth activation functions, an understanding in the more general setting of non-smooth activation functions, such as the rectified linear unit (ReLU), which tend to perform better, is required. Here we propose that the geometric transformations performed by DNNs during classification tasks have parallels to those expected under Hamilton's Ricci flow - a tool from differential geometry that evolves a manifold by smoothing its curvature, in order to identify its topology. To illustrate this idea, we present a computational framework to quantify the geometric changes that occur as data passes through successive layers of a DNN, and use this framework to motivate a notion of `global Ricci network flow' that can be used to assess a DNN's ability to disentangle complex data geometries to solve classification problems. By training more than $1,500$ DNN classifiers of different widths and depths on synthetic and real-world data, we show that the strength of global Ricci network flow-like behaviour correlates with accuracy for well-trained DNNs, independently of depth, width and data set. Our findings motivate the use of tools from differential and discrete geometry to the problem of explainability in deep learning.","sentences":["Deep neural networks (DNNs) are powerful tools for approximating the distribution of complex data.","It is known that data passing through a trained DNN classifier undergoes a series of geometric and topological simplifications.","While some progress has been made toward understanding these transformations in neural networks with smooth activation functions, an understanding in the more general setting of non-smooth activation functions, such as the rectified linear unit (ReLU), which tend to perform better, is required.","Here we propose that the geometric transformations performed by DNNs during classification tasks have parallels to those expected under Hamilton's Ricci flow - a tool from differential geometry that evolves a manifold by smoothing its curvature, in order to identify its topology.","To illustrate this idea, we present a computational framework to quantify the geometric changes that occur as data passes through successive layers of a DNN, and use this framework to motivate a notion of `global Ricci network flow' that can be used to assess a DNN's ability to disentangle complex data geometries to solve classification problems.","By training more than $1,500$ DNN classifiers of different widths and depths on synthetic and real-world data, we show that the strength of global Ricci network flow-like behaviour correlates with accuracy for well-trained DNNs, independently of depth, width and data set.","Our findings motivate the use of tools from differential and discrete geometry to the problem of explainability in deep learning."],"url":"http://arxiv.org/abs/2404.14265v1"}
{"created":"2024-04-22 15:01:32","title":"CLIP-GS: CLIP-Informed Gaussian Splatting for Real-time and View-consistent 3D Semantic Understanding","abstract":"The recent 3D Gaussian Splatting (GS) exhibits high-quality and real-time synthesis of novel views in 3D scenes. Currently, it primarily focuses on geometry and appearance modeling, while lacking the semantic understanding of scenes. To bridge this gap, we present CLIP-GS, which integrates semantics from Contrastive Language-Image Pre-Training (CLIP) into Gaussian Splatting to efficiently comprehend 3D environments without annotated semantic data. In specific, rather than straightforwardly learning and rendering high-dimensional semantic features of 3D Gaussians, which significantly diminishes the efficiency, we propose a Semantic Attribute Compactness (SAC) approach. SAC exploits the inherent unified semantics within objects to learn compact yet effective semantic representations of 3D Gaussians, enabling highly efficient rendering (>100 FPS). Additionally, to address the semantic ambiguity, caused by utilizing view-inconsistent 2D CLIP semantics to supervise Gaussians, we introduce a 3D Coherent Self-training (3DCS) strategy, resorting to the multi-view consistency originated from the 3D model. 3DCS imposes cross-view semantic consistency constraints by leveraging refined, self-predicted pseudo-labels derived from the trained 3D Gaussian model, thereby enhancing precise and view-consistent segmentation results. Extensive experiments demonstrate that our method remarkably outperforms existing state-of-the-art approaches, achieving improvements of 17.29% and 20.81% in mIoU metric on Replica and ScanNet datasets, respectively, while maintaining real-time rendering speed. Furthermore, our approach exhibits superior performance even with sparse input data, verifying the robustness of our method.","sentences":["The recent 3D Gaussian Splatting (GS) exhibits high-quality and real-time synthesis of novel views in 3D scenes.","Currently, it primarily focuses on geometry and appearance modeling, while lacking the semantic understanding of scenes.","To bridge this gap, we present CLIP-GS, which integrates semantics from Contrastive Language-Image Pre-Training (CLIP) into Gaussian Splatting to efficiently comprehend 3D environments without annotated semantic data.","In specific, rather than straightforwardly learning and rendering high-dimensional semantic features of 3D Gaussians, which significantly diminishes the efficiency, we propose a Semantic Attribute Compactness (SAC) approach.","SAC exploits the inherent unified semantics within objects to learn compact yet effective semantic representations of 3D Gaussians, enabling highly efficient rendering (>100 FPS).","Additionally, to address the semantic ambiguity, caused by utilizing view-inconsistent 2D CLIP semantics to supervise Gaussians, we introduce a 3D Coherent Self-training (3DCS) strategy, resorting to the multi-view consistency originated from the 3D model.","3DCS imposes cross-view semantic consistency constraints by leveraging refined, self-predicted pseudo-labels derived from the trained 3D Gaussian model, thereby enhancing precise and view-consistent segmentation results.","Extensive experiments demonstrate that our method remarkably outperforms existing state-of-the-art approaches, achieving improvements of 17.29% and 20.81% in mIoU metric on Replica and ScanNet datasets, respectively, while maintaining real-time rendering speed.","Furthermore, our approach exhibits superior performance even with sparse input data, verifying the robustness of our method."],"url":"http://arxiv.org/abs/2404.14249v1"}
{"created":"2024-04-22 14:57:17","title":"AI-Generated Faces in the Real World: A Large-Scale Case Study of Twitter Profile Images","abstract":"Recent advances in the field of generative artificial intelligence (AI) have blurred the lines between authentic and machine-generated content, making it almost impossible for humans to distinguish between such media. One notable consequence is the use of AI-generated images for fake profiles on social media. While several types of disinformation campaigns and similar incidents have been reported in the past, a systematic analysis has been lacking. In this work, we conduct the first large-scale investigation of the prevalence of AI-generated profile pictures on Twitter. We tackle the challenges of a real-world measurement study by carefully integrating various data sources and designing a multi-stage detection pipeline. Our analysis of nearly 15 million Twitter profile pictures shows that 0.052% were artificially generated, confirming their notable presence on the platform. We comprehensively examine the characteristics of these accounts and their tweet content, and uncover patterns of coordinated inauthentic behavior. The results also reveal several motives, including spamming and political amplification campaigns. Our research reaffirms the need for effective detection and mitigation strategies to cope with the potential negative effects of generative AI in the future.","sentences":["Recent advances in the field of generative artificial intelligence (AI) have blurred the lines between authentic and machine-generated content, making it almost impossible for humans to distinguish between such media.","One notable consequence is the use of AI-generated images for fake profiles on social media.","While several types of disinformation campaigns and similar incidents have been reported in the past, a systematic analysis has been lacking.","In this work, we conduct the first large-scale investigation of the prevalence of AI-generated profile pictures on Twitter.","We tackle the challenges of a real-world measurement study by carefully integrating various data sources and designing a multi-stage detection pipeline.","Our analysis of nearly 15 million Twitter profile pictures shows that 0.052% were artificially generated, confirming their notable presence on the platform.","We comprehensively examine the characteristics of these accounts and their tweet content, and uncover patterns of coordinated inauthentic behavior.","The results also reveal several motives, including spamming and political amplification campaigns.","Our research reaffirms the need for effective detection and mitigation strategies to cope with the potential negative effects of generative AI in the future."],"url":"http://arxiv.org/abs/2404.14244v1"}
{"created":"2024-04-22 14:47:42","title":"Beyond the Edge: An Advanced Exploration of Reinforcement Learning for Mobile Edge Computing, its Applications, and Future Research Trajectories","abstract":"Mobile Edge Computing (MEC) broadens the scope of computation and storage beyond the central network, incorporating edge nodes close to end devices. This expansion facilitates the implementation of large-scale \"connected things\" within edge networks. The advent of applications necessitating real-time, high-quality service presents several challenges, such as low latency, high data rate, reliability, efficiency, and security, all of which demand resolution. The incorporation of reinforcement learning (RL) methodologies within MEC networks promotes a deeper understanding of mobile user behaviors and network dynamics, thereby optimizing resource use in computing and communication processes. This paper offers an exhaustive survey of RL applications in MEC networks, initially presenting an overview of RL from its fundamental principles to the latest advanced frameworks. Furthermore, it outlines various RL strategies employed in offloading, caching, and communication within MEC networks. Finally, it explores open issues linked with software and hardware platforms, representation, RL robustness, safe RL, large-scale scheduling, generalization, security, and privacy. The paper proposes specific RL techniques to mitigate these issues and provides insights into their practical applications.","sentences":["Mobile Edge Computing (MEC) broadens the scope of computation and storage beyond the central network, incorporating edge nodes close to end devices.","This expansion facilitates the implementation of large-scale \"connected things\" within edge networks.","The advent of applications necessitating real-time, high-quality service presents several challenges, such as low latency, high data rate, reliability, efficiency, and security, all of which demand resolution.","The incorporation of reinforcement learning (RL) methodologies within MEC networks promotes a deeper understanding of mobile user behaviors and network dynamics, thereby optimizing resource use in computing and communication processes.","This paper offers an exhaustive survey of RL applications in MEC networks, initially presenting an overview of RL from its fundamental principles to the latest advanced frameworks.","Furthermore, it outlines various RL strategies employed in offloading, caching, and communication within MEC networks.","Finally, it explores open issues linked with software and hardware platforms, representation, RL robustness, safe RL, large-scale scheduling, generalization, security, and privacy.","The paper proposes specific RL techniques to mitigate these issues and provides insights into their practical applications."],"url":"http://arxiv.org/abs/2404.14238v1"}
{"created":"2024-04-22 14:46:30","title":"Computing the LCP Array of a Labeled Graph","abstract":"The LCP array is an important tool in stringology, allowing to speed up pattern matching algorithms and enabling compact representations of the suffix tree. Recently, Conte et al. [DCC 2023] and Cotumaccio et al. [SPIRE 2023] extended the definition of this array to Wheeler DFAs and, ultimately, to arbitrary labeled graphs, proving that it can be used to efficiently solve matching statistics queries on the graph's paths. In this paper, we provide the first efficient algorithm building the LCP array of a directed labeled graph with $n$ nodes and $m$ edges labeled over an alphabet of size $\\sigma$. After arguing that the natural generalization of a compact-space LCP-construction algorithm by Beller et al. [J. Discrete Algorithms 2013] runs in time $\\Omega(n\\sigma)$, we present a new algorithm based on dynamic range stabbing building the LCP array in $O(n\\log \\sigma)$ time and $O(n\\log\\sigma)$ bits of working space.","sentences":["The LCP array is an important tool in stringology, allowing to speed up pattern matching algorithms and enabling compact representations of the suffix tree.","Recently, Conte et al.","[DCC 2023] and Cotumaccio et al.","[SPIRE 2023] extended the definition of this array to Wheeler DFAs and, ultimately, to arbitrary labeled graphs, proving that it can be used to efficiently solve matching statistics queries on the graph's paths.","In this paper, we provide the first efficient algorithm building the LCP array of a directed labeled graph with $n$ nodes and $m$ edges labeled over an alphabet of size $\\sigma$. After arguing that the natural generalization of a compact-space LCP-construction algorithm by Beller et al.","[J. Discrete Algorithms 2013] runs in time $\\Omega(n\\sigma)$, we present a new algorithm based on dynamic range stabbing building the LCP array in $O(n\\log \\sigma)$ time and $O(n\\log\\sigma)$ bits of working space."],"url":"http://arxiv.org/abs/2404.14235v1"}
{"created":"2024-04-22 14:45:30","title":"Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting and Cognitive Load on User Attention and Saliency Prediction","abstract":"Visual highlighting can guide user attention in complex interfaces. However, its effectiveness under limited attentional capacities is underexplored. This paper examines the joint impact of visual highlighting (permanent and dynamic) and dual-task-induced cognitive load on gaze behaviour. Our analysis, using eye-movement data from 27 participants viewing 150 unique webpages reveals that while participants' ability to attend to UI elements decreases with increasing cognitive load, dynamic adaptations (i.e., highlighting) remain attention-grabbing. The presence of these factors significantly alters what people attend to and thus what is salient. Accordingly, we show that state-of-the-art saliency models increase their performance when accounting for different cognitive loads. Our empirical insights, along with our openly available dataset, enhance our understanding of attentional processes in UIs under varying cognitive (and perceptual) loads and open the door for new models that can predict user attention while multitasking.","sentences":["Visual highlighting can guide user attention in complex interfaces.","However, its effectiveness under limited attentional capacities is underexplored.","This paper examines the joint impact of visual highlighting (permanent and dynamic) and dual-task-induced cognitive load on gaze behaviour.","Our analysis, using eye-movement data from 27 participants viewing 150 unique webpages reveals that while participants' ability to attend to UI elements decreases with increasing cognitive load, dynamic adaptations (i.e., highlighting) remain attention-grabbing.","The presence of these factors significantly alters what people attend to and thus what is salient.","Accordingly, we show that state-of-the-art saliency models increase their performance when accounting for different cognitive loads.","Our empirical insights, along with our openly available dataset, enhance our understanding of attentional processes in UIs under varying cognitive (and perceptual) loads and open the door for new models that can predict user attention while multitasking."],"url":"http://arxiv.org/abs/2404.14232v1"}
{"created":"2024-04-22 14:38:58","title":"A Survey of Decomposition-Based Evolutionary Multi-Objective Optimization: Part II -- A Data Science Perspective","abstract":"This paper presents the second part of the two-part survey series on decomposition-based evolutionary multi-objective optimization where we mainly focus on discussing the literature related to multi-objective evolutionary algorithms based on decomposition (MOEA/D). Complementary to the first part, here we employ a series of advanced data mining approaches to provide a comprehensive anatomy of the enormous landscape of MOEA/D research, which is far beyond the capacity of classic manual literature review protocol. In doing so, we construct a heterogeneous knowledge graph that encapsulates more than 5,400 papers, 10,000 authors, 400 venues, and 1,600 institutions for MOEA/D research. We start our analysis with basic descriptive statistics. Then we delve into prominent research/application topics pertaining to MOEA/D with state-of-the-art topic modeling techniques and interrogate their sptial-temporal and bilateral relationships. We also explored the collaboration and citation networks of MOEA/D, uncovering hidden patterns in the growth of literature as well as collaboration between researchers. Our data mining results here, combined with the expert review in Part I, together offer a holistic view of the MOEA/D research, and demonstrate the potential of an exciting new paradigm for conducting scientific surveys from a data science perspective.","sentences":["This paper presents the second part of the two-part survey series on decomposition-based evolutionary multi-objective optimization where we mainly focus on discussing the literature related to multi-objective evolutionary algorithms based on decomposition (MOEA/D).","Complementary to the first part, here we employ a series of advanced data mining approaches to provide a comprehensive anatomy of the enormous landscape of MOEA/D research, which is far beyond the capacity of classic manual literature review protocol.","In doing so, we construct a heterogeneous knowledge graph that encapsulates more than 5,400 papers, 10,000 authors, 400 venues, and 1,600 institutions for MOEA/D research.","We start our analysis with basic descriptive statistics.","Then we delve into prominent research/application topics pertaining to MOEA/D with state-of-the-art topic modeling techniques and interrogate their sptial-temporal and bilateral relationships.","We also explored the collaboration and citation networks of MOEA/D, uncovering hidden patterns in the growth of literature as well as collaboration between researchers.","Our data mining results here, combined with the expert review in Part I, together offer a holistic view of the MOEA/D research, and demonstrate the potential of an exciting new paradigm for conducting scientific surveys from a data science perspective."],"url":"http://arxiv.org/abs/2404.14228v1"}
{"created":"2024-04-22 14:34:14","title":"Error Credits: Resourceful Reasoning about Error Bounds for Higher-Order Probabilistic Programs","abstract":"Probabilistic programs often trade accuracy for efficiency, and are thus only approximately correct. It is important to obtain precise error bounds for these approximations, but existing approaches rely on simplifications that make the error bounds excesively coarse, or only apply to first-order programs. In this paper we present Eris, a higher-order separation logic for probabilistic programs written in an expressive higher-order language.   Our key novelty is the introduction of error credits, a separation logic resource that tracks the error bound of a program. By representing error bounds as a resource, we recover the benefits of separation logic, including compositionality, modularity, and dependency between errors and program terms, allowing for more precise specifications. Moreover, we enable novel reasoning principles such as expectation-preserving error composition, amortized error reasoning, and proving almost-sure termination by induction on the error.   We illustrate the advantages of our approach by proving amortized error bounds on a range of examples, including collision probabilities in hash functions, which allows us to write more modular specifications for data structures that use them as clients. We also use our logic to prove correctness and almost-sure termination of rejection sampling algorithms. All of our results have been mechanized in the Coq proof assistant using the Iris separation logic framework and the Coquelicot real analysis library.","sentences":["Probabilistic programs often trade accuracy for efficiency, and are thus only approximately correct.","It is important to obtain precise error bounds for these approximations, but existing approaches rely on simplifications that make the error bounds excesively coarse, or only apply to first-order programs.","In this paper we present Eris, a higher-order separation logic for probabilistic programs written in an expressive higher-order language.   ","Our key novelty is the introduction of error credits, a separation logic resource that tracks the error bound of a program.","By representing error bounds as a resource, we recover the benefits of separation logic, including compositionality, modularity, and dependency between errors and program terms, allowing for more precise specifications.","Moreover, we enable novel reasoning principles such as expectation-preserving error composition, amortized error reasoning, and proving almost-sure termination by induction on the error.   ","We illustrate the advantages of our approach by proving amortized error bounds on a range of examples, including collision probabilities in hash functions, which allows us to write more modular specifications for data structures that use them as clients.","We also use our logic to prove correctness and almost-sure termination of rejection sampling algorithms.","All of our results have been mechanized in the Coq proof assistant using the Iris separation logic framework and the Coquelicot real analysis library."],"url":"http://arxiv.org/abs/2404.14223v1"}
{"created":"2024-04-22 14:32:33","title":"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone","abstract":"We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75% and 78% on MMLU, and 8.7 and 8.9 on MT-bench).","sentences":["We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone.","The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered web data and synthetic data.","The model is also further aligned for robustness, safety, and chat format.","We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75% and 78% on MMLU, and 8.7 and 8.9 on MT-bench)."],"url":"http://arxiv.org/abs/2404.14219v1"}
{"created":"2024-04-22 14:31:28","title":"Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction","abstract":"The task of condensing large chunks of textual information into concise and structured tables has gained attention recently due to the emergence of Large Language Models (LLMs) and their potential benefit for downstream tasks, such as text summarization and text mining. Previous approaches often generate tables that directly replicate information from the text, limiting their applicability in broader contexts, as text-to-table generation in real-life scenarios necessitates information extraction, reasoning, and integration. However, there is a lack of both datasets and methodologies towards this task. In this paper, we introduce LiveSum, a new benchmark dataset created for generating summary tables of competitions based on real-time commentary texts. We evaluate the performances of state-of-the-art LLMs on this task in both fine-tuning and zero-shot settings, and additionally propose a novel pipeline called $T^3$(Text-Tuple-Table) to improve their performances. Extensive experimental results demonstrate that LLMs still struggle with this task even after fine-tuning, while our approach can offer substantial performance gains without explicit training. Further analyses demonstrate that our method exhibits strong generalization abilities, surpassing previous approaches on several other text-to-table datasets. Our code and data can be found at https://github.com/HKUST-KnowComp/LiveSum-TTT.","sentences":["The task of condensing large chunks of textual information into concise and structured tables has gained attention recently due to the emergence of Large Language Models (LLMs) and their potential benefit for downstream tasks, such as text summarization and text mining.","Previous approaches often generate tables that directly replicate information from the text, limiting their applicability in broader contexts, as text-to-table generation in real-life scenarios necessitates information extraction, reasoning, and integration.","However, there is a lack of both datasets and methodologies towards this task.","In this paper, we introduce LiveSum, a new benchmark dataset created for generating summary tables of competitions based on real-time commentary texts.","We evaluate the performances of state-of-the-art LLMs on this task in both fine-tuning and zero-shot settings, and additionally propose a novel pipeline called $T^3$(Text-Tuple-Table) to improve their performances.","Extensive experimental results demonstrate that LLMs still struggle with this task even after fine-tuning, while our approach can offer substantial performance gains without explicit training.","Further analyses demonstrate that our method exhibits strong generalization abilities, surpassing previous approaches on several other text-to-table datasets.","Our code and data can be found at https://github.com/HKUST-KnowComp/LiveSum-TTT."],"url":"http://arxiv.org/abs/2404.14215v1"}
{"created":"2024-04-22 14:18:28","title":"Minimizing the Number of Tardy Jobs with Uniform Processing Times on Parallel Machines","abstract":"In this work, we study the computational (parameterized) complexity of $P \\mid r_j, p_j=p \\mid \\sum_j w_j U_j$. Here, we are given $m$ identical parallel machines and $n$ jobs with equal processing time, each characterized by a release date, a due date, and a weight. The task is to find a feasible schedule, that is, an assignment of the jobs to starting times on machines, such that no job starts before its release date and no machine processes several jobs at the same time, that minimizes the weighted number of tardy jobs. A job is considered tardy if it finishes after its due date.   Our main contribution is showing that $P \\mid r_j, p_j=p \\mid \\sum_j U_j$ (the unweighted version of the problem) is NP-hard and W[2]-hard when parameterized by the number of machines. The former resolves an open problem in Note 2.1.19 by Kravchenko and Werner [Journal of Scheduling, 2011] and Open Problem 2 by Sgall [ESA, 2012], and the latter resolves Open Problem 7 by Mnich and van Bevern [Computers & Operations Research, 2018]. Furthermore, our result shows that the known XP-algorithm for $P \\mid r_j, p_j=p \\mid \\sum_j w_j U_j$ parameterized by the number of machines is optimal from a classification standpoint.   On the algorithmic side, we provide alternative running time bounds for the above-mentioned known XP-algorithm. Our analysis shows that $P \\mid r_j, p_j=p \\mid \\sum_j w_j U_j$ is contained in XP when parameterized by the processing time, and that it is contained in FPT when parameterized by the combination of the number of machines and the processing time. Finally, we give an FPT-algorithm for $P \\mid r_j, p_j=p \\mid \\sum_j w_j U_j$ parameterized by the number of release dates or the number of due dates. With this work, we lay out the foundation for a systematic study of the parameterized complexity of $P \\mid r_j, p_j=p \\mid \\sum_j w_j U_j$.","sentences":["In this work, we study the computational (parameterized) complexity of $P \\mid r_j, p_j=p \\mid \\sum_j w_j","U_j$. Here, we are given $m$ identical parallel machines and $n$ jobs with equal processing time, each characterized by a release date, a due date, and a weight.","The task is to find a feasible schedule, that is, an assignment of the jobs to starting times on machines, such that no job starts before its release date and no machine processes several jobs at the same time, that minimizes the weighted number of tardy jobs.","A job is considered tardy if it finishes after its due date.   ","Our main contribution is showing that $P \\mid r_j, p_j=p \\mid \\sum_j U_j$ (the unweighted version of the problem) is NP-hard and W[2]-hard when parameterized by the number of machines.","The former resolves an open problem in Note 2.1.19 by Kravchenko and Werner [Journal of Scheduling, 2011] and Open Problem 2 by Sgall [ESA, 2012], and the latter resolves Open Problem 7 by Mnich and van Bevern [Computers & Operations Research, 2018].","Furthermore, our result shows that the known XP-algorithm for $P \\mid r_j, p_j=p \\mid \\sum_j w_j","U_j$ parameterized by the number of machines is optimal from a classification standpoint.   ","On the algorithmic side, we provide alternative running time bounds for the above-mentioned known XP-algorithm.","Our analysis shows that $P \\mid r_j, p_j=p \\mid \\sum_j w_j","U_j$ is contained in XP when parameterized by the processing time, and that it is contained in FPT when parameterized by the combination of the number of machines and the processing time.","Finally, we give an FPT-algorithm for $P \\mid r_j, p_j=p \\mid \\sum_j w_j","U_j$ parameterized by the number of release dates or the number of due dates.","With this work, we lay out the foundation for a systematic study of the parameterized complexity of $P \\mid r_j, p_j=p \\mid \\sum_j w_j","U_j$."],"url":"http://arxiv.org/abs/2404.14208v1"}
{"created":"2024-04-22 14:01:24","title":"LLAMP: Assessing Network Latency Tolerance of HPC Applications with Linear Programming","abstract":"The shift towards high-bandwidth networks driven by AI workloads in data centers and HPC clusters has unintentionally aggravated network latency, adversely affecting the performance of communication-intensive HPC applications. As large-scale MPI applications often exhibit significant differences in their network latency tolerance, it is crucial to accurately determine the extent of network latency an application can withstand without significant performance degradation. Current approaches to assessing this metric often rely on specialized hardware or network simulators, which can be inflexible and time-consuming. In response, we introduce LLAMP, a novel toolchain that offers an efficient, analytical approach to evaluating HPC applications' network latency tolerance using the LogGPS model and linear programming. LLAMP equips software developers and network architects with essential insights for optimizing HPC infrastructures and strategically deploying applications to minimize latency impacts. Through our validation on a variety of MPI applications like MILC, LULESH, and LAMMPS, we demonstrate our tool's high accuracy, with relative prediction errors generally below 2%. Additionally, we include a case study of the ICON weather and climate model to illustrate LLAMP's broad applicability in evaluating collective algorithms and network topologies.","sentences":["The shift towards high-bandwidth networks driven by AI workloads in data centers and HPC clusters has unintentionally aggravated network latency, adversely affecting the performance of communication-intensive HPC applications.","As large-scale MPI applications often exhibit significant differences in their network latency tolerance, it is crucial to accurately determine the extent of network latency an application can withstand without significant performance degradation.","Current approaches to assessing this metric often rely on specialized hardware or network simulators, which can be inflexible and time-consuming.","In response, we introduce LLAMP, a novel toolchain that offers an efficient, analytical approach to evaluating HPC applications' network latency tolerance using the LogGPS model and linear programming.","LLAMP equips software developers and network architects with essential insights for optimizing HPC infrastructures and strategically deploying applications to minimize latency impacts.","Through our validation on a variety of MPI applications like MILC, LULESH, and LAMMPS, we demonstrate our tool's high accuracy, with relative prediction errors generally below 2%.","Additionally, we include a case study of the ICON weather and climate model to illustrate LLAMP's broad applicability in evaluating collective algorithms and network topologies."],"url":"http://arxiv.org/abs/2404.14193v1"}
{"created":"2024-04-22 13:57:30","title":"Bayesian Windkessel calibration using optimized 0D surrogate models","abstract":"Boundary condition (BC) calibration to assimilate clinical measurements is an essential step in any subject-specific simulation of cardiovascular fluid dynamics. Bayesian calibration approaches have successfully quantified the uncertainties inherent in identified parameters. Yet, routinely estimating the posterior distribution for all BC parameters in 3D simulations has been unattainable due to the infeasible computational demand. We propose an efficient method to identify Windkessel parameter posteriors using results from a single high-fidelity three-dimensional (3D) model evaluation. We only evaluate the 3D model once for an initial choice of BCs and use the result to create a highly accurate zero-dimensional (0D) surrogate. We then perform Sequential Monte Carlo (SMC) using the optimized 0D model to derive the high-dimensional Windkessel BC posterior distribution. We validate this approach in a publicly available dataset of N=72 subject-specific vascular models. We found that optimizing 0D models to match 3D data a priori lowered their median approximation error by nearly one order of magnitude. In a subset of models, we confirm that the optimized 0D models still generalize to a wide range of BCs. Finally, we present the high-dimensional Windkessel parameter posterior for different measured signal-to-noise ratios in a vascular model using SMC. We further validate that the 0D-derived posterior is a good approximation of the 3D posterior. The minimal computational demand of our method using a single 3D simulation, combined with the open-source nature of all software and data used in this work, will increase access and efficiency of Bayesian Windkessel calibration in cardiovascular fluid dynamics simulations.","sentences":["Boundary condition (BC) calibration to assimilate clinical measurements is an essential step in any subject-specific simulation of cardiovascular fluid dynamics.","Bayesian calibration approaches have successfully quantified the uncertainties inherent in identified parameters.","Yet, routinely estimating the posterior distribution for all BC parameters in 3D simulations has been unattainable due to the infeasible computational demand.","We propose an efficient method to identify Windkessel parameter posteriors using results from a single high-fidelity three-dimensional (3D) model evaluation.","We only evaluate the 3D model once for an initial choice of BCs and use the result to create a highly accurate zero-dimensional (0D) surrogate.","We then perform Sequential Monte Carlo (SMC) using the optimized 0D model to derive the high-dimensional Windkessel BC posterior distribution.","We validate this approach in a publicly available dataset of N=72 subject-specific vascular models.","We found that optimizing 0D models to match 3D data a priori lowered their median approximation error by nearly one order of magnitude.","In a subset of models, we confirm that the optimized 0D models still generalize to a wide range of BCs.","Finally, we present the high-dimensional Windkessel parameter posterior for different measured signal-to-noise ratios in a vascular model using SMC.","We further validate that the 0D-derived posterior is a good approximation of the 3D posterior.","The minimal computational demand of our method using a single 3D simulation, combined with the open-source nature of all software and data used in this work, will increase access and efficiency of Bayesian Windkessel calibration in cardiovascular fluid dynamics simulations."],"url":"http://arxiv.org/abs/2404.14187v1"}
{"created":"2024-04-22 13:26:42","title":"New Solutions Based on the Generalized Eigenvalue Problem for the Data Collaboration Analysis","abstract":"In recent years, the accumulation of data across various institutions has garnered attention for the technology of confidential data analysis, which improves analytical accuracy by sharing data between multiple institutions while protecting sensitive information. Among these methods, Data Collaboration Analysis (DCA) is noted for its efficiency in terms of computational cost and communication load, facilitating data sharing and analysis across different institutions while safeguarding confidential information. However, existing optimization problems for determining the necessary collaborative functions have faced challenges, such as the optimal solution for the collaborative representation often being a zero matrix and the difficulty in understanding the process of deriving solutions. This research addresses these issues by formulating the optimization problem through the segmentation of matrices into column vectors and proposing a solution method based on the generalized eigenvalue problem. Additionally, we demonstrate methods for constructing collaborative functions more effectively through weighting and the selection of efficient algorithms suited to specific situations. Experiments using real-world datasets have shown that our proposed formulation and solution for the collaborative function optimization problem achieve superior predictive accuracy compared to existing methods.","sentences":["In recent years, the accumulation of data across various institutions has garnered attention for the technology of confidential data analysis, which improves analytical accuracy by sharing data between multiple institutions while protecting sensitive information.","Among these methods, Data Collaboration Analysis (DCA) is noted for its efficiency in terms of computational cost and communication load, facilitating data sharing and analysis across different institutions while safeguarding confidential information.","However, existing optimization problems for determining the necessary collaborative functions have faced challenges, such as the optimal solution for the collaborative representation often being a zero matrix and the difficulty in understanding the process of deriving solutions.","This research addresses these issues by formulating the optimization problem through the segmentation of matrices into column vectors and proposing a solution method based on the generalized eigenvalue problem.","Additionally, we demonstrate methods for constructing collaborative functions more effectively through weighting and the selection of efficient algorithms suited to specific situations.","Experiments using real-world datasets have shown that our proposed formulation and solution for the collaborative function optimization problem achieve superior predictive accuracy compared to existing methods."],"url":"http://arxiv.org/abs/2404.14164v1"}
{"created":"2024-04-22 13:18:59","title":"Semirandom Planted Clique and the Restricted Isometry Property","abstract":"We give a simple, greedy $O(n^{\\omega+0.5})=O(n^{2.872})$-time algorithm to list-decode planted cliques in a semirandom model introduced in [CSV17] (following [FK01]) that succeeds whenever the size of the planted clique is $k\\geq O(\\sqrt{n} \\log^2 n)$. In the model, the edges touching the vertices in the planted $k$-clique are drawn independently with probability $p=1/2$ while the edges not touching the planted clique are chosen by an adversary in response to the random choices. Our result shows that the computational threshold in the semirandom setting is within a $O(\\log^2 n)$ factor of the information-theoretic one [Ste17] thus resolving an open question of Steinhardt. This threshold also essentially matches the conjectured computational threshold for the well-studied special case of fully random planted clique.   All previous algorithms [CSV17, MMT20, BKS23] in this model are based on rather sophisticated rounding algorithms for entropy-constrained semidefinite programming relaxations and their sum-of-squares strengthenings and the best known guarantee is a $n^{O(1/\\epsilon)}$-time algorithm to list-decode planted cliques of size $k \\geq \\tilde{O}(n^{1/2+\\epsilon})$. In particular, the guarantee trivializes to quasi-polynomial time if the planted clique is of size $O(\\sqrt{n} \\operatorname{polylog} n)$. Our algorithm achieves an almost optimal guarantee with a surprisingly simple greedy algorithm.   The prior state-of-the-art algorithmic result above is based on a reduction to certifying bounds on the size of unbalanced bicliques in random graphs -- closely related to certifying the restricted isometry property (RIP) of certain random matrices and known to be hard in the low-degree polynomial model. Our key idea is a new approach that relies on the truth of -- but not efficient certificates for -- RIP of a new class of matrices built from the input graphs.","sentences":["We give a simple, greedy $O(n^{\\omega+0.5})=O(n^{2.872})$-time algorithm to list-decode planted cliques in a semirandom model introduced in [CSV17] (following [FK01]) that succeeds whenever the size of the planted clique is $k\\geq O(\\sqrt{n} \\log^2","n)$. In the model, the edges touching the vertices in the planted $k$-clique are drawn independently with probability $p=1/2$ while the edges not touching the planted clique are chosen by an adversary in response to the random choices.","Our result shows that the computational threshold in the semirandom setting is within a $O(\\log^2","n)$ factor of the information-theoretic one [Ste17] thus resolving an open question of Steinhardt.","This threshold also essentially matches the conjectured computational threshold for the well-studied special case of fully random planted clique.   ","All previous algorithms [CSV17, MMT20, BKS23] in this model are based on rather sophisticated rounding algorithms for entropy-constrained semidefinite programming relaxations and their sum-of-squares strengthenings and the best known guarantee is a $n^{O(1/\\epsilon)}$-time algorithm to list-decode planted cliques of size $k \\geq \\tilde{O}(n^{1/2+\\epsilon})$.","In particular, the guarantee trivializes to quasi-polynomial time if the planted clique is of size $O(\\sqrt{n} \\operatorname{polylog} n)$. Our algorithm achieves an almost optimal guarantee with a surprisingly simple greedy algorithm.   ","The prior state-of-the-art algorithmic result above is based on a reduction to certifying bounds on the size of unbalanced bicliques in random graphs -- closely related to certifying the restricted isometry property (RIP) of certain random matrices and known to be hard in the low-degree polynomial model.","Our key idea is a new approach that relies on the truth of -- but not efficient certificates for -- RIP of a new class of matrices built from the input graphs."],"url":"http://arxiv.org/abs/2404.14159v1"}
{"created":"2024-04-22 12:50:15","title":"Access-Point to Access-Point Connectivity for PON-based OWC Spine and Leaf Data Centre Architecture","abstract":"In this paper, we propose incorporating Optical Wireless Communication (OWC) and Passive Optical Network (PON) technologies into next generation spine-and-leaf Data Centre Networks (DCNs). In this work, OWC systems are used to connect the Data Centre (DC) racks through Wavelength Division Multiplexing (WDM) Infrared (IR) transceivers. The transceivers are placed on top of the racks and at distributed Access Points (APs) in the ceiling. Each transceiver on a rack is connected to a leaf switch that connects the servers within the rack. We replace the spine switches by Optical Line Terminal (OLT) and Network Interface Cards (NIC) in the APs to achieve the desired connectivity. We benchmark the power consumption of the proposed OWC-PON-based spine-and-leaf DC against traditional spine-and-leaf DC and report 46% reduction in the power consumption when considering eight racks.","sentences":["In this paper, we propose incorporating Optical Wireless Communication (OWC) and Passive Optical Network (PON) technologies into next generation spine-and-leaf Data Centre Networks (DCNs).","In this work, OWC systems are used to connect the Data Centre (DC) racks through Wavelength Division Multiplexing (WDM) Infrared (IR) transceivers.","The transceivers are placed on top of the racks and at distributed Access Points (APs) in the ceiling.","Each transceiver on a rack is connected to a leaf switch that connects the servers within the rack.","We replace the spine switches by Optical Line Terminal (OLT) and Network Interface Cards (NIC) in the APs to achieve the desired connectivity.","We benchmark the power consumption of the proposed OWC-PON-based spine-and-leaf DC against traditional spine-and-leaf DC and report 46% reduction in the power consumption when considering eight racks."],"url":"http://arxiv.org/abs/2404.14143v1"}
{"created":"2024-04-22 12:27:30","title":"Individual Rationality in Topological Distance Games is Surprisingly Hard","abstract":"In the recently introduced topological distance games, strategic agents need to be assigned to a subset of vertices of a topology. In the assignment, the utility of an agent depends on both the agent's inherent utilities for other agents and its distance from them on the topology. We study the computational complexity of finding individually rational outcomes; this notion is widely assumed to be the very minimal stability requirement and requires that the utility of every agent in a solution is non-negative. We perform a comprehensive study of the problem's complexity, and we prove that even in very basic cases, deciding whether an individually rational solution exists is intractable. To reach at least some tractability, one needs to combine multiple restrictions of the input instance, including the number of agents and the topology and the influence of distant agents on the utility.","sentences":["In the recently introduced topological distance games, strategic agents need to be assigned to a subset of vertices of a topology.","In the assignment, the utility of an agent depends on both the agent's inherent utilities for other agents and its distance from them on the topology.","We study the computational complexity of finding individually rational outcomes; this notion is widely assumed to be the very minimal stability requirement and requires that the utility of every agent in a solution is non-negative.","We perform a comprehensive study of the problem's complexity, and we prove that even in very basic cases, deciding whether an individually rational solution exists is intractable.","To reach at least some tractability, one needs to combine multiple restrictions of the input instance, including the number of agents and the topology and the influence of distant agents on the utility."],"url":"http://arxiv.org/abs/2404.14128v1"}
{"created":"2024-04-22 12:21:12","title":"Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?","abstract":"Traditionally, success in multilingual machine translation can be attributed to three key factors in training data: large volume, diverse translation directions, and high quality. In the current practice of fine-tuning large language models (LLMs) for translation, we revisit the importance of all these factors. We find that LLMs display strong translation capability after being fine-tuned on as few as 32 training instances, and that fine-tuning on a single translation direction effectively enables LLMs to translate in multiple directions. However, the choice of direction is critical: fine-tuning LLMs with English on the target side can lead to task misinterpretation, which hinders translations into non-English languages. A similar problem arises when noise is introduced into the target side of parallel data, especially when the target language is well-represented in the LLM's pre-training. In contrast, noise in an under-represented language has a less pronounced effect. Our findings suggest that attaining successful alignment hinges on teaching the model to maintain a \"superficial\" focus, thereby avoiding the learning of erroneous biases beyond translation.","sentences":["Traditionally, success in multilingual machine translation can be attributed to three key factors in training data: large volume, diverse translation directions, and high quality.","In the current practice of fine-tuning large language models (LLMs) for translation, we revisit the importance of all these factors.","We find that LLMs display strong translation capability after being fine-tuned on as few as 32 training instances, and that fine-tuning on a single translation direction effectively enables LLMs to translate in multiple directions.","However, the choice of direction is critical: fine-tuning LLMs with English on the target side can lead to task misinterpretation, which hinders translations into non-English languages.","A similar problem arises when noise is introduced into the target side of parallel data, especially when the target language is well-represented in the LLM's pre-training.","In contrast, noise in an under-represented language has a less pronounced effect.","Our findings suggest that attaining successful alignment hinges on teaching the model to maintain a \"superficial\" focus, thereby avoiding the learning of erroneous biases beyond translation."],"url":"http://arxiv.org/abs/2404.14122v1"}
{"created":"2024-04-22 11:52:23","title":"PGNAA Spectral Classification of Aluminium and Copper Alloys with Machine Learning","abstract":"In this paper, we explore the optimization of metal recycling with a focus on real-time differentiation between alloys of copper and aluminium. Spectral data, obtained through Prompt Gamma Neutron Activation Analysis (PGNAA), is utilized for classification. The study compares data from two detectors, cerium bromide (CeBr$_{3}$) and high purity germanium (HPGe), considering their energy resolution and sensitivity. We test various data generation, preprocessing, and classification methods, with Maximum Likelihood Classifier (MLC) and Conditional Variational Autoencoder (CVAE) yielding the best results. The study also highlights the impact of different detector types on classification accuracy, with CeBr$_{3}$ excelling in short measurement times and HPGe performing better in longer durations. The findings suggest the importance of selecting the appropriate detector and methodology based on specific application requirements.","sentences":["In this paper, we explore the optimization of metal recycling with a focus on real-time differentiation between alloys of copper and aluminium.","Spectral data, obtained through Prompt Gamma Neutron Activation Analysis (PGNAA), is utilized for classification.","The study compares data from two detectors, cerium bromide (CeBr$_{3}$) and high purity germanium (HPGe), considering their energy resolution and sensitivity.","We test various data generation, preprocessing, and classification methods, with Maximum Likelihood Classifier (MLC) and Conditional Variational Autoencoder (CVAE) yielding the best results.","The study also highlights the impact of different detector types on classification accuracy, with CeBr$_{3}$ excelling in short measurement times and HPGe performing better in longer durations.","The findings suggest the importance of selecting the appropriate detector and methodology based on specific application requirements."],"url":"http://arxiv.org/abs/2404.14107v1"}
{"created":"2024-04-22 11:52:11","title":"DPTraj-PM: Differentially Private Trajectory Synthesis Using Prefix Tree and Markov Process","abstract":"The increasing use of GPS-enabled devices has generated a large amount of trajectory data. These data offer us vital insights to understand the movements of individuals and populations, benefiting a broad range of applications from transportation planning to epidemic modeling. However, improper release of trajectory data is increasing concerns on individual privacy. Previous attempts either lack strong privacy guarantees, or fail to preserve sufficient basic characteristics of the original data. In this paper, we propose DPTraj-PM, a method to synthesize trajectory dataset under the differential privacy (DP) framework while ensures high data utility. Based on the assumption that an individual's trajectory could be mainly determined by the initial trajectory segment (which depicts the starting point and the initial direction) and the next location point, DPTraj-PM discretizes the raw trajectories into neighboring cells, and models them by combining a prefix tree structure and an m-order Markov process. After adding noise to the model under differential privacy, DPTraj-PM generates a synthetic dataset from the noisy model to enable a wider spectrum of data mining and modeling tasks. The output traces crafted by DPTraj-PM not only preserves the patterns and variability in individuals' mobility behaviors, but also protects individual privacy. Experiments on two real-world datasets demonstrate that DPTraj-PM substantially outperforms the state-of-the-art techniques in terms of data utility. Our code is available at https://github.com/wnn5/DP-PrefixTreeMarkov.","sentences":["The increasing use of GPS-enabled devices has generated a large amount of trajectory data.","These data offer us vital insights to understand the movements of individuals and populations, benefiting a broad range of applications from transportation planning to epidemic modeling.","However, improper release of trajectory data is increasing concerns on individual privacy.","Previous attempts either lack strong privacy guarantees, or fail to preserve sufficient basic characteristics of the original data.","In this paper, we propose DPTraj-PM, a method to synthesize trajectory dataset under the differential privacy (DP) framework while ensures high data utility.","Based on the assumption that an individual's trajectory could be mainly determined by the initial trajectory segment (which depicts the starting point and the initial direction) and the next location point, DPTraj-PM discretizes the raw trajectories into neighboring cells, and models them by combining a prefix tree structure and an m-order Markov process.","After adding noise to the model under differential privacy, DPTraj-PM generates a synthetic dataset from the noisy model to enable a wider spectrum of data mining and modeling tasks.","The output traces crafted by DPTraj-PM not only preserves the patterns and variability in individuals' mobility behaviors, but also protects individual privacy.","Experiments on two real-world datasets demonstrate that DPTraj-PM substantially outperforms the state-of-the-art techniques in terms of data utility.","Our code is available at https://github.com/wnn5/DP-PrefixTreeMarkov."],"url":"http://arxiv.org/abs/2404.14106v1"}
{"created":"2024-04-22 11:37:47","title":"A Method of Joint Angle Estimation Using Only Relative Changes in Muscle Lengths for Tendon-driven Humanoids with Complex Musculoskeletal Structures","abstract":"Tendon-driven musculoskeletal humanoids typically have complex structures similar to those of human beings, such as ball joints and the scapula, in which encoders cannot be installed. Therefore, joint angles cannot be directly obtained and need to be estimated using the changes in muscle lengths. In previous studies, methods using table-search and extended kalman filter have been developed. These methods express the joint-muscle mapping, which is the nonlinear relationship between joint angles and muscle lengths, by using a data table, polynomials, or a neural network. However, due to computational complexity, these methods cannot consider the effects of polyarticular muscles. In this study, considering the limitation of the computational cost, we reduce unnecessary degrees of freedom, divide joints and muscles into several groups, and formulate a joint angle estimation method that takes into account polyarticular muscles. Also, we extend the estimation method to propose a joint angle estimation method using only the relative changes in muscle lengths. By this extension, which does not use absolute muscle lengths, we do not need to execute a difficult calibration of muscle lengths for tendon-driven musculoskeletal humanoids. Finally, we conduct experiments in simulation and actual environments, and verify the effectiveness of this study.","sentences":["Tendon-driven musculoskeletal humanoids typically have complex structures similar to those of human beings, such as ball joints and the scapula, in which encoders cannot be installed.","Therefore, joint angles cannot be directly obtained and need to be estimated using the changes in muscle lengths.","In previous studies, methods using table-search and extended kalman filter have been developed.","These methods express the joint-muscle mapping, which is the nonlinear relationship between joint angles and muscle lengths, by using a data table, polynomials, or a neural network.","However, due to computational complexity, these methods cannot consider the effects of polyarticular muscles.","In this study, considering the limitation of the computational cost, we reduce unnecessary degrees of freedom, divide joints and muscles into several groups, and formulate a joint angle estimation method that takes into account polyarticular muscles.","Also, we extend the estimation method to propose a joint angle estimation method using only the relative changes in muscle lengths.","By this extension, which does not use absolute muscle lengths, we do not need to execute a difficult calibration of muscle lengths for tendon-driven musculoskeletal humanoids.","Finally, we conduct experiments in simulation and actual environments, and verify the effectiveness of this study."],"url":"http://arxiv.org/abs/2404.14100v1"}
{"created":"2024-04-22 11:37:35","title":"DynaMMo: Dynamic Model Merging for Efficient Class Incremental Learning for Medical Images","abstract":"Continual learning, the ability to acquire knowledge from new data while retaining previously learned information, is a fundamental challenge in machine learning. Various approaches, including memory replay, knowledge distillation, model regularization, and dynamic network expansion, have been proposed to address this issue. Thus far, dynamic network expansion methods have achieved state-of-the-art performance at the cost of incurring significant computational overhead. This is due to the need for additional model buffers, which makes it less feasible in resource-constrained settings, particularly in the medical domain. To overcome this challenge, we propose Dynamic Model Merging, DynaMMo, a method that merges multiple networks at different stages of model training to achieve better computational efficiency. Specifically, we employ lightweight learnable modules for each task and combine them into a unified model to minimize computational overhead. DynaMMo achieves this without compromising performance, offering a cost-effective solution for continual learning in medical applications. We evaluate DynaMMo on three publicly available datasets, demonstrating its effectiveness compared to existing approaches. DynaMMo offers around 10-fold reduction in GFLOPS with a small drop of 2.76 in average accuracy when compared to state-of-the-art dynamic-based approaches. The code implementation of this work will be available upon the acceptance of this work at https://github.com/BioMedIA-MBZUAI/DynaMMo.","sentences":["Continual learning, the ability to acquire knowledge from new data while retaining previously learned information, is a fundamental challenge in machine learning.","Various approaches, including memory replay, knowledge distillation, model regularization, and dynamic network expansion, have been proposed to address this issue.","Thus far, dynamic network expansion methods have achieved state-of-the-art performance at the cost of incurring significant computational overhead.","This is due to the need for additional model buffers, which makes it less feasible in resource-constrained settings, particularly in the medical domain.","To overcome this challenge, we propose Dynamic Model Merging, DynaMMo, a method that merges multiple networks at different stages of model training to achieve better computational efficiency.","Specifically, we employ lightweight learnable modules for each task and combine them into a unified model to minimize computational overhead.","DynaMMo achieves this without compromising performance, offering a cost-effective solution for continual learning in medical applications.","We evaluate DynaMMo on three publicly available datasets, demonstrating its effectiveness compared to existing approaches.","DynaMMo offers around 10-fold reduction in GFLOPS with a small drop of 2.76 in average accuracy when compared to state-of-the-art dynamic-based approaches.","The code implementation of this work will be available upon the acceptance of this work at https://github.com/BioMedIA-MBZUAI/DynaMMo."],"url":"http://arxiv.org/abs/2404.14099v1"}
{"created":"2024-04-22 11:12:00","title":"A Tight Subexponential-time Algorithm for Two-Page Book Embedding","abstract":"A book embedding of a graph is a drawing that maps vertices onto a line and edges to simple pairwise non-crossing curves drawn into pages, which are half-planes bounded by that line. Two-page book embeddings, i.e., book embeddings into 2 pages, are of special importance as they are both NP-hard to compute and have specific applications. We obtain a 2^(O(\\sqrt{n})) algorithm for computing a book embedding of an n-vertex graph on two pages -- a result which is asymptotically tight under the Exponential Time Hypothesis. As a key tool in our approach, we obtain a single-exponential fixed-parameter algorithm for the same problem when parameterized by the treewidth of the input graph. We conclude by establishing the fixed-parameter tractability of computing minimum-page book embeddings when parameterized by the feedback edge number, settling an open question arising from previous work on the problem.","sentences":["A book embedding of a graph is a drawing that maps vertices onto a line and edges to simple pairwise non-crossing curves drawn into pages, which are half-planes bounded by that line.","Two-page book embeddings, i.e., book embeddings into 2 pages, are of special importance as they are both NP-hard to compute and have specific applications.","We obtain a 2^(O(\\sqrt{n}))","algorithm for computing a book embedding of an n-vertex graph on two pages -- a result which is asymptotically tight under the Exponential Time Hypothesis.","As a key tool in our approach, we obtain a single-exponential fixed-parameter algorithm for the same problem when parameterized by the treewidth of the input graph.","We conclude by establishing the fixed-parameter tractability of computing minimum-page book embeddings when parameterized by the feedback edge number, settling an open question arising from previous work on the problem."],"url":"http://arxiv.org/abs/2404.14087v1"}
{"created":"2024-04-22 10:45:59","title":"Noise contrastive estimation with soft targets for conditional models","abstract":"Soft targets combined with the cross-entropy loss have shown to improve generalization performance of deep neural networks on supervised classification tasks. The standard cross-entropy loss however assumes data to be categorically distributed, which may often not be the case in practice. In contrast, InfoNCE does not rely on such an explicit assumption but instead implicitly estimates the true conditional through negative sampling. Unfortunately, it cannot be combined with soft targets in its standard formulation, hindering its use in combination with sophisticated training strategies. In this paper, we address this limitation by proposing a principled loss function that is compatible with probabilistic targets. Our new soft target InfoNCE loss is conceptually simple, efficient to compute, and can be derived within the framework of noise contrastive estimation. Using a toy example, we demonstrate shortcomings of the categorical distribution assumption of cross-entropy, and discuss implications of sampling from soft distributions. We observe that soft target InfoNCE performs on par with strong soft target cross-entropy baselines and outperforms hard target NLL and InfoNCE losses on popular benchmarks, including ImageNet. Finally, we provide a simple implementation of our loss, geared towards supervised classification and fully compatible with deep classification model trained with cross-entropy.","sentences":["Soft targets combined with the cross-entropy loss have shown to improve generalization performance of deep neural networks on supervised classification tasks.","The standard cross-entropy loss however assumes data to be categorically distributed, which may often not be the case in practice.","In contrast, InfoNCE does not rely on such an explicit assumption but instead implicitly estimates the true conditional through negative sampling.","Unfortunately, it cannot be combined with soft targets in its standard formulation, hindering its use in combination with sophisticated training strategies.","In this paper, we address this limitation by proposing a principled loss function that is compatible with probabilistic targets.","Our new soft target InfoNCE loss is conceptually simple, efficient to compute, and can be derived within the framework of noise contrastive estimation.","Using a toy example, we demonstrate shortcomings of the categorical distribution assumption of cross-entropy, and discuss implications of sampling from soft distributions.","We observe that soft target InfoNCE performs on par with strong soft target cross-entropy baselines and outperforms hard target NLL and InfoNCE losses on popular benchmarks, including ImageNet.","Finally, we provide a simple implementation of our loss, geared towards supervised classification and fully compatible with deep classification model trained with cross-entropy."],"url":"http://arxiv.org/abs/2404.14076v1"}
{"created":"2024-04-22 10:35:26","title":"Towards Proxy Staking Accounts Based on NFTs in Ethereum","abstract":"Blockchain is a technology that is often used to share data and assets. However, in the decentralized ecosystem, blockchain-based systems can be utilized to share information and assets without the traditional barriers associated with solo responsibility, e.g., multi-sig wallets. This paper describes an innovative approach to blockchain networks based on a non-fungible token that behaves as an account (NFTAA). The key novelty of this article is using NFTAA to leverage the unique properties of NFTs to manage your ownership better and effectively isolate them to improve the security, transparency, and even interoperability possibilities. Additionally, the account-based solution gives us the ability and flexibility to cover regular use cases such as staking and liquid equities, but also practical composability. This article offers a simple implementation, which allows developers and researchers to choose the best solution for their needs in demand of abstract representation in any use case.","sentences":["Blockchain is a technology that is often used to share data and assets.","However, in the decentralized ecosystem, blockchain-based systems can be utilized to share information and assets without the traditional barriers associated with solo responsibility, e.g., multi-sig wallets.","This paper describes an innovative approach to blockchain networks based on a non-fungible token that behaves as an account (NFTAA).","The key novelty of this article is using NFTAA to leverage the unique properties of NFTs to manage your ownership better and effectively isolate them to improve the security, transparency, and even interoperability possibilities.","Additionally, the account-based solution gives us the ability and flexibility to cover regular use cases such as staking and liquid equities, but also practical composability.","This article offers a simple implementation, which allows developers and researchers to choose the best solution for their needs in demand of abstract representation in any use case."],"url":"http://arxiv.org/abs/2404.14074v1"}
{"created":"2024-04-22 10:19:02","title":"FedTAD: Topology-aware Data-free Knowledge Distillation for Subgraph Federated Learning","abstract":"Subgraph federated learning (subgraph-FL) is a new distributed paradigm that facilitates the collaborative training of graph neural networks (GNNs) by multi-client subgraphs. Unfortunately, a significant challenge of subgraph-FL arises from subgraph heterogeneity, which stems from node and topology variation, causing the impaired performance of the global GNN. Despite various studies, they have not yet thoroughly investigated the impact mechanism of subgraph heterogeneity. To this end, we decouple node and topology variation, revealing that they correspond to differences in label distribution and structure homophily. Remarkably, these variations lead to significant differences in the class-wise knowledge reliability of multiple local GNNs, misguiding the model aggregation with varying degrees. Building on this insight, we propose topology-aware data-free knowledge distillation technology (FedTAD), enhancing reliable knowledge transfer from the local model to the global model. Extensive experiments on six public datasets consistently demonstrate the superiority of FedTAD over state-of-the-art baselines.","sentences":["Subgraph federated learning (subgraph-FL) is a new distributed paradigm that facilitates the collaborative training of graph neural networks (GNNs) by multi-client subgraphs.","Unfortunately, a significant challenge of subgraph-FL arises from subgraph heterogeneity, which stems from node and topology variation, causing the impaired performance of the global GNN.","Despite various studies, they have not yet thoroughly investigated the impact mechanism of subgraph heterogeneity.","To this end, we decouple node and topology variation, revealing that they correspond to differences in label distribution and structure homophily.","Remarkably, these variations lead to significant differences in the class-wise knowledge reliability of multiple local GNNs, misguiding the model aggregation with varying degrees.","Building on this insight, we propose topology-aware data-free knowledge distillation technology (FedTAD), enhancing reliable knowledge transfer from the local model to the global model.","Extensive experiments on six public datasets consistently demonstrate the superiority of FedTAD over state-of-the-art baselines."],"url":"http://arxiv.org/abs/2404.14061v1"}
{"created":"2024-04-22 10:06:21","title":"Differential contributions of machine learning and statistical analysis to language and cognitive sciences","abstract":"Data-driven approaches have revolutionized scientific research. Machine learning and statistical analysis are commonly utilized in this type of research. Despite their widespread use, these methodologies differ significantly in their techniques and objectives. Few studies have utilized a consistent dataset to demonstrate these differences within the social sciences, particularly in language and cognitive sciences. This study leverages the Buckeye Speech Corpus to illustrate how both machine learning and statistical analysis are applied in data-driven research to obtain distinct insights. This study significantly enhances our understanding of the diverse approaches employed in data-driven strategies.","sentences":["Data-driven approaches have revolutionized scientific research.","Machine learning and statistical analysis are commonly utilized in this type of research.","Despite their widespread use, these methodologies differ significantly in their techniques and objectives.","Few studies have utilized a consistent dataset to demonstrate these differences within the social sciences, particularly in language and cognitive sciences.","This study leverages the Buckeye Speech Corpus to illustrate how both machine learning and statistical analysis are applied in data-driven research to obtain distinct insights.","This study significantly enhances our understanding of the diverse approaches employed in data-driven strategies."],"url":"http://arxiv.org/abs/2404.14052v1"}
{"created":"2024-04-22 10:05:08","title":"Decline and Fall of the ICALP 2008 Modular Decomposition algorithm","abstract":"We provide a counterexample to a crucial lemma in the ICALP 2008 paper \"Simpler Linear-Time Modular Decomposition Via Recursive Factorizing Permutations\", invalidating the algorithm described there.","sentences":["We provide a counterexample to a crucial lemma in the ICALP 2008 paper \"Simpler Linear-Time Modular Decomposition Via Recursive Factorizing Permutations\", invalidating the algorithm described there."],"url":"http://arxiv.org/abs/2404.14049v1"}
{"created":"2024-04-22 10:03:03","title":"How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study","abstract":"Meta's LLaMA family has become one of the most powerful open-source Large Language Model (LLM) series. Notably, LLaMA3 models have recently been released and achieve impressive performance across various with super-large scale pre-training on over 15T tokens of data. Given the wide application of low-bit quantization for LLMs in resource-limited scenarios, we explore LLaMA3's capabilities when quantized to low bit-width. This exploration holds the potential to unveil new insights and challenges for low-bit quantization of LLaMA3 and other forthcoming LLMs, especially in addressing performance degradation problems that suffer in LLM compression. Specifically, we evaluate the 10 existing post-training quantization and LoRA-finetuning methods of LLaMA3 on 1-8 bits and diverse datasets to comprehensively reveal LLaMA3's low-bit quantization performance. Our experiment results indicate that LLaMA3 still suffers non-negligent degradation in these scenarios, especially in ultra-low bit-width. This highlights the significant performance gap under low bit-width that needs to be bridged in future developments. We expect that this empirical study will prove valuable in advancing future models, pushing the LLMs to lower bit-width with higher accuracy for being practical. Our project is released on https://github.com/Macaronlin/LLaMA3-Quantization and quantized LLaMA3 models are released in https://huggingface.co/LLMQ.","sentences":["Meta's LLaMA family has become one of the most powerful open-source Large Language Model (LLM) series.","Notably, LLaMA3 models have recently been released and achieve impressive performance across various with super-large scale pre-training on over 15T tokens of data.","Given the wide application of low-bit quantization for LLMs in resource-limited scenarios, we explore LLaMA3's capabilities when quantized to low bit-width.","This exploration holds the potential to unveil new insights and challenges for low-bit quantization of LLaMA3 and other forthcoming LLMs, especially in addressing performance degradation problems that suffer in LLM compression.","Specifically, we evaluate the 10 existing post-training quantization and LoRA-finetuning methods of LLaMA3 on 1-8 bits and diverse datasets to comprehensively reveal LLaMA3's low-bit quantization performance.","Our experiment results indicate that LLaMA3 still suffers non-negligent degradation in these scenarios, especially in ultra-low bit-width.","This highlights the significant performance gap under low bit-width that needs to be bridged in future developments.","We expect that this empirical study will prove valuable in advancing future models, pushing the LLMs to lower bit-width with higher accuracy for being practical.","Our project is released on https://github.com/Macaronlin/LLaMA3-Quantization and quantized LLaMA3 models are released in https://huggingface.co/LLMQ."],"url":"http://arxiv.org/abs/2404.14047v1"}
{"created":"2024-04-22 09:55:50","title":"CloudFort: Enhancing Robustness of 3D Point Cloud Classification Against Backdoor Attacks via Spatial Partitioning and Ensemble Prediction","abstract":"The increasing adoption of 3D point cloud data in various applications, such as autonomous vehicles, robotics, and virtual reality, has brought about significant advancements in object recognition and scene understanding. However, this progress is accompanied by new security challenges, particularly in the form of backdoor attacks. These attacks involve inserting malicious information into the training data of machine learning models, potentially compromising the model's behavior. In this paper, we propose CloudFort, a novel defense mechanism designed to enhance the robustness of 3D point cloud classifiers against backdoor attacks. CloudFort leverages spatial partitioning and ensemble prediction techniques to effectively mitigate the impact of backdoor triggers while preserving the model's performance on clean data. We evaluate the effectiveness of CloudFort through extensive experiments, demonstrating its strong resilience against the Point Cloud Backdoor Attack (PCBA). Our results show that CloudFort significantly enhances the security of 3D point cloud classification models without compromising their accuracy on benign samples. Furthermore, we explore the limitations of CloudFort and discuss potential avenues for future research in the field of 3D point cloud security. The proposed defense mechanism represents a significant step towards ensuring the trustworthiness and reliability of point-cloud-based systems in real-world applications.","sentences":["The increasing adoption of 3D point cloud data in various applications, such as autonomous vehicles, robotics, and virtual reality, has brought about significant advancements in object recognition and scene understanding.","However, this progress is accompanied by new security challenges, particularly in the form of backdoor attacks.","These attacks involve inserting malicious information into the training data of machine learning models, potentially compromising the model's behavior.","In this paper, we propose CloudFort, a novel defense mechanism designed to enhance the robustness of 3D point cloud classifiers against backdoor attacks.","CloudFort leverages spatial partitioning and ensemble prediction techniques to effectively mitigate the impact of backdoor triggers while preserving the model's performance on clean data.","We evaluate the effectiveness of CloudFort through extensive experiments, demonstrating its strong resilience against the Point Cloud Backdoor Attack (PCBA).","Our results show that CloudFort significantly enhances the security of 3D point cloud classification models without compromising their accuracy on benign samples.","Furthermore, we explore the limitations of CloudFort and discuss potential avenues for future research in the field of 3D point cloud security.","The proposed defense mechanism represents a significant step towards ensuring the trustworthiness and reliability of point-cloud-based systems in real-world applications."],"url":"http://arxiv.org/abs/2404.14042v1"}
{"created":"2024-04-22 09:51:43","title":"Optimal Structure of Receive Beamforming for Over-the-Air Computation","abstract":"We investigate fast data aggregation via over-the-air computation (AirComp) over wireless networks. In this scenario, an access point (AP) with multiple antennas aims to recover the arithmetic mean of sensory data from multiple wireless devices. To minimize estimation distortion, we formulate a mean-squared-error (MSE) minimization problem that considers joint optimization of transmit scalars at wireless devices, denoising factor, and receive beamforming vector at the AP. We derive closed-form expressions for the transmit scalars and denoising factor, resulting in a non-convex quadratic constrained quadratic programming (QCQP) problem concerning the receive beamforming vector. To tackle the computational complexity of the beamforming design, particularly relevant in massive multiple-input multiple-output (MIMO) AirComp systems, we explore the optimal structure of receive beamforming using successive convex approximation (SCA) and Lagrange duality. By leveraging the proposed optimal beamforming structure, we develop two efficient algorithms based on SCA and semi-definite relaxation (SDR). These algorithms enable fast wireless aggregation with low computational complexity and yield almost identical mean square error (MSE) performance compared to baseline algorithms. Simulation results validate the effectiveness of our proposed methods.","sentences":["We investigate fast data aggregation via over-the-air computation (AirComp) over wireless networks.","In this scenario, an access point (AP) with multiple antennas aims to recover the arithmetic mean of sensory data from multiple wireless devices.","To minimize estimation distortion, we formulate a mean-squared-error (MSE) minimization problem that considers joint optimization of transmit scalars at wireless devices, denoising factor, and receive beamforming vector at the AP.","We derive closed-form expressions for the transmit scalars and denoising factor, resulting in a non-convex quadratic constrained quadratic programming (QCQP) problem concerning the receive beamforming vector.","To tackle the computational complexity of the beamforming design, particularly relevant in massive multiple-input multiple-output (MIMO) AirComp systems, we explore the optimal structure of receive beamforming using successive convex approximation (SCA) and Lagrange duality.","By leveraging the proposed optimal beamforming structure, we develop two efficient algorithms based on SCA and semi-definite relaxation (SDR).","These algorithms enable fast wireless aggregation with low computational complexity and yield almost identical mean square error (MSE) performance compared to baseline algorithms.","Simulation results validate the effectiveness of our proposed methods."],"url":"http://arxiv.org/abs/2404.14036v1"}
{"created":"2024-04-22 09:50:11","title":"Apodotiko: Enabling Efficient Serverless Federated Learning in Heterogeneous Environments","abstract":"Federated Learning (FL) is an emerging machine learning paradigm that enables the collaborative training of a shared global model across distributed clients while keeping the data decentralized. Recent works on designing systems for efficient FL have shown that utilizing serverless computing technologies, particularly Function-as-a-Service (FaaS) for FL, can enhance resource efficiency, reduce training costs, and alleviate the complex infrastructure management burden on data holders. However, current serverless FL systems still suffer from the presence of stragglers, i.e., slow clients that impede the collaborative training process. While strategies aimed at mitigating stragglers in these systems have been proposed, they overlook the diverse hardware resource configurations among FL clients. To this end, we present Apodotiko, a novel asynchronous training strategy designed for serverless FL. Our strategy incorporates a scoring mechanism that evaluates each client's hardware capacity and dataset size to intelligently prioritize and select clients for each training round, thereby minimizing the effects of stragglers on system performance. We comprehensively evaluate Apodotiko across diverse datasets, considering a mix of CPU and GPU clients, and compare its performance against five other FL training strategies. Results from our experiments demonstrate that Apodotiko outperforms other FL training strategies, achieving an average speedup of 2.75x and a maximum speedup of 7.03x. Furthermore, our strategy significantly reduces cold starts by a factor of four on average, demonstrating suitability in serverless environments.","sentences":["Federated Learning (FL) is an emerging machine learning paradigm that enables the collaborative training of a shared global model across distributed clients while keeping the data decentralized.","Recent works on designing systems for efficient FL have shown that utilizing serverless computing technologies, particularly Function-as-a-Service (FaaS) for FL, can enhance resource efficiency, reduce training costs, and alleviate the complex infrastructure management burden on data holders.","However, current serverless FL systems still suffer from the presence of stragglers, i.e., slow clients that impede the collaborative training process.","While strategies aimed at mitigating stragglers in these systems have been proposed, they overlook the diverse hardware resource configurations among FL clients.","To this end, we present Apodotiko, a novel asynchronous training strategy designed for serverless FL.","Our strategy incorporates a scoring mechanism that evaluates each client's hardware capacity and dataset size to intelligently prioritize and select clients for each training round, thereby minimizing the effects of stragglers on system performance.","We comprehensively evaluate Apodotiko across diverse datasets, considering a mix of CPU and GPU clients, and compare its performance against five other FL training strategies.","Results from our experiments demonstrate that Apodotiko outperforms other FL training strategies, achieving an average speedup of 2.75x and a maximum speedup of 7.03x.","Furthermore, our strategy significantly reduces cold starts by a factor of four on average, demonstrating suitability in serverless environments."],"url":"http://arxiv.org/abs/2404.14033v1"}
{"created":"2024-04-22 09:50:05","title":"1st Place Solution to the 1st SkatingVerse Challenge","abstract":"This paper presents the winning solution for the 1st SkatingVerse Challenge. We propose a method that involves several steps. To begin, we leverage the DINO framework to extract the Region of Interest (ROI) and perform precise cropping of the raw video footage. Subsequently, we employ three distinct models, namely Unmasked Teacher, UniformerV2, and InfoGCN, to capture different aspects of the data. By ensembling the prediction results based on logits, our solution attains an impressive leaderboard score of 95.73%.","sentences":["This paper presents the winning solution for the 1st SkatingVerse Challenge.","We propose a method that involves several steps.","To begin, we leverage the DINO framework to extract the Region of Interest (ROI) and perform precise cropping of the raw video footage.","Subsequently, we employ three distinct models, namely Unmasked Teacher, UniformerV2, and InfoGCN, to capture different aspects of the data.","By ensembling the prediction results based on logits, our solution attains an impressive leaderboard score of 95.73%."],"url":"http://arxiv.org/abs/2404.14032v1"}
{"created":"2024-04-22 09:43:03","title":"OccFeat: Self-supervised Occupancy Feature Prediction for Pretraining BEV Segmentation Networks","abstract":"We introduce a self-supervised pretraining method, called OcFeat, for camera-only Bird's-Eye-View (BEV) segmentation networks. With OccFeat, we pretrain a BEV network via occupancy prediction and feature distillation tasks. Occupancy prediction provides a 3D geometric understanding of the scene to the model. However, the geometry learned is class-agnostic. Hence, we add semantic information to the model in the 3D space through distillation from a self-supervised pretrained image foundation model. Models pretrained with our method exhibit improved BEV semantic segmentation performance, particularly in low-data scenarios. Moreover, empirical results affirm the efficacy of integrating feature distillation with 3D occupancy prediction in our pretraining approach.","sentences":["We introduce a self-supervised pretraining method, called OcFeat, for camera-only Bird's-Eye-View (BEV) segmentation networks.","With OccFeat, we pretrain a BEV network via occupancy prediction and feature distillation tasks.","Occupancy prediction provides a 3D geometric understanding of the scene to the model.","However, the geometry learned is class-agnostic.","Hence, we add semantic information to the model in the 3D space through distillation from a self-supervised pretrained image foundation model.","Models pretrained with our method exhibit improved BEV semantic segmentation performance, particularly in low-data scenarios.","Moreover, empirical results affirm the efficacy of integrating feature distillation with 3D occupancy prediction in our pretraining approach."],"url":"http://arxiv.org/abs/2404.14027v1"}
{"created":"2024-04-22 09:36:17","title":"Collaborative Perception Datasets in Autonomous Driving: A Survey","abstract":"This survey offers a comprehensive examination of collaborative perception datasets in the context of Vehicle-to-Infrastructure (V2I), Vehicle-to-Vehicle (V2V), and Vehicle-to-Everything (V2X). It highlights the latest developments in large-scale benchmarks that accelerate advancements in perception tasks for autonomous vehicles. The paper systematically analyzes a variety of datasets, comparing them based on aspects such as diversity, sensor setup, quality, public availability, and their applicability to downstream tasks. It also highlights the key challenges such as domain shift, sensor setup limitations, and gaps in dataset diversity and availability. The importance of addressing privacy and security concerns in the development of datasets is emphasized, regarding data sharing and dataset creation. The conclusion underscores the necessity for comprehensive, globally accessible datasets and collaborative efforts from both technological and research communities to overcome these challenges and fully harness the potential of autonomous driving.","sentences":["This survey offers a comprehensive examination of collaborative perception datasets in the context of Vehicle-to-Infrastructure (V2I), Vehicle-to-Vehicle (V2V), and Vehicle-to-Everything (V2X).","It highlights the latest developments in large-scale benchmarks that accelerate advancements in perception tasks for autonomous vehicles.","The paper systematically analyzes a variety of datasets, comparing them based on aspects such as diversity, sensor setup, quality, public availability, and their applicability to downstream tasks.","It also highlights the key challenges such as domain shift, sensor setup limitations, and gaps in dataset diversity and availability.","The importance of addressing privacy and security concerns in the development of datasets is emphasized, regarding data sharing and dataset creation.","The conclusion underscores the necessity for comprehensive, globally accessible datasets and collaborative efforts from both technological and research communities to overcome these challenges and fully harness the potential of autonomous driving."],"url":"http://arxiv.org/abs/2404.14022v1"}
{"created":"2024-04-22 09:32:38","title":"Hybrid Ensemble-Based Travel Mode Prediction","abstract":"Travel mode choice (TMC) prediction, which can be formulated as a classification task, helps in understanding what makes citizens choose different modes of transport for individual trips. This is also a major step towards fostering sustainable transportation. As behaviour may evolve over time, we also face the question of detecting concept drift in the data. This necessitates using appropriate methods to address potential concept drift. In particular, it is necessary to decide whether batch or stream mining methods should be used to develop periodically updated TMC models. To address the challenge of the development of TMC models, we propose the novel Incremental Ensemble of Batch and Stream Models (IEBSM) method aimed at adapting travel mode choice classifiers to concept drift possibly occurring in the data. It relies on the combination of drift detectors with batch learning and stream mining models. We compare it against batch and incremental learners, including methods relying on active drift detection. Experiments with varied travel mode data sets representing both city and country levels show that the IEBSM method both detects drift in travel mode data and successfully adapts the models to evolving travel mode choice data. The method has a higher rank than batch and stream learners.","sentences":["Travel mode choice (TMC) prediction, which can be formulated as a classification task, helps in understanding what makes citizens choose different modes of transport for individual trips.","This is also a major step towards fostering sustainable transportation.","As behaviour may evolve over time, we also face the question of detecting concept drift in the data.","This necessitates using appropriate methods to address potential concept drift.","In particular, it is necessary to decide whether batch or stream mining methods should be used to develop periodically updated TMC models.","To address the challenge of the development of TMC models, we propose the novel Incremental Ensemble of Batch and Stream Models (IEBSM) method aimed at adapting travel mode choice classifiers to concept drift possibly occurring in the data.","It relies on the combination of drift detectors with batch learning and stream mining models.","We compare it against batch and incremental learners, including methods relying on active drift detection.","Experiments with varied travel mode data sets representing both city and country levels show that the IEBSM method both detects drift in travel mode data and successfully adapts the models to evolving travel mode choice data.","The method has a higher rank than batch and stream learners."],"url":"http://arxiv.org/abs/2404.14017v1"}
{"created":"2024-04-22 09:29:14","title":"Ungeneralizable Examples","abstract":"The training of contemporary deep learning models heavily relies on publicly available data, posing a risk of unauthorized access to online data and raising concerns about data privacy. Current approaches to creating unlearnable data involve incorporating small, specially designed noises, but these methods strictly limit data usability, overlooking its potential usage in authorized scenarios. In this paper, we extend the concept of unlearnable data to conditional data learnability and introduce \\textbf{U}n\\textbf{G}eneralizable \\textbf{E}xamples (UGEs). UGEs exhibit learnability for authorized users while maintaining unlearnability for potential hackers. The protector defines the authorized network and optimizes UGEs to match the gradients of the original data and its ungeneralizable version, ensuring learnability. To prevent unauthorized learning, UGEs are trained by maximizing a designated distance loss in a common feature space. Additionally, to further safeguard the authorized side from potential attacks, we introduce additional undistillation optimization. Experimental results on multiple datasets and various networks demonstrate that the proposed UGEs framework preserves data usability while reducing training performance on hacker networks, even under different types of attacks.","sentences":["The training of contemporary deep learning models heavily relies on publicly available data, posing a risk of unauthorized access to online data and raising concerns about data privacy.","Current approaches to creating unlearnable data involve incorporating small, specially designed noises, but these methods strictly limit data usability, overlooking its potential usage in authorized scenarios.","In this paper, we extend the concept of unlearnable data to conditional data learnability and introduce \\textbf{U}n\\textbf{G}eneralizable \\textbf{E}xamples (UGEs).","UGEs exhibit learnability for authorized users while maintaining unlearnability for potential hackers.","The protector defines the authorized network and optimizes UGEs to match the gradients of the original data and its ungeneralizable version, ensuring learnability.","To prevent unauthorized learning, UGEs are trained by maximizing a designated distance loss in a common feature space.","Additionally, to further safeguard the authorized side from potential attacks, we introduce additional undistillation optimization.","Experimental results on multiple datasets and various networks demonstrate that the proposed UGEs framework preserves data usability while reducing training performance on hacker networks, even under different types of attacks."],"url":"http://arxiv.org/abs/2404.14016v1"}
{"created":"2024-04-22 09:23:55","title":"Coordinated Planning for Stability Enhancement in High IBR-Penetrated Systems","abstract":"Security and stability challenges in future power systems with high penetration Inverter-Based Resources (IBR) have been anticipated as the main barrier to decolonization. Grid-following IBRs may become unstable under small disturbances in weak grids, while, during transient processes, system stability and protection may be jeopardized due to the lack of sufficient Short-Circuit Current (SCC). To solve these challenges and achieve decarbonization, the future system has to be carefully planned. However, it remains unclear how both small-signal and transient processes can be considered during the system planning stage. In this context, this paper proposes a coordinated planning model of different resources to enhance system-level stability. The system strength and SCC constraints are analytically derived by considering the different characteristics of synchronous units and IBRs, which are further effectively linearized through a novel data-driven approach, where an active sampling method is proposed to generate a representative data set. The significant economic value of the proposed coordinated planning framework in both system asset investment and system operation is demonstrated through detailed case studies.","sentences":["Security and stability challenges in future power systems with high penetration Inverter-Based Resources (IBR) have been anticipated as the main barrier to decolonization.","Grid-following IBRs may become unstable under small disturbances in weak grids, while, during transient processes, system stability and protection may be jeopardized due to the lack of sufficient Short-Circuit Current (SCC).","To solve these challenges and achieve decarbonization, the future system has to be carefully planned.","However, it remains unclear how both small-signal and transient processes can be considered during the system planning stage.","In this context, this paper proposes a coordinated planning model of different resources to enhance system-level stability.","The system strength and SCC constraints are analytically derived by considering the different characteristics of synchronous units and IBRs, which are further effectively linearized through a novel data-driven approach, where an active sampling method is proposed to generate a representative data set.","The significant economic value of the proposed coordinated planning framework in both system asset investment and system operation is demonstrated through detailed case studies."],"url":"http://arxiv.org/abs/2404.14012v1"}
{"created":"2024-04-22 09:16:14","title":"Distilled Datamodel with Reverse Gradient Matching","abstract":"The proliferation of large-scale AI models trained on extensive datasets has revolutionized machine learning. With these models taking on increasingly central roles in various applications, the need to understand their behavior and enhance interpretability has become paramount. To investigate the impact of changes in training data on a pre-trained model, a common approach is leave-one-out retraining. This entails systematically altering the training dataset by removing specific samples to observe resulting changes within the model. However, retraining the model for each altered dataset presents a significant computational challenge, given the need to perform this operation for every dataset variation. In this paper, we introduce an efficient framework for assessing data impact, comprising offline training and online evaluation stages. During the offline training phase, we approximate the influence of training data on the target model through a distilled synset, formulated as a reversed gradient matching problem. For online evaluation, we expedite the leave-one-out process using the synset, which is then utilized to compute the attribution matrix based on the evaluation objective. Experimental evaluations, including training data attribution and assessments of data quality, demonstrate that our proposed method achieves comparable model behavior evaluation while significantly speeding up the process compared to the direct retraining method.","sentences":["The proliferation of large-scale AI models trained on extensive datasets has revolutionized machine learning.","With these models taking on increasingly central roles in various applications, the need to understand their behavior and enhance interpretability has become paramount.","To investigate the impact of changes in training data on a pre-trained model, a common approach is leave-one-out retraining.","This entails systematically altering the training dataset by removing specific samples to observe resulting changes within the model.","However, retraining the model for each altered dataset presents a significant computational challenge, given the need to perform this operation for every dataset variation.","In this paper, we introduce an efficient framework for assessing data impact, comprising offline training and online evaluation stages.","During the offline training phase, we approximate the influence of training data on the target model through a distilled synset, formulated as a reversed gradient matching problem.","For online evaluation, we expedite the leave-one-out process using the synset, which is then utilized to compute the attribution matrix based on the evaluation objective.","Experimental evaluations, including training data attribution and assessments of data quality, demonstrate that our proposed method achieves comparable model behavior evaluation while significantly speeding up the process compared to the direct retraining method."],"url":"http://arxiv.org/abs/2404.14006v1"}
{"created":"2024-04-22 09:06:28","title":"Revolutionizing student course selection: Exploring the application prospects and challenges of blockchain token voting technology","abstract":"This paper explores the utilization of blockchain token voting technology in student course selection systems. The current course selection systems face various issues, which can be mitigated through the implementation of blockchain technology. The advantages of blockchain technology, including consensus mechanisms and smart contracts, are discussed in detail. The token voting mechanism, encompassing concepts, token issuance and distribution, and voting rules and procedures, is also explained. The system design takes into account the system architecture, user roles and permissions, course information on the blockchain, student course selection voting process, and course selection result statistics and public display. The technology offers advantages such as transparency, fairness, data security and privacy protection, and system efficiency improvement. However, it also poses several challenges, such as technological and regulatory hurdles. The prospects for the application of blockchain token voting technology in student course selection systems and its potential impact on other fields are summarized. Overall, the utilization of blockchain token voting technology in student course selection systems holds promising future implications, which could revolutionize the education sector.","sentences":["This paper explores the utilization of blockchain token voting technology in student course selection systems.","The current course selection systems face various issues, which can be mitigated through the implementation of blockchain technology.","The advantages of blockchain technology, including consensus mechanisms and smart contracts, are discussed in detail.","The token voting mechanism, encompassing concepts, token issuance and distribution, and voting rules and procedures, is also explained.","The system design takes into account the system architecture, user roles and permissions, course information on the blockchain, student course selection voting process, and course selection result statistics and public display.","The technology offers advantages such as transparency, fairness, data security and privacy protection, and system efficiency improvement.","However, it also poses several challenges, such as technological and regulatory hurdles.","The prospects for the application of blockchain token voting technology in student course selection systems and its potential impact on other fields are summarized.","Overall, the utilization of blockchain token voting technology in student course selection systems holds promising future implications, which could revolutionize the education sector."],"url":"http://arxiv.org/abs/2404.14000v1"}
{"created":"2024-04-22 09:02:24","title":"SIGY: Breaking Intel SGX Enclaves with Malicious Exceptions & Signals","abstract":"User programs recover from hardware exceptions and respond to signals by executing custom handlers that they register specifically for such events. We present SIGY attack, which abuses this programming model on Intel SGX to break the confidentiality and integrity guarantees of enclaves. SIGY uses the untrusted OS to deliver fake hardware events and injects fake signals in an enclave at any point. Such unintended execution of benign program-defined handlers in an enclave corrupts its state and violates execution integrity. 7 runtimes and library OSes (OpenEnclave, Gramine, Scone, Asylo, Teaclave, Occlum, EnclaveOS) are vulnerable to SIGY. 8 languages supported in Intel SGX have programming constructs that are vulnerable to SIGY. We use SIGY to demonstrate 4 proof of concept exploits on webservers (Nginx, Node.js) to leak secrets and data analytics workloads in different languages (C and Java) to break execution integrity.","sentences":["User programs recover from hardware exceptions and respond to signals by executing custom handlers that they register specifically for such events.","We present SIGY attack, which abuses this programming model on Intel SGX to break the confidentiality and integrity guarantees of enclaves.","SIGY uses the untrusted OS to deliver fake hardware events and injects fake signals in an enclave at any point.","Such unintended execution of benign program-defined handlers in an enclave corrupts its state and violates execution integrity.","7 runtimes and library OSes (OpenEnclave, Gramine, Scone, Asylo, Teaclave, Occlum, EnclaveOS) are vulnerable to SIGY.","8 languages supported in Intel SGX have programming constructs that are vulnerable to SIGY.","We use SIGY to demonstrate 4 proof of concept exploits on webservers (Nginx, Node.js) to leak secrets and data analytics workloads in different languages (C and Java) to break execution integrity."],"url":"http://arxiv.org/abs/2404.13998v1"}
{"created":"2024-04-22 09:02:21","title":"Engineering Edge Orientation Algorithms","abstract":"Given an undirected graph G, the edge orientation problem asks for assigning a direction to each edge to convert G into a directed graph. The aim is to minimize the maximum out degree of a vertex in the resulting directed graph. This problem, which is solvable in polynomial time, arises in many applications. An ongoing challenge in edge orientation algorithms is their scalability, particularly in handling large-scale networks with millions or billions of edges efficiently. We propose a novel algorithmic framework based on finding and manipulating simple paths to face this challenge. Our framework is based on an existing algorithm and allows many algorithmic choices. By carefully exploring these choices and engineering the underlying algorithms, we obtain an implementation which is more efficient and scalable than the current state-of-the-art. Our experiments demonstrate significant performance improvements compared to state-of-the-art solvers. On average our algorithm is 6.59 times faster when compared to the state-of-the-art.","sentences":["Given an undirected graph G, the edge orientation problem asks for assigning a direction to each edge to convert G into a directed graph.","The aim is to minimize the maximum out degree of a vertex in the resulting directed graph.","This problem, which is solvable in polynomial time, arises in many applications.","An ongoing challenge in edge orientation algorithms is their scalability, particularly in handling large-scale networks with millions or billions of edges efficiently.","We propose a novel algorithmic framework based on finding and manipulating simple paths to face this challenge.","Our framework is based on an existing algorithm and allows many algorithmic choices.","By carefully exploring these choices and engineering the underlying algorithms, we obtain an implementation which is more efficient and scalable than the current state-of-the-art.","Our experiments demonstrate significant performance improvements compared to state-of-the-art solvers.","On average our algorithm is 6.59 times faster when compared to the state-of-the-art."],"url":"http://arxiv.org/abs/2404.13997v1"}
{"created":"2024-04-22 08:59:35","title":"Zero-Shot Character Identification and Speaker Prediction in Comics via Iterative Multimodal Fusion","abstract":"Recognizing characters and predicting speakers of dialogue are critical for comic processing tasks, such as voice generation or translation. However, because characters vary by comic title, supervised learning approaches like training character classifiers which require specific annotations for each comic title are infeasible. This motivates us to propose a novel zero-shot approach, allowing machines to identify characters and predict speaker names based solely on unannotated comic images. In spite of their importance in real-world applications, these task have largely remained unexplored due to challenges in story comprehension and multimodal integration. Recent large language models (LLMs) have shown great capability for text understanding and reasoning, while their application to multimodal content analysis is still an open problem. To address this problem, we propose an iterative multimodal framework, the first to employ multimodal information for both character identification and speaker prediction tasks. Our experiments demonstrate the effectiveness of the proposed framework, establishing a robust baseline for these tasks. Furthermore, since our method requires no training data or annotations, it can be used as-is on any comic series.","sentences":["Recognizing characters and predicting speakers of dialogue are critical for comic processing tasks, such as voice generation or translation.","However, because characters vary by comic title, supervised learning approaches like training character classifiers which require specific annotations for each comic title are infeasible.","This motivates us to propose a novel zero-shot approach, allowing machines to identify characters and predict speaker names based solely on unannotated comic images.","In spite of their importance in real-world applications, these task have largely remained unexplored due to challenges in story comprehension and multimodal integration.","Recent large language models (LLMs) have shown great capability for text understanding and reasoning, while their application to multimodal content analysis is still an open problem.","To address this problem, we propose an iterative multimodal framework, the first to employ multimodal information for both character identification and speaker prediction tasks.","Our experiments demonstrate the effectiveness of the proposed framework, establishing a robust baseline for these tasks.","Furthermore, since our method requires no training data or annotations, it can be used as-is on any comic series."],"url":"http://arxiv.org/abs/2404.13993v1"}
{"created":"2024-04-22 08:57:46","title":"QCore: Data-Efficient, On-Device Continual Calibration for Quantized Models -- Extended Version","abstract":"We are witnessing an increasing availability of streaming data that may contain valuable information on the underlying processes. It is thus attractive to be able to deploy machine learning models on edge devices near sensors such that decisions can be made instantaneously, rather than first having to transmit incoming data to servers. To enable deployment on edge devices with limited storage and computational capabilities, the full-precision parameters in standard models can be quantized to use fewer bits. The resulting quantized models are then calibrated using back-propagation and full training data to ensure accuracy. This one-time calibration works for deployments in static environments. However, model deployment in dynamic edge environments call for continual calibration to adaptively adjust quantized models to fit new incoming data, which may have different distributions. The first difficulty in enabling continual calibration on the edge is that the full training data may be too large and thus not always available on edge devices. The second difficulty is that the use of back-propagation on the edge for repeated calibration is too expensive. We propose QCore to enable continual calibration on the edge. First, it compresses the full training data into a small subset to enable effective calibration of quantized models with different bit-widths. We also propose means of updating the subset when new streaming data arrives to reflect changes in the environment, while not forgetting earlier training data. Second, we propose a small bit-flipping network that works with the subset to update quantized model parameters, thus enabling efficient continual calibration without back-propagation. An experimental study, conducted with real-world data in a continual learning setting, offers insight into the properties of QCore and shows that it is capable of outperforming strong baseline methods.","sentences":["We are witnessing an increasing availability of streaming data that may contain valuable information on the underlying processes.","It is thus attractive to be able to deploy machine learning models on edge devices near sensors such that decisions can be made instantaneously, rather than first having to transmit incoming data to servers.","To enable deployment on edge devices with limited storage and computational capabilities, the full-precision parameters in standard models can be quantized to use fewer bits.","The resulting quantized models are then calibrated using back-propagation and full training data to ensure accuracy.","This one-time calibration works for deployments in static environments.","However, model deployment in dynamic edge environments call for continual calibration to adaptively adjust quantized models to fit new incoming data, which may have different distributions.","The first difficulty in enabling continual calibration on the edge is that the full training data may be too large and thus not always available on edge devices.","The second difficulty is that the use of back-propagation on the edge for repeated calibration is too expensive.","We propose QCore to enable continual calibration on the edge.","First, it compresses the full training data into a small subset to enable effective calibration of quantized models with different bit-widths.","We also propose means of updating the subset when new streaming data arrives to reflect changes in the environment, while not forgetting earlier training data.","Second, we propose a small bit-flipping network that works with the subset to update quantized model parameters, thus enabling efficient continual calibration without back-propagation.","An experimental study, conducted with real-world data in a continual learning setting, offers insight into the properties of QCore and shows that it is capable of outperforming strong baseline methods."],"url":"http://arxiv.org/abs/2404.13990v1"}
{"created":"2024-04-22 08:44:34","title":"RHanDS: Refining Malformed Hands for Generated Images with Decoupled Structure and Style Guidance","abstract":"Although diffusion models can generate high-quality human images, their applications are limited by the instability in generating hands with correct structures. Some previous works mitigate the problem by considering hand structure yet struggle to maintain style consistency between refined malformed hands and other image regions. In this paper, we aim to solve the problem of inconsistency regarding hand structure and style. We propose a conditional diffusion-based framework RHanDS to refine the hand region with the help of decoupled structure and style guidance. Specifically, the structure guidance is the hand mesh reconstructed from the malformed hand, serving to correct the hand structure. The style guidance is a hand image, e.g., the malformed hand itself, and is employed to furnish the style reference for hand refining. In order to suppress the structure leakage when referencing hand style and effectively utilize hand data to improve the capability of the model, we build a multi-style hand dataset and introduce a twostage training strategy. In the first stage, we use paired hand images for training to generate hands with the same style as the reference. In the second stage, various hand images generated based on the human mesh are used for training to enable the model to gain control over the hand structure. We evaluate our method and counterparts on the test dataset of the proposed multi-style hand dataset. The experimental results show that RHanDS can effectively refine hands structure- and style- correctly compared with previous methods. The codes and datasets will be available soon.","sentences":["Although diffusion models can generate high-quality human images, their applications are limited by the instability in generating hands with correct structures.","Some previous works mitigate the problem by considering hand structure yet struggle to maintain style consistency between refined malformed hands and other image regions.","In this paper, we aim to solve the problem of inconsistency regarding hand structure and style.","We propose a conditional diffusion-based framework RHanDS to refine the hand region with the help of decoupled structure and style guidance.","Specifically, the structure guidance is the hand mesh reconstructed from the malformed hand, serving to correct the hand structure.","The style guidance is a hand image, e.g., the malformed hand itself, and is employed to furnish the style reference for hand refining.","In order to suppress the structure leakage when referencing hand style and effectively utilize hand data to improve the capability of the model, we build a multi-style hand dataset and introduce a twostage training strategy.","In the first stage, we use paired hand images for training to generate hands with the same style as the reference.","In the second stage, various hand images generated based on the human mesh are used for training to enable the model to gain control over the hand structure.","We evaluate our method and counterparts on the test dataset of the proposed multi-style hand dataset.","The experimental results show that RHanDS can effectively refine hands structure- and style- correctly compared with previous methods.","The codes and datasets will be available soon."],"url":"http://arxiv.org/abs/2404.13984v1"}
{"created":"2024-04-22 08:41:43","title":"Modelling Technique for GDPR-compliance: Toward a Comprehensive Solution","abstract":"Data-driven applications and services have been increasingly deployed in all aspects of life including healthcare and medical services in which a huge amount of personal data is collected, aggregated, and processed in a centralised server from various sources. As a consequence, preserving the data privacy and security of these applications is of paramount importance. Since May 2018, the new data protection legislation in the EU/UK, namely the General Data Protection Regulation (GDPR), has come into force and this has called for a critical need for modelling compliance with the GDPR's sophisticated requirements. Existing threat modelling techniques are not designed to model GDPR compliance, particularly in a complex system where personal data is collected, processed, manipulated, and shared with third parties. In this paper, we present a novel comprehensive solution for developing a threat modelling technique to address threats of non-compliance and mitigate them by taking GDPR requirements as the baseline and combining them with the existing security and privacy modelling techniques (i.e., \\textit{STRIDE} and \\textit{LINDDUN}, respectively). For this purpose, we propose a new data flow diagram integrated with the GDPR principles, develop a knowledge base for the non-compliance threats, and leverage an inference engine for reasoning the GDPR non-compliance threats over the knowledge base. Finally, we demonstrate our solution for threats of non-compliance with legal basis and accountability in a telehealth system to show the feasibility and effectiveness of the proposed solution.","sentences":["Data-driven applications and services have been increasingly deployed in all aspects of life including healthcare and medical services in which a huge amount of personal data is collected, aggregated, and processed in a centralised server from various sources.","As a consequence, preserving the data privacy and security of these applications is of paramount importance.","Since May 2018, the new data protection legislation in the EU/UK, namely the General Data Protection Regulation (GDPR), has come into force and this has called for a critical need for modelling compliance with the GDPR's sophisticated requirements.","Existing threat modelling techniques are not designed to model GDPR compliance, particularly in a complex system where personal data is collected, processed, manipulated, and shared with third parties.","In this paper, we present a novel comprehensive solution for developing a threat modelling technique to address threats of non-compliance and mitigate them by taking GDPR requirements as the baseline and combining them with the existing security and privacy modelling techniques (i.e., \\textit{STRIDE} and \\textit{LINDDUN}, respectively).","For this purpose, we propose a new data flow diagram integrated with the GDPR principles, develop a knowledge base for the non-compliance threats, and leverage an inference engine for reasoning the GDPR non-compliance threats over the knowledge base.","Finally, we demonstrate our solution for threats of non-compliance with legal basis and accountability in a telehealth system to show the feasibility and effectiveness of the proposed solution."],"url":"http://arxiv.org/abs/2404.13979v1"}
{"created":"2024-04-22 08:10:38","title":"An Economic Solution to Copyright Challenges of Generative AI","abstract":"Generative artificial intelligence (AI) systems are trained on large data corpora to generate new pieces of text, images, videos, and other media. There is growing concern that such systems may infringe on the copyright interests of training data contributors. To address the copyright challenges of generative AI, we propose a framework that compensates copyright owners proportionally to their contributions to the creation of AI-generated content. The metric for contributions is quantitatively determined by leveraging the probabilistic nature of modern generative AI models and using techniques from cooperative game theory in economics. This framework enables a platform where AI developers benefit from access to high-quality training data, thus improving model performance. Meanwhile, copyright owners receive fair compensation, driving the continued provision of relevant data for generative model training. Experiments demonstrate that our framework successfully identifies the most relevant data sources used in artwork generation, ensuring a fair and interpretable distribution of revenues among copyright owners.","sentences":["Generative artificial intelligence (AI) systems are trained on large data corpora to generate new pieces of text, images, videos, and other media.","There is growing concern that such systems may infringe on the copyright interests of training data contributors.","To address the copyright challenges of generative AI, we propose a framework that compensates copyright owners proportionally to their contributions to the creation of AI-generated content.","The metric for contributions is quantitatively determined by leveraging the probabilistic nature of modern generative AI models and using techniques from cooperative game theory in economics.","This framework enables a platform where AI developers benefit from access to high-quality training data, thus improving model performance.","Meanwhile, copyright owners receive fair compensation, driving the continued provision of relevant data for generative model training.","Experiments demonstrate that our framework successfully identifies the most relevant data sources used in artwork generation, ensuring a fair and interpretable distribution of revenues among copyright owners."],"url":"http://arxiv.org/abs/2404.13964v1"}
{"created":"2024-04-22 07:54:56","title":"A survey of air combat behavior modeling using machine learning","abstract":"With the recent advances in machine learning, creating agents that behave realistically in simulated air combat has become a growing field of interest. This survey explores the application of machine learning techniques for modeling air combat behavior, motivated by the potential to enhance simulation-based pilot training. Current simulated entities tend to lack realistic behavior, and traditional behavior modeling is labor-intensive and prone to loss of essential domain knowledge between development steps. Advancements in reinforcement learning and imitation learning algorithms have demonstrated that agents may learn complex behavior from data, which could be faster and more scalable than manual methods. Yet, making adaptive agents capable of performing tactical maneuvers and operating weapons and sensors still poses a significant challenge. The survey examines applications, behavior model types, prevalent machine learning methods, and the technical and human challenges in developing adaptive and realistically behaving agents. Another challenge is the transfer of agents from learning environments to military simulation systems and the consequent demand for standardization. Four primary recommendations are presented regarding increased emphasis on beyond-visual-range scenarios, multi-agent machine learning and cooperation, utilization of hierarchical behavior models, and initiatives for standardization and research collaboration. These recommendations aim to address current issues and guide the development of more comprehensive, adaptable, and realistic machine learning-based behavior models for air combat applications.","sentences":["With the recent advances in machine learning, creating agents that behave realistically in simulated air combat has become a growing field of interest.","This survey explores the application of machine learning techniques for modeling air combat behavior, motivated by the potential to enhance simulation-based pilot training.","Current simulated entities tend to lack realistic behavior, and traditional behavior modeling is labor-intensive and prone to loss of essential domain knowledge between development steps.","Advancements in reinforcement learning and imitation learning algorithms have demonstrated that agents may learn complex behavior from data, which could be faster and more scalable than manual methods.","Yet, making adaptive agents capable of performing tactical maneuvers and operating weapons and sensors still poses a significant challenge.","The survey examines applications, behavior model types, prevalent machine learning methods, and the technical and human challenges in developing adaptive and realistically behaving agents.","Another challenge is the transfer of agents from learning environments to military simulation systems and the consequent demand for standardization.","Four primary recommendations are presented regarding increased emphasis on beyond-visual-range scenarios, multi-agent machine learning and cooperation, utilization of hierarchical behavior models, and initiatives for standardization and research collaboration.","These recommendations aim to address current issues and guide the development of more comprehensive, adaptable, and realistic machine learning-based behavior models for air combat applications."],"url":"http://arxiv.org/abs/2404.13954v1"}
{"created":"2024-04-22 07:50:24","title":"PeLiCal: Targetless Extrinsic Calibration via Penetrating Lines for RGB-D Cameras with Limited Co-visibility","abstract":"RGB-D cameras are crucial in robotic perception, given their ability to produce images augmented with depth data. However, their limited FOV often requires multiple cameras to cover a broader area. In multi-camera RGB-D setups, the goal is typically to reduce camera overlap, optimizing spatial coverage with as few cameras as possible. The extrinsic calibration of these systems introduces additional complexities. Existing methods for extrinsic calibration either necessitate specific tools or highly depend on the accuracy of camera motion estimation. To address these issues, we present PeLiCal, a novel line-based calibration approach for RGB-D camera systems exhibiting limited overlap. Our method leverages long line features from surroundings, and filters out outliers with a novel convergence voting algorithm, achieving targetless, real-time, and outlier-robust performance compared to existing methods. We open source our implementation on \\url{https://github.com/joomeok/PeLiCal.git}.","sentences":["RGB-D cameras are crucial in robotic perception, given their ability to produce images augmented with depth data.","However, their limited FOV often requires multiple cameras to cover a broader area.","In multi-camera RGB-D setups, the goal is typically to reduce camera overlap, optimizing spatial coverage with as few cameras as possible.","The extrinsic calibration of these systems introduces additional complexities.","Existing methods for extrinsic calibration either necessitate specific tools or highly depend on the accuracy of camera motion estimation.","To address these issues, we present PeLiCal, a novel line-based calibration approach for RGB-D camera systems exhibiting limited overlap.","Our method leverages long line features from surroundings, and filters out outliers with a novel convergence voting algorithm, achieving targetless, real-time, and outlier-robust performance compared to existing methods.","We open source our implementation on \\url{https://github.com/joomeok/PeLiCal.git}."],"url":"http://arxiv.org/abs/2404.13949v1"}
{"created":"2024-04-22 07:44:02","title":"Dual Model Replacement:invisible Multi-target Backdoor Attack based on Federal Learning","abstract":"In recent years, the neural network backdoor hidden in the parameters of the federated learning model has been proved to have great security risks. Considering the characteristics of trigger generation, data poisoning and model training in backdoor attack, this paper designs a backdoor attack method based on federated learning. Firstly, aiming at the concealment of the backdoor trigger, a TrojanGan steganography model with encoder-decoder structure is designed. The model can encode specific attack information as invisible noise and attach it to the image as a backdoor trigger, which improves the concealment and data transformations of the backdoor trigger.Secondly, aiming at the problem of single backdoor trigger mode, an image poisoning attack method called combination trigger attack is proposed. This method realizes multi-backdoor triggering by multiplexing combined triggers and improves the robustness of backdoor attacks. Finally, aiming at the problem that the local training mechanism leads to the decrease of the success rate of backdoor attack, a dual model replacement backdoor attack algorithm based on federated learning is designed. This method can improve the success rate of backdoor attack while maintaining the performance of the federated learning aggregation model. Experiments show that the attack strategy in this paper can not only achieve high backdoor concealment and diversification of trigger forms under federated learning, but also achieve good attack success rate in multi-target attacks.door concealment and diversification of trigger forms but also achieve good results in multi-target attacks.","sentences":["In recent years, the neural network backdoor hidden in the parameters of the federated learning model has been proved to have great security risks.","Considering the characteristics of trigger generation, data poisoning and model training in backdoor attack, this paper designs a backdoor attack method based on federated learning.","Firstly, aiming at the concealment of the backdoor trigger, a TrojanGan steganography model with encoder-decoder structure is designed.","The model can encode specific attack information as invisible noise and attach it to the image as a backdoor trigger, which improves the concealment and data transformations of the backdoor trigger.","Secondly, aiming at the problem of single backdoor trigger mode, an image poisoning attack method called combination trigger attack is proposed.","This method realizes multi-backdoor triggering by multiplexing combined triggers and improves the robustness of backdoor attacks.","Finally, aiming at the problem that the local training mechanism leads to the decrease of the success rate of backdoor attack, a dual model replacement backdoor attack algorithm based on federated learning is designed.","This method can improve the success rate of backdoor attack while maintaining the performance of the federated learning aggregation model.","Experiments show that the attack strategy in this paper can not only achieve high backdoor concealment and diversification of trigger forms under federated learning, but also achieve good attack success rate in multi-target attacks.door concealment and diversification of trigger forms but also achieve good results in multi-target attacks."],"url":"http://arxiv.org/abs/2404.13946v1"}
{"created":"2024-04-22 07:01:19","title":"ActSonic: Everyday Activity Recognition on Smart Glasses using Active Acoustic Sensing","abstract":"In this paper, we introduce ActSonic, an intelligent, low-power active acoustic sensing system integrated into eyeglasses. ActSonic is designed to recognize 27 different everyday activities (e.g., eating, drinking, toothbrushing). It only needs a pair of miniature speakers and microphones mounted on each hinge of eyeglasses to emit ultrasonic waves to create an acoustic aura around the body. Based on the position and motion of various body parts, the acoustic signals are reflected with unique patterns captured by the microphone and analyzed by a customized self-supervised deep learning framework to infer the performed activities. ActSonic was deployed in a user study with 19 participants across 19 households to evaluate its efficacy. Without requiring any training data from a new user (leave-one-participant-out evaluation), ActSonic was able to detect 27 activities with an inference resolution of 1 second, achieving an average F1-score of 86.6% in an unconstrained setting and 93.4% in a prompted setting.","sentences":["In this paper, we introduce ActSonic, an intelligent, low-power active acoustic sensing system integrated into eyeglasses.","ActSonic is designed to recognize 27 different everyday activities (e.g., eating, drinking, toothbrushing).","It only needs a pair of miniature speakers and microphones mounted on each hinge of eyeglasses to emit ultrasonic waves to create an acoustic aura around the body.","Based on the position and motion of various body parts, the acoustic signals are reflected with unique patterns captured by the microphone and analyzed by a customized self-supervised deep learning framework to infer the performed activities.","ActSonic was deployed in a user study with 19 participants across 19 households to evaluate its efficacy.","Without requiring any training data from a new user (leave-one-participant-out evaluation), ActSonic was able to detect 27 activities with an inference resolution of 1 second, achieving an average F1-score of 86.6% in an unconstrained setting and 93.4% in a prompted setting."],"url":"http://arxiv.org/abs/2404.13924v1"}
{"created":"2024-04-22 06:43:18","title":"Global OpenBuildingMap -- Unveiling the Mystery of Global Buildings","abstract":"Understanding how buildings are distributed globally is crucial to revealing the human footprint on our home planet. This built environment affects local climate, land surface albedo, resource distribution, and many other key factors that influence well-being and human health. Despite this, quantitative and comprehensive data on the distribution and properties of buildings worldwide is lacking. To this end, by using a big data analytics approach and nearly 800,000 satellite images, we generated the highest resolution and highest accuracy building map ever created: the Global OpenBuildingMap (Global OBM). A joint analysis of building maps and solar potentials indicates that rooftop solar energy can supply the global energy consumption need at a reasonable cost. Specifically, if solar panels were placed on the roofs of all buildings, they could supply 1.1-3.3 times -- depending on the efficiency of the solar device -- the global energy consumption in 2020, which is the year with the highest consumption on record. We also identified a clear geospatial correlation between building areas and key socioeconomic variables, which indicates our global building map can serve as an important input to modeling global socioeconomic needs and drivers.","sentences":["Understanding how buildings are distributed globally is crucial to revealing the human footprint on our home planet.","This built environment affects local climate, land surface albedo, resource distribution, and many other key factors that influence well-being and human health.","Despite this, quantitative and comprehensive data on the distribution and properties of buildings worldwide is lacking.","To this end, by using a big data analytics approach and nearly 800,000 satellite images, we generated the highest resolution and highest accuracy building map ever created: the Global OpenBuildingMap (Global OBM).","A joint analysis of building maps and solar potentials indicates that rooftop solar energy can supply the global energy consumption need at a reasonable cost.","Specifically, if solar panels were placed on the roofs of all buildings, they could supply 1.1-3.3 times -- depending on the efficiency of the solar device -- the global energy consumption in 2020, which is the year with the highest consumption on record.","We also identified a clear geospatial correlation between building areas and key socioeconomic variables, which indicates our global building map can serve as an important input to modeling global socioeconomic needs and drivers."],"url":"http://arxiv.org/abs/2404.13911v1"}
{"created":"2024-04-22 06:41:26","title":"Physics-informed neural networks with curriculum training for poroelastic flow and deformation processes","abstract":"Physics-Informed Neural Networks (PINNs) have emerged as a highly active research topic across multiple disciplines in science and engineering, including computational geomechanics. PINNs offer a promising approach in different applications where faster, near real-time or real-time numerical prediction is required. Examples of such areas in geomechanics include geotechnical design optimization, digital twins of geo-structures and stability prediction of monitored slopes. But there remain challenges in training of PINNs, especially for problems with high spatial and temporal complexity. In this paper, we study how the training of PINNs can be improved by using an ideal-ized poroelasticity problem as a demonstration example. A curriculum training strat-egy is employed where the PINN model is trained gradually by dividing the training data into intervals along the temporal dimension. We find that the PINN model with curriculum training takes nearly half the time required for training compared to con-ventional training over the whole solution domain. For the particular example here, the quality of the predicted solution was found to be good in both training approach-es, but it is anticipated that the curriculum training approach has the potential to offer a better prediction capability for more complex problems, a subject for further research.","sentences":["Physics-Informed Neural Networks (PINNs) have emerged as a highly active research topic across multiple disciplines in science and engineering, including computational geomechanics.","PINNs offer a promising approach in different applications where faster, near real-time or real-time numerical prediction is required.","Examples of such areas in geomechanics include geotechnical design optimization, digital twins of geo-structures and stability prediction of monitored slopes.","But there remain challenges in training of PINNs, especially for problems with high spatial and temporal complexity.","In this paper, we study how the training of PINNs can be improved by using an ideal-ized poroelasticity problem as a demonstration example.","A curriculum training strat-egy is employed where the PINN model is trained gradually by dividing the training data into intervals along the temporal dimension.","We find that the PINN model with curriculum training takes nearly half the time required for training compared to con-ventional training over the whole solution domain.","For the particular example here, the quality of the predicted solution was found to be good in both training approach-es, but it is anticipated that the curriculum training approach has the potential to offer a better prediction capability for more complex problems, a subject for further research."],"url":"http://arxiv.org/abs/2404.13909v1"}
{"created":"2024-04-22 06:36:27","title":"Faster Algorithms for Dual-Failure Replacement Paths","abstract":"Given a simple weighted directed graph $G = (V, E, \\omega)$ on $n$ vertices as well as two designated terminals $s, t\\in V$, our goal is to compute the shortest path from $s$ to $t$ avoiding any pair of presumably failed edges $f_1, f_2\\in E$, which is a natural generalization of the classical replacement path problem which considers single edge failures only.   This dual failure replacement paths problem was recently studied by Vassilevska Williams, Woldeghebriel and Xu [FOCS 2022] who designed a cubic time algorithm for general weighted digraphs which is conditionally optimal; in the same paper, for unweighted graphs where $\\omega \\equiv 1$, the authors presented an algebraic algorithm with runtime $\\tilde{O}(n^{2.9146})$, as well as a conditional lower bound of $n^{8/3-o(1)}$ against combinatorial algorithms. However, it was unknown in their work whether fast matrix multiplication is necessary for a subcubic runtime in unweighted digraphs.   As our primary result, we present the first truly subcubic combinatorial algorithm for dual failure replacement paths in unweighted digraphs. Our runtime is $\\tilde{O}(n^{3-1/18})$. Besides, we also study algebraic algorithms for digraphs with small integer edge weights from $\\{-M, -M+1, \\cdots, M-1, M\\}$. As our secondary result, we obtained a runtime of $\\tilde{O}(Mn^{2.8716})$, which is faster than the previous bound of $\\tilde{O}(M^{2/3}n^{2.9144} + Mn^{2.8716})$ from [Vassilevska Williams, Woldeghebriela and Xu, 2022].","sentences":["Given a simple weighted directed graph $G = (V, E, \\omega)$ on $n$ vertices as well as two designated terminals $s, t\\in V$, our goal is to compute the shortest path from $s$ to $t$ avoiding any pair of presumably failed edges $f_1, f_2\\in E$, which is a natural generalization of the classical replacement path problem which considers single edge failures only.   ","This dual failure replacement paths problem was recently studied by Vassilevska Williams, Woldeghebriel and Xu","[FOCS 2022] who designed a cubic time algorithm for general weighted digraphs which is conditionally optimal; in the same paper, for unweighted graphs where $\\omega \\equiv 1$, the authors presented an algebraic algorithm with runtime $\\tilde{O}(n^{2.9146})$, as well as a conditional lower bound of $n^{8/3-o(1)}$ against combinatorial algorithms.","However, it was unknown in their work whether fast matrix multiplication is necessary for a subcubic runtime in unweighted digraphs.   ","As our primary result, we present the first truly subcubic combinatorial algorithm for dual failure replacement paths in unweighted digraphs.","Our runtime is $\\tilde{O}(n^{3-1/18})$.","Besides, we also study algebraic algorithms for digraphs with small integer edge weights from $\\{-M, -M+1, \\cdots, M-1, M\\}$.","As our secondary result, we obtained a runtime of $\\tilde{O}(Mn^{2.8716})$, which is faster than the previous bound of $\\tilde{O}(M^{2/3}n^{2.9144} + Mn^{2.8716})$ from [Vassilevska Williams, Woldeghebriela and Xu, 2022]."],"url":"http://arxiv.org/abs/2404.13907v1"}
{"created":"2024-04-22 06:18:37","title":"Towards Better Text-to-Image Generation Alignment via Attention Modulation","abstract":"In text-to-image generation tasks, the advancements of diffusion models have facilitated the fidelity of generated results. However, these models encounter challenges when processing text prompts containing multiple entities and attributes. The uneven distribution of attention results in the issues of entity leakage and attribute misalignment. Training from scratch to address this issue requires numerous labeled data and is resource-consuming. Motivated by this, we propose an attribution-focusing mechanism, a training-free phase-wise mechanism by modulation of attention for diffusion model. One of our core ideas is to guide the model to concentrate on the corresponding syntactic components of the prompt at distinct timesteps. To achieve this, we incorporate a temperature control mechanism within the early phases of the self-attention modules to mitigate entity leakage issues. An object-focused masking scheme and a phase-wise dynamic weight control mechanism are integrated into the cross-attention modules, enabling the model to discern the affiliation of semantic information between entities more effectively. The experimental results in various alignment scenarios demonstrate that our model attain better image-text alignment with minimal additional computational cost.","sentences":["In text-to-image generation tasks, the advancements of diffusion models have facilitated the fidelity of generated results.","However, these models encounter challenges when processing text prompts containing multiple entities and attributes.","The uneven distribution of attention results in the issues of entity leakage and attribute misalignment.","Training from scratch to address this issue requires numerous labeled data and is resource-consuming.","Motivated by this, we propose an attribution-focusing mechanism, a training-free phase-wise mechanism by modulation of attention for diffusion model.","One of our core ideas is to guide the model to concentrate on the corresponding syntactic components of the prompt at distinct timesteps.","To achieve this, we incorporate a temperature control mechanism within the early phases of the self-attention modules to mitigate entity leakage issues.","An object-focused masking scheme and a phase-wise dynamic weight control mechanism are integrated into the cross-attention modules, enabling the model to discern the affiliation of semantic information between entities more effectively.","The experimental results in various alignment scenarios demonstrate that our model attain better image-text alignment with minimal additional computational cost."],"url":"http://arxiv.org/abs/2404.13899v1"}
{"created":"2024-04-22 06:05:35","title":"Optimal Design for Human Feedback","abstract":"Learning of preference models from human feedback has been central to recent advances in artificial intelligence. Motivated by this progress, and the cost of obtaining high-quality human annotations, we study the problem of data collection for learning preference models. The key idea in our work is to generalize optimal designs, a tool for computing efficient data logging policies, to ranked lists. To show the generality of our ideas, we study both absolute and relative feedback on items in the list. We design efficient algorithms for both settings and analyze them. We prove that our preference model estimators improve with more data and so does the ranking error under the estimators. Finally, we experiment with several synthetic and real-world datasets to show the statistical efficiency of our algorithms.","sentences":["Learning of preference models from human feedback has been central to recent advances in artificial intelligence.","Motivated by this progress, and the cost of obtaining high-quality human annotations, we study the problem of data collection for learning preference models.","The key idea in our work is to generalize optimal designs, a tool for computing efficient data logging policies, to ranked lists.","To show the generality of our ideas, we study both absolute and relative feedback on items in the list.","We design efficient algorithms for both settings and analyze them.","We prove that our preference model estimators improve with more data and so does the ranking error under the estimators.","Finally, we experiment with several synthetic and real-world datasets to show the statistical efficiency of our algorithms."],"url":"http://arxiv.org/abs/2404.13895v1"}
{"created":"2024-04-22 05:23:25","title":"Taming Server Memory TCO with Multiple Software-Defined Compressed Tiers","abstract":"Memory accounts for 33 - 50% of the total cost of ownership (TCO) in modern data centers. We propose a novel solution to tame memory TCO through the novel creation and judicious management of multiple software-defined compressed memory tiers.   As opposed to the state-of-the-art solutions that employ a 2-Tier solution, a single compressed tier along with DRAM, we define multiple compressed tiers implemented through a combination of different compression algorithms, memory allocators for compressed objects, and backing media to store compressed objects. These compressed memory tiers represent distinct points in the access latency, data compressibility, and unit memory usage cost spectrum, allowing rich and flexible trade-offs between memory TCO savings and application performance impact. A key advantage with ntier is that it enables aggressive memory TCO saving opportunities by placing warm data in low latency compressed tiers with a reasonable performance impact while simultaneously placing cold data in the best memory TCO saving tiers. We believe our work represents an important server system configuration and optimization capability to achieve the best SLA-aware performance per dollar for applications hosted in production data center environments.   We present a comprehensive and rigorous analytical cost model for performance and TCO trade-off based on continuous monitoring of the application's data access profile. Guided by this model, our placement model takes informed actions to dynamically manage the placement and migration of application data across multiple software-defined compressed tiers. On real-world benchmarks, our solution increases memory TCO savings by 22% - 40% percentage points while maintaining performance parity or improves performance by 2% - 10% percentage points while maintaining memory TCO parity compared to state-of-the-art 2-Tier solutions.","sentences":["Memory accounts for 33 - 50% of the total cost of ownership (TCO) in modern data centers.","We propose a novel solution to tame memory TCO through the novel creation and judicious management of multiple software-defined compressed memory tiers.   ","As opposed to the state-of-the-art solutions that employ a 2-Tier solution, a single compressed tier along with DRAM, we define multiple compressed tiers implemented through a combination of different compression algorithms, memory allocators for compressed objects, and backing media to store compressed objects.","These compressed memory tiers represent distinct points in the access latency, data compressibility, and unit memory usage cost spectrum, allowing rich and flexible trade-offs between memory TCO savings and application performance impact.","A key advantage with ntier is that it enables aggressive memory TCO saving opportunities by placing warm data in low latency compressed tiers with a reasonable performance impact while simultaneously placing cold data in the best memory TCO saving tiers.","We believe our work represents an important server system configuration and optimization capability to achieve the best SLA-aware performance per dollar for applications hosted in production data center environments.   ","We present a comprehensive and rigorous analytical cost model for performance and TCO trade-off based on continuous monitoring of the application's data access profile.","Guided by this model, our placement model takes informed actions to dynamically manage the placement and migration of application data across multiple software-defined compressed tiers.","On real-world benchmarks, our solution increases memory TCO savings by 22% - 40% percentage points while maintaining performance parity or improves performance by 2% - 10% percentage points while maintaining memory TCO parity compared to state-of-the-art 2-Tier solutions."],"url":"http://arxiv.org/abs/2404.13886v1"}
{"created":"2024-04-22 05:12:52","title":"Surveying Attitudinal Alignment Between Large Language Models Vs. Humans Towards 17 Sustainable Development Goals","abstract":"Large Language Models (LLMs) have emerged as potent tools for advancing the United Nations' Sustainable Development Goals (SDGs). However, the attitudinal disparities between LLMs and humans towards these goals can pose significant challenges. This study conducts a comprehensive review and analysis of the existing literature on the attitudes of LLMs towards the 17 SDGs, emphasizing the comparison between their attitudes and support for each goal and those of humans. We examine the potential disparities, primarily focusing on aspects such as understanding and emotions, cultural and regional differences, task objective variations, and factors considered in the decision-making process. These disparities arise from the underrepresentation and imbalance in LLM training data, historical biases, quality issues, lack of contextual understanding, and skewed ethical values reflected. The study also investigates the risks and harms that may arise from neglecting the attitudes of LLMs towards the SDGs, including the exacerbation of social inequalities, racial discrimination, environmental destruction, and resource wastage. To address these challenges, we propose strategies and recommendations to guide and regulate the application of LLMs, ensuring their alignment with the principles and goals of the SDGs, and therefore creating a more just, inclusive, and sustainable future.","sentences":["Large Language Models (LLMs) have emerged as potent tools for advancing the United Nations' Sustainable Development Goals (SDGs).","However, the attitudinal disparities between LLMs and humans towards these goals can pose significant challenges.","This study conducts a comprehensive review and analysis of the existing literature on the attitudes of LLMs towards the 17 SDGs, emphasizing the comparison between their attitudes and support for each goal and those of humans.","We examine the potential disparities, primarily focusing on aspects such as understanding and emotions, cultural and regional differences, task objective variations, and factors considered in the decision-making process.","These disparities arise from the underrepresentation and imbalance in LLM training data, historical biases, quality issues, lack of contextual understanding, and skewed ethical values reflected.","The study also investigates the risks and harms that may arise from neglecting the attitudes of LLMs towards the SDGs, including the exacerbation of social inequalities, racial discrimination, environmental destruction, and resource wastage.","To address these challenges, we propose strategies and recommendations to guide and regulate the application of LLMs, ensuring their alignment with the principles and goals of the SDGs, and therefore creating a more just, inclusive, and sustainable future."],"url":"http://arxiv.org/abs/2404.13885v1"}
{"created":"2024-04-22 04:49:22","title":"VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large Vision-Language Models","abstract":"Large Vision-Language Models (LVLMs) suffer from hallucination issues, wherein the models generate plausible-sounding but factually incorrect outputs, undermining their reliability. A comprehensive quantitative evaluation is necessary to identify and understand the extent of hallucinations in these models. However, existing benchmarks are often limited in scope, focusing mainly on object hallucinations. Furthermore, current evaluation methods struggle to effectively address the subtle semantic distinctions between model outputs and reference data, as well as the balance between hallucination and informativeness. To address these issues, we introduce a multi-dimensional benchmark covering objects, attributes, and relations, with challenging images selected based on associative biases. Moreover, we propose an large language model (LLM)-based two-stage evaluation framework that generalizes the popular CHAIR metric and incorporates both faithfulness and coverage into the evaluation. Experiments on 10 established LVLMs demonstrate that our evaluation metric is more comprehensive and better correlated with humans than existing work when evaluating on our challenging human annotated benchmark dataset. Our work also highlights the critical balance between faithfulness and coverage of model outputs, and encourages future works to address hallucinations in LVLMs while keeping their outputs informative.","sentences":["Large Vision-Language Models (LVLMs) suffer from hallucination issues, wherein the models generate plausible-sounding but factually incorrect outputs, undermining their reliability.","A comprehensive quantitative evaluation is necessary to identify and understand the extent of hallucinations in these models.","However, existing benchmarks are often limited in scope, focusing mainly on object hallucinations.","Furthermore, current evaluation methods struggle to effectively address the subtle semantic distinctions between model outputs and reference data, as well as the balance between hallucination and informativeness.","To address these issues, we introduce a multi-dimensional benchmark covering objects, attributes, and relations, with challenging images selected based on associative biases.","Moreover, we propose an large language model (LLM)-based two-stage evaluation framework that generalizes the popular CHAIR metric and incorporates both faithfulness and coverage into the evaluation.","Experiments on 10 established LVLMs demonstrate that our evaluation metric is more comprehensive and better correlated with humans than existing work when evaluating on our challenging human annotated benchmark dataset.","Our work also highlights the critical balance between faithfulness and coverage of model outputs, and encourages future works to address hallucinations in LVLMs while keeping their outputs informative."],"url":"http://arxiv.org/abs/2404.13874v1"}
{"created":"2024-04-22 04:33:40","title":"TeamTrack: A Dataset for Multi-Sport Multi-Object Tracking in Full-pitch Videos","abstract":"Multi-object tracking (MOT) is a critical and challenging task in computer vision, particularly in situations involving objects with similar appearances but diverse movements, as seen in team sports. Current methods, largely reliant on object detection and appearance, often fail to track targets in such complex scenarios accurately. This limitation is further exacerbated by the lack of comprehensive and diverse datasets covering the full view of sports pitches. Addressing these issues, we introduce TeamTrack, a pioneering benchmark dataset specifically designed for MOT in sports. TeamTrack is an extensive collection of full-pitch video data from various sports, including soccer, basketball, and handball. Furthermore, we perform a comprehensive analysis and benchmarking effort to underscore TeamTrack's utility and potential impact. Our work signifies a crucial step forward, promising to elevate the precision and effectiveness of MOT in complex, dynamic settings such as team sports. The dataset, project code and competition is released at: https://atomscott.github.io/TeamTrack/.","sentences":["Multi-object tracking (MOT) is a critical and challenging task in computer vision, particularly in situations involving objects with similar appearances but diverse movements, as seen in team sports.","Current methods, largely reliant on object detection and appearance, often fail to track targets in such complex scenarios accurately.","This limitation is further exacerbated by the lack of comprehensive and diverse datasets covering the full view of sports pitches.","Addressing these issues, we introduce TeamTrack, a pioneering benchmark dataset specifically designed for MOT in sports.","TeamTrack is an extensive collection of full-pitch video data from various sports, including soccer, basketball, and handball.","Furthermore, we perform a comprehensive analysis and benchmarking effort to underscore TeamTrack's utility and potential impact.","Our work signifies a crucial step forward, promising to elevate the precision and effectiveness of MOT in complex, dynamic settings such as team sports.","The dataset, project code and competition is released at: https://atomscott.github.io/TeamTrack/."],"url":"http://arxiv.org/abs/2404.13868v1"}
{"created":"2024-04-22 04:30:36","title":"Context-Enhanced Language Models for Generating Multi-Paper Citations","abstract":"Citation text plays a pivotal role in elucidating the connection between scientific documents, demanding an in-depth comprehension of the cited paper. Constructing citations is often time-consuming, requiring researchers to delve into extensive literature and grapple with articulating relevant content. To address this challenge, the field of citation text generation (CTG) has emerged. However, while earlier methods have primarily centered on creating single-sentence citations, practical scenarios frequently necessitate citing multiple papers within a single paragraph. To bridge this gap, we propose a method that leverages Large Language Models (LLMs) to generate multi-citation sentences. Our approach involves a single source paper and a collection of target papers, culminating in a coherent paragraph containing multi-sentence citation text. Furthermore, we introduce a curated dataset named MCG-S2ORC, composed of English-language academic research papers in Computer Science, showcasing multiple citation instances. In our experiments, we evaluate three LLMs LLaMA, Alpaca, and Vicuna to ascertain the most effective model for this endeavor. Additionally, we exhibit enhanced performance by integrating knowledge graphs from target papers into the prompts for generating citation text. This research underscores the potential of harnessing LLMs for citation generation, opening a compelling avenue for exploring the intricate connections between scientific documents.","sentences":["Citation text plays a pivotal role in elucidating the connection between scientific documents, demanding an in-depth comprehension of the cited paper.","Constructing citations is often time-consuming, requiring researchers to delve into extensive literature and grapple with articulating relevant content.","To address this challenge, the field of citation text generation (CTG) has emerged.","However, while earlier methods have primarily centered on creating single-sentence citations, practical scenarios frequently necessitate citing multiple papers within a single paragraph.","To bridge this gap, we propose a method that leverages Large Language Models (LLMs) to generate multi-citation sentences.","Our approach involves a single source paper and a collection of target papers, culminating in a coherent paragraph containing multi-sentence citation text.","Furthermore, we introduce a curated dataset named MCG-S2ORC, composed of English-language academic research papers in Computer Science, showcasing multiple citation instances.","In our experiments, we evaluate three LLMs LLaMA, Alpaca, and Vicuna to ascertain the most effective model for this endeavor.","Additionally, we exhibit enhanced performance by integrating knowledge graphs from target papers into the prompts for generating citation text.","This research underscores the potential of harnessing LLMs for citation generation, opening a compelling avenue for exploring the intricate connections between scientific documents."],"url":"http://arxiv.org/abs/2404.13865v1"}
{"created":"2024-04-22 04:25:02","title":"PM-VIS: High-Performance Box-Supervised Video Instance Segmentation","abstract":"Labeling pixel-wise object masks in videos is a resource-intensive and laborious process. Box-supervised Video Instance Segmentation (VIS) methods have emerged as a viable solution to mitigate the labor-intensive annotation process. . In practical applications, the two-step approach is not only more flexible but also exhibits a higher recognition accuracy. Inspired by the recent success of Segment Anything Model (SAM), we introduce a novel approach that aims at harnessing instance box annotations from multiple perspectives to generate high-quality instance pseudo masks, thus enriching the information contained in instance annotations. We leverage ground-truth boxes to create three types of pseudo masks using the HQ-SAM model, the box-supervised VIS model (IDOL-BoxInst), and the VOS model (DeAOT) separately, along with three corresponding optimization mechanisms. Additionally, we introduce two ground-truth data filtering methods, assisted by high-quality pseudo masks, to further enhance the training dataset quality and improve the performance of fully supervised VIS methods. To fully capitalize on the obtained high-quality Pseudo Masks, we introduce a novel algorithm, PM-VIS, to integrate mask losses into IDOL-BoxInst. Our PM-VIS model, trained with high-quality pseudo mask annotations, demonstrates strong ability in instance mask prediction, achieving state-of-the-art performance on the YouTube-VIS 2019, YouTube-VIS 2021, and OVIS validation sets, notably narrowing the gap between box-supervised and fully supervised VIS methods.","sentences":["Labeling pixel-wise object masks in videos is a resource-intensive and laborious process.","Box-supervised Video Instance Segmentation (VIS) methods have emerged as a viable solution to mitigate the labor-intensive annotation process. .","In practical applications, the two-step approach is not only more flexible but also exhibits a higher recognition accuracy.","Inspired by the recent success of Segment Anything Model (SAM), we introduce a novel approach that aims at harnessing instance box annotations from multiple perspectives to generate high-quality instance pseudo masks, thus enriching the information contained in instance annotations.","We leverage ground-truth boxes to create three types of pseudo masks using the HQ-SAM model, the box-supervised VIS model (IDOL-BoxInst), and the VOS model (DeAOT) separately, along with three corresponding optimization mechanisms.","Additionally, we introduce two ground-truth data filtering methods, assisted by high-quality pseudo masks, to further enhance the training dataset quality and improve the performance of fully supervised VIS methods.","To fully capitalize on the obtained high-quality Pseudo Masks, we introduce a novel algorithm, PM-VIS, to integrate mask losses into IDOL-BoxInst.","Our PM-VIS model, trained with high-quality pseudo mask annotations, demonstrates strong ability in instance mask prediction, achieving state-of-the-art performance on the YouTube-VIS 2019, YouTube-VIS 2021, and OVIS validation sets, notably narrowing the gap between box-supervised and fully supervised VIS methods."],"url":"http://arxiv.org/abs/2404.13863v1"}
{"created":"2024-04-22 04:18:38","title":"Distributional Black-Box Model Inversion Attack with Multi-Agent Reinforcement Learning","abstract":"A Model Inversion (MI) attack based on Generative Adversarial Networks (GAN) aims to recover the private training data from complex deep learning models by searching codes in the latent space. However, they merely search a deterministic latent space such that the found latent code is usually suboptimal. In addition, the existing distributional MI schemes assume that an attacker can access the structures and parameters of the target model, which is not always viable in practice. To overcome the above shortcomings, this paper proposes a novel Distributional Black-Box Model Inversion (DBB-MI) attack by constructing the probabilistic latent space for searching the target privacy data. Specifically, DBB-MI does not need the target model parameters or specialized GAN training. Instead, it finds the latent probability distribution by combining the output of the target model with multi-agent reinforcement learning techniques. Then, it randomly chooses latent codes from the latent probability distribution for recovering the private data. As the latent probability distribution closely aligns with the target privacy data in latent space, the recovered data will leak the privacy of training samples of the target model significantly. Abundant experiments conducted on diverse datasets and networks show that the present DBB-MI has better performance than state-of-the-art in attack accuracy, K-nearest neighbor feature distance, and Peak Signal-to-Noise Ratio.","sentences":["A Model Inversion (MI) attack based on Generative Adversarial Networks (GAN) aims to recover the private training data from complex deep learning models by searching codes in the latent space.","However, they merely search a deterministic latent space such that the found latent code is usually suboptimal.","In addition, the existing distributional MI schemes assume that an attacker can access the structures and parameters of the target model, which is not always viable in practice.","To overcome the above shortcomings, this paper proposes a novel Distributional Black-Box Model Inversion (DBB-MI) attack by constructing the probabilistic latent space for searching the target privacy data.","Specifically, DBB-MI does not need the target model parameters or specialized GAN training.","Instead, it finds the latent probability distribution by combining the output of the target model with multi-agent reinforcement learning techniques.","Then, it randomly chooses latent codes from the latent probability distribution for recovering the private data.","As the latent probability distribution closely aligns with the target privacy data in latent space, the recovered data will leak the privacy of training samples of the target model significantly.","Abundant experiments conducted on diverse datasets and networks show that the present DBB-MI has better performance than state-of-the-art in attack accuracy, K-nearest neighbor feature distance, and Peak Signal-to-Noise Ratio."],"url":"http://arxiv.org/abs/2404.13860v1"}
{"created":"2024-04-22 03:39:03","title":"Self-Supervised Monocular Depth Estimation in the Dark: Towards Data Distribution Compensation","abstract":"Nighttime self-supervised monocular depth estimation has received increasing attention in recent years. However, using night images for self-supervision is unreliable because the photometric consistency assumption is usually violated in the videos taken under complex lighting conditions. Even with domain adaptation or photometric loss repair, performance is still limited by the poor supervision of night images on trainable networks. In this paper, we propose a self-supervised nighttime monocular depth estimation method that does not use any night images during training. Our framework utilizes day images as a stable source for self-supervision and applies physical priors (e.g., wave optics, reflection model and read-shot noise model) to compensate for some key day-night differences. With day-to-night data distribution compensation, our framework can be trained in an efficient one-stage self-supervised manner. Though no nighttime images are considered during training, qualitative and quantitative results demonstrate that our method achieves SoTA depth estimating results on the challenging nuScenes-Night and RobotCar-Night compared with existing methods.","sentences":["Nighttime self-supervised monocular depth estimation has received increasing attention in recent years.","However, using night images for self-supervision is unreliable because the photometric consistency assumption is usually violated in the videos taken under complex lighting conditions.","Even with domain adaptation or photometric loss repair, performance is still limited by the poor supervision of night images on trainable networks.","In this paper, we propose a self-supervised nighttime monocular depth estimation method that does not use any night images during training.","Our framework utilizes day images as a stable source for self-supervision and applies physical priors (e.g., wave optics, reflection model and read-shot noise model) to compensate for some key day-night differences.","With day-to-night data distribution compensation, our framework can be trained in an efficient one-stage self-supervised manner.","Though no nighttime images are considered during training, qualitative and quantitative results demonstrate that our method achieves SoTA depth estimating results on the challenging nuScenes-Night and RobotCar-Night compared with existing methods."],"url":"http://arxiv.org/abs/2404.13854v1"}
{"created":"2024-04-22 03:35:19","title":"ICST-DNET: An Interpretable Causal Spatio-Temporal Diffusion Network for Traffic Speed Prediction","abstract":"Traffic speed prediction is significant for intelligent navigation and congestion alleviation. However, making accurate predictions is challenging due to three factors: 1) traffic diffusion, i.e., the spatial and temporal causality existing between the traffic conditions of multiple neighboring roads, 2) the poor interpretability of traffic data with complicated spatio-temporal correlations, and 3) the latent pattern of traffic speed fluctuations over time, such as morning and evening rush. Jointly considering these factors, in this paper, we present a novel architecture for traffic speed prediction, called Interpretable Causal Spatio-Temporal Diffusion Network (ICST-DNET). Specifically, ICST-DENT consists of three parts, namely the Spatio-Temporal Causality Learning (STCL), Causal Graph Generation (CGG), and Speed Fluctuation Pattern Recognition (SFPR) modules. First, to model the traffic diffusion within road networks, an STCL module is proposed to capture both the temporal causality on each individual road and the spatial causality in each road pair. The CGG module is then developed based on STCL to enhance the interpretability of the traffic diffusion procedure from the temporal and spatial perspectives. Specifically, a time causality matrix is generated to explain the temporal causality between each road's historical and future traffic conditions. For spatial causality, we utilize causal graphs to visualize the diffusion process in road pairs. Finally, to adapt to traffic speed fluctuations in different scenarios, we design a personalized SFPR module to select the historical timesteps with strong influences for learning the pattern of traffic speed fluctuations. Extensive experimental results prove that ICST-DNET can outperform all existing baselines, as evidenced by the higher prediction accuracy, ability to explain causality, and adaptability to different scenarios.","sentences":["Traffic speed prediction is significant for intelligent navigation and congestion alleviation.","However, making accurate predictions is challenging due to three factors: 1) traffic diffusion, i.e., the spatial and temporal causality existing between the traffic conditions of multiple neighboring roads, 2) the poor interpretability of traffic data with complicated spatio-temporal correlations, and 3) the latent pattern of traffic speed fluctuations over time, such as morning and evening rush.","Jointly considering these factors, in this paper, we present a novel architecture for traffic speed prediction, called Interpretable Causal Spatio-Temporal Diffusion Network (ICST-DNET).","Specifically, ICST-DENT consists of three parts, namely the Spatio-Temporal Causality Learning (STCL), Causal Graph Generation (CGG), and Speed Fluctuation Pattern Recognition (SFPR) modules.","First, to model the traffic diffusion within road networks, an STCL module is proposed to capture both the temporal causality on each individual road and the spatial causality in each road pair.","The CGG module is then developed based on STCL to enhance the interpretability of the traffic diffusion procedure from the temporal and spatial perspectives.","Specifically, a time causality matrix is generated to explain the temporal causality between each road's historical and future traffic conditions.","For spatial causality, we utilize causal graphs to visualize the diffusion process in road pairs.","Finally, to adapt to traffic speed fluctuations in different scenarios, we design a personalized SFPR module to select the historical timesteps with strong influences for learning the pattern of traffic speed fluctuations.","Extensive experimental results prove that ICST-DNET can outperform all existing baselines, as evidenced by the higher prediction accuracy, ability to explain causality, and adaptability to different scenarios."],"url":"http://arxiv.org/abs/2404.13853v1"}
{"created":"2024-04-22 03:15:42","title":"DSDRNet: Disentangling Representation and Reconstruct Network for Domain Generalization","abstract":"Domain generalization faces challenges due to the distribution shift between training and testing sets, and the presence of unseen target domains. Common solutions include domain alignment, meta-learning, data augmentation, or ensemble learning, all of which rely on domain labels or domain adversarial techniques. In this paper, we propose a Dual-Stream Separation and Reconstruction Network, dubbed DSDRNet. It is a disentanglement-reconstruction approach that integrates features of both inter-instance and intra-instance through dual-stream fusion. The method introduces novel supervised signals by combining inter-instance semantic distance and intra-instance similarity. Incorporating Adaptive Instance Normalization (AdaIN) into a two-stage cyclic reconstruction process enhances self-disentangled reconstruction signals to facilitate model convergence. Extensive experiments on four benchmark datasets demonstrate that DSDRNet outperforms other popular methods in terms of domain generalization capabilities.","sentences":["Domain generalization faces challenges due to the distribution shift between training and testing sets, and the presence of unseen target domains.","Common solutions include domain alignment, meta-learning, data augmentation, or ensemble learning, all of which rely on domain labels or domain adversarial techniques.","In this paper, we propose a Dual-Stream Separation and Reconstruction Network, dubbed DSDRNet.","It is a disentanglement-reconstruction approach that integrates features of both inter-instance and intra-instance through dual-stream fusion.","The method introduces novel supervised signals by combining inter-instance semantic distance and intra-instance similarity.","Incorporating Adaptive Instance Normalization (AdaIN) into a two-stage cyclic reconstruction process enhances self-disentangled reconstruction signals to facilitate model convergence.","Extensive experiments on four benchmark datasets demonstrate that DSDRNet outperforms other popular methods in terms of domain generalization capabilities."],"url":"http://arxiv.org/abs/2404.13848v1"}
{"created":"2024-04-22 02:41:10","title":"Fair Concurrent Training of Multiple Models in Federated Learning","abstract":"Federated learning (FL) enables collaborative learning across multiple clients. In most FL work, all clients train a single learning task. However, the recent proliferation of FL applications may increasingly require multiple FL tasks to be trained simultaneously, sharing clients' computing and communication resources, which we call Multiple-Model Federated Learning (MMFL). Current MMFL algorithms use naive average-based client-task allocation schemes that can lead to unfair performance when FL tasks have heterogeneous difficulty levels, e.g., tasks with larger models may need more rounds and data to train. Just as naively allocating resources to generic computing jobs with heterogeneous resource needs can lead to unfair outcomes, naive allocation of clients to FL tasks can lead to unfairness, with some tasks having excessively long training times, or lower converged accuracies. Furthermore, in the FL setting, since clients are typically not paid for their training effort, we face a further challenge that some clients may not even be willing to train some tasks, e.g., due to high computational costs, which may exacerbate unfairness in training outcomes across tasks. We address both challenges by firstly designing FedFairMMFL, a difficulty-aware algorithm that dynamically allocates clients to tasks in each training round. We provide guarantees on airness and FedFairMMFL's convergence rate. We then propose a novel auction design that incentivizes clients to train multiple tasks, so as to fairly distribute clients' training efforts across the tasks. We show how our fairness-based learning and incentive mechanisms impact training convergence and finally evaluate our algorithm with multiple sets of learning tasks on real world datasets.","sentences":["Federated learning (FL) enables collaborative learning across multiple clients.","In most FL work, all clients train a single learning task.","However, the recent proliferation of FL applications may increasingly require multiple FL tasks to be trained simultaneously, sharing clients' computing and communication resources, which we call Multiple-Model Federated Learning (MMFL).","Current MMFL algorithms use naive average-based client-task allocation schemes that can lead to unfair performance when FL tasks have heterogeneous difficulty levels, e.g., tasks with larger models may need more rounds and data to train.","Just as naively allocating resources to generic computing jobs with heterogeneous resource needs can lead to unfair outcomes, naive allocation of clients to FL tasks can lead to unfairness, with some tasks having excessively long training times, or lower converged accuracies.","Furthermore, in the FL setting, since clients are typically not paid for their training effort, we face a further challenge that some clients may not even be willing to train some tasks, e.g., due to high computational costs, which may exacerbate unfairness in training outcomes across tasks.","We address both challenges by firstly designing FedFairMMFL, a difficulty-aware algorithm that dynamically allocates clients to tasks in each training round.","We provide guarantees on airness and FedFairMMFL's convergence rate.","We then propose a novel auction design that incentivizes clients to train multiple tasks, so as to fairly distribute clients' training efforts across the tasks.","We show how our fairness-based learning and incentive mechanisms impact training convergence and finally evaluate our algorithm with multiple sets of learning tasks on real world datasets."],"url":"http://arxiv.org/abs/2404.13841v1"}
{"created":"2024-04-22 02:04:34","title":"GazeIntent: Adapting dwell-time selection in VR interaction with real-time intent modeling","abstract":"The use of ML models to predict a user's cognitive state from behavioral data has been studied for various applications which includes predicting the intent to perform selections in VR. We developed a novel technique that uses gaze-based intent models to adapt dwell-time thresholds to aid gaze-only selection. A dataset of users performing selection in arithmetic tasks was used to develop intent prediction models (F1 = 0.94). We developed GazeIntent to adapt selection dwell times based on intent model outputs and conducted an end-user study with returning and new users performing additional tasks with varied selection frequencies. Personalized models for returning users effectively accounted for prior experience and were preferred by 63% of users. Our work provides the field with methods to adapt dwell-based selection to users, account for experience over time, and consider tasks that vary by selection frequency","sentences":["The use of ML models to predict a user's cognitive state from behavioral data has been studied for various applications which includes predicting the intent to perform selections in VR.","We developed a novel technique that uses gaze-based intent models to adapt dwell-time thresholds to aid gaze-only selection.","A dataset of users performing selection in arithmetic tasks was used to develop intent prediction models (F1 = 0.94).","We developed GazeIntent to adapt selection dwell times based on intent model outputs and conducted an end-user study with returning and new users performing additional tasks with varied selection frequencies.","Personalized models for returning users effectively accounted for prior experience and were preferred by 63% of users.","Our work provides the field with methods to adapt dwell-based selection to users, account for experience over time, and consider tasks that vary by selection frequency"],"url":"http://arxiv.org/abs/2404.13829v1"}
{"created":"2024-04-22 01:59:48","title":"Swap It Like Its Hot: Segmentation-based spoof attacks on eye-tracking images","abstract":"Video-based eye trackers capture the iris biometric and enable authentication to secure user identity. However, biometric authentication is susceptible to spoofing another user's identity through physical or digital manipulation. The current standard to identify physical spoofing attacks on eye-tracking sensors uses liveness detection. Liveness detection classifies gaze data as real or fake, which is sufficient to detect physical presentation attacks. However, such defenses cannot detect a spoofing attack when real eye image inputs are digitally manipulated to swap the iris pattern of another person. We propose IrisSwap as a novel attack on gaze-based liveness detection. IrisSwap allows attackers to segment and digitally swap in a victim's iris pattern to fool iris authentication. Both offline and online attacks produce gaze data that deceives the current state-of-the-art defense models at rates up to 58% and motivates the need to develop more advanced authentication methods for eye trackers.","sentences":["Video-based eye trackers capture the iris biometric and enable authentication to secure user identity.","However, biometric authentication is susceptible to spoofing another user's identity through physical or digital manipulation.","The current standard to identify physical spoofing attacks on eye-tracking sensors uses liveness detection.","Liveness detection classifies gaze data as real or fake, which is sufficient to detect physical presentation attacks.","However, such defenses cannot detect a spoofing attack when real eye image inputs are digitally manipulated to swap the iris pattern of another person.","We propose IrisSwap as a novel attack on gaze-based liveness detection.","IrisSwap allows attackers to segment and digitally swap in a victim's iris pattern to fool iris authentication.","Both offline and online attacks produce gaze data that deceives the current state-of-the-art defense models at rates up to 58% and motivates the need to develop more advanced authentication methods for eye trackers."],"url":"http://arxiv.org/abs/2404.13827v1"}
{"created":"2024-04-22 01:51:22","title":"Robotic Blended Sonification: Consequential Robot Sound as Creative Material for Human-Robot Interaction","abstract":"Current research in robotic sounds generally focuses on either masking the consequential sound produced by the robot or on sonifying data about the robot to create a synthetic robot sound. We propose to capture, modify, and utilise rather than mask the sounds that robots are already producing. In short, this approach relies on capturing a robot's sounds, processing them according to contextual information (e.g., collaborators' proximity or particular work sequences), and playing back the modified sound. Previous research indicates the usefulness of non-semantic, and even mechanical, sounds as a communication tool for conveying robotic affect and function. Adding to this, this paper presents a novel approach which makes two key contributions: (1) a technique for real-time capture and processing of consequential robot sounds, and (2) an approach to explore these sounds through direct human-robot interaction. Drawing on methodologies from design, human-robot interaction, and creative practice, the resulting 'Robotic Blended Sonification' is a concept which transforms the consequential robot sounds into a creative material that can be explored artistically and within application-based studies.","sentences":["Current research in robotic sounds generally focuses on either masking the consequential sound produced by the robot or on sonifying data about the robot to create a synthetic robot sound.","We propose to capture, modify, and utilise rather than mask the sounds that robots are already producing.","In short, this approach relies on capturing a robot's sounds, processing them according to contextual information (e.g., collaborators' proximity or particular work sequences), and playing back the modified sound.","Previous research indicates the usefulness of non-semantic, and even mechanical, sounds as a communication tool for conveying robotic affect and function.","Adding to this, this paper presents a novel approach which makes two key contributions: (1) a technique for real-time capture and processing of consequential robot sounds, and (2) an approach to explore these sounds through direct human-robot interaction.","Drawing on methodologies from design, human-robot interaction, and creative practice, the resulting 'Robotic Blended Sonification' is a concept which transforms the consequential robot sounds into a creative material that can be explored artistically and within application-based studies."],"url":"http://arxiv.org/abs/2404.13821v1"}
{"created":"2024-04-22 01:48:58","title":"Prove Symbolic Regression is NP-hard by Symbol Graph","abstract":"Symbolic regression (SR) is the task of discovering a symbolic expression that fits a given data set from the space of mathematical expressions. Despite the abundance of research surrounding the SR problem, there's a scarcity of works that confirm its NP-hard nature. Therefore, this paper introduces the concept of a symbol graph as a comprehensive representation of the entire mathematical expression space, effectively illustrating the NP-hard characteristics of the SR problem. Leveraging the symbol graph, we establish a connection between the SR problem and the task of identifying an optimally fitted degree-constrained Steiner Arborescence (DCSAP). The complexity of DCSAP, which is proven to be NP-hard, directly implies the NP-hard nature of the SR problem.","sentences":["Symbolic regression (SR) is the task of discovering a symbolic expression that fits a given data set from the space of mathematical expressions.","Despite the abundance of research surrounding the SR problem, there's a scarcity of works that confirm its NP-hard nature.","Therefore, this paper introduces the concept of a symbol graph as a comprehensive representation of the entire mathematical expression space, effectively illustrating the NP-hard characteristics of the SR problem.","Leveraging the symbol graph, we establish a connection between the SR problem and the task of identifying an optimally fitted degree-constrained Steiner Arborescence (DCSAP).","The complexity of DCSAP, which is proven to be NP-hard, directly implies the NP-hard nature of the SR problem."],"url":"http://arxiv.org/abs/2404.13820v1"}
{"created":"2024-04-22 01:22:23","title":"From LLM to NMT: Advancing Low-Resource Machine Translation with Claude","abstract":"We show that Claude 3 Opus, a large language model (LLM) released by Anthropic in March 2024, exhibits stronger machine translation competence than other LLMs. Though we find evidence of data contamination with Claude on FLORES-200, we curate new benchmarks that corroborate the effectiveness of Claude for low-resource machine translation into English. We find that Claude has remarkable \\textit{resource efficiency} -- the degree to which the quality of the translation model depends on a language pair's resource level. Finally, we show that advancements in LLM translation can be compressed into traditional neural machine translation (NMT) models. Using Claude to generate synthetic data, we demonstrate that knowledge distillation advances the state-of-the-art in Yoruba-English translation, meeting or surpassing strong baselines like NLLB-54B and Google Translate.","sentences":["We show that Claude 3 Opus, a large language model (LLM) released by Anthropic in March 2024, exhibits stronger machine translation competence than other LLMs.","Though we find evidence of data contamination with Claude on FLORES-200, we curate new benchmarks that corroborate the effectiveness of Claude for low-resource machine translation into English.","We find that Claude has remarkable \\textit{resource efficiency} -- the degree to which the quality of the translation model depends on a language pair's resource level.","Finally, we show that advancements in LLM translation can be compressed into traditional neural machine translation (NMT) models.","Using Claude to generate synthetic data, we demonstrate that knowledge distillation advances the state-of-the-art in Yoruba-English translation, meeting or surpassing strong baselines like NLLB-54B and Google Translate."],"url":"http://arxiv.org/abs/2404.13813v1"}
{"created":"2024-04-22 01:16:11","title":"A Comparative Study on Enhancing Prediction in Social Network Advertisement through Data Augmentation","abstract":"In the ever-evolving landscape of social network advertising, the volume and accuracy of data play a critical role in the performance of predictive models. However, the development of robust predictive algorithms is often hampered by the limited size and potential bias present in real-world datasets. This study presents and explores a generative augmentation framework of social network advertising data. Our framework explores three generative models for data augmentation - Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and diversity in the context of social network advertising analytics effectiveness. By performing synthetic extensions of the feature space, we find that through data augmentation, the performance of various classifiers has been quantitatively improved. Furthermore, we compare the relative performance gains brought by each data augmentation technique, providing insights for practitioners to select appropriate techniques to enhance model performance. This paper contributes to the literature by showing that synthetic data augmentation alleviates the limitations imposed by small or imbalanced datasets in the field of social network advertising. At the same time, this article also provides a comparative perspective on the practicality of different data augmentation methods, thereby guiding practitioners to choose appropriate techniques to enhance model performance.","sentences":["In the ever-evolving landscape of social network advertising, the volume and accuracy of data play a critical role in the performance of predictive models.","However, the development of robust predictive algorithms is often hampered by the limited size and potential bias present in real-world datasets.","This study presents and explores a generative augmentation framework of social network advertising data.","Our framework explores three generative models for data augmentation - Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and diversity in the context of social network advertising analytics effectiveness.","By performing synthetic extensions of the feature space, we find that through data augmentation, the performance of various classifiers has been quantitatively improved.","Furthermore, we compare the relative performance gains brought by each data augmentation technique, providing insights for practitioners to select appropriate techniques to enhance model performance.","This paper contributes to the literature by showing that synthetic data augmentation alleviates the limitations imposed by small or imbalanced datasets in the field of social network advertising.","At the same time, this article also provides a comparative perspective on the practicality of different data augmentation methods, thereby guiding practitioners to choose appropriate techniques to enhance model performance."],"url":"http://arxiv.org/abs/2404.13812v1"}
{"created":"2024-04-22 00:48:56","title":"General Item Representation Learning for Cold-start Content Recommendations","abstract":"Cold-start item recommendation is a long-standing challenge in recommendation systems. A common remedy is to use a content-based approach, but rich information from raw contents in various forms has not been fully utilized. In this paper, we propose a domain/data-agnostic item representation learning framework for cold-start recommendations, naturally equipped with multimodal alignment among various features by adopting a Transformer-based architecture. Our proposed model is end-to-end trainable completely free from classification labels, not just costly to collect but suboptimal for recommendation-purpose representation learning. From extensive experiments on real-world movie and news recommendation benchmarks, we verify that our approach better preserves fine-grained user taste than state-of-the-art baselines, universally applicable to multiple domains at large scale.","sentences":["Cold-start item recommendation is a long-standing challenge in recommendation systems.","A common remedy is to use a content-based approach, but rich information from raw contents in various forms has not been fully utilized.","In this paper, we propose a domain/data-agnostic item representation learning framework for cold-start recommendations, naturally equipped with multimodal alignment among various features by adopting a Transformer-based architecture.","Our proposed model is end-to-end trainable completely free from classification labels, not just costly to collect but suboptimal for recommendation-purpose representation learning.","From extensive experiments on real-world movie and news recommendation benchmarks, we verify that our approach better preserves fine-grained user taste than state-of-the-art baselines, universally applicable to multiple domains at large scale."],"url":"http://arxiv.org/abs/2404.13808v1"}
{"created":"2024-04-21 23:34:45","title":"Enforcing Conditional Independence for Fair Representation Learning and Causal Image Generation","abstract":"Conditional independence (CI) constraints are critical for defining and evaluating fairness in machine learning, as well as for learning unconfounded or causal representations. Traditional methods for ensuring fairness either blindly learn invariant features with respect to a protected variable (e.g., race when classifying sex from face images) or enforce CI relative to the protected attribute only on the model output (e.g., the sex label). Neither of these methods are effective in enforcing CI in high-dimensional feature spaces. In this paper, we focus on a nascent approach characterizing the CI constraint in terms of two Jensen-Shannon divergence terms, and we extend it to high-dimensional feature spaces using a novel dynamic sampling strategy. In doing so, we introduce a new training paradigm that can be applied to any encoder architecture. We are able to enforce conditional independence of the diffusion autoencoder latent representation with respect to any protected attribute under the equalized odds constraint and show that this approach enables causal image generation with controllable latent spaces. Our experimental results demonstrate that our approach can achieve high accuracy on downstream tasks while upholding equality of odds.","sentences":["Conditional independence (CI) constraints are critical for defining and evaluating fairness in machine learning, as well as for learning unconfounded or causal representations.","Traditional methods for ensuring fairness either blindly learn invariant features with respect to a protected variable (e.g., race when classifying sex from face images) or enforce CI relative to the protected attribute only on the model output (e.g., the sex label).","Neither of these methods are effective in enforcing CI in high-dimensional feature spaces.","In this paper, we focus on a nascent approach characterizing the CI constraint in terms of two Jensen-Shannon divergence terms, and we extend it to high-dimensional feature spaces using a novel dynamic sampling strategy.","In doing so, we introduce a new training paradigm that can be applied to any encoder architecture.","We are able to enforce conditional independence of the diffusion autoencoder latent representation with respect to any protected attribute under the equalized odds constraint and show that this approach enables causal image generation with controllable latent spaces.","Our experimental results demonstrate that our approach can achieve high accuracy on downstream tasks while upholding equality of odds."],"url":"http://arxiv.org/abs/2404.13798v1"}
{"created":"2024-04-21 23:03:47","title":"Counterfactual Reasoning Using Predicted Latent Personality Dimensions for Optimizing Persuasion Outcome","abstract":"Customizing persuasive conversations related to the outcome of interest for specific users achieves better persuasion results. However, existing persuasive conversation systems rely on persuasive strategies and encounter challenges in dynamically adjusting dialogues to suit the evolving states of individual users during interactions. This limitation restricts the system's ability to deliver flexible or dynamic conversations and achieve suboptimal persuasion outcomes. In this paper, we present a novel approach that tracks a user's latent personality dimensions (LPDs) during ongoing persuasion conversation and generates tailored counterfactual utterances based on these LPDs to optimize the overall persuasion outcome. In particular, our proposed method leverages a Bi-directional Generative Adversarial Network (BiCoGAN) in tandem with a Dialogue-based Personality Prediction Regression (DPPR) model to generate counterfactual data. This enables the system to formulate alternative persuasive utterances that are more suited to the user. Subsequently, we utilize the D3QN model to learn policies for optimized selection of system utterances on counterfactual data. Experimental results we obtained from using the PersuasionForGood dataset demonstrate the superiority of our approach over the existing method, BiCoGAN. The cumulative rewards and Q-values produced by our method surpass ground truth benchmarks, showcasing the efficacy of employing counterfactual reasoning and LPDs to optimize reinforcement learning policy in online interactions.","sentences":["Customizing persuasive conversations related to the outcome of interest for specific users achieves better persuasion results.","However, existing persuasive conversation systems rely on persuasive strategies and encounter challenges in dynamically adjusting dialogues to suit the evolving states of individual users during interactions.","This limitation restricts the system's ability to deliver flexible or dynamic conversations and achieve suboptimal persuasion outcomes.","In this paper, we present a novel approach that tracks a user's latent personality dimensions (LPDs) during ongoing persuasion conversation and generates tailored counterfactual utterances based on these LPDs to optimize the overall persuasion outcome.","In particular, our proposed method leverages a Bi-directional Generative Adversarial Network (BiCoGAN) in tandem with a Dialogue-based Personality Prediction Regression (DPPR) model to generate counterfactual data.","This enables the system to formulate alternative persuasive utterances that are more suited to the user.","Subsequently, we utilize the D3QN model to learn policies for optimized selection of system utterances on counterfactual data.","Experimental results we obtained from using the PersuasionForGood dataset demonstrate the superiority of our approach over the existing method, BiCoGAN.","The cumulative rewards and Q-values produced by our method surpass ground truth benchmarks, showcasing the efficacy of employing counterfactual reasoning and LPDs to optimize reinforcement learning policy in online interactions."],"url":"http://arxiv.org/abs/2404.13792v1"}
{"created":"2024-04-21 23:01:08","title":"Universal Fingerprint Generation: Controllable Diffusion Model with Multimodal Conditions","abstract":"The utilization of synthetic data for fingerprint recognition has garnered increased attention due to its potential to alleviate privacy concerns surrounding sensitive biometric data. However, current methods for generating fingerprints have limitations in creating impressions of the same finger with useful intra-class variations. To tackle this challenge, we present GenPrint, a framework to produce fingerprint images of various types while maintaining identity and offering humanly understandable control over different appearance factors such as fingerprint class, acquisition type, sensor device, and quality level. Unlike previous fingerprint generation approaches, GenPrint is not confined to replicating style characteristics from the training dataset alone: it enables the generation of novel styles from unseen devices without requiring additional fine-tuning. To accomplish these objectives, we developed GenPrint using latent diffusion models with multimodal conditions (text and image) for consistent generation of style and identity. Our experiments leverage a variety of publicly available datasets for training and evaluation. Results demonstrate the benefits of GenPrint in terms of identity preservation, explainable control, and universality of generated images. Importantly, the GenPrint-generated images yield comparable or even superior accuracy to models trained solely on real data and further enhances performance when augmenting the diversity of existing real fingerprint datasets.","sentences":["The utilization of synthetic data for fingerprint recognition has garnered increased attention due to its potential to alleviate privacy concerns surrounding sensitive biometric data.","However, current methods for generating fingerprints have limitations in creating impressions of the same finger with useful intra-class variations.","To tackle this challenge, we present GenPrint, a framework to produce fingerprint images of various types while maintaining identity and offering humanly understandable control over different appearance factors such as fingerprint class, acquisition type, sensor device, and quality level.","Unlike previous fingerprint generation approaches, GenPrint is not confined to replicating style characteristics from the training dataset alone: it enables the generation of novel styles from unseen devices without requiring additional fine-tuning.","To accomplish these objectives, we developed GenPrint using latent diffusion models with multimodal conditions (text and image) for consistent generation of style and identity.","Our experiments leverage a variety of publicly available datasets for training and evaluation.","Results demonstrate the benefits of GenPrint in terms of identity preservation, explainable control, and universality of generated images.","Importantly, the GenPrint-generated images yield comparable or even superior accuracy to models trained solely on real data and further enhances performance when augmenting the diversity of existing real fingerprint datasets."],"url":"http://arxiv.org/abs/2404.13791v1"}
{"created":"2024-04-21 22:44:44","title":"Anchor-aware Deep Metric Learning for Audio-visual Retrieval","abstract":"Metric learning minimizes the gap between similar (positive) pairs of data points and increases the separation of dissimilar (negative) pairs, aiming at capturing the underlying data structure and enhancing the performance of tasks like audio-visual cross-modal retrieval (AV-CMR). Recent works employ sampling methods to select impactful data points from the embedding space during training. However, the model training fails to fully explore the space due to the scarcity of training data points, resulting in an incomplete representation of the overall positive and negative distributions. In this paper, we propose an innovative Anchor-aware Deep Metric Learning (AADML) method to address this challenge by uncovering the underlying correlations among existing data points, which enhances the quality of the shared embedding space. Specifically, our method establishes a correlation graph-based manifold structure by considering the dependencies between each sample as the anchor and its semantically similar samples. Through dynamic weighting of the correlations within this underlying manifold structure using an attention-driven mechanism, Anchor Awareness (AA) scores are obtained for each anchor. These AA scores serve as data proxies to compute relative distances in metric learning approaches. Extensive experiments conducted on two audio-visual benchmark datasets demonstrate the effectiveness of our proposed AADML method, significantly surpassing state-of-the-art models. Furthermore, we investigate the integration of AA proxies with various metric learning methods, further highlighting the efficacy of our approach.","sentences":["Metric learning minimizes the gap between similar (positive) pairs of data points and increases the separation of dissimilar (negative) pairs, aiming at capturing the underlying data structure and enhancing the performance of tasks like audio-visual cross-modal retrieval (AV-CMR).","Recent works employ sampling methods to select impactful data points from the embedding space during training.","However, the model training fails to fully explore the space due to the scarcity of training data points, resulting in an incomplete representation of the overall positive and negative distributions.","In this paper, we propose an innovative Anchor-aware Deep Metric Learning (AADML) method to address this challenge by uncovering the underlying correlations among existing data points, which enhances the quality of the shared embedding space.","Specifically, our method establishes a correlation graph-based manifold structure by considering the dependencies between each sample as the anchor and its semantically similar samples.","Through dynamic weighting of the correlations within this underlying manifold structure using an attention-driven mechanism, Anchor Awareness (AA) scores are obtained for each anchor.","These AA scores serve as data proxies to compute relative distances in metric learning approaches.","Extensive experiments conducted on two audio-visual benchmark datasets demonstrate the effectiveness of our proposed AADML method, significantly surpassing state-of-the-art models.","Furthermore, we investigate the integration of AA proxies with various metric learning methods, further highlighting the efficacy of our approach."],"url":"http://arxiv.org/abs/2404.13789v1"}
{"created":"2024-04-21 21:36:42","title":"How to Inverting the Leverage Score Distribution?","abstract":"Leverage score is a fundamental problem in machine learning and theoretical computer science. It has extensive applications in regression analysis, randomized algorithms, and neural network inversion. Despite leverage scores are widely used as a tool, in this paper, we study a novel problem, namely the inverting leverage score problem. We analyze to invert the leverage score distributions back to recover model parameters. Specifically, given a leverage score $\\sigma \\in \\mathbb{R}^n$, the matrix $A \\in \\mathbb{R}^{n \\times d}$, and the vector $b \\in \\mathbb{R}^n$, we analyze the non-convex optimization problem of finding $x \\in \\mathbb{R}^d$ to minimize $\\| \\mathrm{diag}( \\sigma ) - I_n \\circ (A(x) (A(x)^\\top A(x) )^{-1} A(x)^\\top ) \\|_F$, where $A(x):= S(x)^{-1} A \\in \\mathbb{R}^{n \\times d} $, $S(x) := \\mathrm{diag}(s(x)) \\in \\mathbb{R}^{n \\times n}$ and $s(x) : = Ax - b \\in \\mathbb{R}^n$. Our theoretical studies include computing the gradient and Hessian, demonstrating that the Hessian matrix is positive definite and Lipschitz, and constructing first-order and second-order algorithms to solve this regression problem. Our work combines iterative shrinking and the induction hypothesis to ensure global convergence rates for the Newton method, as well as the properties of Lipschitz and strong convexity to guarantee the performance of gradient descent. This important study on inverting statistical leverage opens up numerous new applications in interpretation, data recovery, and security.","sentences":["Leverage score is a fundamental problem in machine learning and theoretical computer science.","It has extensive applications in regression analysis, randomized algorithms, and neural network inversion.","Despite leverage scores are widely used as a tool, in this paper, we study a novel problem, namely the inverting leverage score problem.","We analyze to invert the leverage score distributions back to recover model parameters.","Specifically, given a leverage score $\\sigma \\in \\mathbb{R}^n$, the matrix $A \\in \\mathbb{R}^{n \\times d}$, and the vector $b \\in \\mathbb{R}^n$, we analyze the non-convex optimization problem of finding $x \\in \\mathbb{R}^d$ to minimize $\\| \\mathrm{diag}( \\sigma ) - I_n \\circ (A(x) (A(x)^\\top A(x) )^{-1} A(x)^\\top )","\\|_F$, where $A(x):= S(x)^{-1} A \\in \\mathbb{R}^{n \\times d} $, $S(x) := \\mathrm{diag}(s(x))","\\in \\mathbb{R}^{n \\times n}$ and $s(x) :","= Ax - b \\in \\mathbb{R}^n$.","Our theoretical studies include computing the gradient and Hessian, demonstrating that the Hessian matrix is positive definite and Lipschitz, and constructing first-order and second-order algorithms to solve this regression problem.","Our work combines iterative shrinking and the induction hypothesis to ensure global convergence rates for the Newton method, as well as the properties of Lipschitz and strong convexity to guarantee the performance of gradient descent.","This important study on inverting statistical leverage opens up numerous new applications in interpretation, data recovery, and security."],"url":"http://arxiv.org/abs/2404.13785v1"}
{"created":"2024-04-21 21:19:31","title":"Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems","abstract":"Watching movies is one of the social activities typically done in groups. Emotion is the most vital factor that affects movie viewers' preferences. So, the emotional aspect of the movie needs to be determined and analyzed for further recommendations. It can be challenging to choose a movie that appeals to the emotions of a diverse group. Reaching an agreement for a group can be difficult due to the various genres and choices. This paper proposes a novel approach to group movie suggestions by examining emotions from three different channels: movie descriptions (text), soundtracks (audio), and posters (image). We employ the Jaccard similarity index to match each participant's emotional preferences to prospective movie choices, followed by a fuzzy inference technique to determine group consensus. We use a weighted integration process for the fusion of emotion scores from diverse data types. Then, group movie recommendation is based on prevailing emotions and viewers' best-loved movies. After determining the recommendations, the group's consensus level is calculated using a fuzzy inference system, taking participants' feedback as input. Participants (n=130) in the survey were provided with different emotion categories and asked to select the emotions best suited for particular movies (n=12). Comparison results between predicted and actual scores demonstrate the efficiency of using emotion detection for this problem (Jaccard similarity index = 0.76). We explored the relationship between induced emotions and movie popularity as an additional experiment, analyzing emotion distribution in 100 popular movies from the TMDB database. Such systems can potentially improve the accuracy of movie recommendation systems and achieve a high level of consensus among participants with diverse preferences.","sentences":["Watching movies is one of the social activities typically done in groups.","Emotion is the most vital factor that affects movie viewers' preferences.","So, the emotional aspect of the movie needs to be determined and analyzed for further recommendations.","It can be challenging to choose a movie that appeals to the emotions of a diverse group.","Reaching an agreement for a group can be difficult due to the various genres and choices.","This paper proposes a novel approach to group movie suggestions by examining emotions from three different channels: movie descriptions (text), soundtracks (audio), and posters (image).","We employ the Jaccard similarity index to match each participant's emotional preferences to prospective movie choices, followed by a fuzzy inference technique to determine group consensus.","We use a weighted integration process for the fusion of emotion scores from diverse data types.","Then, group movie recommendation is based on prevailing emotions and viewers' best-loved movies.","After determining the recommendations, the group's consensus level is calculated using a fuzzy inference system, taking participants' feedback as input.","Participants (n=130) in the survey were provided with different emotion categories and asked to select the emotions best suited for particular movies (n=12).","Comparison results between predicted and actual scores demonstrate the efficiency of using emotion detection for this problem (Jaccard similarity index = 0.76).","We explored the relationship between induced emotions and movie popularity as an additional experiment, analyzing emotion distribution in 100 popular movies from the TMDB database.","Such systems can potentially improve the accuracy of movie recommendation systems and achieve a high level of consensus among participants with diverse preferences."],"url":"http://arxiv.org/abs/2404.13778v1"}
{"created":"2024-04-21 20:26:46","title":"Object-Attribute Binding in Text-to-Image Generation: Evaluation and Control","abstract":"Current diffusion models create photorealistic images given a text prompt as input but struggle to correctly bind attributes mentioned in the text to the right objects in the image. This is evidenced by our novel image-graph alignment model called EPViT (Edge Prediction Vision Transformer) for the evaluation of image-text alignment. To alleviate the above problem, we propose focused cross-attention (FCA) that controls the visual attention maps by syntactic constraints found in the input sentence. Additionally, the syntax structure of the prompt helps to disentangle the multimodal CLIP embeddings that are commonly used in T2I generation. The resulting DisCLIP embeddings and FCA are easily integrated in state-of-the-art diffusion models without additional training of these models. We show substantial improvements in T2I generation and especially its attribute-object binding on several datasets.\\footnote{Code and data will be made available upon acceptance.","sentences":["Current diffusion models create photorealistic images given a text prompt as input but struggle to correctly bind attributes mentioned in the text to the right objects in the image.","This is evidenced by our novel image-graph alignment model called EPViT (Edge Prediction Vision Transformer) for the evaluation of image-text alignment.","To alleviate the above problem, we propose focused cross-attention (FCA) that controls the visual attention maps by syntactic constraints found in the input sentence.","Additionally, the syntax structure of the prompt helps to disentangle the multimodal CLIP embeddings that are commonly used in T2I generation.","The resulting DisCLIP embeddings and FCA are easily integrated in state-of-the-art diffusion models without additional training of these models.","We show substantial improvements in T2I generation and especially its attribute-object binding on several datasets.\\footnote{Code and data will be made available upon acceptance."],"url":"http://arxiv.org/abs/2404.13766v1"}
{"created":"2024-04-21 20:26:06","title":"SciDaSynth: Interactive Structured Knowledge Extraction and Synthesis from Scientific Literature with Large Language Model","abstract":"Extraction and synthesis of structured knowledge from extensive scientific literature are crucial for advancing and disseminating scientific progress. Although many existing systems facilitate literature review and digest, they struggle to process multimodal, varied, and inconsistent information within and across the literature into structured data. We introduce SciDaSynth, a novel interactive system powered by large language models (LLMs) that enables researchers to efficiently build structured knowledge bases from scientific literature at scale. The system automatically creates data tables to organize and summarize users' interested knowledge in literature via question-answering. Furthermore, it provides multi-level and multi-faceted exploration of the generated data tables, facilitating iterative validation, correction, and refinement. Our within-subjects study with researchers demonstrates the effectiveness and efficiency of SciDaSynth in constructing quality scientific knowledge bases. We further discuss the design implications for human-AI interaction tools for data extraction and structuring.","sentences":["Extraction and synthesis of structured knowledge from extensive scientific literature are crucial for advancing and disseminating scientific progress.","Although many existing systems facilitate literature review and digest, they struggle to process multimodal, varied, and inconsistent information within and across the literature into structured data.","We introduce SciDaSynth, a novel interactive system powered by large language models (LLMs) that enables researchers to efficiently build structured knowledge bases from scientific literature at scale.","The system automatically creates data tables to organize and summarize users' interested knowledge in literature via question-answering.","Furthermore, it provides multi-level and multi-faceted exploration of the generated data tables, facilitating iterative validation, correction, and refinement.","Our within-subjects study with researchers demonstrates the effectiveness and efficiency of SciDaSynth in constructing quality scientific knowledge bases.","We further discuss the design implications for human-AI interaction tools for data extraction and structuring."],"url":"http://arxiv.org/abs/2404.13765v1"}
{"created":"2024-04-21 20:16:35","title":"How to Encode Domain Information in Relation Classification","abstract":"Current language models require a lot of training data to obtain high performance. For Relation Classification (RC), many datasets are domain-specific, so combining datasets to obtain better performance is non-trivial. We explore a multi-domain training setup for RC, and attempt to improve performance by encoding domain information. Our proposed models improve > 2 Macro-F1 against the baseline setup, and our analysis reveals that not all the labels benefit the same: The classes which occupy a similar space across domains (i.e., their interpretation is close across them, for example \"physical\") benefit the least, while domain-dependent relations (e.g., \"part-of'') improve the most when encoding domain information.","sentences":["Current language models require a lot of training data to obtain high performance.","For Relation Classification (RC), many datasets are domain-specific, so combining datasets to obtain better performance is non-trivial.","We explore a multi-domain training setup for RC, and attempt to improve performance by encoding domain information.","Our proposed models improve > 2 Macro-F1 against the baseline setup, and our analysis reveals that not all the labels benefit the same: The classes which occupy a similar space across domains (i.e., their interpretation is close across them, for example \"physical\") benefit the least, while domain-dependent relations (e.g., \"part-of'') improve the most when encoding domain information."],"url":"http://arxiv.org/abs/2404.13760v1"}
{"created":"2024-04-21 19:45:13","title":"Sublinear Time Low-Rank Approximation of Toeplitz Matrices","abstract":"We present a sublinear time algorithm for computing a near optimal low-rank approximation to any positive semidefinite (PSD) Toeplitz matrix $T\\in \\mathbb{R}^{d\\times d}$, given noisy access to its entries. In particular, given entrywise query access to $T+E$ for an arbitrary noise matrix $E\\in \\mathbb{R}^{d\\times d}$, integer rank $k\\leq d$, and error parameter $\\delta>0$, our algorithm runs in time $\\text{poly}(k,\\log(d/\\delta))$ and outputs (in factored form) a Toeplitz matrix $\\widetilde{T} \\in \\mathbb{R}^{d \\times d}$ with rank $\\text{poly}(k,\\log(d/\\delta))$ satisfying, for some fixed constant $C$, \\begin{equation*}   \\|T-\\widetilde{T}\\|_F \\leq C \\cdot \\max\\{\\|E\\|_F,\\|T-T_k\\|_F\\} + \\delta \\cdot \\|T\\|_F. \\end{equation*} Here $\\|\\cdot \\|_F$ is the Frobenius norm and $T_k$ is the best (not necessarily Toeplitz) rank-$k$ approximation to $T$ in the Frobenius norm, given by projecting $T$ onto its top $k$ eigenvectors.   Our result has the following applications. When $E = 0$, we obtain the first sublinear time near-relative-error low-rank approximation algorithm for PSD Toeplitz matrices, resolving the main open problem of Kapralov et al. SODA `23, whose algorithm had sublinear query complexity but exponential runtime. Our algorithm can also be applied to approximate the unknown Toeplitz covariance matrix of a multivariate Gaussian distribution, given sample access to this distribution, resolving an open question of Eldar et al. SODA `20.   Our algorithm applies sparse Fourier transform techniques to recover a low-rank Toeplitz matrix using its Fourier structure. Our key technical contribution is the first polynomial time algorithm for \\emph{discrete time off-grid} sparse Fourier recovery, which may be of independent interest.","sentences":["We present a sublinear time algorithm for computing a near optimal low-rank approximation to any positive semidefinite (PSD)","Toeplitz matrix $T\\in \\mathbb{R}^{d\\times d}$, given noisy access to its entries.","In particular, given entrywise query access to $T+E$ for an arbitrary noise matrix $E\\in \\mathbb{R}^{d\\times d}$, integer rank $k\\leq d$, and error parameter $\\delta>0$, our algorithm runs in time $\\text{poly}(k,\\log(d/\\delta))$ and outputs (in factored form) a Toeplitz matrix $\\widetilde{T} \\in \\mathbb{R}^{d \\times d}$ with rank $\\text{poly}(k,\\log(d/\\delta))$ satisfying, for some fixed constant $C$, \\begin{equation*}   \\|T-\\widetilde{T}\\|_F \\leq C \\cdot \\max\\{\\|E\\|_F,\\|T-T_k\\|_F\\} + \\delta \\cdot \\|T\\|_F. \\end{equation*} Here $\\|\\cdot \\|_F$ is the Frobenius norm and $T_k$ is the best (not necessarily Toeplitz) rank-$k$ approximation to $T$ in the Frobenius norm, given by projecting $T$ onto its top $k$ eigenvectors.   ","Our result has the following applications.","When $E = 0$, we obtain the first sublinear time near-relative-error low-rank approximation algorithm for PSD Toeplitz matrices, resolving the main open problem of Kapralov et al. SODA `23, whose algorithm had sublinear query complexity but exponential runtime.","Our algorithm can also be applied to approximate the unknown Toeplitz covariance matrix of a multivariate Gaussian distribution, given sample access to this distribution, resolving an open question of Eldar et al. SODA `20.   ","Our algorithm applies sparse Fourier transform techniques to recover a low-rank Toeplitz matrix using its Fourier structure.","Our key technical contribution is the first polynomial time algorithm for \\emph{discrete time off-grid} sparse Fourier recovery, which may be of independent interest."],"url":"http://arxiv.org/abs/2404.13757v1"}
{"created":"2024-04-21 19:24:15","title":"Towards General Conceptual Model Editing via Adversarial Representation Engineering","abstract":"Recent research has introduced Representation Engineering (RepE) as a promising approach for understanding complex inner workings of large-scale models like Large Language Models (LLMs). However, finding practical and efficient methods to apply these representations for general and flexible model editing remains an open problem. Inspired by the Generative Adversarial Network (GAN) framework, we introduce a novel approach called Adversarial Representation Engineering (ARE). This method leverages RepE by using a representation sensor to guide the editing of LLMs, offering a unified and interpretable framework for conceptual model editing without degrading baseline performance. Our experiments on multiple conceptual editing confirm ARE's effectiveness. Code and data are available at https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering.","sentences":["Recent research has introduced Representation Engineering (RepE) as a promising approach for understanding complex inner workings of large-scale models like Large Language Models (LLMs).","However, finding practical and efficient methods to apply these representations for general and flexible model editing remains an open problem.","Inspired by the Generative Adversarial Network (GAN) framework, we introduce a novel approach called Adversarial Representation Engineering (ARE).","This method leverages RepE by using a representation sensor to guide the editing of LLMs, offering a unified and interpretable framework for conceptual model editing without degrading baseline performance.","Our experiments on multiple conceptual editing confirm ARE's effectiveness.","Code and data are available at https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering."],"url":"http://arxiv.org/abs/2404.13752v1"}
{"created":"2024-04-21 19:12:22","title":"Efficient Digital Twin Data Processing for Low-Latency Multicast Short Video Streaming","abstract":"In this paper, we propose a novel efficient digital twin (DT) data processing scheme to reduce service latency for multicast short video streaming. Particularly, DT is constructed to emulate and analyze user status for multicast group update and swipe feature abstraction. Then, a precise measurement model of DT data processing is developed to characterize the relationship among DT model size, user dynamics, and user clustering accuracy. A service latency model, consisting of DT data processing delay, video transcoding delay, and multicast transmission delay, is constructed by incorporating the impact of user clustering accuracy. Finally, a joint optimization problem of DT model size selection and bandwidth allocation is formulated to minimize the service latency. To efficiently solve this problem, a diffusion-based resource management algorithm is proposed, which utilizes the denoising technique to improve the action-generation process in the deep reinforcement learning algorithm. Simulation results based on the real-world dataset demonstrate that the proposed DT data processing scheme outperforms benchmark schemes in terms of service latency.","sentences":["In this paper, we propose a novel efficient digital twin (DT) data processing scheme to reduce service latency for multicast short video streaming.","Particularly, DT is constructed to emulate and analyze user status for multicast group update and swipe feature abstraction.","Then, a precise measurement model of DT data processing is developed to characterize the relationship among DT model size, user dynamics, and user clustering accuracy.","A service latency model, consisting of DT data processing delay, video transcoding delay, and multicast transmission delay, is constructed by incorporating the impact of user clustering accuracy.","Finally, a joint optimization problem of DT model size selection and bandwidth allocation is formulated to minimize the service latency.","To efficiently solve this problem, a diffusion-based resource management algorithm is proposed, which utilizes the denoising technique to improve the action-generation process in the deep reinforcement learning algorithm.","Simulation results based on the real-world dataset demonstrate that the proposed DT data processing scheme outperforms benchmark schemes in terms of service latency."],"url":"http://arxiv.org/abs/2404.13749v1"}
{"created":"2024-04-21 18:56:54","title":"Seamless Underwater Navigation with Limited Doppler Velocity Log Measurements","abstract":"Autonomous Underwater Vehicles (AUVs) commonly utilize an inertial navigation system (INS) and a Doppler velocity log (DVL) for underwater navigation. To that end, their measurements are integrated through a nonlinear filter such as the extended Kalman filter (EKF). The DVL velocity vector estimate depends on retrieving reflections from the seabed, ensuring that at least three out of its four transmitted acoustic beams return successfully. When fewer than three beams are obtained, the DVL cannot provide a velocity update to bind the navigation solution drift. To cope with this challenge, in this paper, we propose a hybrid neural coupled (HNC) approach for seamless AUV navigation in situations of limited DVL measurements. First, we drive an approach to regress two or three missing DVL beams. Then, those beams, together with the measured beams, are incorporated into the EKF. We examined INS/DVL fusion both in loosely and tightly coupled approaches. Our method was trained and evaluated on recorded data from AUV experiments conducted in the Mediterranean Sea on two different occasions. The results illustrate that our proposed method outperforms the baseline loosely and tightly coupled model-based approaches by an average of 96.15%. It also demonstrates superior performance compared to a model-based beam estimator by an average of 12.41% in terms of velocity accuracy for scenarios involving two or three missing beams. Therefore, we demonstrate that our approach offers seamless AUV navigation in situations of limited beam measurements.","sentences":["Autonomous Underwater Vehicles (AUVs) commonly utilize an inertial navigation system (INS) and a Doppler velocity log (DVL) for underwater navigation.","To that end, their measurements are integrated through a nonlinear filter such as the extended Kalman filter (EKF).","The DVL velocity vector estimate depends on retrieving reflections from the seabed, ensuring that at least three out of its four transmitted acoustic beams return successfully.","When fewer than three beams are obtained, the DVL cannot provide a velocity update to bind the navigation solution drift.","To cope with this challenge, in this paper, we propose a hybrid neural coupled (HNC) approach for seamless AUV navigation in situations of limited DVL measurements.","First, we drive an approach to regress two or three missing DVL beams.","Then, those beams, together with the measured beams, are incorporated into the EKF.","We examined INS/DVL fusion both in loosely and tightly coupled approaches.","Our method was trained and evaluated on recorded data from AUV experiments conducted in the Mediterranean Sea on two different occasions.","The results illustrate that our proposed method outperforms the baseline loosely and tightly coupled model-based approaches by an average of 96.15%.","It also demonstrates superior performance compared to a model-based beam estimator by an average of 12.41% in terms of velocity accuracy for scenarios involving two or three missing beams.","Therefore, we demonstrate that our approach offers seamless AUV navigation in situations of limited beam measurements."],"url":"http://arxiv.org/abs/2404.13742v1"}
{"created":"2024-04-21 18:24:43","title":"Stochastic Multi-round Submodular Optimization with Budget","abstract":"In this work we study the problem of Stochastic Budgeted Multi-round Submodular Maximization (SBMSm), in which we would like to maximize the sum over multiple rounds of the value of a monotone and submodular objective function, subject to the fact that the values of this function depend on the realization of stochastic events and the number of observations that we can make over all rounds is limited by a given budget. This problem extends, and generalizes to multiple round settings, well-studied problems such as (adaptive) influence maximization and stochastic probing.   We first show that whenever a certain single-round optimization problem can be optimally solved in polynomial time, then there is a polynomial time dynamic programming algorithm that returns the same solution as the optimal algorithm, that can adaptively choose both which observations to make and in which round to have them. Unfortunately, this dynamic programming approach cannot be extended to work when the single-round optimization problem cannot be efficiently solved (even if we allow it would be approximated within an arbitrary small constant). Anyway, in this case we are able to provide a simple greedy algorithm for the problem. It guarantees a $(1/2-\\epsilon)$-approximation to the optimal value, even if it non-adaptively allocates the budget to rounds.","sentences":["In this work we study the problem of Stochastic Budgeted Multi-round Submodular Maximization (SBMSm), in which we would like to maximize the sum over multiple rounds of the value of a monotone and submodular objective function, subject to the fact that the values of this function depend on the realization of stochastic events and the number of observations that we can make over all rounds is limited by a given budget.","This problem extends, and generalizes to multiple round settings, well-studied problems such as (adaptive) influence maximization and stochastic probing.   ","We first show that whenever a certain single-round optimization problem can be optimally solved in polynomial time, then there is a polynomial time dynamic programming algorithm that returns the same solution as the optimal algorithm, that can adaptively choose both which observations to make and in which round to have them.","Unfortunately, this dynamic programming approach cannot be extended to work when the single-round optimization problem cannot be efficiently solved (even if we allow it would be approximated within an arbitrary small constant).","Anyway, in this case we are able to provide a simple greedy algorithm for the problem.","It guarantees a $(1/2-\\epsilon)$-approximation to the optimal value, even if it non-adaptively allocates the budget to rounds."],"url":"http://arxiv.org/abs/2404.13737v1"}
{"created":"2024-04-21 18:19:27","title":"Elucidating the Design Space of Dataset Condensation","abstract":"Dataset condensation, a concept within data-centric learning, efficiently transfers critical attributes from an original dataset to a synthetic version, maintaining both diversity and realism. This approach significantly improves model training efficiency and is adaptable across multiple application areas. Previous methods in dataset condensation have faced challenges: some incur high computational costs which limit scalability to larger datasets (e.g., MTT, DREAM, and TESLA), while others are restricted to less optimal design spaces, which could hinder potential improvements, especially in smaller datasets (e.g., SRe2L, G-VBSM, and RDED). To address these limitations, we propose a comprehensive design framework that includes specific, effective strategies like implementing soft category-aware matching and adjusting the learning rate schedule. These strategies are grounded in empirical evidence and theoretical backing. Our resulting approach, Elucidate Dataset Condensation (EDC), establishes a benchmark for both small and large-scale dataset condensation. In our testing, EDC achieves state-of-the-art accuracy, reaching 48.6% on ImageNet-1k with a ResNet-18 model at an IPC of 10, which corresponds to a compression ratio of 0.78%. This performance exceeds those of SRe2L, G-VBSM, and RDED by margins of 27.3%, 17.2%, and 6.6%, respectively.","sentences":["Dataset condensation, a concept within data-centric learning, efficiently transfers critical attributes from an original dataset to a synthetic version, maintaining both diversity and realism.","This approach significantly improves model training efficiency and is adaptable across multiple application areas.","Previous methods in dataset condensation have faced challenges: some incur high computational costs which limit scalability to larger datasets (e.g., MTT, DREAM, and TESLA), while others are restricted to less optimal design spaces, which could hinder potential improvements, especially in smaller datasets (e.g., SRe2L, G-VBSM, and RDED).","To address these limitations, we propose a comprehensive design framework that includes specific, effective strategies like implementing soft category-aware matching and adjusting the learning rate schedule.","These strategies are grounded in empirical evidence and theoretical backing.","Our resulting approach, Elucidate Dataset Condensation (EDC), establishes a benchmark for both small and large-scale dataset condensation.","In our testing, EDC achieves state-of-the-art accuracy, reaching 48.6% on ImageNet-1k with a ResNet-18 model at an IPC of 10, which corresponds to a compression ratio of 0.78%.","This performance exceeds those of SRe2L, G-VBSM, and RDED by margins of 27.3%, 17.2%, and 6.6%, respectively."],"url":"http://arxiv.org/abs/2404.13733v1"}
{"created":"2024-04-21 16:05:38","title":"Semantic-Rearrangement-Based Multi-Level Alignment for Domain Generalized Segmentation","abstract":"Domain generalized semantic segmentation is an essential computer vision task, for which models only leverage source data to learn the capability of generalized semantic segmentation towards the unseen target domains. Previous works typically address this challenge by global style randomization or feature regularization. In this paper, we argue that given the observation that different local semantic regions perform different visual characteristics from the source domain to the target domain, methods focusing on global operations are hard to capture such regional discrepancies, thus failing to construct domain-invariant representations with the consistency from local to global level. Therefore, we propose the Semantic-Rearrangement-based Multi-Level Alignment (SRMA) to overcome this problem. SRMA first incorporates a Semantic Rearrangement Module (SRM), which conducts semantic region randomization to enhance the diversity of the source domain sufficiently. A Multi-Level Alignment module (MLA) is subsequently proposed with the help of such diversity to establish the global-regional-local consistent domain-invariant representations. By aligning features across randomized samples with domain-neutral knowledge at multiple levels, SRMA provides a more robust way to handle the source-target domain gap. Extensive experiments demonstrate the superiority of SRMA over the current state-of-the-art works on various benchmarks.","sentences":["Domain generalized semantic segmentation is an essential computer vision task, for which models only leverage source data to learn the capability of generalized semantic segmentation towards the unseen target domains.","Previous works typically address this challenge by global style randomization or feature regularization.","In this paper, we argue that given the observation that different local semantic regions perform different visual characteristics from the source domain to the target domain, methods focusing on global operations are hard to capture such regional discrepancies, thus failing to construct domain-invariant representations with the consistency from local to global level.","Therefore, we propose the Semantic-Rearrangement-based Multi-Level Alignment (SRMA) to overcome this problem.","SRMA first incorporates a Semantic Rearrangement Module (SRM), which conducts semantic region randomization to enhance the diversity of the source domain sufficiently.","A Multi-Level Alignment module (MLA) is subsequently proposed with the help of such diversity to establish the global-regional-local consistent domain-invariant representations.","By aligning features across randomized samples with domain-neutral knowledge at multiple levels, SRMA provides a more robust way to handle the source-target domain gap.","Extensive experiments demonstrate the superiority of SRMA over the current state-of-the-art works on various benchmarks."],"url":"http://arxiv.org/abs/2404.13701v1"}
{"created":"2024-04-21 15:40:41","title":"A sustainable development perspective on urban-scale roof greening priorities and benefits","abstract":"Greenspaces are tightly linked to human well-being. Yet, rapid urbanization has exacerbated greenspace exposure inequality and declining human life quality. Roof greening has been recognized as an effective strategy to mitigate these negative impacts. Understanding priorities and benefits is crucial to promoting green roofs. Here, using geospatial big data, we conduct an urban-scale assessment of roof greening at a single building level in Hong Kong from a sustainable development perspective. We identify that 85.3\\% of buildings reveal potential and urgent demand for roof greening. We further find green roofs could increase greenspace exposure by \\textasciitilde61\\% and produce hundreds of millions (HK\\$) in economic benefits annually but play a small role in urban heat mitigation (\\textasciitilde0.15\\degree{C}) and annual carbon emission offsets (\\textasciitilde0.8\\%). Our study offers a comprehensive assessment of roof greening, which could provide reference for sustainable development in cities worldwide, from data utilization to solutions and findings.","sentences":["Greenspaces are tightly linked to human well-being.","Yet, rapid urbanization has exacerbated greenspace exposure inequality and declining human life quality.","Roof greening has been recognized as an effective strategy to mitigate these negative impacts.","Understanding priorities and benefits is crucial to promoting green roofs.","Here, using geospatial big data, we conduct an urban-scale assessment of roof greening at a single building level in Hong Kong from a sustainable development perspective.","We identify that 85.3\\% of buildings reveal potential and urgent demand for roof greening.","We further find green roofs could increase greenspace exposure by \\textasciitilde61\\% and produce hundreds of millions (HK\\$) in economic benefits annually but play a small role in urban heat mitigation (\\textasciitilde0.15\\degree{C}) and annual carbon emission offsets (\\textasciitilde0.8\\%).","Our study offers a comprehensive assessment of roof greening, which could provide reference for sustainable development in cities worldwide, from data utilization to solutions and findings."],"url":"http://arxiv.org/abs/2404.13692v1"}
{"created":"2024-04-21 15:40:32","title":"A Complete System for Automated 3D Semantic-Geometric Mapping of Corrosion in Industrial Environments","abstract":"Corrosion, a naturally occurring process leading to the deterioration of metallic materials, demands diligent detection for quality control and the preservation of metal-based objects, especially within industrial contexts. Traditional techniques for corrosion identification, including ultrasonic testing, radio-graphic testing, and magnetic flux leakage, necessitate the deployment of expensive and bulky equipment on-site for effective data acquisition. An unexplored alternative involves employing lightweight, conventional camera systems, and state-of-the-art computer vision methods for its identification.   In this work, we propose a complete system for semi-automated corrosion identification and mapping in industrial environments. We leverage recent advances in LiDAR-based methods for localization and mapping, with vision-based semantic segmentation deep learning techniques, in order to build semantic-geometric maps of industrial environments. Unlike previous corrosion identification systems available in the literature, our designed multi-modal system is low-cost, portable, semi-autonomous and allows collecting large datasets by untrained personnel.   A set of experiments in an indoor laboratory environment, demonstrate quantitatively the high accuracy of the employed LiDAR based 3D mapping and localization system, with less then $0.05m$ and 0.02m average absolute and relative pose errors. Also, our data-driven semantic segmentation model, achieves around 70\\% precision when trained with our pixel-wise manually annotated dataset.","sentences":["Corrosion, a naturally occurring process leading to the deterioration of metallic materials, demands diligent detection for quality control and the preservation of metal-based objects, especially within industrial contexts.","Traditional techniques for corrosion identification, including ultrasonic testing, radio-graphic testing, and magnetic flux leakage, necessitate the deployment of expensive and bulky equipment on-site for effective data acquisition.","An unexplored alternative involves employing lightweight, conventional camera systems, and state-of-the-art computer vision methods for its identification.   ","In this work, we propose a complete system for semi-automated corrosion identification and mapping in industrial environments.","We leverage recent advances in LiDAR-based methods for localization and mapping, with vision-based semantic segmentation deep learning techniques, in order to build semantic-geometric maps of industrial environments.","Unlike previous corrosion identification systems available in the literature, our designed multi-modal system is low-cost, portable, semi-autonomous and allows collecting large datasets by untrained personnel.   ","A set of experiments in an indoor laboratory environment, demonstrate quantitatively the high accuracy of the employed LiDAR based 3D mapping and localization system, with less then $0.05m$ and 0.02m average absolute and relative pose errors.","Also, our data-driven semantic segmentation model, achieves around 70\\% precision when trained with our pixel-wise manually annotated dataset."],"url":"http://arxiv.org/abs/2404.13691v1"}
{"created":"2024-04-21 15:33:17","title":"Detecting Compromised IoT Devices Using Autoencoders with Sequential Hypothesis Testing","abstract":"IoT devices fundamentally lack built-in security mechanisms to protect themselves from security attacks. Existing works on improving IoT security mostly focus on detecting anomalous behaviors of IoT devices. However, these existing anomaly detection schemes may trigger an overwhelmingly large number of false alerts, rendering them unusable in detecting compromised IoT devices. In this paper we develop an effective and efficient framework, named CUMAD, to detect compromised IoT devices. Instead of directly relying on individual anomalous events, CUMAD aims to accumulate sufficient evidence in detecting compromised IoT devices, by integrating an autoencoder-based anomaly detection subsystem with a sequential probability ratio test (SPRT)-based sequential hypothesis testing subsystem. CUMAD can effectively reduce the number of false alerts in detecting compromised IoT devices, and moreover, it can detect compromised IoT devices quickly. Our evaluation studies based on the public-domain N-BaIoT dataset show that CUMAD can on average reduce the false positive rate from about 3.57% using only the autoencoder-based anomaly detection scheme to about 0.5%; in addition, CUMAD can detect compromised IoT devices quickly, with less than 5 observations on average.","sentences":["IoT devices fundamentally lack built-in security mechanisms to protect themselves from security attacks.","Existing works on improving IoT security mostly focus on detecting anomalous behaviors of IoT devices.","However, these existing anomaly detection schemes may trigger an overwhelmingly large number of false alerts, rendering them unusable in detecting compromised IoT devices.","In this paper we develop an effective and efficient framework, named CUMAD, to detect compromised IoT devices.","Instead of directly relying on individual anomalous events, CUMAD aims to accumulate sufficient evidence in detecting compromised IoT devices, by integrating an autoencoder-based anomaly detection subsystem with a sequential probability ratio test (SPRT)-based sequential hypothesis testing subsystem.","CUMAD can effectively reduce the number of false alerts in detecting compromised IoT devices, and moreover, it can detect compromised IoT devices quickly.","Our evaluation studies based on the public-domain N-BaIoT dataset show that CUMAD can on average reduce the false positive rate from about 3.57% using only the autoencoder-based anomaly detection scheme to about 0.5%; in addition, CUMAD can detect compromised IoT devices quickly, with less than 5 observations on average."],"url":"http://arxiv.org/abs/2404.13690v1"}
{"created":"2024-04-21 14:53:33","title":"Reproducible data science over data lakes: replayable data pipelines with Bauplan and Nessie","abstract":"As the Lakehouse architecture becomes more widespread, ensuring the reproducibility of data workloads over data lakes emerges as a crucial concern for data engineers. However, achieving reproducibility remains challenging. The size of data pipelines contributes to slow testing and iterations, while the intertwining of business logic and data management complicates debugging and increases error susceptibility. In this paper, we highlight recent advancements made at Bauplan in addressing this challenge. We introduce a system designed to decouple compute from data management, by leveraging a cloud runtime alongside Nessie, an open-source catalog with Git semantics. Demonstrating the system's capabilities, we showcase its ability to offer time-travel and branching semantics on top of object storage, and offer full pipeline reproducibility with a few CLI commands.","sentences":["As the Lakehouse architecture becomes more widespread, ensuring the reproducibility of data workloads over data lakes emerges as a crucial concern for data engineers.","However, achieving reproducibility remains challenging.","The size of data pipelines contributes to slow testing and iterations, while the intertwining of business logic and data management complicates debugging and increases error susceptibility.","In this paper, we highlight recent advancements made at Bauplan in addressing this challenge.","We introduce a system designed to decouple compute from data management, by leveraging a cloud runtime alongside Nessie, an open-source catalog with Git semantics.","Demonstrating the system's capabilities, we showcase its ability to offer time-travel and branching semantics on top of object storage, and offer full pipeline reproducibility with a few CLI commands."],"url":"http://arxiv.org/abs/2404.13682v1"}
{"created":"2024-04-21 14:43:31","title":"PoseAnimate: Zero-shot high fidelity pose controllable character animation","abstract":"Image-to-video(I2V) generation aims to create a video sequence from a single image, which requires high temporal coherence and visual fidelity with the source image.However, existing approaches suffer from character appearance inconsistency and poor preservation of fine details. Moreover, they require a large amount of video data for training, which can be computationally demanding.To address these limitations,we propose PoseAnimate, a novel zero-shot I2V framework for character animation.PoseAnimate contains three key components: 1) Pose-Aware Control Module (PACM) incorporates diverse pose signals into conditional embeddings, to preserve character-independent content and maintain precise alignment of actions.2) Dual Consistency Attention Module (DCAM) enhances temporal consistency, and retains character identity and intricate background details.3) Mask-Guided Decoupling Module (MGDM) refines distinct feature perception, improving animation fidelity by decoupling the character and background.We also propose a Pose Alignment Transition Algorithm (PATA) to ensure smooth action transition.Extensive experiment results demonstrate that our approach outperforms the state-of-the-art training-based methods in terms of character consistency and detail fidelity. Moreover, it maintains a high level of temporal coherence throughout the generated animations.","sentences":["Image-to-video(I2V) generation aims to create a video sequence from a single image, which requires high temporal coherence and visual fidelity with the source image.","However, existing approaches suffer from character appearance inconsistency and poor preservation of fine details.","Moreover, they require a large amount of video data for training, which can be computationally demanding.","To address these limitations,we propose PoseAnimate, a novel zero-shot I2V framework for character animation.","PoseAnimate contains three key components: 1) Pose-Aware Control Module (PACM) incorporates diverse pose signals into conditional embeddings, to preserve character-independent content and maintain precise alignment of actions.2) Dual Consistency Attention Module (DCAM) enhances temporal consistency, and retains character identity and intricate background details.3)","Mask-Guided Decoupling Module (MGDM) refines distinct feature perception, improving animation fidelity by decoupling the character and background.","We also propose a Pose Alignment Transition Algorithm (PATA) to ensure smooth action transition.","Extensive experiment results demonstrate that our approach outperforms the state-of-the-art training-based methods in terms of character consistency and detail fidelity.","Moreover, it maintains a high level of temporal coherence throughout the generated animations."],"url":"http://arxiv.org/abs/2404.13680v1"}
{"created":"2024-04-21 14:41:40","title":"Adaptive Social Force Window Planner with Reinforcement Learning","abstract":"Human-aware navigation is a complex task for mobile robots, requiring an autonomous navigation system capable of achieving efficient path planning together with socially compliant behaviors. Social planners usually add costs or constraints to the objective function, leading to intricate tuning processes or tailoring the solution to the specific social scenario. Machine Learning can enhance planners' versatility and help them learn complex social behaviors from data. This work proposes an adaptive social planner, using a Deep Reinforcement Learning agent to dynamically adjust the weighting parameters of the cost function used to evaluate trajectories. The resulting planner combines the robustness of the classic Dynamic Window Approach, integrated with a social cost based on the Social Force Model, and the flexibility of learning methods to boost the overall performance on social navigation tasks. Our extensive experimentation on different environments demonstrates the general advantage of the proposed method over static cost planners.","sentences":["Human-aware navigation is a complex task for mobile robots, requiring an autonomous navigation system capable of achieving efficient path planning together with socially compliant behaviors.","Social planners usually add costs or constraints to the objective function, leading to intricate tuning processes or tailoring the solution to the specific social scenario.","Machine Learning can enhance planners' versatility and help them learn complex social behaviors from data.","This work proposes an adaptive social planner, using a Deep Reinforcement Learning agent to dynamically adjust the weighting parameters of the cost function used to evaluate trajectories.","The resulting planner combines the robustness of the classic Dynamic Window Approach, integrated with a social cost based on the Social Force Model, and the flexibility of learning methods to boost the overall performance on social navigation tasks.","Our extensive experimentation on different environments demonstrates the general advantage of the proposed method over static cost planners."],"url":"http://arxiv.org/abs/2404.13678v1"}
{"created":"2024-04-21 14:03:34","title":"MathNet: A Data-Centric Approach for Printed Mathematical Expression Recognition","abstract":"Printed mathematical expression recognition (MER) models are usually trained and tested using LaTeX-generated mathematical expressions (MEs) as input and the LaTeX source code as ground truth. As the same ME can be generated by various different LaTeX source codes, this leads to unwanted variations in the ground truth data that bias test performance results and hinder efficient learning. In addition, the use of only one font to generate the MEs heavily limits the generalization of the reported results to realistic scenarios. We propose a data-centric approach to overcome this problem, and present convincing experimental results: Our main contribution is an enhanced LaTeX normalization to map any LaTeX ME to a canonical form. Based on this process, we developed an improved version of the benchmark dataset im2latex-100k, featuring 30 fonts instead of one. Second, we introduce the real-world dataset realFormula, with MEs extracted from papers. Third, we developed a MER model, MathNet, based on a convolutional vision transformer, with superior results on all four test sets (im2latex-100k, im2latexv2, realFormula, and InftyMDB-1), outperforming the previous state of the art by up to 88.3%.","sentences":["Printed mathematical expression recognition (MER) models are usually trained and tested using LaTeX-generated mathematical expressions (MEs) as input and the LaTeX source code as ground truth.","As the same ME can be generated by various different LaTeX source codes, this leads to unwanted variations in the ground truth data that bias test performance results and hinder efficient learning.","In addition, the use of only one font to generate the MEs heavily limits the generalization of the reported results to realistic scenarios.","We propose a data-centric approach to overcome this problem, and present convincing experimental results: Our main contribution is an enhanced LaTeX normalization to map any LaTeX ME to a canonical form.","Based on this process, we developed an improved version of the benchmark dataset im2latex-100k, featuring 30 fonts instead of one.","Second, we introduce the real-world dataset realFormula, with MEs extracted from papers.","Third, we developed a MER model, MathNet, based on a convolutional vision transformer, with superior results on all four test sets (im2latex-100k, im2latexv2, realFormula, and InftyMDB-1), outperforming the previous state of the art by up to 88.3%."],"url":"http://arxiv.org/abs/2404.13667v1"}
{"created":"2024-04-21 13:51:31","title":"Cumulative Hazard Function Based Efficient Multivariate Temporal Point Process Learning","abstract":"Most existing temporal point process models are characterized by conditional intensity function. These models often require numerical approximation methods for likelihood evaluation, which potentially hurts their performance. By directly modelling the integral of the intensity function, i.e., the cumulative hazard function (CHF), the likelihood can be evaluated accurately, making it a promising approach. However, existing CHF-based methods are not well-defined, i.e., the mathematical constraints of CHF are not completely satisfied, leading to untrustworthy results. For multivariate temporal point process, most existing methods model intensity (or density, etc.) functions for each variate, limiting the scalability. In this paper, we explore using neural networks to model a flexible but well-defined CHF and learning the multivariate temporal point process with low parameter complexity. Experimental results on six datasets show that the proposed model achieves the state-of-the-art performance on data fitting and event prediction tasks while having significantly fewer parameters and memory usage than the strong competitors. The source code and data can be obtained from https://github.com/lbq8942/NPP.","sentences":["Most existing temporal point process models are characterized by conditional intensity function.","These models often require numerical approximation methods for likelihood evaluation, which potentially hurts their performance.","By directly modelling the integral of the intensity function, i.e., the cumulative hazard function (CHF), the likelihood can be evaluated accurately, making it a promising approach.","However, existing CHF-based methods are not well-defined, i.e., the mathematical constraints of CHF are not completely satisfied, leading to untrustworthy results.","For multivariate temporal point process, most existing methods model intensity (or density, etc.) functions for each variate, limiting the scalability.","In this paper, we explore using neural networks to model a flexible but well-defined CHF and learning the multivariate temporal point process with low parameter complexity.","Experimental results on six datasets show that the proposed model achieves the state-of-the-art performance on data fitting and event prediction tasks while having significantly fewer parameters and memory usage than the strong competitors.","The source code and data can be obtained from https://github.com/lbq8942/NPP."],"url":"http://arxiv.org/abs/2404.13663v1"}
{"created":"2024-04-21 13:29:42","title":"LMFNet: An Efficient Multimodal Fusion Approach for Semantic Segmentation in High-Resolution Remote Sensing","abstract":"Despite the rapid evolution of semantic segmentation for land cover classification in high-resolution remote sensing imagery, integrating multiple data modalities such as Digital Surface Model (DSM), RGB, and Near-infrared (NIR) remains a challenge. Current methods often process only two types of data, missing out on the rich information that additional modalities can provide. Addressing this gap, we propose a novel \\textbf{L}ightweight \\textbf{M}ultimodal data \\textbf{F}usion \\textbf{Net}work (LMFNet) to accomplish the tasks of fusion and semantic segmentation of multimodal remote sensing images. LMFNet uniquely accommodates various data types simultaneously, including RGB, NirRG, and DSM, through a weight-sharing, multi-branch vision transformer that minimizes parameter count while ensuring robust feature extraction. Our proposed multimodal fusion module integrates a \\textit{Multimodal Feature Fusion Reconstruction Layer} and \\textit{Multimodal Feature Self-Attention Fusion Layer}, which can reconstruct and fuse multimodal features. Extensive testing on public datasets such as US3D, ISPRS Potsdam, and ISPRS Vaihingen demonstrates the effectiveness of LMFNet. Specifically, it achieves a mean Intersection over Union ($mIoU$) of 85.09\\% on the US3D dataset, marking a significant improvement over existing methods. Compared to unimodal approaches, LMFNet shows a 10\\% enhancement in $mIoU$ with only a 0.5M increase in parameter count. Furthermore, against bimodal methods, our approach with trilateral inputs enhances $mIoU$ by 0.46 percentage points.","sentences":["Despite the rapid evolution of semantic segmentation for land cover classification in high-resolution remote sensing imagery, integrating multiple data modalities such as Digital Surface Model (DSM), RGB, and Near-infrared (NIR) remains a challenge.","Current methods often process only two types of data, missing out on the rich information that additional modalities can provide.","Addressing this gap, we propose a novel \\textbf{L}ightweight \\textbf{M}ultimodal data \\textbf{F}usion \\textbf{Net}work (LMFNet) to accomplish the tasks of fusion and semantic segmentation of multimodal remote sensing images.","LMFNet uniquely accommodates various data types simultaneously, including RGB, NirRG, and DSM, through a weight-sharing, multi-branch vision transformer that minimizes parameter count while ensuring robust feature extraction.","Our proposed multimodal fusion module integrates a \\textit{Multimodal Feature Fusion Reconstruction Layer} and \\textit{Multimodal Feature Self-Attention Fusion Layer}, which can reconstruct and fuse multimodal features.","Extensive testing on public datasets such as US3D, ISPRS Potsdam, and ISPRS Vaihingen demonstrates the effectiveness of LMFNet.","Specifically, it achieves a mean Intersection over Union ($mIoU$) of 85.09\\% on the US3D dataset, marking a significant improvement over existing methods.","Compared to unimodal approaches, LMFNet shows a 10\\% enhancement in $mIoU$ with only a 0.5M increase in parameter count.","Furthermore, against bimodal methods, our approach with trilateral inputs enhances $mIoU$ by 0.46 percentage points."],"url":"http://arxiv.org/abs/2404.13659v1"}
{"created":"2024-04-21 13:25:46","title":"MLP: Motion Label Prior for Temporal Sentence Localization in Untrimmed 3D Human Motions","abstract":"In this paper, we address the unexplored question of temporal sentence localization in human motions (TSLM), aiming to locate a target moment from a 3D human motion that semantically corresponds to a text query. Considering that 3D human motions are captured using specialized motion capture devices, motions with only a few joints lack complex scene information like objects and lighting. Due to this character, motion data has low contextual richness and semantic ambiguity between frames, which limits the accuracy of predictions made by current video localization frameworks extended to TSLM to only a rough level. To refine this, we devise two novel label-prior-assisted training schemes: one embed prior knowledge of foreground and background to highlight the localization chances of target moments, and the other forces the originally rough predictions to overlap with the more accurate predictions obtained from the flipped start/end prior label sequences during recovery training. We show that injecting label-prior knowledge into the model is crucial for improving performance at high IoU. In our constructed TSLM benchmark, our model termed MLP achieves a recall of 44.13 at IoU@0.7 on the BABEL dataset and 71.17 on HumanML3D (Restore), outperforming prior works. Finally, we showcase the potential of our approach in corpus-level moment retrieval. Our source code is openly accessible at https://github.com/eanson023/mlp.","sentences":["In this paper, we address the unexplored question of temporal sentence localization in human motions (TSLM), aiming to locate a target moment from a 3D human motion that semantically corresponds to a text query.","Considering that 3D human motions are captured using specialized motion capture devices, motions with only a few joints lack complex scene information like objects and lighting.","Due to this character, motion data has low contextual richness and semantic ambiguity between frames, which limits the accuracy of predictions made by current video localization frameworks extended to TSLM to only a rough level.","To refine this, we devise two novel label-prior-assisted training schemes: one embed prior knowledge of foreground and background to highlight the localization chances of target moments, and the other forces the originally rough predictions to overlap with the more accurate predictions obtained from the flipped start/end prior label sequences during recovery training.","We show that injecting label-prior knowledge into the model is crucial for improving performance at high IoU.","In our constructed TSLM benchmark, our model termed MLP achieves a recall of 44.13 at IoU@0.7 on the BABEL dataset and 71.17 on HumanML3D (Restore), outperforming prior works.","Finally, we showcase the potential of our approach in corpus-level moment retrieval.","Our source code is openly accessible at https://github.com/eanson023/mlp."],"url":"http://arxiv.org/abs/2404.13657v1"}
{"created":"2024-04-21 13:11:59","title":"SPGNN: Recognizing Salient Subgraph Patterns via Enhanced Graph Convolution and Pooling","abstract":"Graph neural networks (GNNs) have revolutionized the field of machine learning on non-Euclidean data such as graphs and networks. GNNs effectively implement node representation learning through neighborhood aggregation and achieve impressive results in many graph-related tasks. However, most neighborhood aggregation approaches are summation-based, which can be problematic as they may not be sufficiently expressive to encode informative graph structures. Furthermore, though the graph pooling module is also of vital importance for graph learning, especially for the task of graph classification, research on graph down-sampling mechanisms is rather limited.   To address the above challenges, we propose a concatenation-based graph convolution mechanism that injectively updates node representations to maximize the discriminative power in distinguishing non-isomorphic subgraphs. In addition, we design a novel graph pooling module, called WL-SortPool, to learn important subgraph patterns in a deep-learning manner. WL-SortPool layer-wise sorts node representations (i.e. continuous WL colors) to separately learn the relative importance of subtrees with different depths for the purpose of classification, thus better characterizing the complex graph topology and rich information encoded in the graph. We propose a novel Subgraph Pattern GNN (SPGNN) architecture that incorporates these enhancements. We test the proposed SPGNN architecture on many graph classification benchmarks. Experimental results show that our method can achieve highly competitive results with state-of-the-art graph kernels and other GNN approaches.","sentences":["Graph neural networks (GNNs) have revolutionized the field of machine learning on non-Euclidean data such as graphs and networks.","GNNs effectively implement node representation learning through neighborhood aggregation and achieve impressive results in many graph-related tasks.","However, most neighborhood aggregation approaches are summation-based, which can be problematic as they may not be sufficiently expressive to encode informative graph structures.","Furthermore, though the graph pooling module is also of vital importance for graph learning, especially for the task of graph classification, research on graph down-sampling mechanisms is rather limited.   ","To address the above challenges, we propose a concatenation-based graph convolution mechanism that injectively updates node representations to maximize the discriminative power in distinguishing non-isomorphic subgraphs.","In addition, we design a novel graph pooling module, called WL-SortPool, to learn important subgraph patterns in a deep-learning manner.","WL-SortPool layer-wise sorts node representations (i.e. continuous WL colors) to separately learn the relative importance of subtrees with different depths for the purpose of classification, thus better characterizing the complex graph topology and rich information encoded in the graph.","We propose a novel Subgraph Pattern GNN (SPGNN) architecture that incorporates these enhancements.","We test the proposed SPGNN architecture on many graph classification benchmarks.","Experimental results show that our method can achieve highly competitive results with state-of-the-art graph kernels and other GNN approaches."],"url":"http://arxiv.org/abs/2404.13655v1"}
