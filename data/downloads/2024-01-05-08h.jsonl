{"created":"2024-01-04 18:59:49","title":"Learning to Prompt with Text Only Supervision for Vision-Language Models","abstract":"Foundational vision-language models such as CLIP are becoming a new paradigm in vision, due to their excellent generalization abilities. However, adapting these models for downstream tasks while maintaining their generalization remains a challenge. In literature, one branch of methods adapts CLIP by learning prompts using visual information. While effective, most of these works require labeled data which is not practical, and often struggle to generalize towards new datasets due to over-fitting on the source data. An alternative approach resorts to training-free methods by generating class descriptions from large language models (LLMs) and perform prompt ensembling. However, these methods often generate class specific prompts that cannot be transferred to other classes, which incur higher costs by generating LLM descriptions for each class separately. In this work, we propose to combine the strengths of these both streams of methods by learning prompts using only text data derived from LLMs. As supervised training of prompts is not trivial due to absence of images, we develop a training approach that allows prompts to extract rich contextual knowledge from LLM data. Moreover, with LLM contextual data mapped within the learned prompts, it enables zero-shot transfer of prompts to new classes and datasets potentially cutting the LLM prompt engineering cost. To the best of our knowledge, this is the first work that learns generalized prompts using text only data. We perform extensive evaluations on 4 benchmarks where our method improves over prior ensembling works while being competitive to those utilizing labeled images. Our code and pre-trained models are available at https://github.com/muzairkhattak/ProText.","sentences":["Foundational vision-language models such as CLIP are becoming a new paradigm in vision, due to their excellent generalization abilities.","However, adapting these models for downstream tasks while maintaining their generalization remains a challenge.","In literature, one branch of methods adapts CLIP by learning prompts using visual information.","While effective, most of these works require labeled data which is not practical, and often struggle to generalize towards new datasets due to over-fitting on the source data.","An alternative approach resorts to training-free methods by generating class descriptions from large language models (LLMs) and perform prompt ensembling.","However, these methods often generate class specific prompts that cannot be transferred to other classes, which incur higher costs by generating LLM descriptions for each class separately.","In this work, we propose to combine the strengths of these both streams of methods by learning prompts using only text data derived from LLMs.","As supervised training of prompts is not trivial due to absence of images, we develop a training approach that allows prompts to extract rich contextual knowledge from LLM data.","Moreover, with LLM contextual data mapped within the learned prompts, it enables zero-shot transfer of prompts to new classes and datasets potentially cutting the LLM prompt engineering cost.","To the best of our knowledge, this is the first work that learns generalized prompts using text only data.","We perform extensive evaluations on 4 benchmarks where our method improves over prior ensembling works while being competitive to those utilizing labeled images.","Our code and pre-trained models are available at https://github.com/muzairkhattak/ProText."],"url":"http://arxiv.org/abs/2401.02418v1"}
{"created":"2024-01-04 18:53:01","title":"LLM Augmented LLMs: Expanding Capabilities through Composition","abstract":"Foundational models with billions of parameters which have been trained on large corpora of data have demonstrated non-trivial skills in a variety of domains. However, due to their monolithic structure, it is challenging and expensive to augment them or impart new skills. On the other hand, due to their adaptation abilities, several new instances of these models are being trained towards new domains and tasks. In this work, we study the problem of efficient and practical composition of existing foundation models with more specific models to enable newer capabilities. To this end, we propose CALM -- Composition to Augment Language Models -- which introduces cross-attention between models to compose their representations and enable new capabilities. Salient features of CALM are: (i) Scales up LLMs on new tasks by 're-using' existing LLMs along with a few additional parameters and data, (ii) Existing model weights are kept intact, and hence preserves existing capabilities, and (iii) Applies to diverse domains and settings. We illustrate that augmenting PaLM2-S with a smaller model trained on low-resource languages results in an absolute improvement of up to 13\\% on tasks like translation into English and arithmetic reasoning for low-resource languages. Similarly, when PaLM2-S is augmented with a code-specific model, we see a relative improvement of 40\\% over the base model for code generation and explanation tasks -- on-par with fully fine-tuned counterparts.","sentences":["Foundational models with billions of parameters which have been trained on large corpora of data have demonstrated non-trivial skills in a variety of domains.","However, due to their monolithic structure, it is challenging and expensive to augment them or impart new skills.","On the other hand, due to their adaptation abilities, several new instances of these models are being trained towards new domains and tasks.","In this work, we study the problem of efficient and practical composition of existing foundation models with more specific models to enable newer capabilities.","To this end, we propose CALM -- Composition to Augment Language Models -- which introduces cross-attention between models to compose their representations and enable new capabilities.","Salient features of CALM are: (i) Scales up LLMs on new tasks by 're-using' existing LLMs along with a few additional parameters and data, (ii) Existing model weights are kept intact, and hence preserves existing capabilities, and (iii) Applies to diverse domains and settings.","We illustrate that augmenting PaLM2-S with a smaller model trained on low-resource languages results in an absolute improvement of up to 13\\% on tasks like translation into English and arithmetic reasoning for low-resource languages.","Similarly, when PaLM2-S is augmented with a code-specific model, we see a relative improvement of 40\\% over the base model for code generation and explanation tasks -- on-par with fully fine-tuned counterparts."],"url":"http://arxiv.org/abs/2401.02412v1"}
{"created":"2024-01-04 18:43:26","title":"Correctness Comparison of ChatGPT-4, Bard, Claude-2, and Copilot for Spatial Tasks","abstract":"Generative AI including large language models (LLMs) have recently gained significant interest in the geo-science community through its versatile task-solving capabilities including coding, spatial computations, generation of sample data, time-series forecasting, toponym recognition, or image classification. So far, the assessment of LLMs for spatial tasks has primarily focused on ChatGPT, arguably the most prominent AI chatbot, whereas other chatbots received less attention. To narrow this research gap, this study evaluates the correctness of responses for a set of 54 spatial tasks assigned to four prominent chatbots, i.e., ChatGPT-4, Bard, Claude-2, and Copilot. Overall, the chatbots performed well on spatial literacy, GIS theory, and interpretation of programming code and given functions, but revealed weaknesses in mapping, code generation, and code translation. ChatGPT-4 outperformed other chatbots across most task categories.","sentences":["Generative AI including large language models (LLMs) have recently gained significant interest in the geo-science community through its versatile task-solving capabilities including coding, spatial computations, generation of sample data, time-series forecasting, toponym recognition, or image classification.","So far, the assessment of LLMs for spatial tasks has primarily focused on ChatGPT, arguably the most prominent AI chatbot, whereas other chatbots received less attention.","To narrow this research gap, this study evaluates the correctness of responses for a set of 54 spatial tasks assigned to four prominent chatbots, i.e., ChatGPT-4, Bard, Claude-2, and Copilot.","Overall, the chatbots performed well on spatial literacy, GIS theory, and interpretation of programming code and given functions, but revealed weaknesses in mapping, code generation, and code translation.","ChatGPT-4 outperformed other chatbots across most task categories."],"url":"http://arxiv.org/abs/2401.02404v1"}
{"created":"2024-01-04 18:42:28","title":"Real-Time 2D Temperature Field Prediction in Metal Additive Manufacturing Using Physics-Informed Neural Networks","abstract":"Accurately predicting the temperature field in metal additive manufacturing (AM) processes is critical to preventing overheating, adjusting process parameters, and ensuring process stability. While physics-based computational models offer precision, they are often time-consuming and unsuitable for real-time predictions and online control in iterative design scenarios. Conversely, machine learning models rely heavily on high-quality datasets, which can be costly and challenging to obtain within the metal AM domain. Our work addresses this by introducing a physics-informed neural network framework specifically designed for temperature field prediction in metal AM. This framework incorporates a physics-informed input, physics-informed loss function, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture. Utilizing real-time temperature data from the process, our model predicts 2D temperature fields for future timestamps across diverse geometries, deposition patterns, and process parameters. We validate the proposed framework in two scenarios: full-field temperature prediction for a thin wall and 2D temperature field prediction for cylinder and cubic parts, demonstrating errors below 3% and 1%, respectively. Our proposed framework exhibits the flexibility to be applied across diverse scenarios with varying process parameters, geometries, and deposition patterns.","sentences":["Accurately predicting the temperature field in metal additive manufacturing (AM) processes is critical to preventing overheating, adjusting process parameters, and ensuring process stability.","While physics-based computational models offer precision, they are often time-consuming and unsuitable for real-time predictions and online control in iterative design scenarios.","Conversely, machine learning models rely heavily on high-quality datasets, which can be costly and challenging to obtain within the metal AM domain.","Our work addresses this by introducing a physics-informed neural network framework specifically designed for temperature field prediction in metal AM.","This framework incorporates a physics-informed input, physics-informed loss function, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture.","Utilizing real-time temperature data from the process, our model predicts 2D temperature fields for future timestamps across diverse geometries, deposition patterns, and process parameters.","We validate the proposed framework in two scenarios: full-field temperature prediction for a thin wall and 2D temperature field prediction for cylinder and cubic parts, demonstrating errors below 3% and 1%, respectively.","Our proposed framework exhibits the flexibility to be applied across diverse scenarios with varying process parameters, geometries, and deposition patterns."],"url":"http://arxiv.org/abs/2401.02403v1"}
{"created":"2024-01-04 18:32:48","title":"Learning the 3D Fauna of the Web","abstract":"Learning 3D models of all animals on the Earth requires massively scaling up existing solutions. With this ultimate goal in mind, we develop 3D-Fauna, an approach that learns a pan-category deformable 3D animal model for more than 100 animal species jointly. One crucial bottleneck of modeling animals is the limited availability of training data, which we overcome by simply learning from 2D Internet images. We show that prior category-specific attempts fail to generalize to rare species with limited training images. We address this challenge by introducing the Semantic Bank of Skinned Models (SBSM), which automatically discovers a small set of base animal shapes by combining geometric inductive priors with semantic knowledge implicitly captured by an off-the-shelf self-supervised feature extractor. To train such a model, we also contribute a new large-scale dataset of diverse animal species. At inference time, given a single image of any quadruped animal, our model reconstructs an articulated 3D mesh in a feed-forward fashion within seconds.","sentences":["Learning 3D models of all animals on the Earth requires massively scaling up existing solutions.","With this ultimate goal in mind, we develop 3D-Fauna, an approach that learns a pan-category deformable 3D animal model for more than 100 animal species jointly.","One crucial bottleneck of modeling animals is the limited availability of training data, which we overcome by simply learning from 2D Internet images.","We show that prior category-specific attempts fail to generalize to rare species with limited training images.","We address this challenge by introducing the Semantic Bank of Skinned Models (SBSM), which automatically discovers a small set of base animal shapes by combining geometric inductive priors with semantic knowledge implicitly captured by an off-the-shelf self-supervised feature extractor.","To train such a model, we also contribute a new large-scale dataset of diverse animal species.","At inference time, given a single image of any quadruped animal, our model reconstructs an articulated 3D mesh in a feed-forward fashion within seconds."],"url":"http://arxiv.org/abs/2401.02400v1"}
{"created":"2024-01-04 18:31:21","title":"Generating synthetic data for neural operators","abstract":"Numerous developments in the recent literature show the promising potential of deep learning in obtaining numerical solutions to partial differential equations (PDEs) beyond the reach of current numerical solvers. However, data-driven neural operators all suffer from the same problem: the data needed to train a network depends on classical numerical solvers such as finite difference or finite element, among others. In this paper, we propose a new approach to generating synthetic functional training data that does not require solving a PDE numerically. The way we do this is simple: we draw a large number $N$ of independent and identically distributed `random functions' $u_j$ from the underlying solution space (e.g., $H_0^1(\\Omega)$) in which we know the solution lies according to classical theory. We then plug each such random candidate solution into the equation and get a corresponding right-hand side function $f_j$ for the equation, and consider $(f_j, u_j)_{j=1}^N$ as supervised training data for learning the underlying inverse problem $f \\rightarrow u$. This `backwards' approach to generating training data only requires derivative computations, in contrast to standard `forward' approaches, which require a numerical PDE solver, enabling us to generate a large number of such data points quickly and efficiently. While the idea is simple, we hope that this method will expand the potential for developing neural PDE solvers that do not depend on classical numerical solvers.","sentences":["Numerous developments in the recent literature show the promising potential of deep learning in obtaining numerical solutions to partial differential equations (PDEs) beyond the reach of current numerical solvers.","However, data-driven neural operators all suffer from the same problem: the data needed to train a network depends on classical numerical solvers such as finite difference or finite element, among others.","In this paper, we propose a new approach to generating synthetic functional training data that does not require solving a PDE numerically.","The way we do this is simple: we draw a large number $N$ of independent and identically distributed `random functions' $u_j$ from the underlying solution space (e.g., $H_0^1(\\Omega)$) in which we know the solution lies according to classical theory.","We then plug each such random candidate solution into the equation and get a corresponding right-hand side function $f_j$ for the equation, and consider $(f_j, u_j)_{j=1}^N$ as supervised training data for learning the underlying inverse problem $f \\rightarrow u$.","This `backwards' approach to generating training data only requires derivative computations, in contrast to standard `forward' approaches, which require a numerical PDE solver, enabling us to generate a large number of such data points quickly and efficiently.","While the idea is simple, we hope that this method will expand the potential for developing neural PDE solvers that do not depend on classical numerical solvers."],"url":"http://arxiv.org/abs/2401.02398v1"}
{"created":"2024-01-04 18:18:32","title":"Analyzing Misinformation Claims During the 2022 Brazilian General Election on WhatsApp, Twitter, and Kwai","abstract":"This study analyzes misinformation from WhatsApp, Twitter, and Kwai during the 2022 Brazilian general election. Given the democratic importance of accurate information during elections, multiple fact-checking organizations collaborated to identify and respond to misinformation via WhatsApp tiplines and power a fact-checking feature within a chatbot operated by Brazil's election authority, the TSE. WhatsApp is installed on over 99% of smartphones in Brazil, and the TSE chatbot was used by millions of citizens in the run-up to the elections. During the same period, we collected social media data from Twitter (now X) and Kwai (a popular video-sharing app similar to TikTok). Using the WhatsApp, Kwai, and Twitter data along with fact-checks from three Brazilian fact-checking organizations, we find unique claims on each platform. Even when the same claims are present on different platforms, they often differ in format, detail, length, or other characteristics. Our research highlights the limitations of current claim matching algorithms to match claims across platforms with such differences and identifies areas for further algorithmic development. Finally, we perform a descriptive analysis examining the formats (image, video, audio, text) and content themes of popular misinformation claims.","sentences":["This study analyzes misinformation from WhatsApp, Twitter, and Kwai during the 2022 Brazilian general election.","Given the democratic importance of accurate information during elections, multiple fact-checking organizations collaborated to identify and respond to misinformation via WhatsApp tiplines and power a fact-checking feature within a chatbot operated by Brazil's election authority, the TSE.","WhatsApp is installed on over 99% of smartphones in Brazil, and the TSE chatbot was used by millions of citizens in the run-up to the elections.","During the same period, we collected social media data from Twitter (now X) and Kwai (a popular video-sharing app similar to TikTok).","Using the WhatsApp, Kwai, and Twitter data along with fact-checks from three Brazilian fact-checking organizations, we find unique claims on each platform.","Even when the same claims are present on different platforms, they often differ in format, detail, length, or other characteristics.","Our research highlights the limitations of current claim matching algorithms to match claims across platforms with such differences and identifies areas for further algorithmic development.","Finally, we perform a descriptive analysis examining the formats (image, video, audio, text) and content themes of popular misinformation claims."],"url":"http://arxiv.org/abs/2401.02395v1"}
{"created":"2024-01-04 17:51:48","title":"ChartAssisstant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning","abstract":"Charts play a vital role in data visualization, understanding data patterns, and informed decision-making. However, their unique combination of graphical elements (e.g., bars, lines) and textual components (e.g., labels, legends) poses challenges for general-purpose multimodal models. While vision-language models trained on chart data excel in comprehension, they struggle with generalization and require task-specific fine-tuning. To address these challenges, we propose ChartAssistant, a chart-based vision-language model for universal chart comprehension and reasoning. ChartAssistant leverages ChartSFT, a comprehensive dataset covering diverse chart-related tasks with basic and specialized chart types. It undergoes a two-stage training process, starting with pre-training on chart-to-table parsing to align chart and text, followed by multitask instruction-following fine-tuning. This approach enables ChartAssistant to achieve competitive performance across various chart tasks without task-specific fine-tuning. Experimental results demonstrate significant performance gains over the state-of-the-art UniChart method, outperforming OpenAI's GPT-4V(ision) on real-world chart data. The code and data are available at https://github.com/OpenGVLab/ChartAst.","sentences":["Charts play a vital role in data visualization, understanding data patterns, and informed decision-making.","However, their unique combination of graphical elements (e.g., bars, lines) and textual components (e.g., labels, legends) poses challenges for general-purpose multimodal models.","While vision-language models trained on chart data excel in comprehension, they struggle with generalization and require task-specific fine-tuning.","To address these challenges, we propose ChartAssistant, a chart-based vision-language model for universal chart comprehension and reasoning.","ChartAssistant leverages ChartSFT, a comprehensive dataset covering diverse chart-related tasks with basic and specialized chart types.","It undergoes a two-stage training process, starting with pre-training on chart-to-table parsing to align chart and text, followed by multitask instruction-following fine-tuning.","This approach enables ChartAssistant to achieve competitive performance across various chart tasks without task-specific fine-tuning.","Experimental results demonstrate significant performance gains over the state-of-the-art UniChart method, outperforming OpenAI's GPT-4V(ision) on real-world chart data.","The code and data are available at https://github.com/OpenGVLab/ChartAst."],"url":"http://arxiv.org/abs/2401.02384v1"}
{"created":"2024-01-04 17:49:20","title":"Faster optimal univariate microgaggregation","abstract":"Microaggregation is a method to coarsen a dataset, by optimally clustering data points in groups of at least $k$ points, thereby providing a $k$-anonymity type disclosure guarantee for each point in the dataset. Previous algorithms for univariate microaggregation had a $O(k n)$ time complexity. By rephrasing microaggregation as an instance of the concave least weight subsequence problem, in this work we provide improved algorithms that provide an optimal univariate microaggregation on sorted data in $O(n)$ time and space. We further show that our algorithms work not only for sum of squares cost functions, as typically considered, but seamlessly extend to many other cost functions used for univariate microaggregation tasks. In experiments we show that the presented algorithms lead to real world performance improvements.","sentences":["Microaggregation is a method to coarsen a dataset, by optimally clustering data points in groups of at least $k$ points, thereby providing a $k$-anonymity type disclosure guarantee for each point in the dataset.","Previous algorithms for univariate microaggregation had a $O(k n)$ time complexity.","By rephrasing microaggregation as an instance of the concave least weight subsequence problem, in this work we provide improved algorithms that provide an optimal univariate microaggregation on sorted data in $O(n)$ time and space.","We further show that our algorithms work not only for sum of squares cost functions, as typically considered, but seamlessly extend to many other cost functions used for univariate microaggregation tasks.","In experiments we show that the presented algorithms lead to real world performance improvements."],"url":"http://arxiv.org/abs/2401.02381v1"}
{"created":"2024-01-04 17:47:44","title":"Byzantine-Resilient Gradient Coding through Local Gradient Computations","abstract":"We consider gradient coding in the presence of an adversary controlling so-called malicious workers trying to corrupt the computations. Previous works propose the use of MDS codes to treat the responses from malicious workers as errors and correct them using the error-correction properties of the code. This comes at the expense of increasing the replication, i.e., the number of workers each partial gradient is computed by. In this work, we propose a way to reduce the replication to $s+1$ instead of $2s+1$ in the presence of $s$ malicious workers. Our method detects erroneous inputs from the malicious workers, transforming them into erasures. This comes at the expense of $s$ additional local computations at the main node and additional rounds of light communication between the main node and the workers. We define a general framework and give fundamental limits for fractional repetition data allocations. Our scheme is optimal in terms of replication and local computation and incurs a communication cost that is asymptotically, in the size of the dataset, a multiplicative factor away from the derived bound. We furthermore show how additional redundancy can be exploited to reduce the number of local computations and communication cost, or, alternatively, tolerate straggling workers.","sentences":["We consider gradient coding in the presence of an adversary controlling so-called malicious workers trying to corrupt the computations.","Previous works propose the use of MDS codes to treat the responses from malicious workers as errors and correct them using the error-correction properties of the code.","This comes at the expense of increasing the replication, i.e., the number of workers each partial gradient is computed by.","In this work, we propose a way to reduce the replication to $s+1$ instead of $2s+1$ in the presence of $s$ malicious workers.","Our method detects erroneous inputs from the malicious workers, transforming them into erasures.","This comes at the expense of $s$ additional local computations at the main node and additional rounds of light communication between the main node and the workers.","We define a general framework and give fundamental limits for fractional repetition data allocations.","Our scheme is optimal in terms of replication and local computation and incurs a communication cost that is asymptotically, in the size of the dataset, a multiplicative factor away from the derived bound.","We furthermore show how additional redundancy can be exploited to reduce the number of local computations and communication cost, or, alternatively, tolerate straggling workers."],"url":"http://arxiv.org/abs/2401.02380v1"}
{"created":"2024-01-04 17:37:09","title":"Machine Learning in Robotic Ultrasound Imaging: Challenges and Perspectives","abstract":"This article reviews the recent advances in intelligent robotic ultrasound (US) imaging systems. We commence by presenting the commonly employed robotic mechanisms and control techniques in robotic US imaging, along with their clinical applications. Subsequently, we focus on the deployment of machine learning techniques in the development of robotic sonographers, emphasizing crucial developments aimed at enhancing the intelligence of these systems. The methods for achieving autonomous action reasoning are categorized into two sets of approaches: those relying on implicit environmental data interpretation and those using explicit interpretation. Throughout this exploration, we also discuss practical challenges, including those related to the scarcity of medical data, the need for a deeper understanding of the physical aspects involved, and effective data representation approaches. Moreover, we conclude by highlighting the open problems in the field and analyzing different possible perspectives on how the community could move forward in this research area.","sentences":["This article reviews the recent advances in intelligent robotic ultrasound (US) imaging systems.","We commence by presenting the commonly employed robotic mechanisms and control techniques in robotic US imaging, along with their clinical applications.","Subsequently, we focus on the deployment of machine learning techniques in the development of robotic sonographers, emphasizing crucial developments aimed at enhancing the intelligence of these systems.","The methods for achieving autonomous action reasoning are categorized into two sets of approaches: those relying on implicit environmental data interpretation and those using explicit interpretation.","Throughout this exploration, we also discuss practical challenges, including those related to the scarcity of medical data, the need for a deeper understanding of the physical aspects involved, and effective data representation approaches.","Moreover, we conclude by highlighting the open problems in the field and analyzing different possible perspectives on how the community could move forward in this research area."],"url":"http://arxiv.org/abs/2401.02376v1"}
{"created":"2024-01-04 17:01:54","title":"Integration of physics-informed operator learning and finite element method for parametric learning of partial differential equations","abstract":"We present a method that employs physics-informed deep learning techniques for parametrically solving partial differential equations. The focus is on the steady-state heat equations within heterogeneous solids exhibiting significant phase contrast. Similar equations manifest in diverse applications like chemical diffusion, electrostatics, and Darcy flow. The neural network aims to establish the link between the complex thermal conductivity profiles and temperature distributions, as well as heat flux components within the microstructure, under fixed boundary conditions. A distinctive aspect is our independence from classical solvers like finite element methods for data. A noteworthy contribution lies in our novel approach to defining the loss function, based on the discretized weak form of the governing equation. This not only reduces the required order of derivatives but also eliminates the need for automatic differentiation in the construction of loss terms, accepting potential numerical errors from the chosen discretization method. As a result, the loss function in this work is an algebraic equation that significantly enhances training efficiency. We benchmark our methodology against the standard finite element method, demonstrating accurate yet faster predictions using the trained neural network for temperature and flux profiles. We also show higher accuracy by using the proposed method compared to purely data-driven approaches for unforeseen scenarios.","sentences":["We present a method that employs physics-informed deep learning techniques for parametrically solving partial differential equations.","The focus is on the steady-state heat equations within heterogeneous solids exhibiting significant phase contrast.","Similar equations manifest in diverse applications like chemical diffusion, electrostatics, and Darcy flow.","The neural network aims to establish the link between the complex thermal conductivity profiles and temperature distributions, as well as heat flux components within the microstructure, under fixed boundary conditions.","A distinctive aspect is our independence from classical solvers like finite element methods for data.","A noteworthy contribution lies in our novel approach to defining the loss function, based on the discretized weak form of the governing equation.","This not only reduces the required order of derivatives but also eliminates the need for automatic differentiation in the construction of loss terms, accepting potential numerical errors from the chosen discretization method.","As a result, the loss function in this work is an algebraic equation that significantly enhances training efficiency.","We benchmark our methodology against the standard finite element method, demonstrating accurate yet faster predictions using the trained neural network for temperature and flux profiles.","We also show higher accuracy by using the proposed method compared to purely data-driven approaches for unforeseen scenarios."],"url":"http://arxiv.org/abs/2401.02363v1"}
{"created":"2024-01-04 16:38:47","title":"Multi-Source Domain Adaptation with Transformer-based Feature Generation for Subject-Independent EEG-based Emotion Recognition","abstract":"Although deep learning-based algorithms have demonstrated excellent performance in automated emotion recognition via electroencephalogram (EEG) signals, variations across brain signal patterns of individuals can diminish the model's effectiveness when applied across different subjects. While transfer learning techniques have exhibited promising outcomes, they still encounter challenges related to inadequate feature representations and may overlook the fact that source subjects themselves can possess distinct characteristics. In this work, we propose a multi-source domain adaptation approach with a transformer-based feature generator (MSDA-TF) designed to leverage information from multiple sources. The proposed feature generator retains convolutional layers to capture shallow spatial, temporal, and spectral EEG data representations, while self-attention mechanisms extract global dependencies within these features. During the adaptation process, we group the source subjects based on correlation values and aim to align the moments of the target subject with each source as well as within the sources. MSDA-TF is validated on the SEED dataset and is shown to yield promising results.","sentences":["Although deep learning-based algorithms have demonstrated excellent performance in automated emotion recognition via electroencephalogram (EEG) signals, variations across brain signal patterns of individuals can diminish the model's effectiveness when applied across different subjects.","While transfer learning techniques have exhibited promising outcomes, they still encounter challenges related to inadequate feature representations and may overlook the fact that source subjects themselves can possess distinct characteristics.","In this work, we propose a multi-source domain adaptation approach with a transformer-based feature generator (MSDA-TF) designed to leverage information from multiple sources.","The proposed feature generator retains convolutional layers to capture shallow spatial, temporal, and spectral EEG data representations, while self-attention mechanisms extract global dependencies within these features.","During the adaptation process, we group the source subjects based on correlation values and aim to align the moments of the target subject with each source as well as within the sources.","MSDA-TF is validated on the SEED dataset and is shown to yield promising results."],"url":"http://arxiv.org/abs/2401.02344v1"}
{"created":"2024-01-04 16:34:27","title":"AERIAL-CORE: AI-Powered Aerial Robots for Inspection and Maintenance of Electrical Power Infrastructures","abstract":"Large-scale infrastructures are prone to deterioration due to age, environmental influences, and heavy usage. Ensuring their safety through regular inspections and maintenance is crucial to prevent incidents that can significantly affect public safety and the environment. This is especially pertinent in the context of electrical power networks, which, while essential for energy provision, can also be sources of forest fires. Intelligent drones have the potential to revolutionize inspection and maintenance, eliminating the risks for human operators, increasing productivity, reducing inspection time, and improving data collection quality. However, most of the current methods and technologies in aerial robotics have been trialed primarily in indoor testbeds or outdoor settings under strictly controlled conditions, always within the line of sight of human operators. Additionally, these methods and technologies have typically been evaluated in isolation, lacking comprehensive integration. This paper introduces the first autonomous system that combines various innovative aerial robots. This system is designed for extended-range inspections beyond the visual line of sight, features aerial manipulators for maintenance tasks, and includes support mechanisms for human operators working at elevated heights. The paper further discusses the successful validation of this system on numerous electrical power lines, with aerial robots executing flights over 10 kilometers away from their ground control stations.","sentences":["Large-scale infrastructures are prone to deterioration due to age, environmental influences, and heavy usage.","Ensuring their safety through regular inspections and maintenance is crucial to prevent incidents that can significantly affect public safety and the environment.","This is especially pertinent in the context of electrical power networks, which, while essential for energy provision, can also be sources of forest fires.","Intelligent drones have the potential to revolutionize inspection and maintenance, eliminating the risks for human operators, increasing productivity, reducing inspection time, and improving data collection quality.","However, most of the current methods and technologies in aerial robotics have been trialed primarily in indoor testbeds or outdoor settings under strictly controlled conditions, always within the line of sight of human operators.","Additionally, these methods and technologies have typically been evaluated in isolation, lacking comprehensive integration.","This paper introduces the first autonomous system that combines various innovative aerial robots.","This system is designed for extended-range inspections beyond the visual line of sight, features aerial manipulators for maintenance tasks, and includes support mechanisms for human operators working at elevated heights.","The paper further discusses the successful validation of this system on numerous electrical power lines, with aerial robots executing flights over 10 kilometers away from their ground control stations."],"url":"http://arxiv.org/abs/2401.02343v1"}
{"created":"2024-01-04 16:16:14","title":"Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models","abstract":"The conventional use of the Retrieval-Augmented Generation (RAG) architecture has proven effective for retrieving information from diverse documents. However, challenges arise in handling complex table queries, especially within PDF documents containing intricate tabular structures.This research introduces an innovative approach to enhance the accuracy of complex table queries in RAG-based systems. Our methodology involves storing PDFs in the retrieval database and extracting tabular content separately. The extracted tables undergo a process of context enrichment, concatenating headers with corresponding values. To ensure a comprehensive understanding of the enriched data, we employ a fine-tuned version of the Llama-2-chat language model for summarisation within the RAG architecture. Furthermore, we augment the tabular data with contextual sense using the ChatGPT 3.5 API through a one-shot prompt. This enriched data is then fed into the retrieval database alongside other PDFs. Our approach aims to significantly improve the precision of complex table queries, offering a promising solution to a longstanding challenge in information retrieval.","sentences":["The conventional use of the Retrieval-Augmented Generation (RAG) architecture has proven effective for retrieving information from diverse documents.","However, challenges arise in handling complex table queries, especially within PDF documents containing intricate tabular structures.","This research introduces an innovative approach to enhance the accuracy of complex table queries in RAG-based systems.","Our methodology involves storing PDFs in the retrieval database and extracting tabular content separately.","The extracted tables undergo a process of context enrichment, concatenating headers with corresponding values.","To ensure a comprehensive understanding of the enriched data, we employ a fine-tuned version of the Llama-2-chat language model for summarisation within the RAG architecture.","Furthermore, we augment the tabular data with contextual sense using the ChatGPT 3.5 API through a one-shot prompt.","This enriched data is then fed into the retrieval database alongside other PDFs.","Our approach aims to significantly improve the precision of complex table queries, offering a promising solution to a longstanding challenge in information retrieval."],"url":"http://arxiv.org/abs/2401.02333v1"}
{"created":"2024-01-04 16:06:31","title":"Not all Minorities are Equal: Empty-Class-Aware Distillation for Heterogeneous Federated Learning","abstract":"Data heterogeneity, characterized by disparities in local data distribution across clients, poses a significant challenge in federated learning. Substantial efforts have been devoted to addressing the heterogeneity in local label distribution. As minority classes suffer from worse accuracy due to overfitting on local imbalanced data, prior methods often incorporate class-balanced learning techniques during local training. Despite the improved mean accuracy across all classes, we observe that empty classes-referring to categories absent from a client's data distribution-are still not well recognized. This paper introduces FedED, a novel approach in heterogeneous federated learning that integrates both empty-class distillation and logit suppression simultaneously. Specifically, empty-class distillation leverages knowledge distillation during local training on each client to retain essential information related to empty classes from the global model. Moreover, logit suppression directly penalizes network logits for non-label classes, effectively addressing misclassifications in minority classes that may be biased toward majority classes. Extensive experiments validate the efficacy of FedED, surpassing previous state-of-the-art methods across diverse datasets with varying degrees of label distribution shift.","sentences":["Data heterogeneity, characterized by disparities in local data distribution across clients, poses a significant challenge in federated learning.","Substantial efforts have been devoted to addressing the heterogeneity in local label distribution.","As minority classes suffer from worse accuracy due to overfitting on local imbalanced data, prior methods often incorporate class-balanced learning techniques during local training.","Despite the improved mean accuracy across all classes, we observe that empty classes-referring to categories absent from a client's data distribution-are still not well recognized.","This paper introduces FedED, a novel approach in heterogeneous federated learning that integrates both empty-class distillation and logit suppression simultaneously.","Specifically, empty-class distillation leverages knowledge distillation during local training on each client to retain essential information related to empty classes from the global model.","Moreover, logit suppression directly penalizes network logits for non-label classes, effectively addressing misclassifications in minority classes that may be biased toward majority classes.","Extensive experiments validate the efficacy of FedED, surpassing previous state-of-the-art methods across diverse datasets with varying degrees of label distribution shift."],"url":"http://arxiv.org/abs/2401.02329v1"}
{"created":"2024-01-04 15:54:45","title":"ClassWise-SAM-Adapter: Parameter Efficient Fine-tuning Adapts Segment Anything to SAR Domain for Semantic Segmentation","abstract":"In the realm of artificial intelligence, the emergence of foundation models, backed by high computing capabilities and extensive data, has been revolutionary. Segment Anything Model (SAM), built on the Vision Transformer (ViT) model with millions of parameters and vast training dataset SA-1B, excels in various segmentation scenarios relying on its significance of semantic information and generalization ability. Such achievement of visual foundation model stimulates continuous researches on specific downstream tasks in computer vision. The ClassWise-SAM-Adapter (CWSAM) is designed to adapt the high-performing SAM for landcover classification on space-borne Synthetic Aperture Radar (SAR) images. The proposed CWSAM freezes most of SAM's parameters and incorporates lightweight adapters for parameter efficient fine-tuning, and a classwise mask decoder is designed to achieve semantic segmentation task. This adapt-tuning method allows for efficient landcover classification of SAR images, balancing the accuracy with computational demand. In addition, the task specific input module injects low frequency information of SAR images by MLP-based layers to improve the model performance. Compared to conventional state-of-the-art semantic segmentation algorithms by extensive experiments, CWSAM showcases enhanced performance with fewer computing resources, highlighting the potential of leveraging foundational models like SAM for specific downstream tasks in the SAR domain. The source code is available at: https://github.com/xypu98/CWSAM.","sentences":["In the realm of artificial intelligence, the emergence of foundation models, backed by high computing capabilities and extensive data, has been revolutionary.","Segment Anything Model (SAM), built on the Vision Transformer (ViT) model with millions of parameters and vast training dataset SA-1B, excels in various segmentation scenarios relying on its significance of semantic information and generalization ability.","Such achievement of visual foundation model stimulates continuous researches on specific downstream tasks in computer vision.","The ClassWise-SAM-Adapter (CWSAM) is designed to adapt the high-performing SAM for landcover classification on space-borne Synthetic Aperture Radar (SAR) images.","The proposed CWSAM freezes most of SAM's parameters and incorporates lightweight adapters for parameter efficient fine-tuning, and a classwise mask decoder is designed to achieve semantic segmentation task.","This adapt-tuning method allows for efficient landcover classification of SAR images, balancing the accuracy with computational demand.","In addition, the task specific input module injects low frequency information of SAR images by MLP-based layers to improve the model performance.","Compared to conventional state-of-the-art semantic segmentation algorithms by extensive experiments, CWSAM showcases enhanced performance with fewer computing resources, highlighting the potential of leveraging foundational models like SAM for specific downstream tasks in the SAR domain.","The source code is available at: https://github.com/xypu98/CWSAM."],"url":"http://arxiv.org/abs/2401.02326v1"}
{"created":"2024-01-04 15:51:49","title":"A Robust Quantile Huber Loss With Interpretable Parameter Adjustment In Distributional Reinforcement Learning","abstract":"Distributional Reinforcement Learning (RL) estimates return distribution mainly by learning quantile values via minimizing the quantile Huber loss function, entailing a threshold parameter often selected heuristically or via hyperparameter search, which may not generalize well and can be suboptimal. This paper introduces a generalized quantile Huber loss function derived from Wasserstein distance (WD) calculation between Gaussian distributions, capturing noise in predicted (current) and target (Bellman-updated) quantile values. Compared to the classical quantile Huber loss, this innovative loss function enhances robustness against outliers. Notably, the classical Huber loss function can be seen as an approximation of our proposed loss, enabling parameter adjustment by approximating the amount of noise in the data during the learning process. Empirical tests on Atari games, a common application in distributional RL, and a recent hedging strategy using distributional RL, validate the effectiveness of our proposed loss function and its potential for parameter adjustments in distributional RL.","sentences":["Distributional Reinforcement Learning (RL) estimates return distribution mainly by learning quantile values via minimizing the quantile Huber loss function, entailing a threshold parameter often selected heuristically or via hyperparameter search, which may not generalize well and can be suboptimal.","This paper introduces a generalized quantile Huber loss function derived from Wasserstein distance (WD) calculation between Gaussian distributions, capturing noise in predicted (current) and target (Bellman-updated) quantile values.","Compared to the classical quantile Huber loss, this innovative loss function enhances robustness against outliers.","Notably, the classical Huber loss function can be seen as an approximation of our proposed loss, enabling parameter adjustment by approximating the amount of noise in the data during the learning process.","Empirical tests on Atari games, a common application in distributional RL, and a recent hedging strategy using distributional RL, validate the effectiveness of our proposed loss function and its potential for parameter adjustments in distributional RL."],"url":"http://arxiv.org/abs/2401.02325v1"}
{"created":"2024-01-04 14:42:29","title":"Robust Physics Informed Neural Networks","abstract":"We introduce a Robust version of the Physics-Informed Neural Networks (RPINNs) to approximate the Partial Differential Equations (PDEs) solution. Standard Physics Informed Neural Networks (PINN) takes into account the governing physical laws described by PDE during the learning process. The network is trained on a data set that consists of randomly selected points in the physical domain and its boundary. PINNs have been successfully applied to solve various problems described by PDEs with boundary conditions. The loss function in traditional PINNs is based on the strong residuals of the PDEs. This loss function in PINNs is generally not robust with respect to the true error. The loss function in PINNs can be far from the true error, which makes the training process more difficult. In particular, we do not know if the training process has already converged to the solution with the required accuracy. This is especially true if we do not know the exact solution, so we cannot estimate the true error during the training. This paper introduces a different way of defining the loss function. It incorporates the residual and the inverse of the Gram matrix, computed using the energy norm. We test our RPINN algorithm on two Laplace problems and one advection-diffusion problem in two spatial dimensions. We conclude that RPINN is a robust method. The proposed loss coincides well with the true error of the solution, as measured in the energy norm. Thus, we know if our training process goes well, and we know when to stop the training to obtain the neural network approximation of the solution of the PDE with the true error of required accuracy.","sentences":["We introduce a Robust version of the Physics-Informed Neural Networks (RPINNs) to approximate the Partial Differential Equations (PDEs) solution.","Standard Physics Informed Neural Networks (PINN) takes into account the governing physical laws described by PDE during the learning process.","The network is trained on a data set that consists of randomly selected points in the physical domain and its boundary.","PINNs have been successfully applied to solve various problems described by PDEs with boundary conditions.","The loss function in traditional PINNs is based on the strong residuals of the PDEs.","This loss function in PINNs is generally not robust with respect to the true error.","The loss function in PINNs can be far from the true error, which makes the training process more difficult.","In particular, we do not know if the training process has already converged to the solution with the required accuracy.","This is especially true if we do not know the exact solution, so we cannot estimate the true error during the training.","This paper introduces a different way of defining the loss function.","It incorporates the residual and the inverse of the Gram matrix, computed using the energy norm.","We test our RPINN algorithm on two Laplace problems and one advection-diffusion problem in two spatial dimensions.","We conclude that RPINN is a robust method.","The proposed loss coincides well with the true error of the solution, as measured in the energy norm.","Thus, we know if our training process goes well, and we know when to stop the training to obtain the neural network approximation of the solution of the PDE with the true error of required accuracy."],"url":"http://arxiv.org/abs/2401.02300v1"}
{"created":"2024-01-04 13:58:14","title":"PEGASUS: Physically Enhanced Gaussian Splatting Simulation System for 6DOF Object Pose Dataset Generation","abstract":"We introduce Physically Enhanced Gaussian Splatting Simulation System (PEGASUS) for 6DOF object pose dataset generation, a versatile dataset generator based on 3D Gaussian Splatting. Environment and object representations can be easily obtained using commodity cameras to reconstruct with Gaussian Splatting. PEGASUS allows the composition of new scenes by merging the respective underlying Gaussian Splatting point cloud of an environment with one or multiple objects. Leveraging a physics engine enables the simulation of natural object placement within a scene through interaction between meshes extracted for the objects and the environment. Consequently, an extensive amount of new scenes - static or dynamic - can be created by combining different environments and objects. By rendering scenes from various perspectives, diverse data points such as RGB images, depth maps, semantic masks, and 6DoF object poses can be extracted. Our study demonstrates that training on data generated by PEGASUS enables pose estimation networks to successfully transfer from synthetic data to real-world data. Moreover, we introduce the Ramen dataset, comprising 30 Japanese cup noodle items. This dataset includes spherical scans that captures images from both object hemisphere and the Gaussian Splatting reconstruction, making them compatible with PEGASUS.","sentences":["We introduce Physically Enhanced Gaussian Splatting Simulation System (PEGASUS) for 6DOF object pose dataset generation, a versatile dataset generator based on 3D Gaussian Splatting.","Environment and object representations can be easily obtained using commodity cameras to reconstruct with Gaussian Splatting.","PEGASUS allows the composition of new scenes by merging the respective underlying Gaussian Splatting point cloud of an environment with one or multiple objects.","Leveraging a physics engine enables the simulation of natural object placement within a scene through interaction between meshes extracted for the objects and the environment.","Consequently, an extensive amount of new scenes - static or dynamic - can be created by combining different environments and objects.","By rendering scenes from various perspectives, diverse data points such as RGB images, depth maps, semantic masks, and 6DoF object poses can be extracted.","Our study demonstrates that training on data generated by PEGASUS enables pose estimation networks to successfully transfer from synthetic data to real-world data.","Moreover, we introduce the Ramen dataset, comprising 30 Japanese cup noodle items.","This dataset includes spherical scans that captures images from both object hemisphere and the Gaussian Splatting reconstruction, making them compatible with PEGASUS."],"url":"http://arxiv.org/abs/2401.02281v1"}
{"created":"2024-01-04 13:49:45","title":"ShapeAug: Occlusion Augmentation for Event Camera Data","abstract":"Recently, Dynamic Vision Sensors (DVSs) sparked a lot of interest due to their inherent advantages over conventional RGB cameras. These advantages include a low latency, a high dynamic range and a low energy consumption. Nevertheless, the processing of DVS data using Deep Learning (DL) methods remains a challenge, particularly since the availability of event training data is still limited. This leads to a need for event data augmentation techniques in order to improve accuracy as well as to avoid over-fitting on the training data. Another challenge especially in real world automotive applications is occlusion, meaning one object is hindering the view onto the object behind it. In this paper, we present a novel event data augmentation approach, which addresses this problem by introducing synthetic events for randomly moving objects in a scene. We test our method on multiple DVS classification datasets, resulting in an relative improvement of up to 6.5 % in top1-accuracy. Moreover, we apply our augmentation technique on the real world Gen1 Automotive Event Dataset for object detection, where we especially improve the detection of pedestrians by up to 5 %.","sentences":["Recently, Dynamic Vision Sensors (DVSs) sparked a lot of interest due to their inherent advantages over conventional RGB cameras.","These advantages include a low latency, a high dynamic range and a low energy consumption.","Nevertheless, the processing of DVS data using Deep Learning (DL) methods remains a challenge, particularly since the availability of event training data is still limited.","This leads to a need for event data augmentation techniques in order to improve accuracy as well as to avoid over-fitting on the training data.","Another challenge especially in real world automotive applications is occlusion, meaning one object is hindering the view onto the object behind it.","In this paper, we present a novel event data augmentation approach, which addresses this problem by introducing synthetic events for randomly moving objects in a scene.","We test our method on multiple DVS classification datasets, resulting in an relative improvement of up to 6.5 % in top1-accuracy.","Moreover, we apply our augmentation technique on the real world Gen1 Automotive Event Dataset for object detection, where we especially improve the detection of pedestrians by up to 5 %."],"url":"http://arxiv.org/abs/2401.02274v1"}
{"created":"2024-01-04 13:30:59","title":"The Effects of Generative AI on Computing Students' Help-Seeking Preferences","abstract":"Help-seeking is a critical way for students to learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.","sentences":["Help-seeking is a critical way for students to learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses.","The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand.","However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness.","In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them.","We collected survey data (n=47) and conducted interviews (n=8) with computing students.","Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources.","The help-seeking resources that students rely on continue to vary depending on the task and other factors.","Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs.","We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI."],"url":"http://arxiv.org/abs/2401.02262v1"}
{"created":"2024-01-04 13:21:11","title":"Uncertainty-Aware Deep Attention Recurrent Neural Network for Heterogeneous Time Series Imputation","abstract":"Missingness is ubiquitous in multivariate time series and poses an obstacle to reliable downstream analysis. Although recurrent network imputation achieved the SOTA, existing models do not scale to deep architectures that can potentially alleviate issues arising in complex data. Moreover, imputation carries the risk of biased estimations of the ground truth. Yet, confidence in the imputed values is always unmeasured or computed post hoc from model output. We propose DEep Attention Recurrent Imputation (DEARI), which jointly estimates missing values and their associated uncertainty in heterogeneous multivariate time series. By jointly representing feature-wise correlations and temporal dynamics, we adopt a self attention mechanism, along with an effective residual component, to achieve a deep recurrent neural network with good imputation performance and stable convergence. We also leverage self-supervised metric learning to boost performance by optimizing sample similarity. Finally, we transform DEARI into a Bayesian neural network through a novel Bayesian marginalization strategy to produce stochastic DEARI, which outperforms its deterministic equivalent. Experiments show that DEARI surpasses the SOTA in diverse imputation tasks using real-world datasets, namely air quality control, healthcare and traffic.","sentences":["Missingness is ubiquitous in multivariate time series and poses an obstacle to reliable downstream analysis.","Although recurrent network imputation achieved the SOTA, existing models do not scale to deep architectures that can potentially alleviate issues arising in complex data.","Moreover, imputation carries the risk of biased estimations of the ground truth.","Yet, confidence in the imputed values is always unmeasured or computed post hoc from model output.","We propose DEep Attention Recurrent Imputation (DEARI), which jointly estimates missing values and their associated uncertainty in heterogeneous multivariate time series.","By jointly representing feature-wise correlations and temporal dynamics, we adopt a self attention mechanism, along with an effective residual component, to achieve a deep recurrent neural network with good imputation performance and stable convergence.","We also leverage self-supervised metric learning to boost performance by optimizing sample similarity.","Finally, we transform DEARI into a Bayesian neural network through a novel Bayesian marginalization strategy to produce stochastic DEARI, which outperforms its deterministic equivalent.","Experiments show that DEARI surpasses the SOTA in diverse imputation tasks using real-world datasets, namely air quality control, healthcare and traffic."],"url":"http://arxiv.org/abs/2401.02258v1"}
{"created":"2024-01-04 13:11:43","title":"Balancing Continual Learning and Fine-tuning for Human Activity Recognition","abstract":"Wearable-based Human Activity Recognition (HAR) is a key task in human-centric machine learning due to its fundamental understanding of human behaviours. Due to the dynamic nature of human behaviours, continual learning promises HAR systems that are tailored to users' needs. However, because of the difficulty in collecting labelled data with wearable sensors, existing approaches that focus on supervised continual learning have limited applicability, while unsupervised continual learning methods only handle representation learning while delaying classifier training to a later stage. This work explores the adoption and adaptation of CaSSLe, a continual self-supervised learning model, and Kaizen, a semi-supervised continual learning model that balances representation learning and down-stream classification, for the task of wearable-based HAR. These schemes re-purpose contrastive learning for knowledge retention and, Kaizen combines that with self-training in a unified scheme that can leverage unlabelled and labelled data for continual learning. In addition to comparing state-of-the-art self-supervised continual learning schemes, we further investigated the importance of different loss terms and explored the trade-off between knowledge retention and learning from new tasks. In particular, our extensive evaluation demonstrated that the use of a weighting factor that reflects the ratio between learned and new classes achieves the best overall trade-off in continual learning.","sentences":["Wearable-based Human Activity Recognition (HAR) is a key task in human-centric machine learning due to its fundamental understanding of human behaviours.","Due to the dynamic nature of human behaviours, continual learning promises HAR systems that are tailored to users' needs.","However, because of the difficulty in collecting labelled data with wearable sensors, existing approaches that focus on supervised continual learning have limited applicability, while unsupervised continual learning methods only handle representation learning while delaying classifier training to a later stage.","This work explores the adoption and adaptation of CaSSLe, a continual self-supervised learning model, and Kaizen, a semi-supervised continual learning model that balances representation learning and down-stream classification, for the task of wearable-based HAR.","These schemes re-purpose contrastive learning for knowledge retention and, Kaizen combines that with self-training in a unified scheme that can leverage unlabelled and labelled data for continual learning.","In addition to comparing state-of-the-art self-supervised continual learning schemes, we further investigated the importance of different loss terms and explored the trade-off between knowledge retention and learning from new tasks.","In particular, our extensive evaluation demonstrated that the use of a weighting factor that reflects the ratio between learned and new classes achieves the best overall trade-off in continual learning."],"url":"http://arxiv.org/abs/2401.02255v1"}
{"created":"2024-01-04 12:54:10","title":"Policy-regularized Offline Multi-objective Reinforcement Learning","abstract":"In this paper, we aim to utilize only offline trajectory data to train a policy for multi-objective RL. We extend the offline policy-regularized method, a widely-adopted approach for single-objective offline RL problems, into the multi-objective setting in order to achieve the above goal. However, such methods face a new challenge in offline MORL settings, namely the preference-inconsistent demonstration problem. We propose two solutions to this problem: 1) filtering out preference-inconsistent demonstrations via approximating behavior preferences, and 2) adopting regularization techniques with high policy expressiveness. Moreover, we integrate the preference-conditioned scalarized update method into policy-regularized offline RL, in order to simultaneously learn a set of policies using a single policy network, thus reducing the computational cost induced by the training of a large number of individual policies for various preferences. Finally, we introduce Regularization Weight Adaptation to dynamically determine appropriate regularization weights for arbitrary target preferences during deployment. Empirical results on various multi-objective datasets demonstrate the capability of our approach in solving offline MORL problems.","sentences":["In this paper, we aim to utilize only offline trajectory data to train a policy for multi-objective RL.","We extend the offline policy-regularized method, a widely-adopted approach for single-objective offline RL problems, into the multi-objective setting in order to achieve the above goal.","However, such methods face a new challenge in offline MORL settings, namely the preference-inconsistent demonstration problem.","We propose two solutions to this problem: 1) filtering out preference-inconsistent demonstrations via approximating behavior preferences, and 2) adopting regularization techniques with high policy expressiveness.","Moreover, we integrate the preference-conditioned scalarized update method into policy-regularized offline RL, in order to simultaneously learn a set of policies using a single policy network, thus reducing the computational cost induced by the training of a large number of individual policies for various preferences.","Finally, we introduce Regularization Weight Adaptation to dynamically determine appropriate regularization weights for arbitrary target preferences during deployment.","Empirical results on various multi-objective datasets demonstrate the capability of our approach in solving offline MORL problems."],"url":"http://arxiv.org/abs/2401.02244v1"}
{"created":"2024-01-04 12:41:40","title":"U-Mixer: An Unet-Mixer Architecture with Stationarity Correction for Time Series Forecasting","abstract":"Time series forecasting is a crucial task in various domains. Caused by factors such as trends, seasonality, or irregular fluctuations, time series often exhibits non-stationary. It obstructs stable feature propagation through deep layers, disrupts feature distributions, and complicates learning data distribution changes. As a result, many existing models struggle to capture the underlying patterns, leading to degraded forecasting performance. In this study, we tackle the challenge of non-stationarity in time series forecasting with our proposed framework called U-Mixer. By combining Unet and Mixer, U-Mixer effectively captures local temporal dependencies between different patches and channels separately to avoid the influence of distribution variations among channels, and merge low- and high-levels features to obtain comprehensive data representations. The key contribution is a novel stationarity correction method, explicitly restoring data distribution by constraining the difference in stationarity between the data before and after model processing to restore the non-stationarity information, while ensuring the temporal dependencies are preserved. Through extensive experiments on various real-world time series datasets, U-Mixer demonstrates its effectiveness and robustness, and achieves 14.5\\% and 7.7\\% improvements over state-of-the-art (SOTA) methods.","sentences":["Time series forecasting is a crucial task in various domains.","Caused by factors such as trends, seasonality, or irregular fluctuations, time series often exhibits non-stationary.","It obstructs stable feature propagation through deep layers, disrupts feature distributions, and complicates learning data distribution changes.","As a result, many existing models struggle to capture the underlying patterns, leading to degraded forecasting performance.","In this study, we tackle the challenge of non-stationarity in time series forecasting with our proposed framework called U-Mixer.","By combining Unet and Mixer, U-Mixer effectively captures local temporal dependencies between different patches and channels separately to avoid the influence of distribution variations among channels, and merge low- and high-levels features to obtain comprehensive data representations.","The key contribution is a novel stationarity correction method, explicitly restoring data distribution by constraining the difference in stationarity between the data before and after model processing to restore the non-stationarity information, while ensuring the temporal dependencies are preserved.","Through extensive experiments on various real-world time series datasets, U-Mixer demonstrates its effectiveness and robustness, and achieves 14.5\\% and 7.7\\% improvements over state-of-the-art (SOTA) methods."],"url":"http://arxiv.org/abs/2401.02236v1"}
{"created":"2024-01-04 12:04:22","title":"A Decentralized Multiagent-Based Task Scheduling Framework for Handling Uncertain Events in Fog Computing","abstract":"Fog computing has become an attractive research topic in recent years. As an extension of the cloud, fog computing provides computing resources for Internet of Things (IoT) applications through communicative fog nodes located at the network edge. Fog nodes assist cloud services in handling real-time and mobile applications by bringing the processing capability to where the data is generated. However, the introduction of fog nodes can increase scheduling openness and uncertainty. The scheduling issues in fog computing need to consider the geography, load balancing, and network latency between IoT devices, fog nodes, as well as the parent cloud. Besides, the scheduling methods also need to deal with the occurrence of uncertain events in real-time so as to ensure service reliability. This paper proposes an agent-based framework with a decentralized structure to construct the architecture of fog computing, while three agent-based algorithms are proposed to implement the scheduling, load balance, and rescheduling processes. The proposed framework is implemented by JADE and evaluated on the iFogSim toolkit. Experimental results show that the proposed scheduling framework can adaptively schedule tasks and resources for different service requests in fog computing and can also improve the task success rate when uncertain events occur.","sentences":["Fog computing has become an attractive research topic in recent years.","As an extension of the cloud, fog computing provides computing resources for Internet of Things (IoT) applications through communicative fog nodes located at the network edge.","Fog nodes assist cloud services in handling real-time and mobile applications by bringing the processing capability to where the data is generated.","However, the introduction of fog nodes can increase scheduling openness and uncertainty.","The scheduling issues in fog computing need to consider the geography, load balancing, and network latency between IoT devices, fog nodes, as well as the parent cloud.","Besides, the scheduling methods also need to deal with the occurrence of uncertain events in real-time so as to ensure service reliability.","This paper proposes an agent-based framework with a decentralized structure to construct the architecture of fog computing, while three agent-based algorithms are proposed to implement the scheduling, load balance, and rescheduling processes.","The proposed framework is implemented by JADE and evaluated on the iFogSim toolkit.","Experimental results show that the proposed scheduling framework can adaptively schedule tasks and resources for different service requests in fog computing and can also improve the task success rate when uncertain events occur."],"url":"http://arxiv.org/abs/2401.02219v1"}
{"created":"2024-01-04 10:29:02","title":"FairGridSearch: A Framework to Compare Fairness-Enhancing Models","abstract":"Machine learning models are increasingly used in critical decision-making applications. However, these models are susceptible to replicating or even amplifying bias present in real-world data. While there are various bias mitigation methods and base estimators in the literature, selecting the optimal model for a specific application remains challenging.   This paper focuses on binary classification and proposes FairGridSearch, a novel framework for comparing fairness-enhancing models. FairGridSearch enables experimentation with different model parameter combinations and recommends the best one. The study applies FairGridSearch to three popular datasets (Adult, COMPAS, and German Credit) and analyzes the impacts of metric selection, base estimator choice, and classification threshold on model fairness.   The results highlight the significance of selecting appropriate accuracy and fairness metrics for model evaluation. Additionally, different base estimators and classification threshold values affect the effectiveness of bias mitigation methods and fairness stability respectively, but the effects are not consistent across all datasets. Based on these findings, future research on fairness in machine learning should consider a broader range of factors when building fair models, going beyond bias mitigation methods alone.","sentences":["Machine learning models are increasingly used in critical decision-making applications.","However, these models are susceptible to replicating or even amplifying bias present in real-world data.","While there are various bias mitigation methods and base estimators in the literature, selecting the optimal model for a specific application remains challenging.   ","This paper focuses on binary classification and proposes FairGridSearch, a novel framework for comparing fairness-enhancing models.","FairGridSearch enables experimentation with different model parameter combinations and recommends the best one.","The study applies FairGridSearch to three popular datasets (Adult, COMPAS, and German Credit) and analyzes the impacts of metric selection, base estimator choice, and classification threshold on model fairness.   ","The results highlight the significance of selecting appropriate accuracy and fairness metrics for model evaluation.","Additionally, different base estimators and classification threshold values affect the effectiveness of bias mitigation methods and fairness stability respectively, but the effects are not consistent across all datasets.","Based on these findings, future research on fairness in machine learning should consider a broader range of factors when building fair models, going beyond bias mitigation methods alone."],"url":"http://arxiv.org/abs/2401.02183v1"}
{"created":"2024-01-04 10:22:26","title":"Proven Distributed Memory Parallelization of Particle Methods","abstract":"We provide a mathematically proven parallelization scheme for particle methods on distributed-memory computer systems. Particle methods are a versatile and widely used class of algorithms for computer simulations and numerical predictions in various applications, ranging from continuum fluid dynamics and granular flows, using methods such as Smoothed Particle Hydrodynamics (SPH) and Discrete Element Methods (DEM) to Molecular Dynamics (MD) simulations in molecular modeling. Particle methods naturally lend themselves to implementation on parallel-computing hardware. So far, however, a mathematical proof of correctness and equivalence to sequential implementations was only available for shared-memory parallelism. Here, we leverage a formal definition of the algorithmic class of particle methods to provide a proven parallelization scheme for distributed-memory computers. We prove that these parallelized particle methods on distributed memory computers are formally equivalent to their sequential counterpart for a well-defined class of particle methods. Notably, the here analyzed parallelization scheme is well-known and commonly used. Our analysis is, therefore, of immediate practical relevance to existing and new parallel software implementations of particle methods and places them on solid theoretical grounds.","sentences":["We provide a mathematically proven parallelization scheme for particle methods on distributed-memory computer systems.","Particle methods are a versatile and widely used class of algorithms for computer simulations and numerical predictions in various applications, ranging from continuum fluid dynamics and granular flows, using methods such as Smoothed Particle Hydrodynamics (SPH) and Discrete Element Methods (DEM) to Molecular Dynamics (MD) simulations in molecular modeling.","Particle methods naturally lend themselves to implementation on parallel-computing hardware.","So far, however, a mathematical proof of correctness and equivalence to sequential implementations was only available for shared-memory parallelism.","Here, we leverage a formal definition of the algorithmic class of particle methods to provide a proven parallelization scheme for distributed-memory computers.","We prove that these parallelized particle methods on distributed memory computers are formally equivalent to their sequential counterpart for a well-defined class of particle methods.","Notably, the here analyzed parallelization scheme is well-known and commonly used.","Our analysis is, therefore, of immediate practical relevance to existing and new parallel software implementations of particle methods and places them on solid theoretical grounds."],"url":"http://arxiv.org/abs/2401.02180v1"}
{"created":"2024-01-04 09:55:15","title":"Prompt Decoupling for Text-to-Image Person Re-identification","abstract":"Text-to-image person re-identification (TIReID) aims to retrieve the target person from an image gallery via a textual description query. Recently, pre-trained vision-language models like CLIP have attracted significant attention and have been widely utilized for this task due to their robust capacity for semantic concept learning and rich multi-modal knowledge. However, recent CLIP-based TIReID methods commonly rely on direct fine-tuning of the entire network to adapt the CLIP model for the TIReID task. Although these methods show competitive performance on this topic, they are suboptimal as they necessitate simultaneous domain adaptation and task adaptation. To address this issue, we attempt to decouple these two processes during the training stage. Specifically, we introduce the prompt tuning strategy to enable domain adaptation and propose a two-stage training approach to disentangle domain adaptation from task adaptation. In the first stage, we freeze the two encoders from CLIP and solely focus on optimizing the prompts to alleviate domain gap between the original training data of CLIP and downstream tasks. In the second stage, we maintain the fixed prompts and fine-tune the CLIP model to prioritize capturing fine-grained information, which is more suitable for TIReID task. Finally, we evaluate the effectiveness of our method on three widely used datasets. Compared to the directly fine-tuned approach, our method achieves significant improvements.","sentences":["Text-to-image person re-identification (TIReID) aims to retrieve the target person from an image gallery via a textual description query.","Recently, pre-trained vision-language models like CLIP have attracted significant attention and have been widely utilized for this task due to their robust capacity for semantic concept learning and rich multi-modal knowledge.","However, recent CLIP-based TIReID methods commonly rely on direct fine-tuning of the entire network to adapt the CLIP model for the TIReID task.","Although these methods show competitive performance on this topic, they are suboptimal as they necessitate simultaneous domain adaptation and task adaptation.","To address this issue, we attempt to decouple these two processes during the training stage.","Specifically, we introduce the prompt tuning strategy to enable domain adaptation and propose a two-stage training approach to disentangle domain adaptation from task adaptation.","In the first stage, we freeze the two encoders from CLIP and solely focus on optimizing the prompts to alleviate domain gap between the original training data of CLIP and downstream tasks.","In the second stage, we maintain the fixed prompts and fine-tune the CLIP model to prioritize capturing fine-grained information, which is more suitable for TIReID task.","Finally, we evaluate the effectiveness of our method on three widely used datasets.","Compared to the directly fine-tuned approach, our method achieves significant improvements."],"url":"http://arxiv.org/abs/2401.02173v1"}
{"created":"2024-01-04 09:20:36","title":"Enumerating m-Length Walks in Directed Graphs with Constant Delay","abstract":"In this paper, we provide a novel enumeration algorithm for the set of all walks of a given length within a directed graph. Our algorithm has worst-case constant delay between outputting succinct representations of such walks, after a preprocessing step requiring linear time relative to the size of the graph. We apply these results to the problem of enumerating succinct representations of the strings of a given length from a prefix-closed regular language (languages accepted by a finite automaton which has final states only).","sentences":["In this paper, we provide a novel enumeration algorithm for the set of all walks of a given length within a directed graph.","Our algorithm has worst-case constant delay between outputting succinct representations of such walks, after a preprocessing step requiring linear time relative to the size of the graph.","We apply these results to the problem of enumerating succinct representations of the strings of a given length from a prefix-closed regular language (languages accepted by a finite automaton which has final states only)."],"url":"http://arxiv.org/abs/2401.02163v1"}
{"created":"2024-01-04 09:05:37","title":"Disentangle Estimation of Causal Effects from Cross-Silo Data","abstract":"Estimating causal effects among different events is of great importance to critical fields such as drug development. Nevertheless, the data features associated with events may be distributed across various silos and remain private within respective parties, impeding direct information exchange between them. This, in turn, can result in biased estimations of local causal effects, which rely on the characteristics of only a subset of the covariates. To tackle this challenge, we introduce an innovative disentangle architecture designed to facilitate the seamless cross-silo transmission of model parameters, enriched with causal mechanisms, through a combination of shared and private branches. Besides, we introduce global constraints into the equation to effectively mitigate bias within the various missing domains, thereby elevating the accuracy of our causal effect estimation. Extensive experiments conducted on new semi-synthetic datasets show that our method outperforms state-of-the-art baselines.","sentences":["Estimating causal effects among different events is of great importance to critical fields such as drug development.","Nevertheless, the data features associated with events may be distributed across various silos and remain private within respective parties, impeding direct information exchange between them.","This, in turn, can result in biased estimations of local causal effects, which rely on the characteristics of only a subset of the covariates.","To tackle this challenge, we introduce an innovative disentangle architecture designed to facilitate the seamless cross-silo transmission of model parameters, enriched with causal mechanisms, through a combination of shared and private branches.","Besides, we introduce global constraints into the equation to effectively mitigate bias within the various missing domains, thereby elevating the accuracy of our causal effect estimation.","Extensive experiments conducted on new semi-synthetic datasets show that our method outperforms state-of-the-art baselines."],"url":"http://arxiv.org/abs/2401.02154v1"}
{"created":"2024-01-04 09:04:16","title":"Estimating continuous data of wrist joint angles using ultrasound images","abstract":"Ultrasound imaging has recently been introduced as a sensing interface for joint motion estimation. The use of ultrasound images as an estimation method is expected to improve the control performance of assistive devices and human--machine interfaces. This study aimed to estimate continuous wrist joint angles using ultrasound images. Specifically, in an experiment, joint angle information was obtained during extension--flexion movements, and ultrasound images of the associated muscles were acquired. Using the features obtained from ultrasound images, a multivariate linear regression model was used to estimate the joint angles. The coordinates of the feature points obtained using optical flow from the ultrasound images were used as explanatory variables of the multivariate linear regression model. The model was trained and tested for each trial by each participant to verify the estimation accuracy. The results show that the mean and standard deviation of the estimation accuracy for all trials were root mean square error (RMSE)=1.82 $\\pm$ 0.54 deg and coefficient of determination (R2)=0.985 $\\pm$ 0.009. Our method achieves a highly accurate estimation of joint angles compared with previous studies using other signals, such as surface electromyography, while the multivariate linear regression model is simple and both computational and model training costs are low.","sentences":["Ultrasound imaging has recently been introduced as a sensing interface for joint motion estimation.","The use of ultrasound images as an estimation method is expected to improve the control performance of assistive devices and human--machine interfaces.","This study aimed to estimate continuous wrist joint angles using ultrasound images.","Specifically, in an experiment, joint angle information was obtained during extension--flexion movements, and ultrasound images of the associated muscles were acquired.","Using the features obtained from ultrasound images, a multivariate linear regression model was used to estimate the joint angles.","The coordinates of the feature points obtained using optical flow from the ultrasound images were used as explanatory variables of the multivariate linear regression model.","The model was trained and tested for each trial by each participant to verify the estimation accuracy.","The results show that the mean and standard deviation of the estimation accuracy for all trials were root mean square error (RMSE)=1.82 $\\pm$ 0.54 deg and coefficient of determination (R2)=0.985 $\\pm$ 0.009.","Our method achieves a highly accurate estimation of joint angles compared with previous studies using other signals, such as surface electromyography, while the multivariate linear regression model is simple and both computational and model training costs are low."],"url":"http://arxiv.org/abs/2401.02152v1"}
{"created":"2024-01-04 08:57:09","title":"Marginal Debiased Network for Fair Visual Recognition","abstract":"Deep neural networks (DNNs) are often prone to learn the spurious correlations between target classes and bias attributes, like gender and race, inherent in a major portion of training data (bias-aligned samples), thus showing unfair behavior and arising controversy in the modern pluralistic and egalitarian society. In this paper, we propose a novel marginal debiased network (MDN) to learn debiased representations. More specifically, a marginal softmax loss (MSL) is designed by introducing the idea of margin penalty into the fairness problem, which assigns a larger margin for bias-conflicting samples (data without spurious correlations) than for bias-aligned ones, so as to deemphasize the spurious correlations and improve generalization on unbiased test criteria. To determine the margins, our MDN is optimized through a meta learning framework. We propose a meta equalized loss (MEL) to perceive the model fairness, and adaptively update the margin parameters by metaoptimization which requires the trained model guided by the optimal margins should minimize MEL computed on an unbiased meta-validation set. Extensive experiments on BiasedMNIST, Corrupted CIFAR-10, CelebA and UTK-Face datasets demonstrate that our MDN can achieve a remarkable performance on under-represented samples and obtain superior debiased results against the previous approaches.","sentences":["Deep neural networks (DNNs) are often prone to learn the spurious correlations between target classes and bias attributes, like gender and race, inherent in a major portion of training data (bias-aligned samples), thus showing unfair behavior and arising controversy in the modern pluralistic and egalitarian society.","In this paper, we propose a novel marginal debiased network (MDN) to learn debiased representations.","More specifically, a marginal softmax loss (MSL) is designed by introducing the idea of margin penalty into the fairness problem, which assigns a larger margin for bias-conflicting samples (data without spurious correlations) than for bias-aligned ones, so as to deemphasize the spurious correlations and improve generalization on unbiased test criteria.","To determine the margins, our MDN is optimized through a meta learning framework.","We propose a meta equalized loss (MEL) to perceive the model fairness, and adaptively update the margin parameters by metaoptimization which requires the trained model guided by the optimal margins should minimize MEL computed on an unbiased meta-validation set.","Extensive experiments on BiasedMNIST, Corrupted CIFAR-10, CelebA and UTK-Face datasets demonstrate that our MDN can achieve a remarkable performance on under-represented samples and obtain superior debiased results against the previous approaches."],"url":"http://arxiv.org/abs/2401.02150v1"}
{"created":"2024-01-04 08:49:10","title":"Graph Neural Networks for Tabular Data Learning: A Survey with Taxonomy and Directions","abstract":"In this survey, we dive into Tabular Data Learning (TDL) using Graph Neural Networks (GNNs), a domain where deep learning-based approaches have increasingly shown superior performance in both classification and regression tasks compared to traditional methods. The survey highlights a critical gap in deep neural TDL methods: the underrepresentation of latent correlations among data instances and feature values. GNNs, with their innate capability to model intricate relationships and interactions between diverse elements of tabular data, have garnered significant interest and application across various TDL domains. Our survey provides a systematic review of the methods involved in designing and implementing GNNs for TDL (GNN4TDL). It encompasses a detailed investigation into the foundational aspects and an overview of GNN-based TDL methods, offering insights into their evolving landscape. We present a comprehensive taxonomy focused on constructing graph structures and representation learning within GNN-based TDL methods. In addition, the survey examines various training plans, emphasizing the integration of auxiliary tasks to enhance the effectiveness of instance representations. A critical part of our discussion is dedicated to the practical application of GNNs across a spectrum of GNN4TDL scenarios, demonstrating their versatility and impact. Lastly, we discuss the limitations and propose future research directions, aiming to spur advancements in GNN4TDL. This survey serves as a resource for researchers and practitioners, offering a thorough understanding of GNNs' role in revolutionizing TDL and pointing towards future innovations in this promising area.","sentences":["In this survey, we dive into Tabular Data Learning (TDL) using Graph Neural Networks (GNNs), a domain where deep learning-based approaches have increasingly shown superior performance in both classification and regression tasks compared to traditional methods.","The survey highlights a critical gap in deep neural TDL methods: the underrepresentation of latent correlations among data instances and feature values.","GNNs, with their innate capability to model intricate relationships and interactions between diverse elements of tabular data, have garnered significant interest and application across various TDL domains.","Our survey provides a systematic review of the methods involved in designing and implementing GNNs for TDL (GNN4TDL).","It encompasses a detailed investigation into the foundational aspects and an overview of GNN-based TDL methods, offering insights into their evolving landscape.","We present a comprehensive taxonomy focused on constructing graph structures and representation learning within GNN-based TDL methods.","In addition, the survey examines various training plans, emphasizing the integration of auxiliary tasks to enhance the effectiveness of instance representations.","A critical part of our discussion is dedicated to the practical application of GNNs across a spectrum of GNN4TDL scenarios, demonstrating their versatility and impact.","Lastly, we discuss the limitations and propose future research directions, aiming to spur advancements in GNN4TDL.","This survey serves as a resource for researchers and practitioners, offering a thorough understanding of GNNs' role in revolutionizing TDL and pointing towards future innovations in this promising area."],"url":"http://arxiv.org/abs/2401.02143v1"}
{"created":"2024-01-04 08:39:49","title":"PosCUDA: Position based Convolution for Unlearnable Audio Datasets","abstract":"Deep learning models require large amounts of clean data to acheive good performance. To avoid the cost of expensive data acquisition, researchers use the abundant data available on the internet. This raises significant privacy concerns on the potential misuse of personal data for model training without authorisation. Recent works such as CUDA propose solutions to this problem by adding class-wise blurs to make datasets unlearnable, i.e a model can never use the acquired dataset for learning. However these methods often reduce the quality of the data making it useless for practical applications. We introduce PosCUDA, a position based convolution for creating unlearnable audio datasets. PosCUDA uses class-wise convolutions on small patches of audio. The location of the patches are based on a private key for each class, hence the model learns the relations between positional blurs and labels, while failing to generalize. We empirically show that PosCUDA can achieve unlearnability while maintaining the quality of the original audio datasets. Our proposed method is also robust to different audio feature representations such as MFCC, raw audio and different architectures such as transformers, convolutional networks etc.","sentences":["Deep learning models require large amounts of clean data to acheive good performance.","To avoid the cost of expensive data acquisition, researchers use the abundant data available on the internet.","This raises significant privacy concerns on the potential misuse of personal data for model training without authorisation.","Recent works such as CUDA propose solutions to this problem by adding class-wise blurs to make datasets unlearnable, i.e a model can never use the acquired dataset for learning.","However these methods often reduce the quality of the data making it useless for practical applications.","We introduce PosCUDA, a position based convolution for creating unlearnable audio datasets.","PosCUDA uses class-wise convolutions on small patches of audio.","The location of the patches are based on a private key for each class, hence the model learns the relations between positional blurs and labels, while failing to generalize.","We empirically show that PosCUDA can achieve unlearnability while maintaining the quality of the original audio datasets.","Our proposed method is also robust to different audio feature representations such as MFCC, raw audio and different architectures such as transformers, convolutional networks etc."],"url":"http://arxiv.org/abs/2401.02135v1"}
{"created":"2024-01-04 07:55:53","title":"Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation","abstract":"Imitation learning from human demonstrations has shown impressive performance in robotics. However, most results focus on table-top manipulation, lacking the mobility and dexterity necessary for generally useful tasks. In this work, we develop a system for imitating mobile manipulation tasks that are bimanual and require whole-body control. We first present Mobile ALOHA, a low-cost and whole-body teleoperation system for data collection. It augments the ALOHA system with a mobile base, and a whole-body teleoperation interface. Using data collected with Mobile ALOHA, we then perform supervised behavior cloning and find that co-training with existing static ALOHA datasets boosts performance on mobile manipulation tasks. With 50 demonstrations for each task, co-training can increase success rates by up to 90%, allowing Mobile ALOHA to autonomously complete complex mobile manipulation tasks such as sauteing and serving a piece of shrimp, opening a two-door wall cabinet to store heavy cooking pots, calling and entering an elevator, and lightly rinsing a used pan using a kitchen faucet. Project website: https://mobile-aloha.github.io","sentences":["Imitation learning from human demonstrations has shown impressive performance in robotics.","However, most results focus on table-top manipulation, lacking the mobility and dexterity necessary for generally useful tasks.","In this work, we develop a system for imitating mobile manipulation tasks that are bimanual and require whole-body control.","We first present Mobile ALOHA, a low-cost and whole-body teleoperation system for data collection.","It augments the ALOHA system with a mobile base, and a whole-body teleoperation interface.","Using data collected with Mobile ALOHA, we then perform supervised behavior cloning and find that co-training with existing static ALOHA datasets boosts performance on mobile manipulation tasks.","With 50 demonstrations for each task, co-training can increase success rates by up to 90%, allowing Mobile ALOHA to autonomously complete complex mobile manipulation tasks such as sauteing and serving a piece of shrimp, opening a two-door wall cabinet to store heavy cooking pots, calling and entering an elevator, and lightly rinsing a used pan using a kitchen faucet.","Project website: https://mobile-aloha.github.io"],"url":"http://arxiv.org/abs/2401.02117v1"}
{"created":"2024-01-04 07:52:00","title":"Starling: An I/O-Efficient Disk-Resident Graph Index Framework for High-Dimensional Vector Similarity Search on Data Segment","abstract":"High-dimensional vector similarity search (HVSS) is receiving a spotlight as a powerful tool for various data science and AI applications. As vector data grows larger, in-memory indexes become extremely expensive because they necessitate substantial expansion of main memory resources. One possible solution is to use disk-based implementation, which stores and searches vector data in high-performance devices like NVMe SSDs. However, HVSS for data segments is still challenging in vector databases, where one machine has multiple segments for system features (like scaling) purposes. In this setting, each segment has limited memory and disk space, so HVSS on the data segment needs to balance accuracy, efficiency, and space cost. Existing disk-based methods are sub-optimal because they do not consider all these requirements together. In this paper, we present Starling, an I/O-efficient disk-resident graph index framework that optimizes data layout and search strategy in the segment. It has two main components: (1) a data layout that includes an in-memory navigation graph and a reordered disk-based graph with locality enhancement, which reduces the search path length and disk bandwidth wastage; and (2) a block search strategy that minimizes expensive disk I/Os when executing a vector query. We conduct extensive experiments to verify Starling's effectiveness, efficiency, and scalability. On a data segment with 2GB memory and 10GB disk capacity, Starling can maintain up to 33 million vectors in 128 dimensions, and serve HVSS with more than 0.9 average precision and top-10 recall rate, and latency of under 1 millisecond. The results show that Starling exhibits 43.9$\\times$ higher throughput with 98% lower query latency than state-of-the-art methods under the same accuracy.","sentences":["High-dimensional vector similarity search (HVSS) is receiving a spotlight as a powerful tool for various data science and AI applications.","As vector data grows larger, in-memory indexes become extremely expensive because they necessitate substantial expansion of main memory resources.","One possible solution is to use disk-based implementation, which stores and searches vector data in high-performance devices like NVMe SSDs.","However, HVSS for data segments is still challenging in vector databases, where one machine has multiple segments for system features (like scaling) purposes.","In this setting, each segment has limited memory and disk space, so HVSS on the data segment needs to balance accuracy, efficiency, and space cost.","Existing disk-based methods are sub-optimal because they do not consider all these requirements together.","In this paper, we present Starling, an I/O-efficient disk-resident graph index framework that optimizes data layout and search strategy in the segment.","It has two main components: (1) a data layout that includes an in-memory navigation graph and a reordered disk-based graph with locality enhancement, which reduces the search path length and disk bandwidth wastage; and (2) a block search strategy that minimizes expensive disk","I/","Os when executing a vector query.","We conduct extensive experiments to verify Starling's effectiveness, efficiency, and scalability.","On a data segment with 2GB memory and 10GB disk capacity, Starling can maintain up to 33 million vectors in 128 dimensions, and serve HVSS with more than 0.9 average precision and top-10 recall rate, and latency of under 1 millisecond.","The results show that Starling exhibits 43.9$\\times$ higher throughput with 98% lower query latency than state-of-the-art methods under the same accuracy."],"url":"http://arxiv.org/abs/2401.02116v1"}
{"created":"2024-01-04 07:49:32","title":"Source-Free Online Domain Adaptive Semantic Segmentation of Satellite Images under Image Degradation","abstract":"Online adaptation to distribution shifts in satellite image segmentation stands as a crucial yet underexplored problem. In this paper, we address source-free and online domain adaptation, i.e., test-time adaptation (TTA), for satellite images, with the focus on mitigating distribution shifts caused by various forms of image degradation. Towards achieving this goal, we propose a novel TTA approach involving two effective strategies. First, we progressively estimate the global Batch Normalization (BN) statistics of the target distribution with incoming data stream. Leveraging these statistics during inference has the ability to effectively reduce domain gap. Furthermore, we enhance prediction quality by refining the predicted masks using global class centers. Both strategies employ dynamic momentum for fast and stable convergence. Notably, our method is backpropagation-free and hence fast and lightweight, making it highly suitable for on-the-fly adaptation to new domain. Through comprehensive experiments across various domain adaptation scenarios, we demonstrate the robust performance of our method.","sentences":["Online adaptation to distribution shifts in satellite image segmentation stands as a crucial yet underexplored problem.","In this paper, we address source-free and online domain adaptation, i.e., test-time adaptation (TTA), for satellite images, with the focus on mitigating distribution shifts caused by various forms of image degradation.","Towards achieving this goal, we propose a novel TTA approach involving two effective strategies.","First, we progressively estimate the global Batch Normalization (BN) statistics of the target distribution with incoming data stream.","Leveraging these statistics during inference has the ability to effectively reduce domain gap.","Furthermore, we enhance prediction quality by refining the predicted masks using global class centers.","Both strategies employ dynamic momentum for fast and stable convergence.","Notably, our method is backpropagation-free and hence fast and lightweight, making it highly suitable for on-the-fly adaptation to new domain.","Through comprehensive experiments across various domain adaptation scenarios, we demonstrate the robust performance of our method."],"url":"http://arxiv.org/abs/2401.02113v1"}
{"created":"2024-01-04 07:26:52","title":"Perceptions of Humanoid Robots in Caregiving: A Study of Skilled Nursing Home and Long Term Care Administrators","abstract":"As the aging population increases and the shortage of healthcare workers increases, the need to examine other means for caring for the aging population increases. One such means is the use of humanoid robots to care for social, emotional, and physical wellbeing of the people above 65. Understanding skilled and long term care nursing home administrators' perspectives on humanoid robots in caregiving is crucial as their insights shape the implementation of robots and their potential impact on resident well-being and quality of life. This authors surveyed two hundred and sixty nine nursing homes executives to understand their perspectives on the use of humanoid robots in their nursing home facilities. The data was coded and results revealed that the executives were keen on exploring other avenues for care such as robotics that would enhance their nursing homes abilities to care for their residents. Qualitative analysis reveals diverse perspectives on integrating humanoid robots in nursing homes. While acknowledging benefits like improved engagement and staff support, concerns persist about costs, impacts on human interaction, and doubts about robot effectiveness. This highlights complex barriers financial, technical, and human and emphasizes the need for strategic implementation. It underscores the importance of thorough training, role clarity, and showcasing technology benefits to ensure efficiency and satisfaction among staff and residents.","sentences":["As the aging population increases and the shortage of healthcare workers increases, the need to examine other means for caring for the aging population increases.","One such means is the use of humanoid robots to care for social, emotional, and physical wellbeing of the people above 65.","Understanding skilled and long term care nursing home administrators' perspectives on humanoid robots in caregiving is crucial as their insights shape the implementation of robots and their potential impact on resident well-being and quality of life.","This authors surveyed two hundred and sixty nine nursing homes executives to understand their perspectives on the use of humanoid robots in their nursing home facilities.","The data was coded and results revealed that the executives were keen on exploring other avenues for care such as robotics that would enhance their nursing homes abilities to care for their residents.","Qualitative analysis reveals diverse perspectives on integrating humanoid robots in nursing homes.","While acknowledging benefits like improved engagement and staff support, concerns persist about costs, impacts on human interaction, and doubts about robot effectiveness.","This highlights complex barriers financial, technical, and human and emphasizes the need for strategic implementation.","It underscores the importance of thorough training, role clarity, and showcasing technology benefits to ensure efficiency and satisfaction among staff and residents."],"url":"http://arxiv.org/abs/2401.02105v1"}
{"created":"2024-01-04 07:11:16","title":"CLAPP: Contrastive Language-Audio Pre-training in Passive Underwater Vessel Classification","abstract":"Existing research on audio classification faces challenges in recognizing attributes of passive underwater vessel scenarios and lacks well-annotated datasets due to data privacy concerns. In this study, we introduce CLAPP (Contrastive Language-Audio Pre-training in Passive Underwater Vessel Classification), a novel model. Our aim is to train a neural network using a wide range of vessel audio and vessel state text pairs obtained from an oceanship dataset. CLAPP is capable of directly learning from raw vessel audio data and, when available, from carefully curated labels, enabling improved recognition of vessel attributes in passive underwater vessel scenarios. Model's zero-shot capability allows predicting the most relevant vessel state description for a given vessel audio, without directly optimizing for the task. Our approach aims to solve 2 challenges: vessel audio-text classification and passive underwater vessel audio attribute recognition. The proposed method achieves new state-of-the-art results on both Deepship and Shipsear public datasets, with a notable margin of about 7%-13% for accuracy compared to prior methods on zero-shot task.","sentences":["Existing research on audio classification faces challenges in recognizing attributes of passive underwater vessel scenarios and lacks well-annotated datasets due to data privacy concerns.","In this study, we introduce CLAPP (Contrastive Language-Audio Pre-training in Passive Underwater Vessel Classification), a novel model.","Our aim is to train a neural network using a wide range of vessel audio and vessel state text pairs obtained from an oceanship dataset.","CLAPP is capable of directly learning from raw vessel audio data and, when available, from carefully curated labels, enabling improved recognition of vessel attributes in passive underwater vessel scenarios.","Model's zero-shot capability allows predicting the most relevant vessel state description for a given vessel audio, without directly optimizing for the task.","Our approach aims to solve 2 challenges: vessel audio-text classification and passive underwater vessel audio attribute recognition.","The proposed method achieves new state-of-the-art results on both Deepship and Shipsear public datasets, with a notable margin of about 7%-13% for accuracy compared to prior methods on zero-shot task."],"url":"http://arxiv.org/abs/2401.02099v1"}
{"created":"2024-01-04 06:55:49","title":"Preserving Image Properties Through Initializations in Diffusion Models","abstract":"Retail photography imposes specific requirements on images. For instance, images may need uniform background colors, consistent model poses, centered products, and consistent lighting. Minor deviations from these standards impact a site's aesthetic appeal, making the images unsuitable for use. We show that Stable Diffusion methods, as currently applied, do not respect these requirements. The usual practice of training the denoiser with a very noisy image and starting inference with a sample of pure noise leads to inconsistent generated images during inference. This inconsistency occurs because it is easy to tell the difference between samples of the training and inference distributions. As a result, a network trained with centered retail product images with uniform backgrounds generates images with erratic backgrounds. The problem is easily fixed by initializing inference with samples from an approximation of noisy images. However, in using such an approximation, the joint distribution of text and noisy image at inference time still slightly differs from that at training time. This discrepancy is corrected by training the network with samples from the approximate noisy image distribution. Extensive experiments on real application data show significant qualitative and quantitative improvements in performance from adopting these procedures. Finally, our procedure can interact well with other control-based methods to further enhance the controllability of diffusion-based methods.","sentences":["Retail photography imposes specific requirements on images.","For instance, images may need uniform background colors, consistent model poses, centered products, and consistent lighting.","Minor deviations from these standards impact a site's aesthetic appeal, making the images unsuitable for use.","We show that Stable Diffusion methods, as currently applied, do not respect these requirements.","The usual practice of training the denoiser with a very noisy image and starting inference with a sample of pure noise leads to inconsistent generated images during inference.","This inconsistency occurs because it is easy to tell the difference between samples of the training and inference distributions.","As a result, a network trained with centered retail product images with uniform backgrounds generates images with erratic backgrounds.","The problem is easily fixed by initializing inference with samples from an approximation of noisy images.","However, in using such an approximation, the joint distribution of text and noisy image at inference time still slightly differs from that at training time.","This discrepancy is corrected by training the network with samples from the approximate noisy image distribution.","Extensive experiments on real application data show significant qualitative and quantitative improvements in performance from adopting these procedures.","Finally, our procedure can interact well with other control-based methods to further enhance the controllability of diffusion-based methods."],"url":"http://arxiv.org/abs/2401.02097v1"}
{"created":"2024-01-04 06:46:19","title":"Federated Class-Incremental Learning with Prototype Guided Transformer","abstract":"Existing federated learning methods have effectively addressed decentralized learning in scenarios involving data privacy and non-IID data. However, in real-world situations, each client dynamically learns new classes, requiring the global model to maintain discriminative capabilities for both new and old classes. To effectively mitigate the effects of catastrophic forgetting and data heterogeneity under low communication costs, we designed a simple and effective method named PLoRA. On the one hand, we adopt prototype learning to learn better feature representations and leverage the heuristic information between prototypes and class features to design a prototype re-weight module to solve the classifier bias caused by data heterogeneity without retraining the classification layer. On the other hand, our approach utilizes a pre-trained model as the backbone and utilizes LoRA to fine-tune with a tiny amount of parameters when learning new classes. Moreover, PLoRA does not rely on similarity-based module selection strategies, thereby further reducing communication overhead. Experimental results on standard datasets indicate that our method outperforms the state-of-the-art approaches significantly. More importantly, our method exhibits strong robustness and superiority in various scenarios and degrees of data heterogeneity. Our code will be publicly available.","sentences":["Existing federated learning methods have effectively addressed decentralized learning in scenarios involving data privacy and non-IID data.","However, in real-world situations, each client dynamically learns new classes, requiring the global model to maintain discriminative capabilities for both new and old classes.","To effectively mitigate the effects of catastrophic forgetting and data heterogeneity under low communication costs, we designed a simple and effective method named PLoRA.","On the one hand, we adopt prototype learning to learn better feature representations and leverage the heuristic information between prototypes and class features to design a prototype re-weight module to solve the classifier bias caused by data heterogeneity without retraining the classification layer.","On the other hand, our approach utilizes a pre-trained model as the backbone and utilizes LoRA to fine-tune with a tiny amount of parameters when learning new classes.","Moreover, PLoRA does not rely on similarity-based module selection strategies, thereby further reducing communication overhead.","Experimental results on standard datasets indicate that our method outperforms the state-of-the-art approaches significantly.","More importantly, our method exhibits strong robustness and superiority in various scenarios and degrees of data heterogeneity.","Our code will be publicly available."],"url":"http://arxiv.org/abs/2401.02094v1"}
{"created":"2024-01-04 06:20:24","title":"View-based Explanations for Graph Neural Networks","abstract":"Generating explanations for graph neural networks (GNNs) has been studied to understand their behavior in analytical tasks such as graph classification. Existing approaches aim to understand the overall results of GNNs rather than providing explanations for specific class labels of interest, and may return explanation structures that are hard to access, nor directly queryable.   We propose GVEX, a novel paradigm that generates Graph Views for EXplanation. (1) We design a two-tier explanation structure called explanation views. An explanation view consists of a set of graph patterns and a set of induced explanation subgraphs. Given a database G of multiple graphs and a specific class label l assigned by a GNN-based classifier M, it concisely describes the fraction of G that best explains why l is assigned by M. (2) We propose quality measures and formulate an optimization problem to compute optimal explanation views for GNN explanation. We show that the problem is $\\Sigma^2_P$-hard. (3) We present two algorithms. The first one follows an explain-and-summarize strategy that first generates high-quality explanation subgraphs which best explain GNNs in terms of feature influence maximization, and then performs a summarization step to generate patterns. We show that this strategy provides an approximation ratio of 1/2. Our second algorithm performs a single-pass to an input node stream in batches to incrementally maintain explanation views, having an anytime quality guarantee of 1/4 approximation. Using real-world benchmark data, we experimentally demonstrate the effectiveness, efficiency, and scalability of GVEX. Through case studies, we showcase the practical applications of GVEX.","sentences":["Generating explanations for graph neural networks (GNNs) has been studied to understand their behavior in analytical tasks such as graph classification.","Existing approaches aim to understand the overall results of GNNs rather than providing explanations for specific class labels of interest, and may return explanation structures that are hard to access, nor directly queryable.   ","We propose GVEX, a novel paradigm that generates Graph Views for EXplanation.","(1) We design a two-tier explanation structure called explanation views.","An explanation view consists of a set of graph patterns and a set of induced explanation subgraphs.","Given a database G of multiple graphs and a specific class label l assigned by a GNN-based classifier M, it concisely describes the fraction of G that best explains why l is assigned by M. (2) We propose quality measures and formulate an optimization problem to compute optimal explanation views for GNN explanation.","We show that the problem is $\\Sigma^2_P$-hard.","(3) We present two algorithms.","The first one follows an explain-and-summarize strategy that first generates high-quality explanation subgraphs which best explain GNNs in terms of feature influence maximization, and then performs a summarization step to generate patterns.","We show that this strategy provides an approximation ratio of 1/2.","Our second algorithm performs a single-pass to an input node stream in batches to incrementally maintain explanation views, having an anytime quality guarantee of 1/4 approximation.","Using real-world benchmark data, we experimentally demonstrate the effectiveness, efficiency, and scalability of GVEX.","Through case studies, we showcase the practical applications of GVEX."],"url":"http://arxiv.org/abs/2401.02086v1"}
{"created":"2024-01-04 06:16:16","title":"Outage Analysis for Active Reconfigurable Intelligent Surface-Enhanced Wireless Powered Communication Networks","abstract":"Wireless powered communication (WPC) involves the integration of energy harvesting and data transmission. This allows devices to communicate without constant battery replacements or wired power sources. Reconfigurable intelligent surfaces (RISs) can dynamically manipulate radio signals. In this paper, we explore the use of active elements to mitigate double-fading challenges inherent in RIS-aided links. We enhance the reliability performance for an energy-constrained user by combining active RIS and WPC. The theoretical closed-form analysis, which includes transmission rate, harvested energy, and outage probability, provides valuable insights that inform parameter selection.","sentences":["Wireless powered communication (WPC) involves the integration of energy harvesting and data transmission.","This allows devices to communicate without constant battery replacements or wired power sources.","Reconfigurable intelligent surfaces (RISs) can dynamically manipulate radio signals.","In this paper, we explore the use of active elements to mitigate double-fading challenges inherent in RIS-aided links.","We enhance the reliability performance for an energy-constrained user by combining active RIS and WPC.","The theoretical closed-form analysis, which includes transmission rate, harvested energy, and outage probability, provides valuable insights that inform parameter selection."],"url":"http://arxiv.org/abs/2401.02083v1"}
{"created":"2024-01-04 05:47:41","title":"ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers","abstract":"The emergence of Large Language Models (LLMs) such as ChatGPT and LLaMA encounter limitations in domain-specific tasks, with these models often lacking depth and accuracy in specialized areas, and exhibiting a decrease in general capabilities when fine-tuned, particularly analysis ability in small sized models. To address these gaps, we introduce ICE-GRT, utilizing Reinforcement Learning from Human Feedback (RLHF) grounded in Proximal Policy Optimization (PPO), demonstrating remarkable ability in in-domain scenarios without compromising general task performance. Our exploration of ICE-GRT highlights its understanding and reasoning ability to not only generate robust answers but also to provide detailed analyses of the reasons behind the answer. This capability marks a significant progression beyond the scope of Supervised Fine-Tuning models. The success of ICE-GRT is dependent on several crucial factors, including Appropriate Data, Reward Size Scaling, KL-Control, Advantage Normalization, etc. The ICE-GRT model exhibits state-of-the-art performance in domain-specific tasks and across 12 general Language tasks against equivalent size and even larger size LLMs, highlighting the effectiveness of our approach. We provide a comprehensive analysis of the ICE-GRT, underscoring the significant advancements it brings to the field of LLM.","sentences":["The emergence of Large Language Models (LLMs) such as ChatGPT and LLaMA encounter limitations in domain-specific tasks, with these models often lacking depth and accuracy in specialized areas, and exhibiting a decrease in general capabilities when fine-tuned, particularly analysis ability in small sized models.","To address these gaps, we introduce ICE-GRT, utilizing Reinforcement Learning from Human Feedback (RLHF) grounded in Proximal Policy Optimization (PPO), demonstrating remarkable ability in in-domain scenarios without compromising general task performance.","Our exploration of ICE-GRT highlights its understanding and reasoning ability to not only generate robust answers but also to provide detailed analyses of the reasons behind the answer.","This capability marks a significant progression beyond the scope of Supervised Fine-Tuning models.","The success of ICE-GRT is dependent on several crucial factors, including Appropriate Data, Reward Size Scaling, KL-Control, Advantage Normalization, etc.","The ICE-GRT model exhibits state-of-the-art performance in domain-specific tasks and across 12 general Language tasks against equivalent size and even larger size LLMs, highlighting the effectiveness of our approach.","We provide a comprehensive analysis of the ICE-GRT, underscoring the significant advancements it brings to the field of LLM."],"url":"http://arxiv.org/abs/2401.02072v1"}
{"created":"2024-01-04 05:45:31","title":"Joint Beamforming and Offloading Design for Integrated Sensing, Communication and Computation System","abstract":"Mobile edge computing (MEC) is powerful to alleviate the heavy computing tasks in integrated sensing and communication (ISAC) systems. In this paper, we investigate joint beamforming and offloading design in a three-tier integrated sensing, communication and computation (ISCC) framework comprising one cloud server, multiple mobile edge servers, and multiple terminals. While executing sensing tasks, the user terminals can optionally offload sensing data to either MEC server or cloud servers. To minimize the execution latency, we jointly optimize the transmit beamforming matrices and offloading decision variables under the constraint of sensing performance. An alternating optimization algorithm based on multidimensional fractional programming is proposed to tackle the non-convex problem. Simulation results demonstrates the superiority of the proposed mechanism in terms of convergence and task execution latency reduction, compared with the state-of-the-art two-tier ISCC framework.","sentences":["Mobile edge computing (MEC) is powerful to alleviate the heavy computing tasks in integrated sensing and communication (ISAC) systems.","In this paper, we investigate joint beamforming and offloading design in a three-tier integrated sensing, communication and computation (ISCC) framework comprising one cloud server, multiple mobile edge servers, and multiple terminals.","While executing sensing tasks, the user terminals can optionally offload sensing data to either MEC server or cloud servers.","To minimize the execution latency, we jointly optimize the transmit beamforming matrices and offloading decision variables under the constraint of sensing performance.","An alternating optimization algorithm based on multidimensional fractional programming is proposed to tackle the non-convex problem.","Simulation results demonstrates the superiority of the proposed mechanism in terms of convergence and task execution latency reduction, compared with the state-of-the-art two-tier ISCC framework."],"url":"http://arxiv.org/abs/2401.02071v1"}
{"created":"2024-01-04 03:33:14","title":"Covid19 Vaccine Acceptance and Deprivation in US Counties","abstract":"This report explores the central question of how socioeconomic status affects Covid19 vaccination rates in the United States, using existing open-source data. In general, a negative correlation exists between Area Deprivation Index (ADI) of a county and first dose, primary series and booster vaccination rates. Higher area deprivation correlated with polled vaccine hesitancy and lower search interest in vaccine interest, intention to vaccinate or concern about safety of vaccination. Positive correlations between ADI and certain mental health search trends were noted. No clear correlation between deprivation index and accessibility to vaccination sites were observed. In a small data sample, county level housing assistance policies and public information campaigns were noted to positively influence vaccine follow through rates. Finally, random forest, linear regression and KNN models were explored to validate the use of the above features for vaccine acceptance prediction.","sentences":["This report explores the central question of how socioeconomic status affects Covid19 vaccination rates in the United States, using existing open-source data.","In general, a negative correlation exists between Area Deprivation Index (ADI) of a county and first dose, primary series and booster vaccination rates.","Higher area deprivation correlated with polled vaccine hesitancy and lower search interest in vaccine interest, intention to vaccinate or concern about safety of vaccination.","Positive correlations between ADI and certain mental health search trends were noted.","No clear correlation between deprivation index and accessibility to vaccination sites were observed.","In a small data sample, county level housing assistance policies and public information campaigns were noted to positively influence vaccine follow through rates.","Finally, random forest, linear regression and KNN models were explored to validate the use of the above features for vaccine acceptance prediction."],"url":"http://arxiv.org/abs/2401.02047v1"}
{"created":"2024-01-04 02:43:57","title":"Understanding LLMs: A Comprehensive Overview from Training to Inference","abstract":"The introduction of ChatGPT has led to a significant increase in the utilization of Large Language Models (LLMs) for addressing downstream tasks. There's an increasing focus on cost-efficient training and deployment within this context. Low-cost training and deployment of LLMs represent the future development trend. This paper reviews the evolution of large language model training techniques and inference deployment technologies aligned with this emerging trend. The discussion on training includes various aspects, including data preprocessing, training architecture, pre-training tasks, parallel training, and relevant content related to model fine-tuning. On the inference side, the paper covers topics such as model compression, parallel computation, memory scheduling, and structural optimization. It also explores LLMs' utilization and provides insights into their future development.","sentences":["The introduction of ChatGPT has led to a significant increase in the utilization of Large Language Models (LLMs) for addressing downstream tasks.","There's an increasing focus on cost-efficient training and deployment within this context.","Low-cost training and deployment of LLMs represent the future development trend.","This paper reviews the evolution of large language model training techniques and inference deployment technologies aligned with this emerging trend.","The discussion on training includes various aspects, including data preprocessing, training architecture, pre-training tasks, parallel training, and relevant content related to model fine-tuning.","On the inference side, the paper covers topics such as model compression, parallel computation, memory scheduling, and structural optimization.","It also explores LLMs' utilization and provides insights into their future development."],"url":"http://arxiv.org/abs/2401.02038v1"}
{"created":"2024-01-04 02:15:09","title":"Spy-Watermark: Robust Invisible Watermarking for Backdoor Attack","abstract":"Backdoor attack aims to deceive a victim model when facing backdoor instances while maintaining its performance on benign data. Current methods use manual patterns or special perturbations as triggers, while they often overlook the robustness against data corruption, making backdoor attacks easy to defend in practice. To address this issue, we propose a novel backdoor attack method named Spy-Watermark, which remains effective when facing data collapse and backdoor defense. Therein, we introduce a learnable watermark embedded in the latent domain of images, serving as the trigger. Then, we search for a watermark that can withstand collapse during image decoding, cooperating with several anti-collapse operations to further enhance the resilience of our trigger against data corruption. Extensive experiments are conducted on CIFAR10, GTSRB, and ImageNet datasets, demonstrating that Spy-Watermark overtakes ten state-of-the-art methods in terms of robustness and stealthiness.","sentences":["Backdoor attack aims to deceive a victim model when facing backdoor instances while maintaining its performance on benign data.","Current methods use manual patterns or special perturbations as triggers, while they often overlook the robustness against data corruption, making backdoor attacks easy to defend in practice.","To address this issue, we propose a novel backdoor attack method named Spy-Watermark, which remains effective when facing data collapse and backdoor defense.","Therein, we introduce a learnable watermark embedded in the latent domain of images, serving as the trigger.","Then, we search for a watermark that can withstand collapse during image decoding, cooperating with several anti-collapse operations to further enhance the resilience of our trigger against data corruption.","Extensive experiments are conducted on CIFAR10, GTSRB, and ImageNet datasets, demonstrating that Spy-Watermark overtakes ten state-of-the-art methods in terms of robustness and stealthiness."],"url":"http://arxiv.org/abs/2401.02031v1"}
{"created":"2024-01-04 02:14:18","title":"Examining the Challenges in Archiving Instagram","abstract":"To prevent the spread of disinformation on Instagram, we need to study the accounts and content of disinformation actors. However, due to their malicious nature, Instagram often bans accounts that are responsible for spreading disinformation, making these accounts inaccessible from the live web. The only way we can study the content of banned accounts is through public web archives such as the Internet Archive. However, there are many issues present with archiving Instagram pages. Specifically, we focused on the issue that many Wayback Machine Instagram mementos redirect to the Instagram login page. In this study, we determined that mementos of Instagram account pages on the Wayback Machine began redirecting to the Instagram login page in August 2019. We also found that Instagram mementos on Archive.today, Arquivo.pt, and Perma.cc are also not well archived in terms of quantity and quality. Moreover, we were unsuccessful in all our attempts to archive Katy Perry's Instagram account page on Archive.today, Arquivo.pt, and Conifer. Although in the minority, replayable Instagram mementos exist in public archives and contain valuable data for studying disinformation on Instagram. With that in mind, we developed a Python script to web scrape Instagram mementos. As of August 2023, the Python script can scrape Wayback Machine archives of Instagram account pages between November 7, 2012 and June 8, 2018.","sentences":["To prevent the spread of disinformation on Instagram, we need to study the accounts and content of disinformation actors.","However, due to their malicious nature, Instagram often bans accounts that are responsible for spreading disinformation, making these accounts inaccessible from the live web.","The only way we can study the content of banned accounts is through public web archives such as the Internet Archive.","However, there are many issues present with archiving Instagram pages.","Specifically, we focused on the issue that many Wayback Machine Instagram mementos redirect to the Instagram login page.","In this study, we determined that mementos of Instagram account pages on the Wayback Machine began redirecting to the Instagram login page in August 2019.","We also found that Instagram mementos on Archive.today, Arquivo.pt, and Perma.cc are also not well archived in terms of quantity and quality.","Moreover, we were unsuccessful in all our attempts to archive Katy Perry's Instagram account page on Archive.today, Arquivo.pt, and Conifer.","Although in the minority, replayable Instagram mementos exist in public archives and contain valuable data for studying disinformation on Instagram.","With that in mind, we developed a Python script to web scrape Instagram mementos.","As of August 2023, the Python script can scrape Wayback Machine archives of Instagram account pages between November 7, 2012 and June 8, 2018."],"url":"http://arxiv.org/abs/2401.02029v1"}
{"created":"2024-01-04 01:32:50","title":"From Function to Distribution Modeling: A PAC-Generative Approach to Offline Optimization","abstract":"This paper considers the problem of offline optimization, where the objective function is unknown except for a collection of ``offline\" data examples. While recent years have seen a flurry of work on applying various machine learning techniques to the offline optimization problem, the majority of these work focused on learning a surrogate of the unknown objective function and then applying existing optimization algorithms. While the idea of modeling the unknown objective function is intuitive and appealing, from the learning point of view it also makes it very difficult to tune the objective of the learner according to the objective of optimization. Instead of learning and then optimizing the unknown objective function, in this paper we take on a less intuitive but more direct view that optimization can be thought of as a process of sampling from a generative model. To learn an effective generative model from the offline data examples, we consider the standard technique of ``re-weighting\", and our main technical contribution is a probably approximately correct (PAC) lower bound on the natural optimization objective, which allows us to jointly learn a weight function and a score-based generative model. The robustly competitive performance of the proposed approach is demonstrated via empirical studies using the standard offline optimization benchmarks.","sentences":["This paper considers the problem of offline optimization, where the objective function is unknown except for a collection of ``offline\" data examples.","While recent years have seen a flurry of work on applying various machine learning techniques to the offline optimization problem, the majority of these work focused on learning a surrogate of the unknown objective function and then applying existing optimization algorithms.","While the idea of modeling the unknown objective function is intuitive and appealing, from the learning point of view it also makes it very difficult to tune the objective of the learner according to the objective of optimization.","Instead of learning and then optimizing the unknown objective function, in this paper we take on a less intuitive but more direct view that optimization can be thought of as a process of sampling from a generative model.","To learn an effective generative model from the offline data examples, we consider the standard technique of ``re-weighting\", and our main technical contribution is a probably approximately correct (PAC) lower bound on the natural optimization objective, which allows us to jointly learn a weight function and a score-based generative model.","The robustly competitive performance of the proposed approach is demonstrated via empirical studies using the standard offline optimization benchmarks."],"url":"http://arxiv.org/abs/2401.02019v1"}
{"created":"2024-01-04 01:05:45","title":"SwitchTab: Switched Autoencoders Are Effective Tabular Learners","abstract":"Self-supervised representation learning methods have achieved significant success in computer vision and natural language processing, where data samples exhibit explicit spatial or semantic dependencies. However, applying these methods to tabular data is challenging due to the less pronounced dependencies among data samples. In this paper, we address this limitation by introducing SwitchTab, a novel self-supervised method specifically designed to capture latent dependencies in tabular data. SwitchTab leverages an asymmetric encoder-decoder framework to decouple mutual and salient features among data pairs, resulting in more representative embeddings. These embeddings, in turn, contribute to better decision boundaries and lead to improved results in downstream tasks. To validate the effectiveness of SwitchTab, we conduct extensive experiments across various domains involving tabular data. The results showcase superior performance in end-to-end prediction tasks with fine-tuning. Moreover, we demonstrate that pre-trained salient embeddings can be utilized as plug-and-play features to enhance the performance of various traditional classification methods (e.g., Logistic Regression, XGBoost, etc.). Lastly, we highlight the capability of SwitchTab to create explainable representations through visualization of decoupled mutual and salient features in the latent space.","sentences":["Self-supervised representation learning methods have achieved significant success in computer vision and natural language processing, where data samples exhibit explicit spatial or semantic dependencies.","However, applying these methods to tabular data is challenging due to the less pronounced dependencies among data samples.","In this paper, we address this limitation by introducing SwitchTab, a novel self-supervised method specifically designed to capture latent dependencies in tabular data.","SwitchTab leverages an asymmetric encoder-decoder framework to decouple mutual and salient features among data pairs, resulting in more representative embeddings.","These embeddings, in turn, contribute to better decision boundaries and lead to improved results in downstream tasks.","To validate the effectiveness of SwitchTab, we conduct extensive experiments across various domains involving tabular data.","The results showcase superior performance in end-to-end prediction tasks with fine-tuning.","Moreover, we demonstrate that pre-trained salient embeddings can be utilized as plug-and-play features to enhance the performance of various traditional classification methods (e.g., Logistic Regression, XGBoost, etc.).","Lastly, we highlight the capability of SwitchTab to create explainable representations through visualization of decoupled mutual and salient features in the latent space."],"url":"http://arxiv.org/abs/2401.02013v1"}
{"created":"2024-01-04 00:25:12","title":"Two-Stage Surrogate Modeling for Data-Driven Design Optimization with Application to Composite Microstructure Generation","abstract":"This paper introduces a novel two-stage machine learning-based surrogate modeling framework to address inverse problems in scientific and engineering fields. In the first stage of the proposed framework, a machine learning model termed the \"learner\" identifies a limited set of candidates within the input design space whose predicted outputs closely align with desired outcomes. Subsequently, in the second stage, a separate surrogate model, functioning as an \"evaluator,\" is employed to assess the reduced candidate space generated in the first stage. This evaluation process eliminates inaccurate and uncertain solutions, guided by a user-defined coverage level. The framework's distinctive contribution is the integration of conformal inference, providing a versatile and efficient approach that can be widely applicable. To demonstrate the effectiveness of the proposed framework compared to conventional single-stage inverse problems, we conduct several benchmark tests and investigate an engineering application focused on the micromechanical modeling of fiber-reinforced composites. The results affirm the superiority of our proposed framework, as it consistently produces more reliable solutions. Therefore, the introduced framework offers a unique perspective on fostering interactions between machine learning-based surrogate models in real-world applications.","sentences":["This paper introduces a novel two-stage machine learning-based surrogate modeling framework to address inverse problems in scientific and engineering fields.","In the first stage of the proposed framework, a machine learning model termed the \"learner\" identifies a limited set of candidates within the input design space whose predicted outputs closely align with desired outcomes.","Subsequently, in the second stage, a separate surrogate model, functioning as an \"evaluator,\" is employed to assess the reduced candidate space generated in the first stage.","This evaluation process eliminates inaccurate and uncertain solutions, guided by a user-defined coverage level.","The framework's distinctive contribution is the integration of conformal inference, providing a versatile and efficient approach that can be widely applicable.","To demonstrate the effectiveness of the proposed framework compared to conventional single-stage inverse problems, we conduct several benchmark tests and investigate an engineering application focused on the micromechanical modeling of fiber-reinforced composites.","The results affirm the superiority of our proposed framework, as it consistently produces more reliable solutions.","Therefore, the introduced framework offers a unique perspective on fostering interactions between machine learning-based surrogate models in real-world applications."],"url":"http://arxiv.org/abs/2401.02008v1"}
{"created":"2024-01-03 21:39:06","title":"GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning","abstract":"We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a general method to inject a priori knowledge into Self-Supervised Learning (SSL) positive samples selection. Current SSL methods leverage Data-Augmentations (DA) for generating positive samples and incorporate prior knowledge - an incorrect, or too weak DA will drastically reduce the quality of the learned representation. GPS-SSL proposes instead to design a metric space where Euclidean distances become a meaningful proxy for semantic relationship. In that space, it is now possible to generate positive samples from nearest neighbor sampling. Any prior knowledge can now be embedded into that metric space independently from the employed DA. From its simplicity, GPS-SSL is applicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL is in reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches 85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. We therefore move a step forward towards the goal of making SSL less reliant on DA. We also show that even when using strong DAs, GPS-SSL outperforms the baselines on under-studied domains. We evaluate GPS-SSL along with multiple baseline SSL methods on numerous downstream datasets from different domains when the models use strong or minimal data augmentations. We hope that GPS-SSL will open new avenues in studying how to inject a priori knowledge into SSL in a principled manner.","sentences":["We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a general method to inject a priori knowledge into Self-Supervised Learning (SSL) positive samples selection.","Current SSL methods leverage Data-Augmentations (DA) for generating positive samples and incorporate prior knowledge - an incorrect, or too weak DA will drastically reduce the quality of the learned representation.","GPS-SSL proposes instead to design a metric space where Euclidean distances become a meaningful proxy for semantic relationship.","In that space, it is now possible to generate positive samples from nearest neighbor sampling.","Any prior knowledge can now be embedded into that metric space independently from the employed DA.","From its simplicity, GPS-SSL is applicable to any SSL method, e.g. SimCLR or BYOL.","A key benefit of GPS-SSL is in reducing the pressure in tailoring strong DAs.","For example GPS-SSL reaches 85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%.","We therefore move a step forward towards the goal of making SSL less reliant on DA.","We also show that even when using strong DAs, GPS-SSL outperforms the baselines on under-studied domains.","We evaluate GPS-SSL along with multiple baseline SSL methods on numerous downstream datasets from different domains when the models use strong or minimal data augmentations.","We hope that GPS-SSL will open new avenues in studying how to inject a priori knowledge into SSL in a principled manner."],"url":"http://arxiv.org/abs/2401.01990v1"}
{"created":"2024-01-03 21:32:46","title":"Representation Learning of Multivariate Time Series using Attention and Adversarial Training","abstract":"A critical factor in trustworthy machine learning is to develop robust representations of the training data. Only under this guarantee methods are legitimate to artificially generate data, for example, to counteract imbalanced datasets or provide counterfactual explanations for blackbox decision-making systems. In recent years, Generative Adversarial Networks (GANs) have shown considerable results in forming stable representations and generating realistic data. While many applications focus on generating image data, less effort has been made in generating time series data, especially multivariate signals. In this work, a Transformer-based autoencoder is proposed that is regularized using an adversarial training scheme to generate artificial multivariate time series signals. The representation is evaluated using t-SNE visualizations, Dynamic Time Warping (DTW) and Entropy scores. Our results indicate that the generated signals exhibit higher similarity to an exemplary dataset than using a convolutional network approach.","sentences":["A critical factor in trustworthy machine learning is to develop robust representations of the training data.","Only under this guarantee methods are legitimate to artificially generate data, for example, to counteract imbalanced datasets or provide counterfactual explanations for blackbox decision-making systems.","In recent years, Generative Adversarial Networks (GANs) have shown considerable results in forming stable representations and generating realistic data.","While many applications focus on generating image data, less effort has been made in generating time series data, especially multivariate signals.","In this work, a Transformer-based autoencoder is proposed that is regularized using an adversarial training scheme to generate artificial multivariate time series signals.","The representation is evaluated using t-SNE visualizations, Dynamic Time Warping (DTW) and Entropy scores.","Our results indicate that the generated signals exhibit higher similarity to an exemplary dataset than using a convolutional network approach."],"url":"http://arxiv.org/abs/2401.01987v1"}
{"created":"2024-01-03 19:39:23","title":"MULTI-CASE: A Transformer-based Ethics-aware Multimodal Investigative Intelligence Framework","abstract":"AI-driven models are increasingly deployed in operational analytics solutions, for instance, in investigative journalism or the intelligence community. Current approaches face two primary challenges: ethical and privacy concerns, as well as difficulties in efficiently combining heterogeneous data sources for multimodal analytics. To tackle the challenge of multimodal analytics, we present MULTI-CASE, a holistic visual analytics framework tailored towards ethics-aware and multimodal intelligence exploration, designed in collaboration with domain experts. It leverages an equal joint agency between human and AI to explore and assess heterogeneous information spaces, checking and balancing automation through Visual Analytics. MULTI-CASE operates on a fully-integrated data model and features type-specific analysis with multiple linked components, including a combined search, annotated text view, and graph-based analysis. Parts of the underlying entity detection are based on a RoBERTa-based language model, which we tailored towards user requirements through fine-tuning. An overarching knowledge exploration graph combines all information streams, provides in-situ explanations, transparent source attribution, and facilitates effective exploration. To assess our approach, we conducted a comprehensive set of evaluations: We benchmarked the underlying language model on relevant NER tasks, achieving state-of-the-art performance. The demonstrator was assessed according to intelligence capability assessments, while the methodology was evaluated according to ethics design guidelines. As a case study, we present our framework in an investigative journalism setting, supporting war crime investigations. Finally, we conduct a formative user evaluation with domain experts in law enforcement. Our evaluations confirm that our framework facilitates human agency and steering in security-sensitive applications.","sentences":["AI-driven models are increasingly deployed in operational analytics solutions, for instance, in investigative journalism or the intelligence community.","Current approaches face two primary challenges: ethical and privacy concerns, as well as difficulties in efficiently combining heterogeneous data sources for multimodal analytics.","To tackle the challenge of multimodal analytics, we present MULTI-CASE, a holistic visual analytics framework tailored towards ethics-aware and multimodal intelligence exploration, designed in collaboration with domain experts.","It leverages an equal joint agency between human and AI to explore and assess heterogeneous information spaces, checking and balancing automation through Visual Analytics.","MULTI-CASE operates on a fully-integrated data model and features type-specific analysis with multiple linked components, including a combined search, annotated text view, and graph-based analysis.","Parts of the underlying entity detection are based on a RoBERTa-based language model, which we tailored towards user requirements through fine-tuning.","An overarching knowledge exploration graph combines all information streams, provides in-situ explanations, transparent source attribution, and facilitates effective exploration.","To assess our approach, we conducted a comprehensive set of evaluations: We benchmarked the underlying language model on relevant NER tasks, achieving state-of-the-art performance.","The demonstrator was assessed according to intelligence capability assessments, while the methodology was evaluated according to ethics design guidelines.","As a case study, we present our framework in an investigative journalism setting, supporting war crime investigations.","Finally, we conduct a formative user evaluation with domain experts in law enforcement.","Our evaluations confirm that our framework facilitates human agency and steering in security-sensitive applications."],"url":"http://arxiv.org/abs/2401.01955v1"}
{"created":"2024-01-03 19:03:32","title":"Generalist embedding models are better at short-context clinical semantic search than specialized embedding models","abstract":"The increasing use of tools and solutions based on Large Language Models (LLMs) for various tasks in the medical domain has become a prominent trend. Their use in this highly critical and sensitive domain has thus raised important questions about their robustness, especially in response to variations in input, and the reliability of the generated outputs. This study addresses these questions by constructing a textual dataset based on the ICD-10-CM code descriptions, widely used in US hospitals and containing many clinical terms, and their easily reproducible rephrasing. We then benchmarked existing embedding models, either generalist or specialized in the clinical domain, in a semantic search task where the goal was to correctly match the rephrased text to the original description. Our results showed that generalist models performed better than clinical models, suggesting that existing clinical specialized models are more sensitive to small changes in input that confuse them. The highlighted problem of specialized models may be due to the fact that they have not been trained on sufficient data, and in particular on datasets that are not diverse enough to have a reliable global language understanding, which is still necessary for accurate handling of medical documents.","sentences":["The increasing use of tools and solutions based on Large Language Models (LLMs) for various tasks in the medical domain has become a prominent trend.","Their use in this highly critical and sensitive domain has thus raised important questions about their robustness, especially in response to variations in input, and the reliability of the generated outputs.","This study addresses these questions by constructing a textual dataset based on the ICD-10-CM code descriptions, widely used in US hospitals and containing many clinical terms, and their easily reproducible rephrasing.","We then benchmarked existing embedding models, either generalist or specialized in the clinical domain, in a semantic search task where the goal was to correctly match the rephrased text to the original description.","Our results showed that generalist models performed better than clinical models, suggesting that existing clinical specialized models are more sensitive to small changes in input that confuse them.","The highlighted problem of specialized models may be due to the fact that they have not been trained on sufficient data, and in particular on datasets that are not diverse enough to have a reliable global language understanding, which is still necessary for accurate handling of medical documents."],"url":"http://arxiv.org/abs/2401.01943v1"}
