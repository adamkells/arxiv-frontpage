{"created":"2023-12-19 18:59:53","title":"Weakly Supervised Open-Vocabulary Object Detection","abstract":"Despite weakly supervised object detection (WSOD) being a promising step toward evading strong instance-level annotations, its capability is confined to closed-set categories within a single training dataset. In this paper, we propose a novel weakly supervised open-vocabulary object detection framework, namely WSOVOD, to extend traditional WSOD to detect novel concepts and utilize diverse datasets with only image-level annotations. To achieve this, we explore three vital strategies, including dataset-level feature adaptation, image-level salient object localization, and region-level vision-language alignment. First, we perform data-aware feature extraction to produce an input-conditional coefficient, which is leveraged into dataset attribute prototypes to identify dataset bias and help achieve cross-dataset generalization. Second, a customized location-oriented weakly supervised region proposal network is proposed to utilize high-level semantic layouts from the category-agnostic segment anything model to distinguish object boundaries. Lastly, we introduce a proposal-concept synchronized multiple-instance network, i.e., object mining and refinement with visual-semantic alignment, to discover objects matched to the text embeddings of concepts. Extensive experiments on Pascal VOC and MS COCO demonstrate that the proposed WSOVOD achieves new state-of-the-art compared with previous WSOD methods in both close-set object localization and detection tasks. Meanwhile, WSOVOD enables cross-dataset and open-vocabulary learning to achieve on-par or even better performance than well-established fully-supervised open-vocabulary object detection (FSOVOD).","sentences":["Despite weakly supervised object detection (WSOD) being a promising step toward evading strong instance-level annotations, its capability is confined to closed-set categories within a single training dataset.","In this paper, we propose a novel weakly supervised open-vocabulary object detection framework, namely WSOVOD, to extend traditional WSOD to detect novel concepts and utilize diverse datasets with only image-level annotations.","To achieve this, we explore three vital strategies, including dataset-level feature adaptation, image-level salient object localization, and region-level vision-language alignment.","First, we perform data-aware feature extraction to produce an input-conditional coefficient, which is leveraged into dataset attribute prototypes to identify dataset bias and help achieve cross-dataset generalization.","Second, a customized location-oriented weakly supervised region proposal network is proposed to utilize high-level semantic layouts from the category-agnostic segment anything model to distinguish object boundaries.","Lastly, we introduce a proposal-concept synchronized multiple-instance network, i.e., object mining and refinement with visual-semantic alignment, to discover objects matched to the text embeddings of concepts.","Extensive experiments on Pascal VOC and MS COCO demonstrate that the proposed WSOVOD achieves new state-of-the-art compared with previous WSOD methods in both close-set object localization and detection tasks.","Meanwhile, WSOVOD enables cross-dataset and open-vocabulary learning to achieve on-par or even better performance than well-established fully-supervised open-vocabulary object detection (FSOVOD)."],"url":"http://arxiv.org/abs/2312.12437v1"}
{"created":"2023-12-19 18:58:40","title":"Tracking Any Object Amodally","abstract":"Amodal perception, the ability to comprehend complete object structures from partial visibility, is a fundamental skill, even for infants. Its significance extends to applications like autonomous driving, where a clear understanding of heavily occluded objects is essential. However, modern detection and tracking algorithms often overlook this critical capability, perhaps due to the prevalence of modal annotations in most datasets. To address the scarcity of amodal data, we introduce the TAO-Amodal benchmark, featuring 880 diverse categories in thousands of video sequences. Our dataset includes amodal and modal bounding boxes for visible and occluded objects, including objects that are partially out-of-frame. To enhance amodal tracking with object permanence, we leverage a lightweight plug-in module, the amodal expander, to transform standard, modal trackers into amodal ones through fine-tuning on a few hundred video sequences with data augmentation. We achieve a 3.3\\% and 1.6\\% improvement on the detection and tracking of occluded objects on TAO-Amodal. When evaluated on people, our method produces dramatic improvements of 2x compared to state-of-the-art modal baselines.","sentences":["Amodal perception, the ability to comprehend complete object structures from partial visibility, is a fundamental skill, even for infants.","Its significance extends to applications like autonomous driving, where a clear understanding of heavily occluded objects is essential.","However, modern detection and tracking algorithms often overlook this critical capability, perhaps due to the prevalence of modal annotations in most datasets.","To address the scarcity of amodal data, we introduce the TAO-Amodal benchmark, featuring 880 diverse categories in thousands of video sequences.","Our dataset includes amodal and modal bounding boxes for visible and occluded objects, including objects that are partially out-of-frame.","To enhance amodal tracking with object permanence, we leverage a lightweight plug-in module, the amodal expander, to transform standard, modal trackers into amodal ones through fine-tuning on a few hundred video sequences with data augmentation.","We achieve a 3.3\\% and 1.6\\% improvement on the detection and tracking of occluded objects on TAO-Amodal.","When evaluated on people, our method produces dramatic improvements of 2x compared to state-of-the-art modal baselines."],"url":"http://arxiv.org/abs/2312.12433v1"}
{"created":"2023-12-19 18:53:47","title":"SegRefiner: Towards Model-Agnostic Segmentation Refinement with Discrete Diffusion Process","abstract":"In this paper, we explore a principal way to enhance the quality of object masks produced by different segmentation models. We propose a model-agnostic solution called SegRefiner, which offers a novel perspective on this problem by interpreting segmentation refinement as a data generation process. As a result, the refinement process can be smoothly implemented through a series of denoising diffusion steps. Specifically, SegRefiner takes coarse masks as inputs and refines them using a discrete diffusion process. By predicting the label and corresponding states-transition probabilities for each pixel, SegRefiner progressively refines the noisy masks in a conditional denoising manner. To assess the effectiveness of SegRefiner, we conduct comprehensive experiments on various segmentation tasks, including semantic segmentation, instance segmentation, and dichotomous image segmentation. The results demonstrate the superiority of our SegRefiner from multiple aspects. Firstly, it consistently improves both the segmentation metrics and boundary metrics across different types of coarse masks. Secondly, it outperforms previous model-agnostic refinement methods by a significant margin. Lastly, it exhibits a strong capability to capture extremely fine details when refining high-resolution images. The source code and trained models are available at https://github.com/MengyuWang826/SegRefiner.","sentences":["In this paper, we explore a principal way to enhance the quality of object masks produced by different segmentation models.","We propose a model-agnostic solution called SegRefiner, which offers a novel perspective on this problem by interpreting segmentation refinement as a data generation process.","As a result, the refinement process can be smoothly implemented through a series of denoising diffusion steps.","Specifically, SegRefiner takes coarse masks as inputs and refines them using a discrete diffusion process.","By predicting the label and corresponding states-transition probabilities for each pixel, SegRefiner progressively refines the noisy masks in a conditional denoising manner.","To assess the effectiveness of SegRefiner, we conduct comprehensive experiments on various segmentation tasks, including semantic segmentation, instance segmentation, and dichotomous image segmentation.","The results demonstrate the superiority of our SegRefiner from multiple aspects.","Firstly, it consistently improves both the segmentation metrics and boundary metrics across different types of coarse masks.","Secondly, it outperforms previous model-agnostic refinement methods by a significant margin.","Lastly, it exhibits a strong capability to capture extremely fine details when refining high-resolution images.","The source code and trained models are available at https://github.com/MengyuWang826/SegRefiner."],"url":"http://arxiv.org/abs/2312.12425v1"}
{"created":"2023-12-19 18:50:10","title":"LASA: Instance Reconstruction from Real Scans using A Large-scale Aligned Shape Annotation Dataset","abstract":"Instance shape reconstruction from a 3D scene involves recovering the full geometries of multiple objects at the semantic instance level. Many methods leverage data-driven learning due to the intricacies of scene complexity and significant indoor occlusions. Training these methods often requires a large-scale, high-quality dataset with aligned and paired shape annotations with real-world scans. Existing datasets are either synthetic or misaligned, restricting the performance of data-driven methods on real data. To this end, we introduce LASA, a Large-scale Aligned Shape Annotation Dataset comprising 10,412 high-quality CAD annotations aligned with 920 real-world scene scans from ArkitScenes, created manually by professional artists. On this top, we propose a novel Diffusion-based Cross-Modal Shape Reconstruction (DisCo) method. It is empowered by a hybrid feature aggregation design to fuse multi-modal inputs and recover high-fidelity object geometries. Besides, we present an Occupancy-Guided 3D Object Detection (OccGOD) method and demonstrate that our shape annotations provide scene occupancy clues that can further improve 3D object detection. Supported by LASA, extensive experiments show that our methods achieve state-of-the-art performance in both instance-level scene reconstruction and 3D object detection tasks.","sentences":["Instance shape reconstruction from a 3D scene involves recovering the full geometries of multiple objects at the semantic instance level.","Many methods leverage data-driven learning due to the intricacies of scene complexity and significant indoor occlusions.","Training these methods often requires a large-scale, high-quality dataset with aligned and paired shape annotations with real-world scans.","Existing datasets are either synthetic or misaligned, restricting the performance of data-driven methods on real data.","To this end, we introduce LASA, a Large-scale Aligned Shape Annotation Dataset comprising 10,412 high-quality CAD annotations aligned with 920 real-world scene scans from ArkitScenes, created manually by professional artists.","On this top, we propose a novel Diffusion-based Cross-Modal Shape Reconstruction (DisCo) method.","It is empowered by a hybrid feature aggregation design to fuse multi-modal inputs and recover high-fidelity object geometries.","Besides, we present an Occupancy-Guided 3D Object Detection (OccGOD) method and demonstrate that our shape annotations provide scene occupancy clues that can further improve 3D object detection.","Supported by LASA, extensive experiments show that our methods achieve state-of-the-art performance in both instance-level scene reconstruction and 3D object detection tasks."],"url":"http://arxiv.org/abs/2312.12418v1"}
{"created":"2023-12-19 18:00:15","title":"Chasing Fairness in Graphs: A GNN Architecture Perspective","abstract":"There has been significant progress in improving the performance of graph neural networks (GNNs) through enhancements in graph data, model architecture design, and training strategies. For fairness in graphs, recent studies achieve fair representations and predictions through either graph data pre-processing (e.g., node feature masking, and topology rewiring) or fair training strategies (e.g., regularization, adversarial debiasing, and fair contrastive learning). How to achieve fairness in graphs from the model architecture perspective is less explored. More importantly, GNNs exhibit worse fairness performance compared to multilayer perception since their model architecture (i.e., neighbor aggregation) amplifies biases. To this end, we aim to achieve fairness via a new GNN architecture. We propose \\textsf{F}air \\textsf{M}essage \\textsf{P}assing (FMP) designed within a unified optimization framework for GNNs. Notably, FMP \\textit{explicitly} renders sensitive attribute usage in \\textit{forward propagation} for node classification task using cross-entropy loss without data pre-processing. In FMP, the aggregation is first adopted to utilize neighbors' information and then the bias mitigation step explicitly pushes demographic group node presentation centers together. In this way, FMP scheme can aggregate useful information from neighbors and mitigate bias to achieve better fairness and prediction tradeoff performance. Experiments on node classification tasks demonstrate that the proposed FMP outperforms several baselines in terms of fairness and accuracy on three real-world datasets. The code is available in {\\url{https://github.com/zhimengj0326/FMP}}.","sentences":["There has been significant progress in improving the performance of graph neural networks (GNNs) through enhancements in graph data, model architecture design, and training strategies.","For fairness in graphs, recent studies achieve fair representations and predictions through either graph data pre-processing (e.g., node feature masking, and topology rewiring) or fair training strategies (e.g., regularization, adversarial debiasing, and fair contrastive learning).","How to achieve fairness in graphs from the model architecture perspective is less explored.","More importantly, GNNs exhibit worse fairness performance compared to multilayer perception since their model architecture (i.e., neighbor aggregation) amplifies biases.","To this end, we aim to achieve fairness via a new GNN architecture.","We propose \\textsf{F}air \\textsf{M}essage \\textsf{P}assing (FMP) designed within a unified optimization framework for GNNs.","Notably, FMP \\textit{explicitly} renders sensitive attribute usage in \\textit{forward propagation} for node classification task using cross-entropy loss without data pre-processing.","In FMP, the aggregation is first adopted to utilize neighbors' information and then the bias mitigation step explicitly pushes demographic group node presentation centers together.","In this way, FMP scheme can aggregate useful information from neighbors and mitigate bias to achieve better fairness and prediction tradeoff performance.","Experiments on node classification tasks demonstrate that the proposed FMP outperforms several baselines in terms of fairness and accuracy on three real-world datasets.","The code is available in {\\url{https://github.com/zhimengj0326/FMP}}."],"url":"http://arxiv.org/abs/2312.12369v1"}
{"created":"2023-12-19 17:26:44","title":"SMC-NCA: Semantic-guided Multi-level Contrast for Semi-supervised Action Segmentation","abstract":"Semi-supervised action segmentation aims to perform frame-wise classification in long untrimmed videos, where only a fraction of videos in the training set have labels. Recent studies have shown the potential of contrastive learning in unsupervised representation learning using unlabelled data. However, learning the representation of each frame by unsupervised contrastive learning for action segmentation remains an open and challenging problem. In this paper, we propose a novel Semantic-guided Multi-level Contrast scheme with a Neighbourhood-Consistency-Aware unit (SMC-NCA) to extract strong frame-wise representations for semi-supervised action segmentation. Specifically, for representation learning, SMC is firstly used to explore intra- and inter-information variations in a unified and contrastive way, based on dynamic clustering process of the original input, encoded semantic and temporal features. Then, the NCA module, which is responsible for enforcing spatial consistency between neighbourhoods centered at different frames to alleviate over-segmentation issues, works alongside SMC for semi-supervised learning. Our SMC outperforms the other state-of-the-art methods on three benchmarks, offering improvements of up to 17.8% and 12.6% in terms of edit distance and accuracy, respectively. Additionally, the NCA unit results in significant better segmentation performance against the others in the presence of only 5% labelled videos. We also demonstrate the effectiveness of the proposed method on our Parkinson's Disease Mouse Behaviour (PDMB) dataset. The code and datasets will be made publicly available.","sentences":["Semi-supervised action segmentation aims to perform frame-wise classification in long untrimmed videos, where only a fraction of videos in the training set have labels.","Recent studies have shown the potential of contrastive learning in unsupervised representation learning using unlabelled data.","However, learning the representation of each frame by unsupervised contrastive learning for action segmentation remains an open and challenging problem.","In this paper, we propose a novel Semantic-guided Multi-level Contrast scheme with a Neighbourhood-Consistency-Aware unit (SMC-NCA) to extract strong frame-wise representations for semi-supervised action segmentation.","Specifically, for representation learning, SMC is firstly used to explore intra- and inter-information variations in a unified and contrastive way, based on dynamic clustering process of the original input, encoded semantic and temporal features.","Then, the NCA module, which is responsible for enforcing spatial consistency between neighbourhoods centered at different frames to alleviate over-segmentation issues, works alongside SMC for semi-supervised learning.","Our SMC outperforms the other state-of-the-art methods on three benchmarks, offering improvements of up to 17.8% and 12.6% in terms of edit distance and accuracy, respectively.","Additionally, the NCA unit results in significant better segmentation performance against the others in the presence of only 5% labelled videos.","We also demonstrate the effectiveness of the proposed method on our Parkinson's Disease Mouse Behaviour (PDMB) dataset.","The code and datasets will be made publicly available."],"url":"http://arxiv.org/abs/2312.12347v1"}
{"created":"2023-12-19 17:16:43","title":"Avoiding Data Contamination in Language Model Evaluation: Dynamic Test Construction with Latest Materials","abstract":"Data contamination in evaluation is getting increasingly prevalent with the emerge of language models pre-trained on super large, automatically-crawled corpora. This problem leads to significant challenges in accurate assessment of model capabilities and generalisations. In this paper, we propose LatestEval, an automatic method leverages the most recent texts to create uncontaminated reading comprehension evaluations. LatestEval avoids data contamination by only using texts published within a recent time window, ensuring no overlap with the training corpora of pre-trained language models. We develop LatestEval automated pipeline to 1) gather latest texts; 2) identify key information, and 3) construct questions targeting the information while removing the existing answers from the context. This encourages models to infer the answers themselves based on the remaining context, rather than just copy-paste. Our experiments demonstrate that language models exhibit negligible memorisation behaviours on LatestEval as opposed to previous benchmarks, suggesting a significantly reduced risk of data contamination and leading to a more robust evaluation. Data and code are publicly available at: https://github.com/liyucheng09/LatestEval.","sentences":["Data contamination in evaluation is getting increasingly prevalent with the emerge of language models pre-trained on super large, automatically-crawled corpora.","This problem leads to significant challenges in accurate assessment of model capabilities and generalisations.","In this paper, we propose LatestEval, an automatic method leverages the most recent texts to create uncontaminated reading comprehension evaluations.","LatestEval avoids data contamination by only using texts published within a recent time window, ensuring no overlap with the training corpora of pre-trained language models.","We develop LatestEval automated pipeline to 1) gather latest texts; 2) identify key information, and 3) construct questions targeting the information while removing the existing answers from the context.","This encourages models to infer the answers themselves based on the remaining context, rather than just copy-paste.","Our experiments demonstrate that language models exhibit negligible memorisation behaviours on LatestEval as opposed to previous benchmarks, suggesting a significantly reduced risk of data contamination and leading to a more robust evaluation.","Data and code are publicly available at: https://github.com/liyucheng09/LatestEval."],"url":"http://arxiv.org/abs/2312.12343v1"}
{"created":"2023-12-19 17:08:43","title":"Smart Connected Farms and Networked Farmers to Tackle Climate Challenges Impacting Agricultural Production","abstract":"To meet the grand challenges of agricultural production including climate change impacts on crop production, a tight integration of social science, technology and agriculture experts including farmers are needed. There are rapid advances in information and communication technology, precision agriculture and data analytics, which are creating a fertile field for the creation of smart connected farms (SCF) and networked farmers. A network and coordinated farmer network provides unique advantages to farmers to enhance farm production and profitability, while tackling adverse climate events. The aim of this article is to provide a comprehensive overview of the state of the art in SCF including the advances in engineering, computer sciences, data sciences, social sciences and economics including data privacy, sharing and technology adoption.","sentences":["To meet the grand challenges of agricultural production including climate change impacts on crop production, a tight integration of social science, technology and agriculture experts including farmers are needed.","There are rapid advances in information and communication technology, precision agriculture and data analytics, which are creating a fertile field for the creation of smart connected farms (SCF) and networked farmers.","A network and coordinated farmer network provides unique advantages to farmers to enhance farm production and profitability, while tackling adverse climate events.","The aim of this article is to provide a comprehensive overview of the state of the art in SCF including the advances in engineering, computer sciences, data sciences, social sciences and economics including data privacy, sharing and technology adoption."],"url":"http://arxiv.org/abs/2312.12338v1"}
{"created":"2023-12-19 17:01:58","title":"PowMix: A Versatile Regularizer for Multimodal Sentiment Analysis","abstract":"Multimodal sentiment analysis (MSA) leverages heterogeneous data sources to interpret the complex nature of human sentiments. Despite significant progress in multimodal architecture design, the field lacks comprehensive regularization methods. This paper introduces PowMix, a versatile embedding space regularizer that builds upon the strengths of unimodal mixing-based regularization approaches and introduces novel algorithmic components that are specifically tailored to multimodal tasks. PowMix is integrated before the fusion stage of multimodal architectures and facilitates intra-modal mixing, such as mixing text with text, to act as a regularizer. PowMix consists of five components: 1) a varying number of generated mixed examples, 2) mixing factor reweighting, 3) anisotropic mixing, 4) dynamic mixing, and 5) cross-modal label mixing. Extensive experimentation across benchmark MSA datasets and a broad spectrum of diverse architectural designs demonstrate the efficacy of PowMix, as evidenced by consistent performance improvements over baselines and existing mixing methods. An in-depth ablation study highlights the critical contribution of each PowMix component and how they synergistically enhance performance. Furthermore, algorithmic analysis demonstrates how PowMix behaves in different scenarios, particularly comparing early versus late fusion architectures. Notably, PowMix enhances overall performance without sacrificing model robustness or magnifying text dominance. It also retains its strong performance in situations of limited data. Our findings position PowMix as a promising versatile regularization strategy for MSA. Code will be made available.","sentences":["Multimodal sentiment analysis (MSA) leverages heterogeneous data sources to interpret the complex nature of human sentiments.","Despite significant progress in multimodal architecture design, the field lacks comprehensive regularization methods.","This paper introduces PowMix, a versatile embedding space regularizer that builds upon the strengths of unimodal mixing-based regularization approaches and introduces novel algorithmic components that are specifically tailored to multimodal tasks.","PowMix is integrated before the fusion stage of multimodal architectures and facilitates intra-modal mixing, such as mixing text with text, to act as a regularizer.","PowMix consists of five components: 1) a varying number of generated mixed examples, 2) mixing factor reweighting, 3) anisotropic mixing, 4) dynamic mixing, and 5) cross-modal label mixing.","Extensive experimentation across benchmark MSA datasets and a broad spectrum of diverse architectural designs demonstrate the efficacy of PowMix, as evidenced by consistent performance improvements over baselines and existing mixing methods.","An in-depth ablation study highlights the critical contribution of each PowMix component and how they synergistically enhance performance.","Furthermore, algorithmic analysis demonstrates how PowMix behaves in different scenarios, particularly comparing early versus late fusion architectures.","Notably, PowMix enhances overall performance without sacrificing model robustness or magnifying text dominance.","It also retains its strong performance in situations of limited data.","Our findings position PowMix as a promising versatile regularization strategy for MSA. Code will be made available."],"url":"http://arxiv.org/abs/2312.12334v1"}
{"created":"2023-12-19 16:47:12","title":"Bypassing the Safety Training of Open-Source LLMs with Priming Attacks","abstract":"With the recent surge in popularity of LLMs has come an ever-increasing need for LLM safety training. In this paper, we show that SOTA open-source LLMs are vulnerable to simple, optimization-free attacks we refer to as $\\textit{priming attacks}$, which are easy to execute and effectively bypass alignment from safety training. Our proposed attack improves the Attack Success Rate on Harmful Behaviors, as measured by Llama Guard, by up to $3.3\\times$ compared to baselines. Source code and data are available at https://github.com/uiuc-focal-lab/llm-priming-attacks .","sentences":["With the recent surge in popularity of LLMs has come an ever-increasing need for LLM safety training.","In this paper, we show that SOTA open-source LLMs are vulnerable to simple, optimization-free attacks we refer to as $\\textit{priming attacks}$, which are easy to execute and effectively bypass alignment from safety training.","Our proposed attack improves the Attack Success Rate on Harmful Behaviors, as measured by Llama Guard, by up to $3.3\\times$ compared to baselines.","Source code and data are available at https://github.com/uiuc-focal-lab/llm-priming-attacks ."],"url":"http://arxiv.org/abs/2312.12321v1"}
{"created":"2023-12-19 16:43:17","title":"An Alternate View on Optimal Filtering in an RKHS","abstract":"Kernel Adaptive Filtering (KAF) are mathematically principled methods which search for a function in a Reproducing Kernel Hilbert Space. While they work well for tasks such as time series prediction and system identification they are plagued by a linear relationship between number of training samples and model size, hampering their use on the very large data sets common in today's data saturated world. Previous methods try to solve this issue by sparsification. We describe a novel view of optimal filtering which may provide a route towards solutions in a RKHS which do not necessarily have this linear growth in model size. We do this by defining a RKHS in which the time structure of a stochastic process is still present. Using correntropy [11], an extension of the idea of a covariance function, we create a time based functional which describes some potentially nonlinear desired mapping function. This form of a solution may provide a fruitful line of research for creating more efficient representations of functionals in a RKHS, while theoretically providing computational complexity in the test set similar to Wiener solution.","sentences":["Kernel Adaptive Filtering (KAF) are mathematically principled methods which search for a function in a Reproducing Kernel Hilbert Space.","While they work well for tasks such as time series prediction and system identification they are plagued by a linear relationship between number of training samples and model size, hampering their use on the very large data sets common in today's data saturated world.","Previous methods try to solve this issue by sparsification.","We describe a novel view of optimal filtering which may provide a route towards solutions in a RKHS which do not necessarily have this linear growth in model size.","We do this by defining a RKHS in which the time structure of a stochastic process is still present.","Using correntropy","[11], an extension of the idea of a covariance function, we create a time based functional which describes some potentially nonlinear desired mapping function.","This form of a solution may provide a fruitful line of research for creating more efficient representations of functionals in a RKHS, while theoretically providing computational complexity in the test set similar to Wiener solution."],"url":"http://arxiv.org/abs/2312.12318v1"}
{"created":"2023-12-19 16:21:51","title":"Peer Neighborhood Mechanisms: A Framework for Mechanism Generalization","abstract":"Peer prediction incentive mechanisms for crowdsourcing are generally limited to eliciting samples from categorical distributions. Prior work on extending peer prediction to arbitrary distributions has largely relied on assumptions on the structures of the distributions or known properties of the data providers. We introduce a novel class of incentive mechanisms that extend peer prediction mechanisms to arbitrary distributions by replacing the notion of an exact match with a concept of neighborhood matching. We present conditions on the belief updates of the data providers that guarantee incentive-compatibility for rational data providers, and admit a broad class of possible reasonable updates.","sentences":["Peer prediction incentive mechanisms for crowdsourcing are generally limited to eliciting samples from categorical distributions.","Prior work on extending peer prediction to arbitrary distributions has largely relied on assumptions on the structures of the distributions or known properties of the data providers.","We introduce a novel class of incentive mechanisms that extend peer prediction mechanisms to arbitrary distributions by replacing the notion of an exact match with a concept of neighborhood matching.","We present conditions on the belief updates of the data providers that guarantee incentive-compatibility for rational data providers, and admit a broad class of possible reasonable updates."],"url":"http://arxiv.org/abs/2312.12303v1"}
{"created":"2023-12-19 15:57:37","title":"Prompt-based Domain Discrimination for Multi-source Time Series Domain Adaptation","abstract":"Time series domain adaptation stands as a pivotal and intricate challenge with diverse applications, including but not limited to human activity recognition, sleep stage classification, and machine fault diagnosis. Despite the numerous domain adaptation techniques proposed to tackle this complex problem, their primary focus has been on the common representations of time series data. This concentration might inadvertently lead to the oversight of valuable domain-specific information originating from different source domains. To bridge this gap, we introduce POND, a novel prompt-based deep learning model designed explicitly for multi-source time series domain adaptation. POND is tailored to address significant challenges, notably: 1) The unavailability of a quantitative relationship between meta-data information and time series distributions, and 2) The dearth of exploration into extracting domain-specific meta-data information. In this paper, we present an instance-level prompt generator and a fidelity loss mechanism to facilitate the faithful learning of meta-data information. Additionally, we propose a domain discrimination technique to discern domain-specific meta-data information from multiple source domains. Our approach involves a simple yet effective meta-learning algorithm to optimize the objective efficiently. Furthermore, we augment the model's performance by incorporating the Mixture of Expert (MoE) technique. The efficacy and robustness of our proposed POND model are extensively validated through experiments across 50 scenarios encompassing five datasets, which demonstrates that our proposed POND model outperforms the state-of-the-art methods by up to $66\\%$ on the F1-score.","sentences":["Time series domain adaptation stands as a pivotal and intricate challenge with diverse applications, including but not limited to human activity recognition, sleep stage classification, and machine fault diagnosis.","Despite the numerous domain adaptation techniques proposed to tackle this complex problem, their primary focus has been on the common representations of time series data.","This concentration might inadvertently lead to the oversight of valuable domain-specific information originating from different source domains.","To bridge this gap, we introduce POND, a novel prompt-based deep learning model designed explicitly for multi-source time series domain adaptation.","POND is tailored to address significant challenges, notably: 1) The unavailability of a quantitative relationship between meta-data information and time series distributions, and 2)","The dearth of exploration into extracting domain-specific meta-data information.","In this paper, we present an instance-level prompt generator and a fidelity loss mechanism to facilitate the faithful learning of meta-data information.","Additionally, we propose a domain discrimination technique to discern domain-specific meta-data information from multiple source domains.","Our approach involves a simple yet effective meta-learning algorithm to optimize the objective efficiently.","Furthermore, we augment the model's performance by incorporating the Mixture of Expert (MoE) technique.","The efficacy and robustness of our proposed POND model are extensively validated through experiments across 50 scenarios encompassing five datasets, which demonstrates that our proposed POND model outperforms the state-of-the-art methods by up to $66\\%$ on the F1-score."],"url":"http://arxiv.org/abs/2312.12276v1"}
{"created":"2023-12-19 15:56:30","title":"Emergence of In-Context Reinforcement Learning from Noise Distillation","abstract":"In-Context Reinforcement Learning is an emerging field with great potential for advancing Artificial Intelligence. Its core capability lies in generalizing to unseen tasks through interaction with the environment. To master these capabilities, an agent must be trained on specifically curated data that includes a policy improvement that an algorithm seeks to extract and then apply in context in the environment. However, for numerous tasks, training RL agents may be unfeasible, while obtaining human demonstrations can be relatively easy. Additionally, it is rare to be given the optimal policy, typically, only suboptimal demonstrations are available. We propose $AD^{\\epsilon}$, a method that leverages demonstrations without policy improvement and enables multi-task in-context learning in the presence of a suboptimal demonstrator. This is achieved by artificially creating a history of incremental improvement, wherein noise is systematically introduced into the demonstrator's policy. Consequently, each successive transition illustrates a marginally better trajectory than the previous one. Our approach was tested on the Dark Room and Dark Key-to-Door environments, resulting in over a $\\textbf{2}$x improvement compared to the best available policy in the data.","sentences":["In-Context Reinforcement Learning is an emerging field with great potential for advancing Artificial Intelligence.","Its core capability lies in generalizing to unseen tasks through interaction with the environment.","To master these capabilities, an agent must be trained on specifically curated data that includes a policy improvement that an algorithm seeks to extract and then apply in context in the environment.","However, for numerous tasks, training RL agents may be unfeasible, while obtaining human demonstrations can be relatively easy.","Additionally, it is rare to be given the optimal policy, typically, only suboptimal demonstrations are available.","We propose $AD^{\\epsilon}$, a method that leverages demonstrations without policy improvement and enables multi-task in-context learning in the presence of a suboptimal demonstrator.","This is achieved by artificially creating a history of incremental improvement, wherein noise is systematically introduced into the demonstrator's policy.","Consequently, each successive transition illustrates a marginally better trajectory than the previous one.","Our approach was tested on the Dark Room and Dark Key-to-Door environments, resulting in over a $\\textbf{2}$x improvement compared to the best available policy in the data."],"url":"http://arxiv.org/abs/2312.12275v1"}
{"created":"2023-12-19 15:46:47","title":"FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy Labels","abstract":"Federated learning with noisy labels (F-LNL) aims at seeking an optimal server model via collaborative distributed learning by aggregating multiple client models trained with local noisy or clean samples. On the basis of a federated learning framework, recent advances primarily adopt label noise filtering to separate clean samples from noisy ones on each client, thereby mitigating the negative impact of label noise. However, these prior methods do not learn noise filters by exploiting knowledge across all clients, leading to sub-optimal and inferior noise filtering performance and thus damaging training stability. In this paper, we present FedDiv to tackle the challenges of F-LNL. Specifically, we propose a global noise filter called Federated Noise Filter for effectively identifying samples with noisy labels on every client, thereby raising stability during local training sessions. Without sacrificing data privacy, this is achieved by modeling the global distribution of label noise across all clients. Then, in an effort to make the global model achieve higher performance, we introduce a Predictive Consistency based Sampler to identify more credible local data for local model training, thus preventing noise memorization and further boosting the training stability. Extensive experiments on CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \\texttt{FedDiv} achieves superior performance over state-of-the-art F-LNL methods under different label noise settings for both IID and non-IID data partitions. Source code is publicly available at https://github.com/lijichang/FLNL-FedDiv.","sentences":["Federated learning with noisy labels (F-LNL) aims at seeking an optimal server model via collaborative distributed learning by aggregating multiple client models trained with local noisy or clean samples.","On the basis of a federated learning framework, recent advances primarily adopt label noise filtering to separate clean samples from noisy ones on each client, thereby mitigating the negative impact of label noise.","However, these prior methods do not learn noise filters by exploiting knowledge across all clients, leading to sub-optimal and inferior noise filtering performance and thus damaging training stability.","In this paper, we present FedDiv to tackle the challenges of F-LNL.","Specifically, we propose a global noise filter called Federated Noise Filter for effectively identifying samples with noisy labels on every client, thereby raising stability during local training sessions.","Without sacrificing data privacy, this is achieved by modeling the global distribution of label noise across all clients.","Then, in an effort to make the global model achieve higher performance, we introduce a Predictive Consistency based Sampler to identify more credible local data for local model training, thus preventing noise memorization and further boosting the training stability.","Extensive experiments on CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \\texttt{FedDiv} achieves superior performance over state-of-the-art F-LNL methods under different label noise settings for both IID and non-IID data partitions.","Source code is publicly available at https://github.com/lijichang/FLNL-FedDiv."],"url":"http://arxiv.org/abs/2312.12263v1"}
{"created":"2023-12-19 15:39:09","title":"TaskFlex Solver for Multi-Agent Pursuit via Automatic Curriculum Learning","abstract":"This paper addresses the problem of multi-agent pursuit, where slow pursuers cooperate to capture fast evaders in a confined environment with obstacles. Existing heuristic algorithms often lack expressive coordination strategies and are highly sensitive to task conditions, requiring extensive hyperparameter tuning. In contrast, reinforcement learning (RL) has been applied to this problem and is capable of obtaining cooperative pursuit strategies. However, RL-based methods face challenges in training for complex scenarios due to the vast amount of training data and limited adaptability to varying task conditions, such as different scene sizes, varying numbers and speeds of obstacles, and flexible speed ratios of the evader to the pursuer. In this work, we combine RL and curriculum learning to introduce a flexible solver for multiagent pursuit problems, named TaskFlex Solver (TFS), which is capable of solving multi-agent pursuit problems with diverse and dynamically changing task conditions in both 2-dimensional and 3-dimensional scenarios. TFS utilizes a curriculum learning method that constructs task distributions based on training progress, enhancing training efficiency and final performance. Our algorithm consists of two main components: the Task Evaluator, which evaluates task success rates and selects tasks of moderate difficulty to maintain a curriculum archive, and the Task Sampler, which constructs training distributions by sampling tasks from the curriculum archive to maximize policy improvement. Experiments show that TFS produces much stronger performance than baselines and achieves close to 100% capture rates in both 2-dimensional and 3-dimensional multi-agent pursuit problems with diverse and dynamically changing scenes. The project website is at https://sites.google.com/view/tfs-2023.","sentences":["This paper addresses the problem of multi-agent pursuit, where slow pursuers cooperate to capture fast evaders in a confined environment with obstacles.","Existing heuristic algorithms often lack expressive coordination strategies and are highly sensitive to task conditions, requiring extensive hyperparameter tuning.","In contrast, reinforcement learning (RL) has been applied to this problem and is capable of obtaining cooperative pursuit strategies.","However, RL-based methods face challenges in training for complex scenarios due to the vast amount of training data and limited adaptability to varying task conditions, such as different scene sizes, varying numbers and speeds of obstacles, and flexible speed ratios of the evader to the pursuer.","In this work, we combine RL and curriculum learning to introduce a flexible solver for multiagent pursuit problems, named TaskFlex Solver (TFS), which is capable of solving multi-agent pursuit problems with diverse and dynamically changing task conditions in both 2-dimensional and 3-dimensional scenarios.","TFS utilizes a curriculum learning method that constructs task distributions based on training progress, enhancing training efficiency and final performance.","Our algorithm consists of two main components: the Task Evaluator, which evaluates task success rates and selects tasks of moderate difficulty to maintain a curriculum archive, and the Task Sampler, which constructs training distributions by sampling tasks from the curriculum archive to maximize policy improvement.","Experiments show that TFS produces much stronger performance than baselines and achieves close to 100% capture rates in both 2-dimensional and 3-dimensional multi-agent pursuit problems with diverse and dynamically changing scenes.","The project website is at https://sites.google.com/view/tfs-2023."],"url":"http://arxiv.org/abs/2312.12255v1"}
{"created":"2023-12-19 15:37:27","title":"Geo-located Aspect Based Sentiment Analysis (ABSA) for Crowdsourced Evaluation of Urban Environments","abstract":"Sentiment analysis methods are rapidly being adopted by the field of Urban Design and Planning, for the crowdsourced evaluation of urban environments. However, most models used within this domain are able to identify positive or negative sentiment associated with a textual appraisal as a whole, without inferring information about specific urban aspects contained within it, or the sentiment associated with them. While Aspect Based Sentiment Analysis (ABSA) is becoming increasingly popular, most existing ABSA models are trained on non-urban themes such as restaurants, electronics, consumer goods and the like. This body of research develops an ABSA model capable of extracting urban aspects contained within geo-located textual urban appraisals, along with corresponding aspect sentiment classification. We annotate a dataset of 2500 crowdsourced reviews of public parks, and train a Bidirectional Encoder Representations from Transformers (BERT) model with Local Context Focus (LCF) on this data. Our model achieves significant improvement in prediction accuracy on urban reviews, for both Aspect Term Extraction (ATE) and Aspect Sentiment Classification (ASC) tasks. For demonstrative analysis, positive and negative urban aspects across Boston are spatially visualized. We hope that this model is useful for designers and planners for fine-grained urban sentiment evaluation.","sentences":["Sentiment analysis methods are rapidly being adopted by the field of Urban Design and Planning, for the crowdsourced evaluation of urban environments.","However, most models used within this domain are able to identify positive or negative sentiment associated with a textual appraisal as a whole, without inferring information about specific urban aspects contained within it, or the sentiment associated with them.","While Aspect Based Sentiment Analysis (ABSA) is becoming increasingly popular, most existing ABSA models are trained on non-urban themes such as restaurants, electronics, consumer goods and the like.","This body of research develops an ABSA model capable of extracting urban aspects contained within geo-located textual urban appraisals, along with corresponding aspect sentiment classification.","We annotate a dataset of 2500 crowdsourced reviews of public parks, and train a Bidirectional Encoder Representations from Transformers (BERT) model with Local Context Focus (LCF) on this data.","Our model achieves significant improvement in prediction accuracy on urban reviews, for both Aspect Term Extraction (ATE) and Aspect Sentiment Classification (ASC) tasks.","For demonstrative analysis, positive and negative urban aspects across Boston are spatially visualized.","We hope that this model is useful for designers and planners for fine-grained urban sentiment evaluation."],"url":"http://arxiv.org/abs/2312.12253v1"}
{"created":"2023-12-19 15:33:57","title":"ST(OR)2: Spatio-Temporal Object Level Reasoning for Activity Recognition in the Operating Room","abstract":"Surgical robotics holds much promise for improving patient safety and clinician experience in the Operating Room (OR). However, it also comes with new challenges, requiring strong team coordination and effective OR management. Automatic detection of surgical activities is a key requirement for developing AI-based intelligent tools to tackle these challenges. The current state-of-the-art surgical activity recognition methods however operate on image-based representations and depend on large-scale labeled datasets whose collection is time-consuming and resource-expensive. This work proposes a new sample-efficient and object-based approach for surgical activity recognition in the OR. Our method focuses on the geometric arrangements between clinicians and surgical devices, thus utilizing the significant object interaction dynamics in the OR. We conduct experiments in a low-data regime study for long video activity recognition. We also benchmark our method againstother object-centric approaches on clip-level action classification and show superior performance.","sentences":["Surgical robotics holds much promise for improving patient safety and clinician experience in the Operating Room (OR).","However, it also comes with new challenges, requiring strong team coordination and effective OR management.","Automatic detection of surgical activities is a key requirement for developing AI-based intelligent tools to tackle these challenges.","The current state-of-the-art surgical activity recognition methods however operate on image-based representations and depend on large-scale labeled datasets whose collection is time-consuming and resource-expensive.","This work proposes a new sample-efficient and object-based approach for surgical activity recognition in the OR.","Our method focuses on the geometric arrangements between clinicians and surgical devices, thus utilizing the significant object interaction dynamics in the OR.","We conduct experiments in a low-data regime study for long video activity recognition.","We also benchmark our method againstother object-centric approaches on clip-level action classification and show superior performance."],"url":"http://arxiv.org/abs/2312.12250v1"}
{"created":"2023-12-19 15:30:10","title":"MDD-UNet: Domain Adaptation for Medical Image Segmentation with Theoretical Guarantees, a Proof of Concept","abstract":"The current state-of-the art techniques for image segmentation are often based on U-Net architectures, a U-shaped encoder-decoder networks with skip connections. Despite the powerful performance, the architecture often does not perform well when used on data which has different characteristics than the data it was trained on. Many techniques for improving performance in the presence of domain shift have been developed, however typically only have loose connections to the theory of domain adaption. In this work, we propose an unsupervised domain adaptation framework for U-Nets with theoretical guarantees based on the Margin Disparity Discrepancy [1] called the MDD-UNet. We evaluate the proposed technique on the task of hippocampus segmentation, and find that the MDD-UNet is able to learn features which are domain-invariant with no knowledge about the labels in the target domain. The MDD-UNet improves performance over the standard U-Net on 11 out of 12 combinations of datasets. This work serves as a proof of concept by demonstrating an improvement on the U-Net in it's standard form without modern enhancements, which opens up a new avenue of studying domain adaptation for models with very large hypothesis spaces from both methodological and practical perspectives. Code is available at https://github.com/asbjrnmunk/mdd-unet.","sentences":["The current state-of-the art techniques for image segmentation are often based on U-Net architectures, a U-shaped encoder-decoder networks with skip connections.","Despite the powerful performance, the architecture often does not perform well when used on data which has different characteristics than the data it was trained on.","Many techniques for improving performance in the presence of domain shift have been developed, however typically only have loose connections to the theory of domain adaption.","In this work, we propose an unsupervised domain adaptation framework for U-Nets with theoretical guarantees based on the Margin Disparity Discrepancy","[1] called the MDD-UNet.","We evaluate the proposed technique on the task of hippocampus segmentation, and find that the MDD-UNet is able to learn features which are domain-invariant with no knowledge about the labels in the target domain.","The MDD-UNet improves performance over the standard U-Net on 11 out of 12 combinations of datasets.","This work serves as a proof of concept by demonstrating an improvement on the U-Net in it's standard form without modern enhancements, which opens up a new avenue of studying domain adaptation for models with very large hypothesis spaces from both methodological and practical perspectives.","Code is available at https://github.com/asbjrnmunk/mdd-unet."],"url":"http://arxiv.org/abs/2312.12246v1"}
{"created":"2023-12-19 15:26:47","title":"Distributed Binary Labeling Problems in High-Degree Graphs","abstract":"Balliu et al. (DISC 2020) classified the hardness of solving binary labeling problems with distributed graph algorithms; in these problems the task is to select a subset of edges in a $2$-colored tree in which white nodes of degree $d$ and black nodes of degree $\\delta$ have constraints on the number of selected incident edges. They showed that the deterministic round complexity of any such problem is $O_{d,\\delta}(1)$, $\\Theta_{d,\\delta}(\\log n)$, or $\\Theta_{d,\\delta}(n)$, or the problem is unsolvable. However, their classification only addresses complexity as a function of $n$; here $O_{d,\\delta}$ hides constants that may depend on parameters $d$ and $\\delta$.   In this work we study the complexity of binary labeling problems as a function of all three parameters: $n$, $d$, and $\\delta$. To this end, we introduce the family of structurally simple problems, which includes, among others, all binary labeling problems in which cardinality constraints can be represented with a context-free grammar. We classify possible complexities of structurally simple problems. As our main result, we show that if the complexity of a problem falls in the broad class of $\\Theta_{d,\\delta}(\\log n)$, then the complexity for each $d$ and $\\delta$ is always either $\\Theta(\\log_d n)$, $\\Theta(\\log_\\delta n)$, or $\\Theta(\\log n)$.   To prove our upper bounds, we introduce a new, more aggressive version of the rake-and-compress technique that benefits from high-degree nodes.","sentences":["Balliu et al. (DISC 2020) classified the hardness of solving binary labeling problems with distributed graph algorithms; in these problems the task is to select a subset of edges in a $2$-colored tree in which white nodes of degree $d$ and black nodes of degree $\\delta$ have constraints on the number of selected incident edges.","They showed that the deterministic round complexity of any such problem is $O_{d,\\delta}(1)$, $\\Theta_{d,\\delta}(\\log n)$, or $\\Theta_{d,\\delta}(n)$, or the problem is unsolvable.","However, their classification only addresses complexity as a function of $n$; here $O_{d,\\delta}$ hides constants that may depend on parameters $d$ and $\\delta$.   ","In this work we study the complexity of binary labeling problems as a function of all three parameters: $n$, $d$, and $\\delta$.","To this end, we introduce the family of structurally simple problems, which includes, among others, all binary labeling problems in which cardinality constraints can be represented with a context-free grammar.","We classify possible complexities of structurally simple problems.","As our main result, we show that if the complexity of a problem falls in the broad class of $\\Theta_{d,\\delta}(\\log n)$, then the complexity for each $d$ and $\\delta$ is always either $\\Theta(\\log_d n)$, $\\Theta(\\log_\\delta n)$, or $\\Theta(\\log n)$.   To prove our upper bounds, we introduce a new, more aggressive version of the rake-and-compress technique that benefits from high-degree nodes."],"url":"http://arxiv.org/abs/2312.12243v1"}
{"created":"2023-12-19 15:22:37","title":"Roll With the Punches: Expansion and Shrinkage of Soft Label Selection for Semi-supervised Fine-Grained Learning","abstract":"While semi-supervised learning (SSL) has yielded promising results, the more realistic SSL scenario remains to be explored, in which the unlabeled data exhibits extremely high recognition difficulty, e.g., fine-grained visual classification in the context of SSL (SS-FGVC). The increased recognition difficulty on fine-grained unlabeled data spells disaster for pseudo-labeling accuracy, resulting in poor performance of the SSL model. To tackle this challenge, we propose Soft Label Selection with Confidence-Aware Clustering based on Class Transition Tracking (SoC) by reconstructing the pseudo-label selection process by jointly optimizing Expansion Objective and Shrinkage Objective, which is based on a soft label manner. Respectively, the former objective encourages soft labels to absorb more candidate classes to ensure the attendance of ground-truth class, while the latter encourages soft labels to reject more noisy classes, which is theoretically proved to be equivalent to entropy minimization. In comparisons with various state-of-the-art methods, our approach demonstrates its superior performance in SS-FGVC. Checkpoints and source code are available at https://github.com/NJUyued/SoC4SS-FGVC.","sentences":["While semi-supervised learning (SSL) has yielded promising results, the more realistic SSL scenario remains to be explored, in which the unlabeled data exhibits extremely high recognition difficulty, e.g., fine-grained visual classification in the context of SSL (SS-FGVC).","The increased recognition difficulty on fine-grained unlabeled data spells disaster for pseudo-labeling accuracy, resulting in poor performance of the SSL model.","To tackle this challenge, we propose Soft Label Selection with Confidence-Aware Clustering based on Class Transition Tracking (SoC) by reconstructing the pseudo-label selection process by jointly optimizing Expansion Objective and Shrinkage Objective, which is based on a soft label manner.","Respectively, the former objective encourages soft labels to absorb more candidate classes to ensure the attendance of ground-truth class, while the latter encourages soft labels to reject more noisy classes, which is theoretically proved to be equivalent to entropy minimization.","In comparisons with various state-of-the-art methods, our approach demonstrates its superior performance in SS-FGVC.","Checkpoints and source code are available at https://github.com/NJUyued/SoC4SS-FGVC."],"url":"http://arxiv.org/abs/2312.12237v1"}
{"created":"2023-12-19 15:20:27","title":"Generalization Analysis of Machine Learning Algorithms via the Worst-Case Data-Generating Probability Measure","abstract":"In this paper, the worst-case probability measure over the data is introduced as a tool for characterizing the generalization capabilities of machine learning algorithms. More specifically, the worst-case probability measure is a Gibbs probability measure and the unique solution to the maximization of the expected loss under a relative entropy constraint with respect to a reference probability measure. Fundamental generalization metrics, such as the sensitivity of the expected loss, the sensitivity of the empirical risk, and the generalization gap are shown to have closed-form expressions involving the worst-case data-generating probability measure. Existing results for the Gibbs algorithm, such as characterizing the generalization gap as a sum of mutual information and lautum information, up to a constant factor, are recovered. A novel parallel is established between the worst-case data-generating probability measure and the Gibbs algorithm. Specifically, the Gibbs probability measure is identified as a fundamental commonality of the model space and the data space for machine learning algorithms.","sentences":["In this paper, the worst-case probability measure over the data is introduced as a tool for characterizing the generalization capabilities of machine learning algorithms.","More specifically, the worst-case probability measure is a Gibbs probability measure and the unique solution to the maximization of the expected loss under a relative entropy constraint with respect to a reference probability measure.","Fundamental generalization metrics, such as the sensitivity of the expected loss, the sensitivity of the empirical risk, and the generalization gap are shown to have closed-form expressions involving the worst-case data-generating probability measure.","Existing results for the Gibbs algorithm, such as characterizing the generalization gap as a sum of mutual information and lautum information, up to a constant factor, are recovered.","A novel parallel is established between the worst-case data-generating probability measure and the Gibbs algorithm.","Specifically, the Gibbs probability measure is identified as a fundamental commonality of the model space and the data space for machine learning algorithms."],"url":"http://arxiv.org/abs/2312.12236v1"}
{"created":"2023-12-19 15:13:08","title":"HuTuMotion: Human-Tuned Navigation of Latent Motion Diffusion Models with Minimal Feedback","abstract":"We introduce HuTuMotion, an innovative approach for generating natural human motions that navigates latent motion diffusion models by leveraging few-shot human feedback. Unlike existing approaches that sample latent variables from a standard normal prior distribution, our method adapts the prior distribution to better suit the characteristics of the data, as indicated by human feedback, thus enhancing the quality of motion generation. Furthermore, our findings reveal that utilizing few-shot feedback can yield performance levels on par with those attained through extensive human feedback. This discovery emphasizes the potential and efficiency of incorporating few-shot human-guided optimization within latent diffusion models for personalized and style-aware human motion generation applications. The experimental results show the significantly superior performance of our method over existing state-of-the-art approaches.","sentences":["We introduce HuTuMotion, an innovative approach for generating natural human motions that navigates latent motion diffusion models by leveraging few-shot human feedback.","Unlike existing approaches that sample latent variables from a standard normal prior distribution, our method adapts the prior distribution to better suit the characteristics of the data, as indicated by human feedback, thus enhancing the quality of motion generation.","Furthermore, our findings reveal that utilizing few-shot feedback can yield performance levels on par with those attained through extensive human feedback.","This discovery emphasizes the potential and efficiency of incorporating few-shot human-guided optimization within latent diffusion models for personalized and style-aware human motion generation applications.","The experimental results show the significantly superior performance of our method over existing state-of-the-art approaches."],"url":"http://arxiv.org/abs/2312.12227v1"}
{"created":"2023-12-19 15:11:46","title":"Self-Supervised Detection of Perfect and Partial Input-Dependent Symmetries","abstract":"Group equivariance ensures consistent responses to group transformations of the input, leading to more robust models and enhanced generalization capabilities. However, this property can lead to overly constrained models if the symmetries considered in the group differ from those observed in data. While common methods address this by determining the appropriate level of symmetry at the dataset level, they are limited to supervised settings and ignore scenarios in which multiple levels of symmetry co-exist in the same dataset. For instance, pictures of cars and planes exhibit different levels of rotation, yet both are included in the CIFAR-10 dataset. In this paper, we propose a method able to detect the level of symmetry of each input without the need for labels. To this end, we derive a sufficient and necessary condition to learn the distribution of symmetries in the data. Using the learned distribution, we generate pseudo-labels that allow us to learn the levels of symmetry of each input in a self-supervised manner. We validate the effectiveness of our approach on synthetic datasets with different per-class levels of symmetries e.g. MNISTMultiple, in which digits are uniformly rotated within a class-dependent interval. We demonstrate that our method can be used for practical applications such as the generation of standardized datasets in which the symmetries are not present, as well as the detection of out-of-distribution symmetries during inference. By doing so, both the generalization and robustness of non-equivariant models can be improved. Our code is publicly available at https://github.com/aurban0/ssl-sym.","sentences":["Group equivariance ensures consistent responses to group transformations of the input, leading to more robust models and enhanced generalization capabilities.","However, this property can lead to overly constrained models if the symmetries considered in the group differ from those observed in data.","While common methods address this by determining the appropriate level of symmetry at the dataset level, they are limited to supervised settings and ignore scenarios in which multiple levels of symmetry co-exist in the same dataset.","For instance, pictures of cars and planes exhibit different levels of rotation, yet both are included in the CIFAR-10 dataset.","In this paper, we propose a method able to detect the level of symmetry of each input without the need for labels.","To this end, we derive a sufficient and necessary condition to learn the distribution of symmetries in the data.","Using the learned distribution, we generate pseudo-labels that allow us to learn the levels of symmetry of each input in a self-supervised manner.","We validate the effectiveness of our approach on synthetic datasets with different per-class levels of symmetries e.g. MNISTMultiple, in which digits are uniformly rotated within a class-dependent interval.","We demonstrate that our method can be used for practical applications such as the generation of standardized datasets in which the symmetries are not present, as well as the detection of out-of-distribution symmetries during inference.","By doing so, both the generalization and robustness of non-equivariant models can be improved.","Our code is publicly available at https://github.com/aurban0/ssl-sym."],"url":"http://arxiv.org/abs/2312.12223v1"}
{"created":"2023-12-19 15:05:52","title":"Sharing is CAIRing: Characterizing Principles and Assessing Properties of Universal Privacy Evaluation for Synthetic Tabular Data","abstract":"Data sharing is a necessity for innovative progress in many domains, especially in healthcare. However, the ability to share data is hindered by regulations protecting the privacy of natural persons. Synthetic tabular data provide a promising solution to address data sharing difficulties but does not inherently guarantee privacy. Still, there is a lack of agreement on appropriate methods for assessing the privacy-preserving capabilities of synthetic data, making it difficult to compare results across studies. To the best of our knowledge, this is the first work to identify properties that constitute good universal privacy evaluation metrics for synthetic tabular data. The goal of such metrics is to enable comparability across studies and to allow non-technical stakeholders to understand how privacy is protected. We identify four principles for the assessment of metrics: Comparability, Applicability, Interpretability, and Representativeness (CAIR). To quantify and rank the degree to which evaluation metrics conform to the CAIR principles, we design a rubric using a scale of 1-4. Each of the four properties is scored on four parameters, yielding 16 total dimensions. We study the applicability and usefulness of the CAIR principles and rubric by assessing a selection of metrics popular in other studies. The results provide granular insights into the strengths and weaknesses of existing metrics that not only rank the metrics but highlight areas of potential improvements. We expect that the CAIR principles will foster agreement among researchers and organizations on which universal privacy evaluation metrics are appropriate for synthetic tabular data.","sentences":["Data sharing is a necessity for innovative progress in many domains, especially in healthcare.","However, the ability to share data is hindered by regulations protecting the privacy of natural persons.","Synthetic tabular data provide a promising solution to address data sharing difficulties but does not inherently guarantee privacy.","Still, there is a lack of agreement on appropriate methods for assessing the privacy-preserving capabilities of synthetic data, making it difficult to compare results across studies.","To the best of our knowledge, this is the first work to identify properties that constitute good universal privacy evaluation metrics for synthetic tabular data.","The goal of such metrics is to enable comparability across studies and to allow non-technical stakeholders to understand how privacy is protected.","We identify four principles for the assessment of metrics: Comparability, Applicability, Interpretability, and Representativeness (CAIR).","To quantify and rank the degree to which evaluation metrics conform to the CAIR principles, we design a rubric using a scale of 1-4.","Each of the four properties is scored on four parameters, yielding 16 total dimensions.","We study the applicability and usefulness of the CAIR principles and rubric by assessing a selection of metrics popular in other studies.","The results provide granular insights into the strengths and weaknesses of existing metrics that not only rank the metrics but highlight areas of potential improvements.","We expect that the CAIR principles will foster agreement among researchers and organizations on which universal privacy evaluation metrics are appropriate for synthetic tabular data."],"url":"http://arxiv.org/abs/2312.12216v1"}
{"created":"2023-12-19 14:44:26","title":"Identification of Causal Structure in the Presence of Missing Data with Additive Noise Model","abstract":"Missing data are an unavoidable complication frequently encountered in many causal discovery tasks. When a missing process depends on the missing values themselves (known as self-masking missingness), the recovery of the joint distribution becomes unattainable, and detecting the presence of such self-masking missingness remains a perplexing challenge. Consequently, due to the inability to reconstruct the original distribution and to discern the underlying missingness mechanism, simply applying existing causal discovery methods would lead to wrong conclusions. In this work, we found that the recent advances additive noise model has the potential for learning causal structure under the existence of the self-masking missingness. With this observation, we aim to investigate the identification problem of learning causal structure from missing data under an additive noise model with different missingness mechanisms, where the `no self-masking missingness' assumption can be eliminated appropriately. Specifically, we first elegantly extend the scope of identifiability of causal skeleton to the case with weak self-masking missingness (i.e., no other variable could be the cause of self-masking indicators except itself). We further provide the sufficient and necessary identification conditions of the causal direction under additive noise model and show that the causal structure can be identified up to an IN-equivalent pattern. We finally propose a practical algorithm based on the above theoretical results on learning the causal skeleton and causal direction. Extensive experiments on synthetic and real data demonstrate the efficiency and effectiveness of the proposed algorithms.","sentences":["Missing data are an unavoidable complication frequently encountered in many causal discovery tasks.","When a missing process depends on the missing values themselves (known as self-masking missingness), the recovery of the joint distribution becomes unattainable, and detecting the presence of such self-masking missingness remains a perplexing challenge.","Consequently, due to the inability to reconstruct the original distribution and to discern the underlying missingness mechanism, simply applying existing causal discovery methods would lead to wrong conclusions.","In this work, we found that the recent advances additive noise model has the potential for learning causal structure under the existence of the self-masking missingness.","With this observation, we aim to investigate the identification problem of learning causal structure from missing data under an additive noise model with different missingness mechanisms, where the `no self-masking missingness' assumption can be eliminated appropriately.","Specifically, we first elegantly extend the scope of identifiability of causal skeleton to the case with weak self-masking missingness (i.e., no other variable could be the cause of self-masking indicators except itself).","We further provide the sufficient and necessary identification conditions of the causal direction under additive noise model and show that the causal structure can be identified up to an IN-equivalent pattern.","We finally propose a practical algorithm based on the above theoretical results on learning the causal skeleton and causal direction.","Extensive experiments on synthetic and real data demonstrate the efficiency and effectiveness of the proposed algorithms."],"url":"http://arxiv.org/abs/2312.12206v1"}
{"created":"2023-12-19 14:40:07","title":"Enhanced Unscented Kalman Filter-Based SLAM in Dynamic Environments: Euclidean Approach","abstract":"This paper introduces an innovative approach to Simultaneous Localization and Mapping (SLAM) using the Unscented Kalman Filter (UKF) in a dynamic environment. The UKF is proven to be a robust estimator and demonstrates lower sensitivity to sensor data errors compared to alternative SLAM algorithms. However, conventional algorithms are primarily concerned with stationary landmarks, which might prevent localization in dynamic environments. This paper proposes an Euclidean-based method for handling moving landmarks, calculating and estimating distances between the robot and each moving landmark, and addressing sensor measurement conflicts. The approach is evaluated through simulations in MATLAB and comparing results with the conventional UKF-SLAM algorithm. We also introduce a dataset for filter-based algorithms in dynamic environments, which can be used as a benchmark for evaluating of future algorithms. The outcomes of the proposed algorithm underscore that this simple yet effective approach mitigates the disruptive impact of moving landmarks, as evidenced by a thorough examination involving parameters such as the number of moving and stationary landmarks, waypoints, and computational efficiency. We also evaluated our algorithms in a realistic simulation of a real-world mapping task. This approach allowed us to assess our methods in practical conditions and gain insights for future enhancements. Our algorithm surpassed the performance of all competing methods in the evaluation, showcasing its ability to excel in real-world mapping scenarios.","sentences":["This paper introduces an innovative approach to Simultaneous Localization and Mapping (SLAM) using the Unscented Kalman Filter (UKF) in a dynamic environment.","The UKF is proven to be a robust estimator and demonstrates lower sensitivity to sensor data errors compared to alternative SLAM algorithms.","However, conventional algorithms are primarily concerned with stationary landmarks, which might prevent localization in dynamic environments.","This paper proposes an Euclidean-based method for handling moving landmarks, calculating and estimating distances between the robot and each moving landmark, and addressing sensor measurement conflicts.","The approach is evaluated through simulations in MATLAB and comparing results with the conventional UKF-SLAM algorithm.","We also introduce a dataset for filter-based algorithms in dynamic environments, which can be used as a benchmark for evaluating of future algorithms.","The outcomes of the proposed algorithm underscore that this simple yet effective approach mitigates the disruptive impact of moving landmarks, as evidenced by a thorough examination involving parameters such as the number of moving and stationary landmarks, waypoints, and computational efficiency.","We also evaluated our algorithms in a realistic simulation of a real-world mapping task.","This approach allowed us to assess our methods in practical conditions and gain insights for future enhancements.","Our algorithm surpassed the performance of all competing methods in the evaluation, showcasing its ability to excel in real-world mapping scenarios."],"url":"http://arxiv.org/abs/2312.12204v1"}
{"created":"2023-12-19 14:27:26","title":"Gaussian process learning of nonlinear dynamics","abstract":"One of the pivotal tasks in scientific machine learning is to represent underlying dynamical systems from time series data. Many methods for such dynamics learning explicitly require the derivatives of state data, which are not directly available and can be approximated conventionally by finite differences. However, the discrete approximations of time derivatives may result in a poor estimation when state data are scarce and/or corrupted by noise, thus compromising the predictiveness of the learned dynamical models. To overcome this technical hurdle, we propose a new method that learns nonlinear dynamics through a Bayesian inference of characterizing model parameters. This method leverages a Gaussian process representation of states, and constructs a likelihood function using the correlation between state data and their derivatives, yet prevents explicit evaluations of time derivatives. Through a Bayesian scheme, a probabilistic estimate of the model parameters is given by the posterior distribution, and thus a quantification is facilitated for uncertainties from noisy state data and the learning process. Specifically, we will discuss the applicability of the proposed method to two typical scenarios for dynamical systems: parameter identification and estimation with an affine structure of the system, and nonlinear parametric approximation without prior knowledge.","sentences":["One of the pivotal tasks in scientific machine learning is to represent underlying dynamical systems from time series data.","Many methods for such dynamics learning explicitly require the derivatives of state data, which are not directly available and can be approximated conventionally by finite differences.","However, the discrete approximations of time derivatives may result in a poor estimation when state data are scarce and/or corrupted by noise, thus compromising the predictiveness of the learned dynamical models.","To overcome this technical hurdle, we propose a new method that learns nonlinear dynamics through a Bayesian inference of characterizing model parameters.","This method leverages a Gaussian process representation of states, and constructs a likelihood function using the correlation between state data and their derivatives, yet prevents explicit evaluations of time derivatives.","Through a Bayesian scheme, a probabilistic estimate of the model parameters is given by the posterior distribution, and thus a quantification is facilitated for uncertainties from noisy state data and the learning process.","Specifically, we will discuss the applicability of the proposed method to two typical scenarios for dynamical systems: parameter identification and estimation with an affine structure of the system, and nonlinear parametric approximation without prior knowledge."],"url":"http://arxiv.org/abs/2312.12193v1"}
{"created":"2023-12-19 14:26:23","title":"CUDC: A Curiosity-Driven Unsupervised Data Collection Method with Adaptive Temporal Distances for Offline Reinforcement Learning","abstract":"Offline reinforcement learning (RL) aims to learn an effective policy from a pre-collected dataset. Most existing works are to develop sophisticated learning algorithms, with less emphasis on improving the data collection process. Moreover, it is even challenging to extend the single-task setting and collect a task-agnostic dataset that allows an agent to perform multiple downstream tasks. In this paper, we propose a Curiosity-driven Unsupervised Data Collection (CUDC) method to expand feature space using adaptive temporal distances for task-agnostic data collection and ultimately improve learning efficiency and capabilities for multi-task offline RL. To achieve this, CUDC estimates the probability of the k-step future states being reachable from the current states, and adapts how many steps into the future that the dynamics model should predict. With this adaptive reachability mechanism in place, the feature representation can be diversified, and the agent can navigate itself to collect higher-quality data with curiosity. Empirically, CUDC surpasses existing unsupervised methods in efficiency and learning performance in various downstream offline RL tasks of the DeepMind control suite.","sentences":["Offline reinforcement learning (RL) aims to learn an effective policy from a pre-collected dataset.","Most existing works are to develop sophisticated learning algorithms, with less emphasis on improving the data collection process.","Moreover, it is even challenging to extend the single-task setting and collect a task-agnostic dataset that allows an agent to perform multiple downstream tasks.","In this paper, we propose a Curiosity-driven Unsupervised Data Collection (CUDC) method to expand feature space using adaptive temporal distances for task-agnostic data collection and ultimately improve learning efficiency and capabilities for multi-task offline RL.","To achieve this, CUDC estimates the probability of the k-step future states being reachable from the current states, and adapts how many steps into the future that the dynamics model should predict.","With this adaptive reachability mechanism in place, the feature representation can be diversified, and the agent can navigate itself to collect higher-quality data with curiosity.","Empirically, CUDC surpasses existing unsupervised methods in efficiency and learning performance in various downstream offline RL tasks of the DeepMind control suite."],"url":"http://arxiv.org/abs/2312.12191v1"}
{"created":"2023-12-19 14:15:20","title":"Poincar\u00e9 Differential Privacy for Hierarchy-aware Graph Embedding","abstract":"Hierarchy is an important and commonly observed topological property in real-world graphs that indicate the relationships between supervisors and subordinates or the organizational behavior of human groups. As hierarchy is introduced as a new inductive bias into the Graph Neural Networks (GNNs) in various tasks, it implies latent topological relations for attackers to improve their inference attack performance, leading to serious privacy leakage issues. In addition, existing privacy-preserving frameworks suffer from reduced protection ability in hierarchical propagation due to the deficiency of adaptive upper-bound estimation of the hierarchical perturbation boundary. It is of great urgency to effectively leverage the hierarchical property of data while satisfying privacy guarantees. To solve the problem, we propose the Poincar\\'e Differential Privacy framework, named PoinDP, to protect the hierarchy-aware graph embedding based on hyperbolic geometry. Specifically, PoinDP first learns the hierarchy weights for each entity based on the Poincar\\'e model in hyperbolic space. Then, the Personalized Hierarchy-aware Sensitivity is designed to measure the sensitivity of the hierarchical structure and adaptively allocate the privacy protection strength. Besides, the Hyperbolic Gaussian Mechanism (HGM) is proposed to extend the Gaussian mechanism in Euclidean space to hyperbolic space to realize random perturbations that satisfy differential privacy under the hyperbolic space metric. Extensive experiment results on five real-world datasets demonstrate the proposed PoinDP's advantages of effective privacy protection while maintaining good performance on the node classification task.","sentences":["Hierarchy is an important and commonly observed topological property in real-world graphs that indicate the relationships between supervisors and subordinates or the organizational behavior of human groups.","As hierarchy is introduced as a new inductive bias into the Graph Neural Networks (GNNs) in various tasks, it implies latent topological relations for attackers to improve their inference attack performance, leading to serious privacy leakage issues.","In addition, existing privacy-preserving frameworks suffer from reduced protection ability in hierarchical propagation due to the deficiency of adaptive upper-bound estimation of the hierarchical perturbation boundary.","It is of great urgency to effectively leverage the hierarchical property of data while satisfying privacy guarantees.","To solve the problem, we propose the Poincar\\'e Differential Privacy framework, named PoinDP, to protect the hierarchy-aware graph embedding based on hyperbolic geometry.","Specifically, PoinDP first learns the hierarchy weights for each entity based on the Poincar\\'e model in hyperbolic space.","Then, the Personalized Hierarchy-aware Sensitivity is designed to measure the sensitivity of the hierarchical structure and adaptively allocate the privacy protection strength.","Besides, the Hyperbolic Gaussian Mechanism (HGM) is proposed to extend the Gaussian mechanism in Euclidean space to hyperbolic space to realize random perturbations that satisfy differential privacy under the hyperbolic space metric.","Extensive experiment results on five real-world datasets demonstrate the proposed PoinDP's advantages of effective privacy protection while maintaining good performance on the node classification task."],"url":"http://arxiv.org/abs/2312.12183v1"}
{"created":"2023-12-19 14:13:26","title":"StyleSpeech: Self-supervised Style Enhancing with VQ-VAE-based Pre-training for Expressive Audiobook Speech Synthesis","abstract":"The expressive quality of synthesized speech for audiobooks is limited by generalized model architecture and unbalanced style distribution in the training data. To address these issues, in this paper, we propose a self-supervised style enhancing method with VQ-VAE-based pre-training for expressive audiobook speech synthesis. Firstly, a text style encoder is pre-trained with a large amount of unlabeled text-only data. Secondly, a spectrogram style extractor based on VQ-VAE is pre-trained in a self-supervised manner, with plenty of audio data that covers complex style variations. Then a novel architecture with two encoder-decoder paths is specially designed to model the pronunciation and high-level style expressiveness respectively, with the guidance of the style extractor. Both objective and subjective evaluations demonstrate that our proposed method can effectively improve the naturalness and expressiveness of the synthesized speech in audiobook synthesis especially for the role and out-of-domain scenarios.","sentences":["The expressive quality of synthesized speech for audiobooks is limited by generalized model architecture and unbalanced style distribution in the training data.","To address these issues, in this paper, we propose a self-supervised style enhancing method with VQ-VAE-based pre-training for expressive audiobook speech synthesis.","Firstly, a text style encoder is pre-trained with a large amount of unlabeled text-only data.","Secondly, a spectrogram style extractor based on VQ-VAE is pre-trained in a self-supervised manner, with plenty of audio data that covers complex style variations.","Then a novel architecture with two encoder-decoder paths is specially designed to model the pronunciation and high-level style expressiveness respectively, with the guidance of the style extractor.","Both objective and subjective evaluations demonstrate that our proposed method can effectively improve the naturalness and expressiveness of the synthesized speech in audiobook synthesis especially for the role and out-of-domain scenarios."],"url":"http://arxiv.org/abs/2312.12181v1"}
{"created":"2023-12-19 13:11:35","title":"Object-Aware Domain Generalization for Object Detection","abstract":"Single-domain generalization (S-DG) aims to generalize a model to unseen environments with a single-source domain. However, most S-DG approaches have been conducted in the field of classification. When these approaches are applied to object detection, the semantic features of some objects can be damaged, which can lead to imprecise object localization and misclassification. To address these problems, we propose an object-aware domain generalization (OA-DG) method for single-domain generalization in object detection. Our method consists of data augmentation and training strategy, which are called OA-Mix and OA-Loss, respectively. OA-Mix generates multi-domain data with multi-level transformation and object-aware mixing strategy. OA-Loss enables models to learn domain-invariant representations for objects and backgrounds from the original and OA-Mixed images. Our proposed method outperforms state-of-the-art works on standard benchmarks. Our code is available at https://github.com/WoojuLee24/OA-DG.","sentences":["Single-domain generalization (S-DG) aims to generalize a model to unseen environments with a single-source domain.","However, most S-DG approaches have been conducted in the field of classification.","When these approaches are applied to object detection, the semantic features of some objects can be damaged, which can lead to imprecise object localization and misclassification.","To address these problems, we propose an object-aware domain generalization (OA-DG) method for single-domain generalization in object detection.","Our method consists of data augmentation and training strategy, which are called OA-Mix and OA-Loss, respectively.","OA-Mix generates multi-domain data with multi-level transformation and object-aware mixing strategy.","OA-Loss enables models to learn domain-invariant representations for objects and backgrounds from the original and OA-Mixed images.","Our proposed method outperforms state-of-the-art works on standard benchmarks.","Our code is available at https://github.com/WoojuLee24/OA-DG."],"url":"http://arxiv.org/abs/2312.12133v1"}
{"created":"2023-12-19 12:56:56","title":"Probabilistic Prediction of Longitudinal Trajectory Considering Driving Heterogeneity with Interpretability","abstract":"Automated vehicles are envisioned to navigate safely in complex mixed-traffic scenarios alongside human-driven vehicles. To promise a high degree of safety, accurately predicting the maneuvers of surrounding vehicles and their future positions is a critical task and attracts much attention. However, most existing studies focused on reasoning about positional information based on objective historical trajectories without fully considering the heterogeneity of driving behaviors. Therefore, this study proposes a trajectory prediction framework that combines Mixture Density Networks (MDN) and considers the driving heterogeneity to provide probabilistic and personalized predictions. Specifically, based on a certain length of historical trajectory data, the situation-specific driving preferences of each driver are identified, where key driving behavior feature vectors are extracted to characterize heterogeneity in driving behavior among different drivers. With the inputs of the short-term historical trajectory data and key driving behavior feature vectors, a probabilistic LSTMMD-DBV model combined with LSTM-based encoder-decoder networks and MDN layers is utilized to carry out personalized predictions. Finally, the SHapley Additive exPlanations (SHAP) method is employed to interpret the trained model for predictions. The proposed framework is tested based on a wide-range vehicle trajectory dataset. The results indicate that the proposed model can generate probabilistic future trajectories with remarkably improved predictions compared to existing benchmark models. Moreover, the results confirm that the additional input of driving behavior feature vectors representing the heterogeneity of driving behavior could provide more information and thus contribute to improving the prediction accuracy.","sentences":["Automated vehicles are envisioned to navigate safely in complex mixed-traffic scenarios alongside human-driven vehicles.","To promise a high degree of safety, accurately predicting the maneuvers of surrounding vehicles and their future positions is a critical task and attracts much attention.","However, most existing studies focused on reasoning about positional information based on objective historical trajectories without fully considering the heterogeneity of driving behaviors.","Therefore, this study proposes a trajectory prediction framework that combines Mixture Density Networks (MDN) and considers the driving heterogeneity to provide probabilistic and personalized predictions.","Specifically, based on a certain length of historical trajectory data, the situation-specific driving preferences of each driver are identified, where key driving behavior feature vectors are extracted to characterize heterogeneity in driving behavior among different drivers.","With the inputs of the short-term historical trajectory data and key driving behavior feature vectors, a probabilistic LSTMMD-DBV model combined with LSTM-based encoder-decoder networks and MDN layers is utilized to carry out personalized predictions.","Finally, the SHapley Additive exPlanations (SHAP) method is employed to interpret the trained model for predictions.","The proposed framework is tested based on a wide-range vehicle trajectory dataset.","The results indicate that the proposed model can generate probabilistic future trajectories with remarkably improved predictions compared to existing benchmark models.","Moreover, the results confirm that the additional input of driving behavior feature vectors representing the heterogeneity of driving behavior could provide more information and thus contribute to improving the prediction accuracy."],"url":"http://arxiv.org/abs/2312.12123v1"}
{"created":"2023-12-19 12:54:54","title":"ZS-SRT: An Efficient Zero-Shot Super-Resolution Training Method for Neural Radiance Fields","abstract":"Neural Radiance Fields (NeRF) have achieved great success in the task of synthesizing novel views that preserve the same resolution as the training views. However, it is challenging for NeRF to synthesize high-quality high-resolution novel views with low-resolution training data. To solve this problem, we propose a zero-shot super-resolution training framework for NeRF. This framework aims to guide the NeRF model to synthesize high-resolution novel views via single-scene internal learning rather than requiring any external high-resolution training data. Our approach consists of two stages. First, we learn a scene-specific degradation mapping by performing internal learning on a pretrained low-resolution coarse NeRF. Second, we optimize a super-resolution fine NeRF by conducting inverse rendering with our mapping function so as to backpropagate the gradients from low-resolution 2D space into the super-resolution 3D sampling space. Then, we further introduce a temporal ensemble strategy in the inference phase to compensate for the scene estimation errors. Our method is featured on two points: (1) it does not consume high-resolution views or additional scene data to train super-resolution NeRF; (2) it can speed up the training process by adopting a coarse-to-fine strategy. By conducting extensive experiments on public datasets, we have qualitatively and quantitatively demonstrated the effectiveness of our method.","sentences":["Neural Radiance Fields (NeRF) have achieved great success in the task of synthesizing novel views that preserve the same resolution as the training views.","However, it is challenging for NeRF to synthesize high-quality high-resolution novel views with low-resolution training data.","To solve this problem, we propose a zero-shot super-resolution training framework for NeRF.","This framework aims to guide the NeRF model to synthesize high-resolution novel views via single-scene internal learning rather than requiring any external high-resolution training data.","Our approach consists of two stages.","First, we learn a scene-specific degradation mapping by performing internal learning on a pretrained low-resolution coarse NeRF.","Second, we optimize a super-resolution fine NeRF by conducting inverse rendering with our mapping function so as to backpropagate the gradients from low-resolution 2D space into the super-resolution 3D sampling space.","Then, we further introduce a temporal ensemble strategy in the inference phase to compensate for the scene estimation errors.","Our method is featured on two points: (1) it does not consume high-resolution views or additional scene data to train super-resolution NeRF; (2) it can speed up the training process by adopting a coarse-to-fine strategy.","By conducting extensive experiments on public datasets, we have qualitatively and quantitatively demonstrated the effectiveness of our method."],"url":"http://arxiv.org/abs/2312.12122v1"}
{"created":"2023-12-19 12:34:46","title":"Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in ultra low-data regimes","abstract":"Machine Learning (ML) in low-data settings remains an underappreciated yet crucial problem. This challenge is pronounced in low-to-middle income countries where access to large datasets is often limited or even absent. Hence, data augmentation methods to increase the sample size of datasets needed for ML are key to unlocking the transformative potential of ML in data-deprived regions and domains. Unfortunately, the limited training set constrains traditional tabular synthetic data generators in their ability to generate a large and diverse augmented dataset needed for ML tasks. To address this technical challenge, we introduce CLLM, which leverages the prior knowledge of Large Language Models (LLMs) for data augmentation in the low-data regime. While diverse, not all the data generated by LLMs will help increase utility for a downstream task, as for any generative model. Consequently, we introduce a principled curation process, leveraging learning dynamics, coupled with confidence and uncertainty metrics, to obtain a high-quality dataset. Empirically, on multiple real-world datasets, we demonstrate the superior performance of LLMs in the low-data regime compared to conventional generators. We further show our curation mechanism improves the downstream performance for all generators, including LLMs. Additionally, we provide insights and understanding into the LLM generation and curation mechanism, shedding light on the features that enable them to output high-quality augmented datasets. CLLM paves the way for wider usage of ML in data scarce domains and regions, by allying the strengths of LLMs with a robust data-centric approach.","sentences":["Machine Learning (ML) in low-data settings remains an underappreciated yet crucial problem.","This challenge is pronounced in low-to-middle income countries where access to large datasets is often limited or even absent.","Hence, data augmentation methods to increase the sample size of datasets needed for ML are key to unlocking the transformative potential of ML in data-deprived regions and domains.","Unfortunately, the limited training set constrains traditional tabular synthetic data generators in their ability to generate a large and diverse augmented dataset needed for ML tasks.","To address this technical challenge, we introduce CLLM, which leverages the prior knowledge of Large Language Models (LLMs) for data augmentation in the low-data regime.","While diverse, not all the data generated by LLMs will help increase utility for a downstream task, as for any generative model.","Consequently, we introduce a principled curation process, leveraging learning dynamics, coupled with confidence and uncertainty metrics, to obtain a high-quality dataset.","Empirically, on multiple real-world datasets, we demonstrate the superior performance of LLMs in the low-data regime compared to conventional generators.","We further show our curation mechanism improves the downstream performance for all generators, including LLMs.","Additionally, we provide insights and understanding into the LLM generation and curation mechanism, shedding light on the features that enable them to output high-quality augmented datasets.","CLLM paves the way for wider usage of ML in data scarce domains and regions, by allying the strengths of LLMs with a robust data-centric approach."],"url":"http://arxiv.org/abs/2312.12112v1"}
{"created":"2023-12-19 12:33:38","title":"Designing and Evaluating General-Purpose User Representations Based on Behavioral Logs from a Measurement Process Perspective: A Case Study with Snapchat","abstract":"In human-computer interaction, understanding user behaviors and tailoring systems accordingly is pivotal. To this end, general-purpose user representation learning based on behavior logs is emerging as a powerful tool in user modeling, offering adaptability to various downstream tasks such as item recommendations and ad conversion prediction, without the need to fine-tune the upstream user model. While this methodology has shown promise in contexts like search engines and e-commerce platforms, its fit for instant messaging apps, a cornerstone of modern digital communication, remains largely uncharted. These apps, with their distinct interaction patterns, data structures, and user expectations, necessitate specialized attention. We explore this user modeling approach with Snapchat data as a case study. Furthermore, we introduce a novel design and evaluation framework rooted in the principles of the Measurement Process Framework from social science research methodology. Using this new framework, we design a Transformer-based user model that can produce high-quality general-purpose user representations for instant messaging platforms like Snapchat.","sentences":["In human-computer interaction, understanding user behaviors and tailoring systems accordingly is pivotal.","To this end, general-purpose user representation learning based on behavior logs is emerging as a powerful tool in user modeling, offering adaptability to various downstream tasks such as item recommendations and ad conversion prediction, without the need to fine-tune the upstream user model.","While this methodology has shown promise in contexts like search engines and e-commerce platforms, its fit for instant messaging apps, a cornerstone of modern digital communication, remains largely uncharted.","These apps, with their distinct interaction patterns, data structures, and user expectations, necessitate specialized attention.","We explore this user modeling approach with Snapchat data as a case study.","Furthermore, we introduce a novel design and evaluation framework rooted in the principles of the Measurement Process Framework from social science research methodology.","Using this new framework, we design a Transformer-based user model that can produce high-quality general-purpose user representations for instant messaging platforms like Snapchat."],"url":"http://arxiv.org/abs/2312.12111v1"}
{"created":"2023-12-19 12:30:24","title":"GraphScope Flex: LEGO-like Graph Computing Stack","abstract":"Graph computing has become increasingly crucial in processing large-scale graph data, with numerous systems developed for this purpose. Two years ago, we introduced GraphScope as a system addressing a wide array of graph computing needs, including graph traversal, analytics, and learning in one system. Since its inception, GraphScope has achieved significant technological advancements and gained widespread adoption across various industries. However, one key lesson from this journey has been understanding the limitations of a \"one-size-fits-all\" approach, especially when dealing with the diversity of programming interfaces, applications, and data storage formats in graph computing. In response to these challenges, we present GraphScope Flex, the next iteration of GraphScope. GraphScope Flex is designed to be both resource-efficient and cost-effective, while also providing flexibility and user-friendliness through its LEGO-like modularity. This paper explores the architectural innovations and fundamental design principles of GraphScope Flex, all of which are direct outcomes of the lessons learned during our ongoing development process. We validate the adaptability and efficiency of GraphScope Flex with extensive evaluations on synthetic and real-world datasets. The results show that GraphScope Flex achieves 2.4X throughput and up to 55.7X speedup over other systems on the LDBC Social Network and Graphalytics benchmarks, respectively. Furthermore, GraphScope Flex accomplishes up to a 2,400X performance gain in real-world applications, demonstrating its proficiency across a wide range of graph computing scenarios with increased effectiveness.","sentences":["Graph computing has become increasingly crucial in processing large-scale graph data, with numerous systems developed for this purpose.","Two years ago, we introduced GraphScope as a system addressing a wide array of graph computing needs, including graph traversal, analytics, and learning in one system.","Since its inception, GraphScope has achieved significant technological advancements and gained widespread adoption across various industries.","However, one key lesson from this journey has been understanding the limitations of a \"one-size-fits-all\" approach, especially when dealing with the diversity of programming interfaces, applications, and data storage formats in graph computing.","In response to these challenges, we present GraphScope Flex, the next iteration of GraphScope.","GraphScope Flex is designed to be both resource-efficient and cost-effective, while also providing flexibility and user-friendliness through its LEGO-like modularity.","This paper explores the architectural innovations and fundamental design principles of GraphScope Flex, all of which are direct outcomes of the lessons learned during our ongoing development process.","We validate the adaptability and efficiency of GraphScope Flex with extensive evaluations on synthetic and real-world datasets.","The results show that GraphScope Flex achieves 2.4X throughput and up to 55.7X speedup over other systems on the LDBC Social Network and Graphalytics benchmarks, respectively.","Furthermore, GraphScope Flex accomplishes up to a 2,400X performance gain in real-world applications, demonstrating its proficiency across a wide range of graph computing scenarios with increased effectiveness."],"url":"http://arxiv.org/abs/2312.12107v1"}
{"created":"2023-12-19 12:30:13","title":"Preserving Data Secrecy in Decentralized Inter-organizational Process Mining","abstract":"Inter-organizational business processes involve multiple independent organizations collaborating to achieve mutual interests. Process mining techniques have the potential to allow these organizations to enhance operational efficiency, improve performance, and deepen the understanding of their business based on the recorded process event data. However, inter-organizational process mining faces substantial challenges, including topical secrecy concerns: The involved organizations may not be willing to expose their own data to run mining algorithms jointly with their counterparts or third parties. In this paper, we introduce CONFINE, a novel approach that unlocks process mining on multiple actors' process event data while safeguarding the secrecy and integrity of the original records in an inter-organizational business setting. To ensure that the phases of the presented interaction protocol are secure and that the processed information is hidden from involved and external actors alike, our approach resorts to a decentralized architecture comprised of trusted applications running in Trusted Execution Environments (TEEs). We show the feasibility of our solution by showcasing its application to a healthcare scenario and evaluating our implementation in terms of memory usage and scalability on real-world event logs.","sentences":["Inter-organizational business processes involve multiple independent organizations collaborating to achieve mutual interests.","Process mining techniques have the potential to allow these organizations to enhance operational efficiency, improve performance, and deepen the understanding of their business based on the recorded process event data.","However, inter-organizational process mining faces substantial challenges, including topical secrecy concerns: The involved organizations may not be willing to expose their own data to run mining algorithms jointly with their counterparts or third parties.","In this paper, we introduce CONFINE, a novel approach that unlocks process mining on multiple actors' process event data while safeguarding the secrecy and integrity of the original records in an inter-organizational business setting.","To ensure that the phases of the presented interaction protocol are secure and that the processed information is hidden from involved and external actors alike, our approach resorts to a decentralized architecture comprised of trusted applications running in Trusted Execution Environments (TEEs).","We show the feasibility of our solution by showcasing its application to a healthcare scenario and evaluating our implementation in terms of memory usage and scalability on real-world event logs."],"url":"http://arxiv.org/abs/2312.12105v1"}
{"created":"2023-12-19 12:26:57","title":"I-CEE: Tailoring Explanations of Image Classifications Models to User Expertise","abstract":"Effectively explaining decisions of black-box machine learning models is critical to responsible deployment of AI systems that rely on them. Recognizing their importance, the field of explainable AI (XAI) provides several techniques to generate these explanations. Yet, there is relatively little emphasis on the user (the explainee) in this growing body of work and most XAI techniques generate \"one-size-fits-all\" explanations. To bridge this gap and achieve a step closer towards human-centered XAI, we present I-CEE, a framework that provides Image Classification Explanations tailored to User Expertise. Informed by existing work, I-CEE explains the decisions of image classification models by providing the user with an informative subset of training data (i.e., example images), corresponding local explanations, and model decisions. However, unlike prior work, I-CEE models the informativeness of the example images to depend on user expertise, resulting in different examples for different users. We posit that by tailoring the example set to user expertise, I-CEE can better facilitate users' understanding and simulatability of the model. To evaluate our approach, we conduct detailed experiments in both simulation and with human participants (N = 100) on multiple datasets. Experiments with simulated users show that I-CEE improves users' ability to accurately predict the model's decisions (simulatability) compared to baselines, providing promising preliminary results. Experiments with human participants demonstrate that our method significantly improves user simulatability accuracy, highlighting the importance of human-centered XAI","sentences":["Effectively explaining decisions of black-box machine learning models is critical to responsible deployment of AI systems that rely on them.","Recognizing their importance, the field of explainable AI (XAI) provides several techniques to generate these explanations.","Yet, there is relatively little emphasis on the user (the explainee) in this growing body of work and most XAI techniques generate \"one-size-fits-all\" explanations.","To bridge this gap and achieve a step closer towards human-centered XAI, we present I-CEE, a framework that provides Image Classification Explanations tailored to User Expertise.","Informed by existing work, I-CEE explains the decisions of image classification models by providing the user with an informative subset of training data (i.e., example images), corresponding local explanations, and model decisions.","However, unlike prior work, I-CEE models the informativeness of the example images to depend on user expertise, resulting in different examples for different users.","We posit that by tailoring the example set to user expertise, I-CEE can better facilitate users' understanding and simulatability of the model.","To evaluate our approach, we conduct detailed experiments in both simulation and with human participants (N = 100) on multiple datasets.","Experiments with simulated users show that I-CEE improves users' ability to accurately predict the model's decisions (simulatability) compared to baselines, providing promising preliminary results.","Experiments with human participants demonstrate that our method significantly improves user simulatability accuracy, highlighting the importance of human-centered XAI"],"url":"http://arxiv.org/abs/2312.12102v1"}
{"created":"2023-12-19 12:12:18","title":"Model-Heterogeneous Federated Learning for Internet of Things: Enabling Technologies and Future Directions","abstract":"Internet of Things (IoT) interconnects a massive amount of devices, generating heterogeneous data with diverse characteristics. IoT data emerges as a vital asset for data-intensive IoT applications, such as healthcare, smart city and predictive maintenance, harnessing the vast volume of heterogeneous data to its maximum advantage. These applications leverage different Artificial Intelligence (AI) algorithms to discover new insights. While machine learning effectively uncovers implicit patterns through model training, centralizing IoT data for training poses significant privacy and security concerns. Federated Learning (FL) offers an promising solution, allowing IoT devices to conduct local learning without sharing raw data with third parties. Model-heterogeneous FL empowers clients to train models with varying complexities based on their hardware capabilities, aligning with heterogeneity of devices in real-world IoT environments. In this article, we review the state-of-the-art model-heterogeneous FL methods and provide insights into their merits and limitations. Moreover, we showcase their applicability to IoT and identify the open problems and future directions. To the best of our knowledge, this is the first article that focuses on the topic of model-heterogeneous FL for IoT.","sentences":["Internet of Things (IoT) interconnects a massive amount of devices, generating heterogeneous data with diverse characteristics.","IoT data emerges as a vital asset for data-intensive IoT applications, such as healthcare, smart city and predictive maintenance, harnessing the vast volume of heterogeneous data to its maximum advantage.","These applications leverage different Artificial Intelligence (AI) algorithms to discover new insights.","While machine learning effectively uncovers implicit patterns through model training, centralizing IoT data for training poses significant privacy and security concerns.","Federated Learning (FL) offers an promising solution, allowing IoT devices to conduct local learning without sharing raw data with third parties.","Model-heterogeneous FL empowers clients to train models with varying complexities based on their hardware capabilities, aligning with heterogeneity of devices in real-world IoT environments.","In this article, we review the state-of-the-art model-heterogeneous FL methods and provide insights into their merits and limitations.","Moreover, we showcase their applicability to IoT and identify the open problems and future directions.","To the best of our knowledge, this is the first article that focuses on the topic of model-heterogeneous FL for IoT."],"url":"http://arxiv.org/abs/2312.12091v1"}
{"created":"2023-12-19 11:57:54","title":"Learning Subject-Aware Cropping by Outpainting Professional Photos","abstract":"How to frame (or crop) a photo often depends on the image subject and its context; e.g., a human portrait. Recent works have defined the subject-aware image cropping task as a nuanced and practical version of image cropping. We propose a weakly-supervised approach (GenCrop) to learn what makes a high-quality, subject-aware crop from professional stock images. Unlike supervised prior work, GenCrop requires no new manual annotations beyond the existing stock image collection. The key challenge in learning from this data, however, is that the images are already cropped and we do not know what regions were removed. Our insight is combine a library of stock images with a modern, pre-trained text-to-image diffusion model. The stock image collection provides diversity and its images serve as pseudo-labels for a good crop, while the text-image diffusion model is used to out-paint (i.e., outward inpainting) realistic uncropped images. Using this procedure, we are able to automatically generate a large dataset of cropped-uncropped training pairs to train a cropping model. Despite being weakly-supervised, GenCrop is competitive with state-of-the-art supervised methods and significantly better than comparable weakly-supervised baselines on quantitative and qualitative evaluation metrics.","sentences":["How to frame (or crop) a photo often depends on the image subject and its context; e.g., a human portrait.","Recent works have defined the subject-aware image cropping task as a nuanced and practical version of image cropping.","We propose a weakly-supervised approach (GenCrop) to learn what makes a high-quality, subject-aware crop from professional stock images.","Unlike supervised prior work, GenCrop requires no new manual annotations beyond the existing stock image collection.","The key challenge in learning from this data, however, is that the images are already cropped and we do not know what regions were removed.","Our insight is combine a library of stock images with a modern, pre-trained text-to-image diffusion model.","The stock image collection provides diversity and its images serve as pseudo-labels for a good crop, while the text-image diffusion model is used to out-paint (i.e., outward inpainting) realistic uncropped images.","Using this procedure, we are able to automatically generate a large dataset of cropped-uncropped training pairs to train a cropping model.","Despite being weakly-supervised, GenCrop is competitive with state-of-the-art supervised methods and significantly better than comparable weakly-supervised baselines on quantitative and qualitative evaluation metrics."],"url":"http://arxiv.org/abs/2312.12080v1"}
{"created":"2023-12-19 11:50:31","title":"A Survey on Property-Preserving Database Encryption Techniques in the Cloud","abstract":"Outsourcing a relational database to the cloud offers several benefits, including scalability, availability, and cost-effectiveness. However, there are concerns about the security and confidentiality of the outsourced data. A general approach here would be to encrypt the data with a standardized encryption algorithm and then store the data only encrypted in the cloud. The problem with this approach, however, is that with encryption, important properties of the data such as sorting, format or comparability, which are essential for the functioning of database queries, are lost. One solution to this problem is the use of encryption algorithms, which also preserve these properties in the encrypted data, thus enabling queries to encrypted data. These algorithms range from simple algorithms like Caesar encryption to secure algorithms like mOPE. The report at hand presents a survey on common encryption techniques used for storing data in relation Cloud database services. It presents the applied methods and identifies their characteristics.","sentences":["Outsourcing a relational database to the cloud offers several benefits, including scalability, availability, and cost-effectiveness.","However, there are concerns about the security and confidentiality of the outsourced data.","A general approach here would be to encrypt the data with a standardized encryption algorithm and then store the data only encrypted in the cloud.","The problem with this approach, however, is that with encryption, important properties of the data such as sorting, format or comparability, which are essential for the functioning of database queries, are lost.","One solution to this problem is the use of encryption algorithms, which also preserve these properties in the encrypted data, thus enabling queries to encrypted data.","These algorithms range from simple algorithms like Caesar encryption to secure algorithms like mOPE.","The report at hand presents a survey on common encryption techniques used for storing data in relation Cloud database services.","It presents the applied methods and identifies their characteristics."],"url":"http://arxiv.org/abs/2312.12075v1"}
{"created":"2023-12-19 11:32:02","title":"MPI Planar Correction of Pulse Based ToF Cameras","abstract":"Time-of-Flight (ToF) cameras are becoming popular in a wide span of areas ranging from consumer-grade electronic devices to safety-critical industrial robots. This is mainly due to their high frame rate, relative good precision and the lowered costs. Although ToF cameras are in continuous development, especially pulse-based variants, they still face different problems, including spurious noise over the points or multipath inference (MPI). The latter can cause deformed surfaces to manifest themselves on curved surfaces instead of planar ones, making standard spatial data preprocessing, such as plane extraction, difficult. In this paper, we focus on the MPI reduction problem using Feature Pyramid Networks (FPN) which allow the mitigation of this type of artifact for pulse-based ToF cameras. With our end-to-end network, we managed to attenuate the MPI effect on planar surfaces using a learning-based method on real ToF data. Both the custom dataset used for our model training as well as the code is available on the author's Github homepage.","sentences":["Time-of-Flight (ToF) cameras are becoming popular in a wide span of areas ranging from consumer-grade electronic devices to safety-critical industrial robots.","This is mainly due to their high frame rate, relative good precision and the lowered costs.","Although ToF cameras are in continuous development, especially pulse-based variants, they still face different problems, including spurious noise over the points or multipath inference (MPI).","The latter can cause deformed surfaces to manifest themselves on curved surfaces instead of planar ones, making standard spatial data preprocessing, such as plane extraction, difficult.","In this paper, we focus on the MPI reduction problem using Feature Pyramid Networks (FPN) which allow the mitigation of this type of artifact for pulse-based ToF cameras.","With our end-to-end network, we managed to attenuate the MPI effect on planar surfaces using a learning-based method on real ToF data.","Both the custom dataset used for our model training as well as the code is available on the author's Github homepage."],"url":"http://arxiv.org/abs/2312.12064v1"}
{"created":"2023-12-19 11:21:18","title":"Monitoring Auditable Claims in the Cloud","abstract":"When deploying mission-critical systems in the cloud, where deviations may have severe consequences, the assurance of critical decisions becomes essential. Typical cloud systems are operated by third parties and are built on complex software stacks consisting of e.g., Kubernetes, Istio, or Kafka, which due to their size are difficult to be verified. Nevertheless, one needs to make sure that mission-critical choices are made correctly. We propose a flexible runtime monitoring approach that is independent of the implementation of the observed system that allows to monitor safety and data-related properties. Our approach is based on combining distributed Datalog-based programs with tamper-proof storage based on Trillian to verify the premises of safety-critical actions. The approach can be seen as a generalization of the Certificate Transparency project. We apply our approach to an industrial use case that uses a cloud infrastructure for orchestrating unmanned air vehicles.","sentences":["When deploying mission-critical systems in the cloud, where deviations may have severe consequences, the assurance of critical decisions becomes essential.","Typical cloud systems are operated by third parties and are built on complex software stacks consisting of e.g., Kubernetes, Istio, or Kafka, which due to their size are difficult to be verified.","Nevertheless, one needs to make sure that mission-critical choices are made correctly.","We propose a flexible runtime monitoring approach that is independent of the implementation of the observed system that allows to monitor safety and data-related properties.","Our approach is based on combining distributed Datalog-based programs with tamper-proof storage based on Trillian to verify the premises of safety-critical actions.","The approach can be seen as a generalization of the Certificate Transparency project.","We apply our approach to an industrial use case that uses a cloud infrastructure for orchestrating unmanned air vehicles."],"url":"http://arxiv.org/abs/2312.12057v1"}
{"created":"2023-12-19 11:14:37","title":"Extension of the Dip-test Repertoire -- Efficient and Differentiable p-value Calculation for Clustering","abstract":"Over the last decade, the Dip-test of unimodality has gained increasing interest in the data mining community as it is a parameter-free statistical test that reliably rates the modality in one-dimensional samples. It returns a so called Dip-value and a corresponding probability for the sample's unimodality (Dip-p-value). These two values share a sigmoidal relationship. However, the specific transformation is dependent on the sample size. Many Dip-based clustering algorithms use bootstrapped look-up tables translating Dip- to Dip-p-values for a certain limited amount of sample sizes. We propose a specifically designed sigmoid function as a substitute for these state-of-the-art look-up tables. This accelerates computation and provides an approximation of the Dip- to Dip-p-value transformation for every single sample size. Further, it is differentiable and can therefore easily be integrated in learning schemes using gradient descent. We showcase this by exploiting our function in a novel subspace clustering algorithm called Dip'n'Sub. We highlight in extensive experiments the various benefits of our proposal.","sentences":["Over the last decade, the Dip-test of unimodality has gained increasing interest in the data mining community as it is a parameter-free statistical test that reliably rates the modality in one-dimensional samples.","It returns a so called Dip-value and a corresponding probability for the sample's unimodality (Dip-p-value).","These two values share a sigmoidal relationship.","However, the specific transformation is dependent on the sample size.","Many Dip-based clustering algorithms use bootstrapped look-up tables translating Dip- to Dip-p-values for a certain limited amount of sample sizes.","We propose a specifically designed sigmoid function as a substitute for these state-of-the-art look-up tables.","This accelerates computation and provides an approximation of the Dip- to Dip-p-value transformation for every single sample size.","Further, it is differentiable and can therefore easily be integrated in learning schemes using gradient descent.","We showcase this by exploiting our function in a novel subspace clustering algorithm called Dip'n'Sub.","We highlight in extensive experiments the various benefits of our proposal."],"url":"http://arxiv.org/abs/2312.12050v1"}
{"created":"2023-12-19 10:55:46","title":"Pose2Gaze: Generating Realistic Human Gaze Behaviour from Full-body Poses using an Eye-body Coordination Model","abstract":"While generating realistic body movements, e.g., for avatars in virtual reality, is widely studied in computer vision and graphics, the generation of eye movements that exhibit realistic coordination with the body remains under-explored. We first report a comprehensive analysis of the coordination of human eye and full-body movements during everyday activities based on data from the MoGaze and GIMO datasets. We show that eye gaze has strong correlations with head directions and also full-body motions and there exists a noticeable time delay between body and eye movements. Inspired by the analyses, we then present Pose2Gaze -- a novel eye-body coordination model that first uses a convolutional neural network and a spatio-temporal graph convolutional neural network to extract features from head directions and full-body poses respectively and then applies a convolutional neural network to generate realistic eye movements. We compare our method with state-of-the-art methods that predict eye gaze only from head movements for three different generation tasks and demonstrate that Pose2Gaze significantly outperforms these baselines on both datasets with an average improvement of 26.4% and 21.6% in mean angular error, respectively. Our findings underline the significant potential of cross-modal human gaze behaviour analysis and modelling.","sentences":["While generating realistic body movements, e.g., for avatars in virtual reality, is widely studied in computer vision and graphics, the generation of eye movements that exhibit realistic coordination with the body remains under-explored.","We first report a comprehensive analysis of the coordination of human eye and full-body movements during everyday activities based on data from the MoGaze and GIMO datasets.","We show that eye gaze has strong correlations with head directions and also full-body motions and there exists a noticeable time delay between body and eye movements.","Inspired by the analyses, we then present Pose2Gaze -- a novel eye-body coordination model that first uses a convolutional neural network and a spatio-temporal graph convolutional neural network to extract features from head directions and full-body poses respectively and then applies a convolutional neural network to generate realistic eye movements.","We compare our method with state-of-the-art methods that predict eye gaze only from head movements for three different generation tasks and demonstrate that Pose2Gaze significantly outperforms these baselines on both datasets with an average improvement of 26.4% and 21.6% in mean angular error, respectively.","Our findings underline the significant potential of cross-modal human gaze behaviour analysis and modelling."],"url":"http://arxiv.org/abs/2312.12042v1"}
{"created":"2023-12-19 10:29:29","title":"EyePreserve: Identity-Preserving Iris Synthesis","abstract":"Synthesis of same-identity biometric iris images, both for existing and non-existing identities while preserving the identity across a wide range of pupil sizes, is complex due to intricate iris muscle constriction mechanism, requiring a precise model of iris non-linear texture deformations to be embedded into the synthesis pipeline. This paper presents the first method of fully data-driven, identity-preserving, pupil size-varying s ynthesis of iris images. This approach is capable of synthesizing images of irises with different pupil sizes representing non-existing identities as well as non-linearly deforming the texture of iris images of existing subjects given the segmentation mask of the target iris image. Iris recognition experiments suggest that the proposed deformation model not only preserves the identity when changing the pupil size but offers better similarity between same-identity iris samples with significant differences in pupil size, compared to state-of-the-art linear and non-linear (bio-mechanical-based) iris deformation models. Two immediate applications of the proposed approach are: (a) synthesis of, or enhancement of the existing biometric datasets for iris recognition, mimicking those acquired with iris sensors, and (b) helping forensic human experts in examining iris image pairs with significant differences in pupil dilation. Source codes and weights of the models are made available with the paper.","sentences":["Synthesis of same-identity biometric iris images, both for existing and non-existing identities while preserving the identity across a wide range of pupil sizes, is complex due to intricate iris muscle constriction mechanism, requiring a precise model of iris non-linear texture deformations to be embedded into the synthesis pipeline.","This paper presents the first method of fully data-driven, identity-preserving, pupil size-varying s ynthesis of iris images.","This approach is capable of synthesizing images of irises with different pupil sizes representing non-existing identities as well as non-linearly deforming the texture of iris images of existing subjects given the segmentation mask of the target iris image.","Iris recognition experiments suggest that the proposed deformation model not only preserves the identity when changing the pupil size but offers better similarity between same-identity iris samples with significant differences in pupil size, compared to state-of-the-art linear and non-linear (bio-mechanical-based) iris deformation models.","Two immediate applications of the proposed approach are: (a) synthesis of, or enhancement of the existing biometric datasets for iris recognition, mimicking those acquired with iris sensors, and (b) helping forensic human experts in examining iris image pairs with significant differences in pupil dilation.","Source codes and weights of the models are made available with the paper."],"url":"http://arxiv.org/abs/2312.12028v1"}
{"created":"2023-12-19 10:10:29","title":"Potentials of ChatGPT for Annotating Vaccine Related Tweets","abstract":"This study evaluates ChatGPT's performance in annotating vaccine-related Arabic tweets by comparing its annotations with human annotations. A dataset of 2,100 tweets representing various factors contributing to vaccine hesitancy was examined. Two domain experts annotated the data, with a third resolving conflicts. ChatGPT was then employed to annotate the same dataset using specific prompts for each factor. The ChatGPT annotations were evaluated through zero-shot, one-shot, and few-shot learning tests, with an average accuracy of 82.14%, 83.85%, and 85.57%, respectively. Precision averaged around 86%, minimizing false positives. The average recall and F1-score ranged from 0.74 to 0.80 and 0.65 to 0.93, respectively. AUC for zero-shot, one-shot, and few-shot learning was 0.79, 0.80, and 0.83. In cases of ambiguity, both human annotators and ChatGPT faced challenges. These findings suggest that ChatGPT holds promise as a tool for annotating vaccine-related tweets.","sentences":["This study evaluates ChatGPT's performance in annotating vaccine-related Arabic tweets by comparing its annotations with human annotations.","A dataset of 2,100 tweets representing various factors contributing to vaccine hesitancy was examined.","Two domain experts annotated the data, with a third resolving conflicts.","ChatGPT was then employed to annotate the same dataset using specific prompts for each factor.","The ChatGPT annotations were evaluated through zero-shot, one-shot, and few-shot learning tests, with an average accuracy of 82.14%, 83.85%, and 85.57%, respectively.","Precision averaged around 86%, minimizing false positives.","The average recall and F1-score ranged from 0.74 to 0.80 and 0.65 to 0.93, respectively.","AUC for zero-shot, one-shot, and few-shot learning was 0.79, 0.80, and 0.83.","In cases of ambiguity, both human annotators and ChatGPT faced challenges.","These findings suggest that ChatGPT holds promise as a tool for annotating vaccine-related tweets."],"url":"http://arxiv.org/abs/2312.12016v1"}
{"created":"2023-12-19 10:05:38","title":"Efficient and Private Federated Trajectory Matching","abstract":"Federated Trajectory Matching (FTM) is gaining increasing importance in big trajectory data analytics, supporting diverse applications such as public health, law enforcement, and emergency response. FTM retrieves trajectories that match with a query trajectory from a large-scale trajectory database, while safeguarding the privacy of trajectories in both the query and the database. A naive solution to FTM is to process the query through Secure Multi-Party Computation (SMC) across the entire database, which is inherently secure yet inevitably slow due to the massive secure operations. A promising acceleration strategy is to filter irrelevant trajectories from the database based on the query, thus reducing the SMC operations. However, a key challenge is how to publish the query in a way that both preserves privacy and enables efficient trajectory filtering. In this paper, we design GIST, a novel framework for efficient Federated Trajectory Matching. GIST is grounded in Geo-Indistinguishability, a privacy criterion dedicated to locations. It employs a new privacy mechanism for the query that facilitates efficient trajectory filtering. We theoretically prove the privacy guarantee of the mechanism and the accuracy of the filtering strategy of GIST. Extensive evaluations on five real datasets show that GIST is significantly faster and incurs up to 3 orders of magnitude lower communication cost than the state-of-the-arts.","sentences":["Federated Trajectory Matching (FTM) is gaining increasing importance in big trajectory data analytics, supporting diverse applications such as public health, law enforcement, and emergency response.","FTM retrieves trajectories that match with a query trajectory from a large-scale trajectory database, while safeguarding the privacy of trajectories in both the query and the database.","A naive solution to FTM is to process the query through Secure Multi-Party Computation (SMC) across the entire database, which is inherently secure yet inevitably slow due to the massive secure operations.","A promising acceleration strategy is to filter irrelevant trajectories from the database based on the query, thus reducing the SMC operations.","However, a key challenge is how to publish the query in a way that both preserves privacy and enables efficient trajectory filtering.","In this paper, we design GIST, a novel framework for efficient Federated Trajectory Matching.","GIST is grounded in Geo-Indistinguishability, a privacy criterion dedicated to locations.","It employs a new privacy mechanism for the query that facilitates efficient trajectory filtering.","We theoretically prove the privacy guarantee of the mechanism and the accuracy of the filtering strategy of GIST.","Extensive evaluations on five real datasets show that GIST is significantly faster and incurs up to 3 orders of magnitude lower communication cost than the state-of-the-arts."],"url":"http://arxiv.org/abs/2312.12012v1"}
{"created":"2023-12-19 10:05:09","title":"Flexible categorization using formal concept analysis and Dempster-Shafer theory","abstract":"Categorization of business processes is an important part of auditing. Large amounts of transactional data in auditing can be represented as transactions between financial accounts using weighted bipartite graphs. We view such bipartite graphs as many-valued formal contexts, which we use to obtain explainable categorization of these business processes in terms of financial accounts involved in a business process by using methods in formal concept analysis. We use Dempster-Shafer mass functions to represent agendas showing different interest in different set of financial accounts. We also model some possible deliberation scenarios between agents with different interrogative agendas to reach an aggregated agenda and categorization. The framework developed in this paper provides a formal ground to obtain and study explainable categorizations from the data represented as bipartite graphs according to the agendas of different agents in an organization (e.g. an audit firm), and interaction between these through deliberation. We use this framework to describe a machine-leaning meta algorithm for outlier detection and classification which can provide local and global explanations of its result and demonstrate it through an outlier detection algorithm.","sentences":["Categorization of business processes is an important part of auditing.","Large amounts of transactional data in auditing can be represented as transactions between financial accounts using weighted bipartite graphs.","We view such bipartite graphs as many-valued formal contexts, which we use to obtain explainable categorization of these business processes in terms of financial accounts involved in a business process by using methods in formal concept analysis.","We use Dempster-Shafer mass functions to represent agendas showing different interest in different set of financial accounts.","We also model some possible deliberation scenarios between agents with different interrogative agendas to reach an aggregated agenda and categorization.","The framework developed in this paper provides a formal ground to obtain and study explainable categorizations from the data represented as bipartite graphs according to the agendas of different agents in an organization (e.g. an audit firm), and interaction between these through deliberation.","We use this framework to describe a machine-leaning meta algorithm for outlier detection and classification which can provide local and global explanations of its result and demonstrate it through an outlier detection algorithm."],"url":"http://arxiv.org/abs/2312.12010v1"}
{"created":"2023-12-19 09:39:27","title":"Coreference Graph Guidance for Mind-Map Generation","abstract":"Mind-map generation aims to process a document into a hierarchical structure to show its central idea and branches. Such a manner is more conducive to understanding the logic and semantics of the document than plain text. Recently, a state-of-the-art method encodes the sentences of a document sequentially and converts them to a relation graph via sequence-to-graph. Though this method is efficient to generate mind-maps in parallel, its mechanism focuses more on sequential features while hardly capturing structural information. Moreover, it's difficult to model long-range semantic relations. In this work, we propose a coreference-guided mind-map generation network (CMGN) to incorporate external structure knowledge. Specifically, we construct a coreference graph based on the coreference semantic relationship to introduce the graph structure information. Then we employ a coreference graph encoder to mine the potential governing relations between sentences. In order to exclude noise and better utilize the information of the coreference graph, we adopt a graph enhancement module in a contrastive learning manner. Experimental results demonstrate that our model outperforms all the existing methods. The case study further proves that our model can more accurately and concisely reveal the structure and semantics of a document. Code and data are available at https://github.com/Cyno2232/CMGN.","sentences":["Mind-map generation aims to process a document into a hierarchical structure to show its central idea and branches.","Such a manner is more conducive to understanding the logic and semantics of the document than plain text.","Recently, a state-of-the-art method encodes the sentences of a document sequentially and converts them to a relation graph via sequence-to-graph.","Though this method is efficient to generate mind-maps in parallel, its mechanism focuses more on sequential features while hardly capturing structural information.","Moreover, it's difficult to model long-range semantic relations.","In this work, we propose a coreference-guided mind-map generation network (CMGN) to incorporate external structure knowledge.","Specifically, we construct a coreference graph based on the coreference semantic relationship to introduce the graph structure information.","Then we employ a coreference graph encoder to mine the potential governing relations between sentences.","In order to exclude noise and better utilize the information of the coreference graph, we adopt a graph enhancement module in a contrastive learning manner.","Experimental results demonstrate that our model outperforms all the existing methods.","The case study further proves that our model can more accurately and concisely reveal the structure and semantics of a document.","Code and data are available at https://github.com/Cyno2232/CMGN."],"url":"http://arxiv.org/abs/2312.11997v1"}
{"created":"2023-12-19 09:30:58","title":"Xpert: Empowering Incident Management with Query Recommendations via Large Language Models","abstract":"Large-scale cloud systems play a pivotal role in modern IT infrastructure. However, incidents occurring within these systems can lead to service disruptions and adversely affect user experience. To swiftly resolve such incidents, on-call engineers depend on crafting domain-specific language (DSL) queries to analyze telemetry data. However, writing these queries can be challenging and time-consuming. This paper presents a thorough empirical study on the utilization of queries of KQL, a DSL employed for incident management in a large-scale cloud management system at Microsoft. The findings obtained underscore the importance and viability of KQL queries recommendation to enhance incident management.   Building upon these valuable insights, we introduce Xpert, an end-to-end machine learning framework that automates KQL recommendation process. By leveraging historical incident data and large language models, Xpert generates customized KQL queries tailored to new incidents. Furthermore, Xpert incorporates a novel performance metric called Xcore, enabling a thorough evaluation of query quality from three comprehensive perspectives. We conduct extensive evaluations of Xpert, demonstrating its effectiveness in offline settings. Notably, we deploy Xpert in the real production environment of a large-scale incident management system in Microsoft, validating its efficiency in supporting incident management. To the best of our knowledge, this paper represents the first empirical study of its kind, and Xpert stands as a pioneering DSL query recommendation framework designed for incident management.","sentences":["Large-scale cloud systems play a pivotal role in modern IT infrastructure.","However, incidents occurring within these systems can lead to service disruptions and adversely affect user experience.","To swiftly resolve such incidents, on-call engineers depend on crafting domain-specific language (DSL) queries to analyze telemetry data.","However, writing these queries can be challenging and time-consuming.","This paper presents a thorough empirical study on the utilization of queries of KQL, a DSL employed for incident management in a large-scale cloud management system at Microsoft.","The findings obtained underscore the importance and viability of KQL queries recommendation to enhance incident management.   ","Building upon these valuable insights, we introduce Xpert, an end-to-end machine learning framework that automates KQL recommendation process.","By leveraging historical incident data and large language models, Xpert generates customized KQL queries tailored to new incidents.","Furthermore, Xpert incorporates a novel performance metric called Xcore, enabling a thorough evaluation of query quality from three comprehensive perspectives.","We conduct extensive evaluations of Xpert, demonstrating its effectiveness in offline settings.","Notably, we deploy Xpert in the real production environment of a large-scale incident management system in Microsoft, validating its efficiency in supporting incident management.","To the best of our knowledge, this paper represents the first empirical study of its kind, and Xpert stands as a pioneering DSL query recommendation framework designed for incident management."],"url":"http://arxiv.org/abs/2312.11988v1"}
{"created":"2023-12-19 09:26:46","title":"Climate Change from Large Language Models","abstract":"Climate change presents significant challenges to the global community, and it is imperative to raise widespread awareness of the climate crisis and educate users about low-carbon living. Artificial intelligence, particularly large language models (LLMs), have emerged as powerful tools in mitigating the climate crisis, leveraging their extensive knowledge, broad user base, and natural language interaction capabilities. However, despite the growing body of research on climate change, there is a lack of comprehensive assessments of climate crisis knowledge within LLMs. This paper aims to resolve this gap by proposing an automatic evaluation framework. We employ a hybrid approach to data acquisition that combines data synthesis and manual collection to compile a diverse set of questions related to the climate crisis. These questions cover various aspects of climate change, including its causes, impacts, mitigation strategies, and adaptation measures. We then evaluate the model knowledge through prompt engineering based on the collected questions and generated answers. We propose a set of comprehensive metrics to evaluate the climate crisis knowledge, incorporating indicators from 10 different perspectives. Experimental results show that our method is effective in evaluating the knowledge of LLMs regarding the climate crisis. We evaluate several state-of-the-art LLMs and find that their knowledge falls short in terms of timeliness.","sentences":["Climate change presents significant challenges to the global community, and it is imperative to raise widespread awareness of the climate crisis and educate users about low-carbon living.","Artificial intelligence, particularly large language models (LLMs), have emerged as powerful tools in mitigating the climate crisis, leveraging their extensive knowledge, broad user base, and natural language interaction capabilities.","However, despite the growing body of research on climate change, there is a lack of comprehensive assessments of climate crisis knowledge within LLMs.","This paper aims to resolve this gap by proposing an automatic evaluation framework.","We employ a hybrid approach to data acquisition that combines data synthesis and manual collection to compile a diverse set of questions related to the climate crisis.","These questions cover various aspects of climate change, including its causes, impacts, mitigation strategies, and adaptation measures.","We then evaluate the model knowledge through prompt engineering based on the collected questions and generated answers.","We propose a set of comprehensive metrics to evaluate the climate crisis knowledge, incorporating indicators from 10 different perspectives.","Experimental results show that our method is effective in evaluating the knowledge of LLMs regarding the climate crisis.","We evaluate several state-of-the-art LLMs and find that their knowledge falls short in terms of timeliness."],"url":"http://arxiv.org/abs/2312.11985v1"}
{"created":"2023-12-19 09:18:12","title":"When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection","abstract":"Time-series anomaly detection deals with the problem of detecting anomalous timesteps by learning normality from the sequence of observations. However, the concept of normality evolves over time, leading to a \"new normal problem\", where the distribution of normality can be changed due to the distribution shifts between training and test data. This paper highlights the prevalence of the new normal problem in unsupervised time-series anomaly detection studies. To tackle this issue, we propose a simple yet effective test-time adaptation strategy based on trend estimation and a self-supervised approach to learning new normalities during inference. Extensive experiments on real-world benchmarks demonstrate that incorporating the proposed strategy into the anomaly detector consistently improves the model's performance compared to the baselines, leading to robustness to the distribution shifts.","sentences":["Time-series anomaly detection deals with the problem of detecting anomalous timesteps by learning normality from the sequence of observations.","However, the concept of normality evolves over time, leading to a \"new normal problem\", where the distribution of normality can be changed due to the distribution shifts between training and test data.","This paper highlights the prevalence of the new normal problem in unsupervised time-series anomaly detection studies.","To tackle this issue, we propose a simple yet effective test-time adaptation strategy based on trend estimation and a self-supervised approach to learning new normalities during inference.","Extensive experiments on real-world benchmarks demonstrate that incorporating the proposed strategy into the anomaly detector consistently improves the model's performance compared to the baselines, leading to robustness to the distribution shifts."],"url":"http://arxiv.org/abs/2312.11976v1"}
{"created":"2023-12-19 09:04:26","title":"GroupMixNorm Layer for Learning Fair Models","abstract":"Recent research has identified discriminatory behavior of automated prediction algorithms towards groups identified on specific protected attributes (e.g., gender, ethnicity, age group, etc.). When deployed in real-world scenarios, such techniques may demonstrate biased predictions resulting in unfair outcomes. Recent literature has witnessed algorithms for mitigating such biased behavior mostly by adding convex surrogates of fairness metrics such as demographic parity or equalized odds in the loss function, which are often not easy to estimate. This research proposes a novel in-processing based GroupMixNorm layer for mitigating bias from deep learning models. The GroupMixNorm layer probabilistically mixes group-level feature statistics of samples across different groups based on the protected attribute. The proposed method improves upon several fairness metrics with minimal impact on overall accuracy. Analysis on benchmark tabular and image datasets demonstrates the efficacy of the proposed method in achieving state-of-the-art performance. Further, the experimental analysis also suggests the robustness of the GroupMixNorm layer against new protected attributes during inference and its utility in eliminating bias from a pre-trained network.","sentences":["Recent research has identified discriminatory behavior of automated prediction algorithms towards groups identified on specific protected attributes (e.g., gender, ethnicity, age group, etc.).","When deployed in real-world scenarios, such techniques may demonstrate biased predictions resulting in unfair outcomes.","Recent literature has witnessed algorithms for mitigating such biased behavior mostly by adding convex surrogates of fairness metrics such as demographic parity or equalized odds in the loss function, which are often not easy to estimate.","This research proposes a novel in-processing based GroupMixNorm layer for mitigating bias from deep learning models.","The GroupMixNorm layer probabilistically mixes group-level feature statistics of samples across different groups based on the protected attribute.","The proposed method improves upon several fairness metrics with minimal impact on overall accuracy.","Analysis on benchmark tabular and image datasets demonstrates the efficacy of the proposed method in achieving state-of-the-art performance.","Further, the experimental analysis also suggests the robustness of the GroupMixNorm layer against new protected attributes during inference and its utility in eliminating bias from a pre-trained network."],"url":"http://arxiv.org/abs/2312.11969v1"}
{"created":"2023-12-19 09:03:53","title":"Context Disentangling and Prototype Inheriting for Robust Visual Grounding","abstract":"Visual grounding (VG) aims to locate a specific target in an image based on a given language query. The discriminative information from context is important for distinguishing the target from other objects, particularly for the targets that have the same category as others. However, most previous methods underestimate such information. Moreover, they are usually designed for the standard scene (without any novel object), which limits their generalization to the open-vocabulary scene. In this paper, we propose a novel framework with context disentangling and prototype inheriting for robust visual grounding to handle both scenes. Specifically, the context disentangling disentangles the referent and context features, which achieves better discrimination between them. The prototype inheriting inherits the prototypes discovered from the disentangled visual features by a prototype bank to fully utilize the seen data, especially for the open-vocabulary scene. The fused features, obtained by leveraging Hadamard product on disentangled linguistic and visual features of prototypes to avoid sharp adjusting the importance between the two types of features, are then attached with a special token and feed to a vision Transformer encoder for bounding box regression. Extensive experiments are conducted on both standard and open-vocabulary scenes. The performance comparisons indicate that our method outperforms the state-of-the-art methods in both scenarios. {The code is available at https://github.com/WayneTomas/TransCP.","sentences":["Visual grounding (VG) aims to locate a specific target in an image based on a given language query.","The discriminative information from context is important for distinguishing the target from other objects, particularly for the targets that have the same category as others.","However, most previous methods underestimate such information.","Moreover, they are usually designed for the standard scene (without any novel object), which limits their generalization to the open-vocabulary scene.","In this paper, we propose a novel framework with context disentangling and prototype inheriting for robust visual grounding to handle both scenes.","Specifically, the context disentangling disentangles the referent and context features, which achieves better discrimination between them.","The prototype inheriting inherits the prototypes discovered from the disentangled visual features by a prototype bank to fully utilize the seen data, especially for the open-vocabulary scene.","The fused features, obtained by leveraging Hadamard product on disentangled linguistic and visual features of prototypes to avoid sharp adjusting the importance between the two types of features, are then attached with a special token and feed to a vision Transformer encoder for bounding box regression.","Extensive experiments are conducted on both standard and open-vocabulary scenes.","The performance comparisons indicate that our method outperforms the state-of-the-art methods in both scenarios.","{The code is available at https://github.com/WayneTomas/TransCP."],"url":"http://arxiv.org/abs/2312.11967v1"}
{"created":"2023-12-19 08:57:31","title":"Traffic Load Prediction and Power Consumption Reduction for Multi-band Networks","abstract":"Energy is a major expense issue for mobile operators. In the case of wireless networks, base stations have been identified as the main source of energy consumption. In this paper, we study the energy consumption reduction problem based on real measurements for a commercial multi-band LTE network. Specifically, we are interested in sleep modes to turn off certain frequency bands during low traffic periods and consequently reduce power consumption. We determine the number of frequency bands really needed at each time period. The frequency bands that are not needed can be disabled to reduce energy consumption. In order to allow the operator to predict how many bands can be switched off without major impact on the quality of service, we propose to use a deep learning algorithm, such as Long-Short Term Memory (LSTM). Based on the captured data traces, we have shown that the proposed LSTM model can save an average of 8% to 21% of the energy consumption during working days.","sentences":["Energy is a major expense issue for mobile operators.","In the case of wireless networks, base stations have been identified as the main source of energy consumption.","In this paper, we study the energy consumption reduction problem based on real measurements for a commercial multi-band LTE network.","Specifically, we are interested in sleep modes to turn off certain frequency bands during low traffic periods and consequently reduce power consumption.","We determine the number of frequency bands really needed at each time period.","The frequency bands that are not needed can be disabled to reduce energy consumption.","In order to allow the operator to predict how many bands can be switched off without major impact on the quality of service, we propose to use a deep learning algorithm, such as Long-Short Term Memory (LSTM).","Based on the captured data traces, we have shown that the proposed LSTM model can save an average of 8% to 21% of the energy consumption during working days."],"url":"http://arxiv.org/abs/2312.11958v1"}
{"created":"2023-12-19 08:55:47","title":"Vertical Symbolic Regression","abstract":"Automating scientific discovery has been a grand goal of Artificial Intelligence (AI) and will bring tremendous societal impact. Learning symbolic expressions from experimental data is a vital step in AI-driven scientific discovery. Despite exciting progress, most endeavors have focused on the horizontal discovery paths, i.e., they directly search for the best expression in the full hypothesis space involving all the independent variables. Horizontal paths are challenging due to the exponentially large hypothesis space involving all the independent variables. We propose Vertical Symbolic Regression (VSR) to expedite symbolic regression. The VSR starts by fitting simple expressions involving a few independent variables under controlled experiments where the remaining variables are held constant. It then extends the expressions learned in previous rounds by adding new independent variables and using new control variable experiments allowing these variables to vary. The first few steps in vertical discovery are significantly cheaper than the horizontal path, as their search is in reduced hypothesis spaces involving a small set of variables. As a consequence, vertical discovery has the potential to supercharge state-of-the-art symbolic regression approaches in handling complex equations with many contributing factors. Theoretically, we show that the search space of VSR can be exponentially smaller than that of horizontal approaches when learning a class of expressions. Experimentally, VSR outperforms several baselines in learning symbolic expressions involving many independent variables.","sentences":["Automating scientific discovery has been a grand goal of Artificial Intelligence (AI) and will bring tremendous societal impact.","Learning symbolic expressions from experimental data is a vital step in AI-driven scientific discovery.","Despite exciting progress, most endeavors have focused on the horizontal discovery paths, i.e., they directly search for the best expression in the full hypothesis space involving all the independent variables.","Horizontal paths are challenging due to the exponentially large hypothesis space involving all the independent variables.","We propose Vertical Symbolic Regression (VSR) to expedite symbolic regression.","The VSR starts by fitting simple expressions involving a few independent variables under controlled experiments where the remaining variables are held constant.","It then extends the expressions learned in previous rounds by adding new independent variables and using new control variable experiments allowing these variables to vary.","The first few steps in vertical discovery are significantly cheaper than the horizontal path, as their search is in reduced hypothesis spaces involving a small set of variables.","As a consequence, vertical discovery has the potential to supercharge state-of-the-art symbolic regression approaches in handling complex equations with many contributing factors.","Theoretically, we show that the search space of VSR can be exponentially smaller than that of horizontal approaches when learning a class of expressions.","Experimentally, VSR outperforms several baselines in learning symbolic expressions involving many independent variables."],"url":"http://arxiv.org/abs/2312.11955v1"}
{"created":"2023-12-19 08:55:00","title":"Adversarial AutoMixup","abstract":"Data mixing augmentation has been widely applied to improve the generalization ability of deep neural networks. Recently, offline data mixing augmentation, e.g. handcrafted and saliency information-based mixup, has been gradually replaced by automatic mixing approaches. Through minimizing two sub-tasks, namely, mixed sample generation and mixup classification in an end-to-end way, AutoMix significantly improves accuracy on image classification tasks. However, as the optimization objective is consistent for the two sub-tasks, this approach is prone to generating consistent instead of diverse mixed samples, which results in overfitting for target task training. In this paper, we propose AdAutomixup, an adversarial automatic mixup augmentation approach that generates challenging samples to train a robust classifier for image classification, by alternatively optimizing the classifier and the mixup sample generator. AdAutomixup comprises two modules, a mixed example generator, and a target classifier. The mixed sample generator aims to produce hard mixed examples to challenge the target classifier while the target classifier`s aim is to learn robust features from hard mixed examples to improve generalization. To prevent the collapse of the inherent meanings of images, we further introduce an exponential moving average (EMA) teacher and cosine similarity to train AdAutomixup in an end-to-end way. Extensive experiments on seven image benchmarks consistently prove that our approach outperforms the state of the art in various classification scenarios.","sentences":["Data mixing augmentation has been widely applied to improve the generalization ability of deep neural networks.","Recently, offline data mixing augmentation, e.g. handcrafted and saliency information-based mixup, has been gradually replaced by automatic mixing approaches.","Through minimizing two sub-tasks, namely, mixed sample generation and mixup classification in an end-to-end way, AutoMix significantly improves accuracy on image classification tasks.","However, as the optimization objective is consistent for the two sub-tasks, this approach is prone to generating consistent instead of diverse mixed samples, which results in overfitting for target task training.","In this paper, we propose AdAutomixup, an adversarial automatic mixup augmentation approach that generates challenging samples to train a robust classifier for image classification, by alternatively optimizing the classifier and the mixup sample generator.","AdAutomixup comprises two modules, a mixed example generator, and a target classifier.","The mixed sample generator aims to produce hard mixed examples to challenge the target classifier while the target classifier`s aim is to learn robust features from hard mixed examples to improve generalization.","To prevent the collapse of the inherent meanings of images, we further introduce an exponential moving average (EMA) teacher and cosine similarity to train AdAutomixup in an end-to-end way.","Extensive experiments on seven image benchmarks consistently prove that our approach outperforms the state of the art in various classification scenarios."],"url":"http://arxiv.org/abs/2312.11954v1"}
{"created":"2023-12-19 08:53:00","title":"Automatic Parameter Selection for Non-Redundant Clustering","abstract":"High-dimensional datasets often contain multiple meaningful clusterings in different subspaces. For example, objects can be clustered either by color, weight, or size, revealing different interpretations of the given dataset. A variety of approaches are able to identify such non-redundant clusterings. However, most of these methods require the user to specify the expected number of subspaces and clusters for each subspace. Stating these values is a non-trivial problem and usually requires detailed knowledge of the input dataset. In this paper, we propose a framework that utilizes the Minimum Description Length Principle (MDL) to detect the number of subspaces and clusters per subspace automatically. We describe an efficient procedure that greedily searches the parameter space by splitting and merging subspaces and clusters within subspaces. Additionally, an encoding strategy is introduced that allows us to detect outliers in each subspace. Extensive experiments show that our approach is highly competitive to state-of-the-art methods.","sentences":["High-dimensional datasets often contain multiple meaningful clusterings in different subspaces.","For example, objects can be clustered either by color, weight, or size, revealing different interpretations of the given dataset.","A variety of approaches are able to identify such non-redundant clusterings.","However, most of these methods require the user to specify the expected number of subspaces and clusters for each subspace.","Stating these values is a non-trivial problem and usually requires detailed knowledge of the input dataset.","In this paper, we propose a framework that utilizes the Minimum Description Length Principle (MDL) to detect the number of subspaces and clusters per subspace automatically.","We describe an efficient procedure that greedily searches the parameter space by splitting and merging subspaces and clusters within subspaces.","Additionally, an encoding strategy is introduced that allows us to detect outliers in each subspace.","Extensive experiments show that our approach is highly competitive to state-of-the-art methods."],"url":"http://arxiv.org/abs/2312.11952v1"}
{"created":"2023-12-19 08:47:50","title":"Emotion Rendering for Conversational Speech Synthesis with Heterogeneous Graph-Based Context Modeling","abstract":"Conversational Speech Synthesis (CSS) aims to accurately express an utterance with the appropriate prosody and emotional inflection within a conversational setting. While recognising the significance of CSS task, the prior studies have not thoroughly investigated the emotional expressiveness problems due to the scarcity of emotional conversational datasets and the difficulty of stateful emotion modeling. In this paper, we propose a novel emotional CSS model, termed ECSS, that includes two main components: 1) to enhance emotion understanding, we introduce a heterogeneous graph-based emotional context modeling mechanism, which takes the multi-source dialogue history as input to model the dialogue context and learn the emotion cues from the context; 2) to achieve emotion rendering, we employ a contrastive learning-based emotion renderer module to infer the accurate emotion style for the target utterance. To address the issue of data scarcity, we meticulously create emotional labels in terms of category and intensity, and annotate additional emotional information on the existing conversational dataset (DailyTalk). Both objective and subjective evaluations suggest that our model outperforms the baseline models in understanding and rendering emotions. These evaluations also underscore the importance of comprehensive emotional annotations. Code and audio samples can be found at: https://github.com/walker-hyf/ECSS.","sentences":["Conversational Speech Synthesis (CSS) aims to accurately express an utterance with the appropriate prosody and emotional inflection within a conversational setting.","While recognising the significance of CSS task, the prior studies have not thoroughly investigated the emotional expressiveness problems due to the scarcity of emotional conversational datasets and the difficulty of stateful emotion modeling.","In this paper, we propose a novel emotional CSS model, termed ECSS, that includes two main components: 1) to enhance emotion understanding, we introduce a heterogeneous graph-based emotional context modeling mechanism, which takes the multi-source dialogue history as input to model the dialogue context and learn the emotion cues from the context; 2) to achieve emotion rendering, we employ a contrastive learning-based emotion renderer module to infer the accurate emotion style for the target utterance.","To address the issue of data scarcity, we meticulously create emotional labels in terms of category and intensity, and annotate additional emotional information on the existing conversational dataset (DailyTalk).","Both objective and subjective evaluations suggest that our model outperforms the baseline models in understanding and rendering emotions.","These evaluations also underscore the importance of comprehensive emotional annotations.","Code and audio samples can be found at: https://github.com/walker-hyf/ECSS."],"url":"http://arxiv.org/abs/2312.11947v1"}
{"created":"2023-12-19 08:41:30","title":"FPT Approximation using Treewidth: Capacitated Vertex Cover, Target Set Selection and Vector Dominating Set","abstract":"Treewidth is a useful tool in designing graph algorithms. Although many NP-hard graph problems can be solved in linear time when the input graphs have small treewidth, there are problems which remain hard on graphs of bounded treewidth. In this paper, we consider three vertex selection problems that are W[1]-hard when parameterized by the treewidth of the input graph, namely the capacitated vertex cover problem, the target set selection problem and the vector dominating set problem. We provide two new methods to obtain FPT approximation algorithms for these problems. For the capacitated vertex cover problem and the vector dominating set problem, we obtain $(1+o(1))$-approximation FPT algorithms. For the target set selection problem, we give an FPT algorithm providing a tradeoff between its running time and the approximation ratio.","sentences":["Treewidth is a useful tool in designing graph algorithms.","Although many NP-hard graph problems can be solved in linear time when the input graphs have small treewidth, there are problems which remain hard on graphs of bounded treewidth.","In this paper, we consider three vertex selection problems that are W[1]-hard when parameterized by the treewidth of the input graph, namely the capacitated vertex cover problem, the target set selection problem and the vector dominating set problem.","We provide two new methods to obtain FPT approximation algorithms for these problems.","For the capacitated vertex cover problem and the vector dominating set problem, we obtain $(1+o(1))$-approximation FPT algorithms.","For the target set selection problem, we give an FPT algorithm providing a tradeoff between its running time and the approximation ratio."],"url":"http://arxiv.org/abs/2312.11944v1"}
{"created":"2023-12-19 08:38:03","title":"Time-Series Contrastive Learning against False Negatives and Class Imbalance","abstract":"As an exemplary self-supervised approach for representation learning, time-series contrastive learning has exhibited remarkable advancements in contemporary research. While recent contrastive learning strategies have focused on how to construct appropriate positives and negatives, in this study, we conduct theoretical analysis and find they have overlooked the fundamental issues: false negatives and class imbalance inherent in the InfoNCE loss-based framework. Therefore, we introduce a straightforward modification grounded in the SimCLR framework, universally adaptable to models engaged in the instance discrimination task. By constructing instance graphs to facilitate interactive learning among instances, we emulate supervised contrastive learning via the multiple-instances discrimination task, mitigating the harmful impact of false negatives. Moreover, leveraging the graph structure and few-labeled data, we perform semi-supervised consistency classification and enhance the representative ability of minority classes. We compared our method with the most popular time-series contrastive learning methods on four real-world time-series datasets and demonstrated our significant advantages in overall performance.","sentences":["As an exemplary self-supervised approach for representation learning, time-series contrastive learning has exhibited remarkable advancements in contemporary research.","While recent contrastive learning strategies have focused on how to construct appropriate positives and negatives, in this study, we conduct theoretical analysis and find they have overlooked the fundamental issues: false negatives and class imbalance inherent in the InfoNCE loss-based framework.","Therefore, we introduce a straightforward modification grounded in the SimCLR framework, universally adaptable to models engaged in the instance discrimination task.","By constructing instance graphs to facilitate interactive learning among instances, we emulate supervised contrastive learning via the multiple-instances discrimination task, mitigating the harmful impact of false negatives.","Moreover, leveraging the graph structure and few-labeled data, we perform semi-supervised consistency classification and enhance the representative ability of minority classes.","We compared our method with the most popular time-series contrastive learning methods on four real-world time-series datasets and demonstrated our significant advantages in overall performance."],"url":"http://arxiv.org/abs/2312.11939v1"}
{"created":"2023-12-19 08:31:30","title":"DMT: Comprehensive Distillation with Multiple Self-supervised Teachers","abstract":"Numerous self-supervised learning paradigms, such as contrastive learning and masked image modeling, have been proposed to acquire powerful and general representations from unlabeled data. However, these models are commonly pretrained within their specific framework alone, failing to consider the complementary nature of visual representations. To tackle this issue, we introduce Comprehensive Distillation with Multiple Self-supervised Teachers (DMT) for pretrained model compression, which leverages the strengths of multiple off-the-shelf self-supervised models. Our experimental results on prominent benchmark datasets exhibit that the proposed method significantly surpasses state-of-the-art competitors while retaining favorable efficiency metrics. On classification tasks, our DMT framework utilizing three different self-supervised ViT-Base teachers enhances the performance of both small/tiny models and the base model itself. For dense tasks, DMT elevates the AP/mIoU of standard SSL models on MS-COCO and ADE20K datasets by 4.0%.","sentences":["Numerous self-supervised learning paradigms, such as contrastive learning and masked image modeling, have been proposed to acquire powerful and general representations from unlabeled data.","However, these models are commonly pretrained within their specific framework alone, failing to consider the complementary nature of visual representations.","To tackle this issue, we introduce Comprehensive Distillation with Multiple Self-supervised Teachers (DMT) for pretrained model compression, which leverages the strengths of multiple off-the-shelf self-supervised models.","Our experimental results on prominent benchmark datasets exhibit that the proposed method significantly surpasses state-of-the-art competitors while retaining favorable efficiency metrics.","On classification tasks, our DMT framework utilizing three different self-supervised ViT-Base teachers enhances the performance of both small/tiny models and the base model itself.","For dense tasks, DMT elevates the AP/mIoU of standard SSL models on MS-COCO and ADE20K datasets by 4.0%."],"url":"http://arxiv.org/abs/2312.11938v1"}
{"created":"2023-12-19 08:27:02","title":"Parameterized Decision-making with Multi-modal Perception for Autonomous Driving","abstract":"Autonomous driving is an emerging technology that has advanced rapidly over the last decade. Modern transportation is expected to benefit greatly from a wise decision-making framework of autonomous vehicles, including the improvement of mobility and the minimization of risks and travel time. However, existing methods either ignore the complexity of environments only fitting straight roads, or ignore the impact on surrounding vehicles during optimization phases, leading to weak environmental adaptability and incomplete optimization objectives. To address these limitations, we propose a parameterized decision-making framework with multi-modal perception based on deep reinforcement learning, called AUTO. We conduct a comprehensive perception to capture the state features of various traffic participants around the autonomous vehicle, based on which we design a graph-based model to learn a state representation of the multi-modal semantic features. To distinguish between lane-following and lane-changing, we decompose an action of the autonomous vehicle into a parameterized action structure that first decides whether to change lanes and then computes an exact action to execute. A hybrid reward function takes into account aspects of safety, traffic efficiency, passenger comfort, and impact to guide the framework to generate optimal actions. In addition, we design a regularization term and a multi-worker paradigm to enhance the training. Extensive experiments offer evidence that AUTO can advance state-of-the-art in terms of both macroscopic and microscopic effectiveness.","sentences":["Autonomous driving is an emerging technology that has advanced rapidly over the last decade.","Modern transportation is expected to benefit greatly from a wise decision-making framework of autonomous vehicles, including the improvement of mobility and the minimization of risks and travel time.","However, existing methods either ignore the complexity of environments only fitting straight roads, or ignore the impact on surrounding vehicles during optimization phases, leading to weak environmental adaptability and incomplete optimization objectives.","To address these limitations, we propose a parameterized decision-making framework with multi-modal perception based on deep reinforcement learning, called AUTO.","We conduct a comprehensive perception to capture the state features of various traffic participants around the autonomous vehicle, based on which we design a graph-based model to learn a state representation of the multi-modal semantic features.","To distinguish between lane-following and lane-changing, we decompose an action of the autonomous vehicle into a parameterized action structure that first decides whether to change lanes and then computes an exact action to execute.","A hybrid reward function takes into account aspects of safety, traffic efficiency, passenger comfort, and impact to guide the framework to generate optimal actions.","In addition, we design a regularization term and a multi-worker paradigm to enhance the training.","Extensive experiments offer evidence that AUTO can advance state-of-the-art in terms of both macroscopic and microscopic effectiveness."],"url":"http://arxiv.org/abs/2312.11935v1"}
{"created":"2023-12-19 08:20:19","title":"Identification of Causal Structure with Latent Variables Based on Higher Order Cumulants","abstract":"Causal discovery with latent variables is a crucial but challenging task. Despite the emergence of numerous methods aimed at addressing this challenge, they are not fully identified to the structure that two observed variables are influenced by one latent variable and there might be a directed edge in between. Interestingly, we notice that this structure can be identified through the utilization of higher-order cumulants. By leveraging the higher-order cumulants of non-Gaussian data, we provide an analytical solution for estimating the causal coefficients or their ratios. With the estimated (ratios of) causal coefficients, we propose a novel approach to identify the existence of a causal edge between two observed variables subject to latent variable influence. In case when such a causal edge exits, we introduce an asymmetry criterion to determine the causal direction. The experimental results demonstrate the effectiveness of our proposed method.","sentences":["Causal discovery with latent variables is a crucial but challenging task.","Despite the emergence of numerous methods aimed at addressing this challenge, they are not fully identified to the structure that two observed variables are influenced by one latent variable and there might be a directed edge in between.","Interestingly, we notice that this structure can be identified through the utilization of higher-order cumulants.","By leveraging the higher-order cumulants of non-Gaussian data, we provide an analytical solution for estimating the causal coefficients or their ratios.","With the estimated (ratios of) causal coefficients, we propose a novel approach to identify the existence of a causal edge between two observed variables subject to latent variable influence.","In case when such a causal edge exits, we introduce an asymmetry criterion to determine the causal direction.","The experimental results demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2312.11934v1"}
{"created":"2023-12-19 08:20:09","title":"Dynamic Frequency Domain Graph Convolutional Network for Traffic Forecasting","abstract":"Complex spatial dependencies in transportation networks make traffic prediction extremely challenging. Much existing work is devoted to learning dynamic graph structures among sensors, and the strategy of mining spatial dependencies from traffic data, known as data-driven, tends to be an intuitive and effective approach. However, Time-Shift of traffic patterns and noise induced by random factors hinder data-driven spatial dependence modeling. In this paper, we propose a novel dynamic frequency domain graph convolution network (DFDGCN) to capture spatial dependencies. Specifically, we mitigate the effects of time-shift by Fourier transform, and introduce the identity embedding of sensors and time embedding when capturing data for graph learning since traffic data with noise is not entirely reliable. The graph is combined with static predefined and self-adaptive graphs during graph convolution to predict future traffic data through classical causal convolutions. Extensive experiments on four real-world datasets demonstrate that our model is effective and outperforms the baselines.","sentences":["Complex spatial dependencies in transportation networks make traffic prediction extremely challenging.","Much existing work is devoted to learning dynamic graph structures among sensors, and the strategy of mining spatial dependencies from traffic data, known as data-driven, tends to be an intuitive and effective approach.","However, Time-Shift of traffic patterns and noise induced by random factors hinder data-driven spatial dependence modeling.","In this paper, we propose a novel dynamic frequency domain graph convolution network (DFDGCN) to capture spatial dependencies.","Specifically, we mitigate the effects of time-shift by Fourier transform, and introduce the identity embedding of sensors and time embedding when capturing data for graph learning since traffic data with noise is not entirely reliable.","The graph is combined with static predefined and self-adaptive graphs during graph convolution to predict future traffic data through classical causal convolutions.","Extensive experiments on four real-world datasets demonstrate that our model is effective and outperforms the baselines."],"url":"http://arxiv.org/abs/2312.11933v1"}
{"created":"2023-12-19 08:18:26","title":"Unravelling Expressive Delegations: Complexity and Normative Analysis","abstract":"We consider binary group decision-making under a rich model of liquid democracy recently proposed by Colley, Grandi, and Novaro (2022): agents submit ranked delegation options, where each option may be a function of multiple agents' votes; e.g., \"I vote yes if a majority of my friends vote yes.\" Such ballots are unravelled into a profile of direct votes by selecting one entry from each ballot so as not to introduce cyclic dependencies. We study delegation via monotonic Boolean functions, and two unravelling procedures: MinSum, which minimises the sum of the ranks of the chosen entries, and its egalitarian counterpart, MinMax. We provide complete computational dichotomies: MinSum is hard to compute (and approximate) as soon as any non-trivial functions are permitted, and polynomial otherwise; for MinMax the easiness results extend to arbitrary-arity logical ORs and ANDs taken in isolation, but not beyond. For the classic model of delegating to individual agents, we give asymptotically near-tight algorithms for carrying out the two procedures and efficient algorithms for finding optimal unravellings with the highest vote count for a given alternative. These algorithms inspire novel tie-breaking rules for the setup of voting to change a status quo. We then introduce a new axiom, which can be viewed as a variant of the participation axiom, and use algorithmic techniques developed earlier in the paper to show that it is satisfied by MinSum and a lexicographic refinement of MinMax (but not MinMax itself).","sentences":["We consider binary group decision-making under a rich model of liquid democracy recently proposed by Colley, Grandi, and Novaro (2022): agents submit ranked delegation options, where each option may be a function of multiple agents' votes; e.g., \"I vote yes if a majority of my friends vote yes.\"","Such ballots are unravelled into a profile of direct votes by selecting one entry from each ballot so as not to introduce cyclic dependencies.","We study delegation via monotonic Boolean functions, and two unravelling procedures: MinSum, which minimises the sum of the ranks of the chosen entries, and its egalitarian counterpart, MinMax.","We provide complete computational dichotomies: MinSum is hard to compute (and approximate) as soon as any non-trivial functions are permitted, and polynomial otherwise; for MinMax the easiness results extend to arbitrary-arity logical ORs and ANDs taken in isolation, but not beyond.","For the classic model of delegating to individual agents, we give asymptotically near-tight algorithms for carrying out the two procedures and efficient algorithms for finding optimal unravellings with the highest vote count for a given alternative.","These algorithms inspire novel tie-breaking rules for the setup of voting to change a status quo.","We then introduce a new axiom, which can be viewed as a variant of the participation axiom, and use algorithmic techniques developed earlier in the paper to show that it is satisfied by MinSum and a lexicographic refinement of MinMax (but not MinMax itself)."],"url":"http://arxiv.org/abs/2312.11932v1"}
{"created":"2023-12-19 08:07:41","title":"Big Learning Expectation Maximization","abstract":"Mixture models serve as one fundamental tool with versatile applications. However, their training techniques, like the popular Expectation Maximization (EM) algorithm, are notoriously sensitive to parameter initialization and often suffer from bad local optima that could be arbitrarily worse than the optimal. To address the long-lasting bad-local-optima challenge, we draw inspiration from the recent ground-breaking foundation models and propose to leverage their underlying big learning principle to upgrade the EM. Specifically, we present the Big Learning EM (BigLearn-EM), an EM upgrade that simultaneously performs joint, marginal, and orthogonally transformed marginal matchings between data and model distributions. Through simulated experiments, we empirically show that the BigLearn-EM is capable of delivering the optimal with high probability; comparisons on benchmark clustering datasets further demonstrate its effectiveness and advantages over existing techniques. The code is available at https://github.com/YulaiCong/Big-Learning-Expectation-Maximization.","sentences":["Mixture models serve as one fundamental tool with versatile applications.","However, their training techniques, like the popular Expectation Maximization (EM) algorithm, are notoriously sensitive to parameter initialization and often suffer from bad local optima that could be arbitrarily worse than the optimal.","To address the long-lasting bad-local-optima challenge, we draw inspiration from the recent ground-breaking foundation models and propose to leverage their underlying big learning principle to upgrade the EM.","Specifically, we present the Big Learning EM (BigLearn-EM), an EM upgrade that simultaneously performs joint, marginal, and orthogonally transformed marginal matchings between data and model distributions.","Through simulated experiments, we empirically show that the BigLearn-EM is capable of delivering the optimal with high probability; comparisons on benchmark clustering datasets further demonstrate its effectiveness and advantages over existing techniques.","The code is available at https://github.com/YulaiCong/Big-Learning-Expectation-Maximization."],"url":"http://arxiv.org/abs/2312.11926v1"}
{"created":"2023-12-19 08:00:10","title":"External Knowledge Augmented Polyphone Disambiguation Using Large Language Model","abstract":"One of the key issues in Mandarin Chinese text-to-speech (TTS) systems is polyphone disambiguation when doing grapheme-to-phoneme (G2P) conversion. In this paper, we introduce a novel method to solve the problem as a generation task. Following the trending research of large language models (LLM) and prompt learning, the proposed method consists of three modules. Retrieval module incorporates external knowledge which is a multi-level semantic dictionary of Chinese polyphonic characters to format the sentence into a prompt. Generation module adopts the decoder-only Transformer architecture to induce the target text. Postprocess module corrects the generated text into a valid result if needed. Experimental results show that our method outperforms the existing methods on a public dataset called CPP. We also empirically study the impacts of different templates of the prompt, different sizes of training data, and whether to incorporate external knowledge.","sentences":["One of the key issues in Mandarin Chinese text-to-speech (TTS) systems is polyphone disambiguation when doing grapheme-to-phoneme (G2P) conversion.","In this paper, we introduce a novel method to solve the problem as a generation task.","Following the trending research of large language models (LLM) and prompt learning, the proposed method consists of three modules.","Retrieval module incorporates external knowledge which is a multi-level semantic dictionary of Chinese polyphonic characters to format the sentence into a prompt.","Generation module adopts the decoder-only Transformer architecture to induce the target text.","Postprocess module corrects the generated text into a valid result if needed.","Experimental results show that our method outperforms the existing methods on a public dataset called CPP.","We also empirically study the impacts of different templates of the prompt, different sizes of training data, and whether to incorporate external knowledge."],"url":"http://arxiv.org/abs/2312.11920v1"}
{"created":"2023-12-19 07:23:49","title":"Convergence Visualizer of Decentralized Federated Distillation with Reduced Communication Costs","abstract":"Federated learning (FL) achieves collaborative learning without the need for data sharing, thus preventing privacy leakage. To extend FL into a fully decentralized algorithm, researchers have applied distributed optimization algorithms to FL by considering machine learning (ML) tasks as parameter optimization problems. Conversely, the consensus-based multi-hop federated distillation (CMFD) proposed in the authors' previous work makes neural network (NN) models get close with others in a function space rather than in a parameter space. Hence, this study solves two unresolved challenges of CMFD: (1) communication cost reduction and (2) visualization of model convergence. Based on a proposed dynamic communication cost reduction method (DCCR), the amount of data transferred in a network is reduced; however, with a slight degradation in the prediction accuracy. In addition, a technique for visualizing the distance between the NN models in a function space is also proposed. The technique applies a dimensionality reduction technique by approximating infinite-dimensional functions as numerical vectors to visualize the trajectory of how the models change by the distributed learning algorithm.","sentences":["Federated learning (FL) achieves collaborative learning without the need for data sharing, thus preventing privacy leakage.","To extend FL into a fully decentralized algorithm, researchers have applied distributed optimization algorithms to FL by considering machine learning (ML) tasks as parameter optimization problems.","Conversely, the consensus-based multi-hop federated distillation (CMFD) proposed in the authors' previous work makes neural network (NN) models get close with others in a function space rather than in a parameter space.","Hence, this study solves two unresolved challenges of CMFD: (1) communication cost reduction and (2) visualization of model convergence.","Based on a proposed dynamic communication cost reduction method (DCCR), the amount of data transferred in a network is reduced; however, with a slight degradation in the prediction accuracy.","In addition, a technique for visualizing the distance between the NN models in a function space is also proposed.","The technique applies a dimensionality reduction technique by approximating infinite-dimensional functions as numerical vectors to visualize the trajectory of how the models change by the distributed learning algorithm."],"url":"http://arxiv.org/abs/2312.11905v1"}
{"created":"2023-12-19 06:47:22","title":"Short-Term Multi-Horizon Line Loss Rate Forecasting of a Distribution Network Using Attention-GCN-LSTM","abstract":"Accurately predicting line loss rates is vital for effective line loss management in distribution networks, especially over short-term multi-horizons ranging from one hour to one week. In this study, we propose Attention-GCN-LSTM, a novel method that combines Graph Convolutional Networks (GCN), Long Short-Term Memory (LSTM), and a three-level attention mechanism to address this challenge. By capturing spatial and temporal dependencies, our model enables accurate forecasting of line loss rates across multiple horizons. Through comprehensive evaluation using real-world data from 10KV feeders, our Attention-GCN-LSTM model consistently outperforms existing algorithms, exhibiting superior performance in terms of prediction accuracy and multi-horizon forecasting. This model holds significant promise for enhancing line loss management in distribution networks.","sentences":["Accurately predicting line loss rates is vital for effective line loss management in distribution networks, especially over short-term multi-horizons ranging from one hour to one week.","In this study, we propose Attention-GCN-LSTM, a novel method that combines Graph Convolutional Networks (GCN), Long Short-Term Memory (LSTM), and a three-level attention mechanism to address this challenge.","By capturing spatial and temporal dependencies, our model enables accurate forecasting of line loss rates across multiple horizons.","Through comprehensive evaluation using real-world data from 10KV feeders, our Attention-GCN-LSTM model consistently outperforms existing algorithms, exhibiting superior performance in terms of prediction accuracy and multi-horizon forecasting.","This model holds significant promise for enhancing line loss management in distribution networks."],"url":"http://arxiv.org/abs/2312.11898v1"}
{"created":"2023-12-19 06:42:47","title":"Text-Conditioned Resampler For Long Form Video Understanding","abstract":"Videos are highly redundant data source and it is often enough to identify a few key moments to solve any given task. In this paper, we present a text-conditioned video resampler (TCR) module that uses a pre-trained and frozen visual encoder and large language model (LLM) to process long video sequences for a task. TCR localises relevant visual features from the video given a text condition and provides them to a LLM to generate a text response. Due to its lightweight design and use of cross-attention, TCR can process more than 100 frames at a time allowing the model to use much longer chunks of video than earlier works. We make the following contributions: (i) we design a transformer-based sampling architecture that can process long videos conditioned on a task, together with a training method that enables it to bridge pre-trained visual and language models; (ii) we empirically validate its efficacy on a wide variety of evaluation tasks, and set a new state-of-the-art on NextQA, EgoSchema, and the EGO4D-LTA challenge; and (iii) we determine tasks which require longer video contexts and that can thus be used effectively for further evaluation of long-range video models.","sentences":["Videos are highly redundant data source and it is often enough to identify a few key moments to solve any given task.","In this paper, we present a text-conditioned video resampler (TCR) module that uses a pre-trained and frozen visual encoder and large language model (LLM) to process long video sequences for a task.","TCR localises relevant visual features from the video given a text condition and provides them to a LLM to generate a text response.","Due to its lightweight design and use of cross-attention, TCR can process more than 100 frames at a time allowing the model to use much longer chunks of video than earlier works.","We make the following contributions: (i) we design a transformer-based sampling architecture that can process long videos conditioned on a task, together with a training method that enables it to bridge pre-trained visual and language models; (ii) we empirically validate its efficacy on a wide variety of evaluation tasks, and set a new state-of-the-art on NextQA, EgoSchema, and the EGO4D-LTA challenge; and (iii) we determine tasks which require longer video contexts and that can thus be used effectively for further evaluation of long-range video models."],"url":"http://arxiv.org/abs/2312.11897v1"}
{"created":"2023-12-19 06:38:18","title":"3D-LFM: Lifting Foundation Model","abstract":"The lifting of 3D structure and camera from 2D landmarks is at the cornerstone of the entire discipline of computer vision. Traditional methods have been confined to specific rigid objects, such as those in Perspective-n-Point (PnP) problems, but deep learning has expanded our capability to reconstruct a wide range of object classes (e.g. C3PDO and PAUL) with resilience to noise, occlusions, and perspective distortions. All these techniques, however, have been limited by the fundamental need to establish correspondences across the 3D training data -- significantly limiting their utility to applications where one has an abundance of \"in-correspondence\" 3D data. Our approach harnesses the inherent permutation equivariance of transformers to manage varying number of points per 3D data instance, withstands occlusions, and generalizes to unseen categories. We demonstrate state of the art performance across 2D-3D lifting task benchmarks. Since our approach can be trained across such a broad class of structures we refer to it simply as a 3D Lifting Foundation Model (3D-LFM) -- the first of its kind.","sentences":["The lifting of 3D structure and camera from 2D landmarks is at the cornerstone of the entire discipline of computer vision.","Traditional methods have been confined to specific rigid objects, such as those in Perspective-n-Point (PnP) problems, but deep learning has expanded our capability to reconstruct a wide range of object classes (e.g. C3PDO and PAUL) with resilience to noise, occlusions, and perspective distortions.","All these techniques, however, have been limited by the fundamental need to establish correspondences across the 3D training data -- significantly limiting their utility to applications where one has an abundance of \"in-correspondence\" 3D data.","Our approach harnesses the inherent permutation equivariance of transformers to manage varying number of points per 3D data instance, withstands occlusions, and generalizes to unseen categories.","We demonstrate state of the art performance across 2D-3D lifting task benchmarks.","Since our approach can be trained across such a broad class of structures we refer to it simply as a 3D Lifting Foundation Model (3D-LFM) -- the first of its kind."],"url":"http://arxiv.org/abs/2312.11894v1"}
{"created":"2023-12-19 06:26:25","title":"Difficulty-Focused Contrastive Learning for Knowledge Tracing with a Large Language Model-Based Difficulty Prediction","abstract":"This paper presents novel techniques for enhancing the performance of knowledge tracing (KT) models by focusing on the crucial factor of question and concept difficulty level. Despite the acknowledged significance of difficulty, previous KT research has yet to exploit its potential for model optimization and has struggled to predict difficulty from unseen data. To address these problems, we propose a difficulty-centered contrastive learning method for KT models and a Large Language Model (LLM)-based framework for difficulty prediction. These innovative methods seek to improve the performance of KT models and provide accurate difficulty estimates for unseen data. Our ablation study demonstrates the efficacy of these techniques by demonstrating enhanced KT model performance. Nonetheless, the complex relationship between language and difficulty merits further investigation.","sentences":["This paper presents novel techniques for enhancing the performance of knowledge tracing (KT) models by focusing on the crucial factor of question and concept difficulty level.","Despite the acknowledged significance of difficulty, previous KT research has yet to exploit its potential for model optimization and has struggled to predict difficulty from unseen data.","To address these problems, we propose a difficulty-centered contrastive learning method for KT models and a Large Language Model (LLM)-based framework for difficulty prediction.","These innovative methods seek to improve the performance of KT models and provide accurate difficulty estimates for unseen data.","Our ablation study demonstrates the efficacy of these techniques by demonstrating enhanced KT model performance.","Nonetheless, the complex relationship between language and difficulty merits further investigation."],"url":"http://arxiv.org/abs/2312.11890v1"}
{"created":"2023-12-19 06:20:27","title":"A Large-Scale Dataset of Search Interests Related to Disease X Originating from Different Geographic Regions","abstract":"The World Health Organization added Disease X to their shortlist of blueprint priority diseases to represent a hypothetical, unknown pathogen that could cause a future epidemic. During different virus outbreaks of the past, such as COVID-19, Influenza, Lyme Disease, and Zika virus, researchers from various disciplines utilized Google Trends to mine multimodal components of web behavior to study, investigate, and analyze the global awareness, preparedness, and response associated with these respective virus outbreaks. As the world prepares for Disease X, a dataset on web behavior related to Disease X would be crucial to contribute towards the timely advancement of research in this field. Furthermore, none of the prior works in this field have focused on the development of a dataset to compile relevant web behavior data, which would help to prepare for Disease X. To address these research challenges, this work presents a dataset of web behavior related to Disease X, which emerged from different geographic regions of the world, between February 2018 and August 2023. Specifically, this dataset presents the search interests related to Disease X from 94 geographic regions. The dataset was developed by collecting data using Google Trends. The relevant search interests for all these regions for each month in this time range are available in this dataset. This paper also discusses the compliance of this dataset with the FAIR principles of scientific data management. Finally, an analysis of this dataset is presented to uphold the applicability, relevance, and usefulness of this dataset for the investigation of different research questions in the interrelated fields of Big Data, Data Mining, Healthcare, Epidemiology, and Data Analysis with a specific focus on Disease X.","sentences":["The World Health Organization added Disease X to their shortlist of blueprint priority diseases to represent a hypothetical, unknown pathogen that could cause a future epidemic.","During different virus outbreaks of the past, such as COVID-19, Influenza, Lyme Disease, and Zika virus, researchers from various disciplines utilized Google Trends to mine multimodal components of web behavior to study, investigate, and analyze the global awareness, preparedness, and response associated with these respective virus outbreaks.","As the world prepares for Disease X, a dataset on web behavior related to Disease X would be crucial to contribute towards the timely advancement of research in this field.","Furthermore, none of the prior works in this field have focused on the development of a dataset to compile relevant web behavior data, which would help to prepare for Disease X. To address these research challenges, this work presents a dataset of web behavior related to Disease X, which emerged from different geographic regions of the world, between February 2018 and August 2023.","Specifically, this dataset presents the search interests related to Disease X from 94 geographic regions.","The dataset was developed by collecting data using Google Trends.","The relevant search interests for all these regions for each month in this time range are available in this dataset.","This paper also discusses the compliance of this dataset with the FAIR principles of scientific data management.","Finally, an analysis of this dataset is presented to uphold the applicability, relevance, and usefulness of this dataset for the investigation of different research questions in the interrelated fields of Big Data, Data Mining, Healthcare, Epidemiology, and Data Analysis with a specific focus on Disease X."],"url":"http://arxiv.org/abs/2312.11885v1"}
{"created":"2023-12-19 06:15:52","title":"Punctuation restoration Model and Spacing Model for Korean Ancient Document","abstract":"In Korean ancient documents, there is no spacing or punctuation, and they are written in classical Chinese characters. This makes it challenging for modern individuals and translation models to accurately interpret and translate them. While China has models predicting punctuation and spacing, applying them directly to Korean texts is problematic due to data differences. Therefore, we developed the first models which predict punctuation and spacing for Korean historical texts and evaluated their performance. Our punctuation restoration model achieved an F1 score of 0.84, and Spacing model achieved a score of 0.96. It has the advantage of enabling inference on low-performance GPUs with less VRAM while maintaining quite high accuracy.","sentences":["In Korean ancient documents, there is no spacing or punctuation, and they are written in classical Chinese characters.","This makes it challenging for modern individuals and translation models to accurately interpret and translate them.","While China has models predicting punctuation and spacing, applying them directly to Korean texts is problematic due to data differences.","Therefore, we developed the first models which predict punctuation and spacing for Korean historical texts and evaluated their performance.","Our punctuation restoration model achieved an F1 score of 0.84, and Spacing model achieved a score of 0.96.","It has the advantage of enabling inference on low-performance GPUs with less VRAM while maintaining quite high accuracy."],"url":"http://arxiv.org/abs/2312.11881v1"}
{"created":"2023-12-19 06:13:58","title":"Point Cloud Segmentation Using Transfer Learning with RandLA-Net: A Case Study on Urban Areas","abstract":"Urban environments are characterized by complex structures and diverse features, making accurate segmentation of point cloud data a challenging task. This paper presents a comprehensive study on the application of RandLA-Net, a state-of-the-art neural network architecture, for the 3D segmentation of large-scale point cloud data in urban areas. The study focuses on three major Chinese cities, namely Chengdu, Jiaoda, and Shenzhen, leveraging their unique characteristics to enhance segmentation performance.   To address the limited availability of labeled data for these specific urban areas, we employed transfer learning techniques. We transferred the learned weights from the Sensat Urban and Toronto 3D datasets to initialize our RandLA-Net model. Additionally, we performed class remapping to adapt the model to the target urban areas, ensuring accurate segmentation results.   The experimental results demonstrate the effectiveness of the proposed approach achieving over 80\\% F1 score for each areas in 3D point cloud segmentation. The transfer learning strategy proves to be crucial in overcoming data scarcity issues, providing a robust solution for urban point cloud analysis. The findings contribute to the advancement of point cloud segmentation methods, especially in the context of rapidly evolving Chinese urban areas.","sentences":["Urban environments are characterized by complex structures and diverse features, making accurate segmentation of point cloud data a challenging task.","This paper presents a comprehensive study on the application of RandLA-Net, a state-of-the-art neural network architecture, for the 3D segmentation of large-scale point cloud data in urban areas.","The study focuses on three major Chinese cities, namely Chengdu, Jiaoda, and Shenzhen, leveraging their unique characteristics to enhance segmentation performance.   ","To address the limited availability of labeled data for these specific urban areas, we employed transfer learning techniques.","We transferred the learned weights from the Sensat Urban and Toronto 3D datasets to initialize our RandLA-Net model.","Additionally, we performed class remapping to adapt the model to the target urban areas, ensuring accurate segmentation results.   ","The experimental results demonstrate the effectiveness of the proposed approach achieving over 80\\% F1 score for each areas in 3D point cloud segmentation.","The transfer learning strategy proves to be crucial in overcoming data scarcity issues, providing a robust solution for urban point cloud analysis.","The findings contribute to the advancement of point cloud segmentation methods, especially in the context of rapidly evolving Chinese urban areas."],"url":"http://arxiv.org/abs/2312.11880v1"}
{"created":"2023-12-19 05:59:16","title":"Faster Algorithms for Internal Dictionary Queries","abstract":"In this paper, we consider the problem of preprocessing a text $T$ of length $n$ and a dictionary $\\mathcal{D}$ to answer multiple types of pattern queries. Inspired by [Charalampopoulos-Kociumaka-Mohamed-Radoszewski-Rytter-Wale\\'n ISAAC 2019], we consider the Internal Dictionary, where the dictionary is interval in the sense that every pattern is given as a fragment of $T$. Therefore, the size of $\\mathcal{D}$ is proportional to the number of patterns instead of their total length, which could be $\\Theta(n \\cdot |\\mathcal{D}|)$. We propose a new technique to preprocess $T$ and organize the substring structure. In this way, we are able to develop algorithms to answer queries more efficiently than in previous works.","sentences":["In this paper, we consider the problem of preprocessing a text $T$ of length $n$ and a dictionary $\\mathcal{D}$ to answer multiple types of pattern queries.","Inspired by [Charalampopoulos-Kociumaka-Mohamed-Radoszewski-Rytter-Wale\\'n ISAAC 2019], we consider the Internal Dictionary, where the dictionary is interval in the sense that every pattern is given as a fragment of $T$. Therefore, the size of $\\mathcal{D}$ is proportional to the number of patterns instead of their total length, which could be $\\Theta(n \\cdot","|\\mathcal{D}|)$.","We propose a new technique to preprocess $T$ and organize the substring structure.","In this way, we are able to develop algorithms to answer queries more efficiently than in previous works."],"url":"http://arxiv.org/abs/2312.11873v1"}
{"created":"2023-12-19 05:52:38","title":"Beyond Prototypes: Semantic Anchor Regularization for Better Representation Learning","abstract":"One of the ultimate goals of representation learning is to achieve compactness within a class and well-separability between classes. Many outstanding metric-based and prototype-based methods following the Expectation-Maximization paradigm, have been proposed for this objective. However, they inevitably introduce biases into the learning process, particularly with long-tail distributed training data. In this paper, we reveal that the class prototype is not necessarily to be derived from training features and propose a novel perspective to use pre-defined class anchors serving as feature centroid to unidirectionally guide feature learning. However, the pre-defined anchors may have a large semantic distance from the pixel features, which prevents them from being directly applied. To address this issue and generate feature centroid independent from feature learning, a simple yet effective Semantic Anchor Regularization (SAR) is proposed. SAR ensures the interclass separability of semantic anchors in the semantic space by employing a classifier-aware auxiliary cross-entropy loss during training via disentanglement learning. By pulling the learned features to these semantic anchors, several advantages can be attained: 1) the intra-class compactness and naturally inter-class separability, 2) induced bias or errors from feature learning can be avoided, and 3) robustness to the long-tailed problem. The proposed SAR can be used in a plug-and-play manner in the existing models. Extensive experiments demonstrate that the SAR performs better than previous sophisticated prototype-based methods. The implementation is available at https://github.com/geyanqi/SAR.","sentences":["One of the ultimate goals of representation learning is to achieve compactness within a class and well-separability between classes.","Many outstanding metric-based and prototype-based methods following the Expectation-Maximization paradigm, have been proposed for this objective.","However, they inevitably introduce biases into the learning process, particularly with long-tail distributed training data.","In this paper, we reveal that the class prototype is not necessarily to be derived from training features and propose a novel perspective to use pre-defined class anchors serving as feature centroid to unidirectionally guide feature learning.","However, the pre-defined anchors may have a large semantic distance from the pixel features, which prevents them from being directly applied.","To address this issue and generate feature centroid independent from feature learning, a simple yet effective Semantic Anchor Regularization (SAR) is proposed.","SAR ensures the interclass separability of semantic anchors in the semantic space by employing a classifier-aware auxiliary cross-entropy loss during training via disentanglement learning.","By pulling the learned features to these semantic anchors, several advantages can be attained: 1) the intra-class compactness and naturally inter-class separability, 2) induced bias or errors from feature learning can be avoided, and 3) robustness to the long-tailed problem.","The proposed SAR can be used in a plug-and-play manner in the existing models.","Extensive experiments demonstrate that the SAR performs better than previous sophisticated prototype-based methods.","The implementation is available at https://github.com/geyanqi/SAR."],"url":"http://arxiv.org/abs/2312.11872v1"}
{"created":"2023-12-19 05:17:27","title":"Neural Network Approximation for Pessimistic Offline Reinforcement Learning","abstract":"Deep reinforcement learning (RL) has shown remarkable success in specific offline decision-making scenarios, yet its theoretical guarantees are still under development. Existing works on offline RL theory primarily emphasize a few trivial settings, such as linear MDP or general function approximation with strong assumptions and independent data, which lack guidance for practical use. The coupling of deep learning and Bellman residuals makes this problem challenging, in addition to the difficulty of data dependence. In this paper, we establish a non-asymptotic estimation error of pessimistic offline RL using general neural network approximation with $\\mathcal{C}$-mixing data regarding the structure of networks, the dimension of datasets, and the concentrability of data coverage, under mild assumptions. Our result shows that the estimation error consists of two parts: the first converges to zero at a desired rate on the sample size with partially controllable concentrability, and the second becomes negligible if the residual constraint is tight. This result demonstrates the explicit efficiency of deep adversarial offline RL frameworks. We utilize the empirical process tool for $\\mathcal{C}$-mixing sequences and the neural network approximation theory for the H\\\"{o}lder class to achieve this. We also develop methods to bound the Bellman estimation error caused by function approximation with empirical Bellman constraint perturbations. Additionally, we present a result that lessens the curse of dimensionality using data with low intrinsic dimensionality and function classes with low complexity. Our estimation provides valuable insights into the development of deep offline RL and guidance for algorithm model design.","sentences":["Deep reinforcement learning (RL) has shown remarkable success in specific offline decision-making scenarios, yet its theoretical guarantees are still under development.","Existing works on offline RL theory primarily emphasize a few trivial settings, such as linear MDP or general function approximation with strong assumptions and independent data, which lack guidance for practical use.","The coupling of deep learning and Bellman residuals makes this problem challenging, in addition to the difficulty of data dependence.","In this paper, we establish a non-asymptotic estimation error of pessimistic offline RL using general neural network approximation with $\\mathcal{C}$-mixing data regarding the structure of networks, the dimension of datasets, and the concentrability of data coverage, under mild assumptions.","Our result shows that the estimation error consists of two parts: the first converges to zero at a desired rate on the sample size with partially controllable concentrability, and the second becomes negligible if the residual constraint is tight.","This result demonstrates the explicit efficiency of deep adversarial offline RL frameworks.","We utilize the empirical process tool for $\\mathcal{C}$-mixing sequences and the neural network approximation theory for the H\\\"{o}lder class to achieve this.","We also develop methods to bound the Bellman estimation error caused by function approximation with empirical Bellman constraint perturbations.","Additionally, we present a result that lessens the curse of dimensionality using data with low intrinsic dimensionality and function classes with low complexity.","Our estimation provides valuable insights into the development of deep offline RL and guidance for algorithm model design."],"url":"http://arxiv.org/abs/2312.11863v1"}
{"created":"2023-12-19 04:58:37","title":"SimCalib: Graph Neural Network Calibration based on Similarity between Nodes","abstract":"Graph neural networks (GNNs) have exhibited impressive performance in modeling graph data as exemplified in various applications. Recently, the GNN calibration problem has attracted increasing attention, especially in cost-sensitive scenarios. Previous work has gained empirical insights on the issue, and devised effective approaches for it, but theoretical supports still fall short. In this work, we shed light on the relationship between GNN calibration and nodewise similarity via theoretical analysis. A novel calibration framework, named SimCalib, is accordingly proposed to consider similarity between nodes at global and local levels. At the global level, the Mahalanobis distance between the current node and class prototypes is integrated to implicitly consider similarity between the current node and all nodes in the same class. At the local level, the similarity of node representation movement dynamics, quantified by nodewise homophily and relative degree, is considered. Informed about the application of nodewise movement patterns in analyzing nodewise behavior on the over-smoothing problem, we empirically present a possible relationship between over-smoothing and GNN calibration problem. Experimentally, we discover a correlation between nodewise similarity and model calibration improvement, in alignment with our theoretical results. Additionally, we conduct extensive experiments investigating different design factors and demonstrate the effectiveness of our proposed SimCalib framework for GNN calibration by achieving state-of-the-art performance on 14 out of 16 benchmarks.","sentences":["Graph neural networks (GNNs) have exhibited impressive performance in modeling graph data as exemplified in various applications.","Recently, the GNN calibration problem has attracted increasing attention, especially in cost-sensitive scenarios.","Previous work has gained empirical insights on the issue, and devised effective approaches for it, but theoretical supports still fall short.","In this work, we shed light on the relationship between GNN calibration and nodewise similarity via theoretical analysis.","A novel calibration framework, named SimCalib, is accordingly proposed to consider similarity between nodes at global and local levels.","At the global level, the Mahalanobis distance between the current node and class prototypes is integrated to implicitly consider similarity between the current node and all nodes in the same class.","At the local level, the similarity of node representation movement dynamics, quantified by nodewise homophily and relative degree, is considered.","Informed about the application of nodewise movement patterns in analyzing nodewise behavior on the over-smoothing problem, we empirically present a possible relationship between over-smoothing and GNN calibration problem.","Experimentally, we discover a correlation between nodewise similarity and model calibration improvement, in alignment with our theoretical results.","Additionally, we conduct extensive experiments investigating different design factors and demonstrate the effectiveness of our proposed SimCalib framework for GNN calibration by achieving state-of-the-art performance on 14 out of 16 benchmarks."],"url":"http://arxiv.org/abs/2312.11858v1"}
{"created":"2023-12-19 04:55:33","title":"Self-supervised Learning for Enhancing Geometrical Modeling in 3D-Aware Generative Adversarial Network","abstract":"3D-aware Generative Adversarial Networks (3D-GANs) currently exhibit artifacts in their 3D geometrical modeling, such as mesh imperfections and holes. These shortcomings are primarily attributed to the limited availability of annotated 3D data, leading to a constrained \"valid latent area\" for satisfactory modeling. To address this, we present a Self-Supervised Learning (SSL) technique tailored as an auxiliary loss for any 3D-GAN, designed to improve its 3D geometrical modeling capabilities. Our approach pioneers an inversion technique for 3D-GANs, integrating an encoder that performs adaptive spatially-varying range operations. Utilizing this inversion, we introduce the Cyclic Generative Constraint (CGC), aiming to densify the valid latent space. The CGC operates via augmented local latent vectors that maintain the same geometric form, and it imposes constraints on the cycle path outputs, specifically the generator-encoder-generator sequence. This SSL methodology seamlessly integrates with the inherent GAN loss, ensuring the integrity of pre-existing 3D-GAN architectures without necessitating alterations. We validate our approach with comprehensive experiments across various datasets and architectures, underscoring its efficacy. Our project website: https://3dgan-ssl.github.io","sentences":["3D-aware Generative Adversarial Networks (3D-GANs) currently exhibit artifacts in their 3D geometrical modeling, such as mesh imperfections and holes.","These shortcomings are primarily attributed to the limited availability of annotated 3D data, leading to a constrained \"valid latent area\" for satisfactory modeling.","To address this, we present a Self-Supervised Learning (SSL) technique tailored as an auxiliary loss for any 3D-GAN, designed to improve its 3D geometrical modeling capabilities.","Our approach pioneers an inversion technique for 3D-GANs, integrating an encoder that performs adaptive spatially-varying range operations.","Utilizing this inversion, we introduce the Cyclic Generative Constraint (CGC), aiming to densify the valid latent space.","The CGC operates via augmented local latent vectors that maintain the same geometric form, and it imposes constraints on the cycle path outputs, specifically the generator-encoder-generator sequence.","This SSL methodology seamlessly integrates with the inherent GAN loss, ensuring the integrity of pre-existing 3D-GAN architectures without necessitating alterations.","We validate our approach with comprehensive experiments across various datasets and architectures, underscoring its efficacy.","Our project website: https://3dgan-ssl.github.io"],"url":"http://arxiv.org/abs/2312.11856v1"}
{"created":"2023-12-19 04:44:33","title":"Outer Channel of DNA-Based Data Storage: Capacity and Efficient Coding Schemes","abstract":"In this paper, we consider the outer channel for DNA-based data storage, where each DNA string is either correctly transmitted, or being erased, or being corrupted by uniformly distributed random substitution errors, and all strings are randomly shuffled with each other. We first derive the capacity of the outer channel, which surprisingly implies that the uniformly distributed random substitution errors are only as harmful as the erasure errors. Next, we propose efficient coding schemes which encode the bits at the same position of different strings into a codeword. We compute the soft/hard information of each bit, which allows us to independently decode the bits within a codeword, leading to an independent decoding scheme. To improve the decoding performance, we measure the reliability of each string based on the independent decoding result, and perform a further step of decoding over the most reliable strings, leading to a joint decoding scheme. Simulations with low-density parity-check codes confirm that the joint decoding scheme can reduce the frame error rate by more than 3 orders of magnitude compared to the independent decoding scheme, and it can outperform the state-of-the-art decoding scheme in the literature in a wide parameter regions.","sentences":["In this paper, we consider the outer channel for DNA-based data storage, where each DNA string is either correctly transmitted, or being erased, or being corrupted by uniformly distributed random substitution errors, and all strings are randomly shuffled with each other.","We first derive the capacity of the outer channel, which surprisingly implies that the uniformly distributed random substitution errors are only as harmful as the erasure errors.","Next, we propose efficient coding schemes which encode the bits at the same position of different strings into a codeword.","We compute the soft/hard information of each bit, which allows us to independently decode the bits within a codeword, leading to an independent decoding scheme.","To improve the decoding performance, we measure the reliability of each string based on the independent decoding result, and perform a further step of decoding over the most reliable strings, leading to a joint decoding scheme.","Simulations with low-density parity-check codes confirm that the joint decoding scheme can reduce the frame error rate by more than 3 orders of magnitude compared to the independent decoding scheme, and it can outperform the state-of-the-art decoding scheme in the literature in a wide parameter regions."],"url":"http://arxiv.org/abs/2312.11854v1"}
{"created":"2023-12-19 04:42:56","title":"Predicting Human Translation Difficulty with Neural Machine Translation","abstract":"Human translators linger on some words and phrases more than others, and predicting this variation is a step towards explaining the underlying cognitive processes. Using data from the CRITT Translation Process Research Database, we evaluate the extent to which surprisal and attentional features derived from a Neural Machine Translation (NMT) model account for reading and production times of human translators. We find that surprisal and attention are complementary predictors of translation difficulty, and that surprisal derived from a NMT model is the single most successful predictor of production duration. Our analyses draw on data from hundreds of translators operating across 13 language pairs, and represent the most comprehensive investigation of human translation difficulty to date.","sentences":["Human translators linger on some words and phrases more than others, and predicting this variation is a step towards explaining the underlying cognitive processes.","Using data from the CRITT Translation Process Research Database, we evaluate the extent to which surprisal and attentional features derived from a Neural Machine Translation (NMT) model account for reading and production times of human translators.","We find that surprisal and attention are complementary predictors of translation difficulty, and that surprisal derived from a NMT model is the single most successful predictor of production duration.","Our analyses draw on data from hundreds of translators operating across 13 language pairs, and represent the most comprehensive investigation of human translation difficulty to date."],"url":"http://arxiv.org/abs/2312.11852v1"}
{"created":"2023-12-19 04:26:12","title":"Initializing Services in Interactive ML Systems for Diverse Users","abstract":"This paper studies ML systems that interactively learn from users across multiple subpopulations with heterogeneous data distributions. The primary objective is to provide specialized services for different user groups while also predicting user preferences. Once the users select a service based on how well the service anticipated their preference, the services subsequently adapt and refine themselves based on the user data they accumulate, resulting in an iterative, alternating minimization process between users and services (learning dynamics). Employing such tailored approaches has two main challenges: (i) Unknown user preferences: Typically, data on user preferences are unavailable without interaction, and uniform data collection across a large and diverse user base can be prohibitively expensive. (ii) Suboptimal Local Solutions: The total loss (sum of loss functions across all users and all services) landscape is not convex even if the individual losses on a single service are convex, making it likely for the learning dynamics to get stuck in local minima. The final outcome of the aforementioned learning dynamics is thus strongly influenced by the initial set of services offered to users, and is not guaranteed to be close to the globally optimal outcome. In this work, we propose a randomized algorithm to adaptively select very few users to collect preference data from, while simultaneously initializing a set of services. We prove that under mild assumptions on the loss functions, the expected total loss achieved by the algorithm right after initialization is within a factor of the globally optimal total loss with complete user preference data, and this factor scales only logarithmically in the number of services. Our theory is complemented by experiments on real as well as semi-synthetic datasets.","sentences":["This paper studies ML systems that interactively learn from users across multiple subpopulations with heterogeneous data distributions.","The primary objective is to provide specialized services for different user groups while also predicting user preferences.","Once the users select a service based on how well the service anticipated their preference, the services subsequently adapt and refine themselves based on the user data they accumulate, resulting in an iterative, alternating minimization process between users and services (learning dynamics).","Employing such tailored approaches has two main challenges: (i) Unknown user preferences: Typically, data on user preferences are unavailable without interaction, and uniform data collection across a large and diverse user base can be prohibitively expensive.","(ii) Suboptimal Local Solutions: The total loss (sum of loss functions across all users and all services) landscape is not convex even if the individual losses on a single service are convex, making it likely for the learning dynamics to get stuck in local minima.","The final outcome of the aforementioned learning dynamics is thus strongly influenced by the initial set of services offered to users, and is not guaranteed to be close to the globally optimal outcome.","In this work, we propose a randomized algorithm to adaptively select very few users to collect preference data from, while simultaneously initializing a set of services.","We prove that under mild assumptions on the loss functions, the expected total loss achieved by the algorithm right after initialization is within a factor of the globally optimal total loss with complete user preference data, and this factor scales only logarithmically in the number of services.","Our theory is complemented by experiments on real as well as semi-synthetic datasets."],"url":"http://arxiv.org/abs/2312.11846v1"}
{"created":"2023-12-19 04:23:23","title":"A Summary of Privacy-Preserving Data Publishing in the Local Setting","abstract":"The exponential growth of collected, processed, and shared data has given rise to concerns about individuals' privacy. Consequently, various laws and regulations have been established to oversee how organizations handle and safeguard data. One such method is Statistical Disclosure Control, which aims to minimize the risk of exposing confidential information by de-identifying it. This de-identification is achieved through specific privacy-preserving techniques. However, a trade-off exists: de-identified data can often lead to a loss of information, which might impact the accuracy of data analysis and the predictive capability of models. The overarching goal remains to safeguard individual privacy while preserving the data's interpretability, meaning its overall usefulness. Despite advances in Statistical Disclosure Control, the field continues to evolve, with no definitive solution that strikes an optimal balance between privacy and utility. This survey delves into the intricate processes of de-identification. We outline the current privacy-preserving techniques employed in microdata de-identification, delve into privacy measures tailored for various disclosure scenarios, and assess metrics for information loss and predictive performance. Herein, we tackle the primary challenges posed by privacy constraints, overview predominant strategies to mitigate these challenges, categorize privacy-preserving techniques, offer a theoretical assessment of current comparative research, and highlight numerous unresolved issues in the domain.","sentences":["The exponential growth of collected, processed, and shared data has given rise to concerns about individuals' privacy.","Consequently, various laws and regulations have been established to oversee how organizations handle and safeguard data.","One such method is Statistical Disclosure Control, which aims to minimize the risk of exposing confidential information by de-identifying it.","This de-identification is achieved through specific privacy-preserving techniques.","However, a trade-off exists: de-identified data can often lead to a loss of information, which might impact the accuracy of data analysis and the predictive capability of models.","The overarching goal remains to safeguard individual privacy while preserving the data's interpretability, meaning its overall usefulness.","Despite advances in Statistical Disclosure Control, the field continues to evolve, with no definitive solution that strikes an optimal balance between privacy and utility.","This survey delves into the intricate processes of de-identification.","We outline the current privacy-preserving techniques employed in microdata de-identification, delve into privacy measures tailored for various disclosure scenarios, and assess metrics for information loss and predictive performance.","Herein, we tackle the primary challenges posed by privacy constraints, overview predominant strategies to mitigate these challenges, categorize privacy-preserving techniques, offer a theoretical assessment of current comparative research, and highlight numerous unresolved issues in the domain."],"url":"http://arxiv.org/abs/2312.11845v1"}
{"created":"2023-12-19 04:15:59","title":"Enhancing Social Decision-Making of Autonomous Vehicles: A Mixed-Strategy Game Approach With Interaction Orientation Identification","abstract":"The integration of Autonomous Vehicles (AVs) into existing human-driven traffic systems poses considerable challenges, especially within environments where human and machine interactions are frequent and complex, such as at unsignalized intersections. Addressing these challenges, we introduce a novel framework predicated on dynamic and socially-aware decision-making game theory to augment the social decision-making prowess of AVs in mixed driving environments.This comprehensive framework is delineated into three primary modules: Social Tendency Recognition, Mixed-Strategy Game Modeling, and Expert Mode Learning. We introduce 'Interaction Orientation' as a metric to evaluate the social decision-making tendencies of various agents, incorporating both environmental factors and trajectory data. The mixed-strategy game model developed as part of this framework considers the evolution of future traffic scenarios and includes a utility function that balances safety, operational efficiency, and the unpredictability of environmental conditions. To adapt to real-world driving complexities, our framework utilizes dynamic optimization techniques for assimilating and learning from expert human driving strategies. These strategies are compiled into a comprehensive library, serving as a reference for future decision-making processes. Our approach is validated through extensive driving datasets, and the results demonstrate marked enhancements in decision timing, precision.","sentences":["The integration of Autonomous Vehicles (AVs) into existing human-driven traffic systems poses considerable challenges, especially within environments where human and machine interactions are frequent and complex, such as at unsignalized intersections.","Addressing these challenges, we introduce a novel framework predicated on dynamic and socially-aware decision-making game theory to augment the social decision-making prowess of AVs in mixed driving environments.","This comprehensive framework is delineated into three primary modules: Social Tendency Recognition, Mixed-Strategy Game Modeling, and Expert Mode Learning.","We introduce 'Interaction Orientation' as a metric to evaluate the social decision-making tendencies of various agents, incorporating both environmental factors and trajectory data.","The mixed-strategy game model developed as part of this framework considers the evolution of future traffic scenarios and includes a utility function that balances safety, operational efficiency, and the unpredictability of environmental conditions.","To adapt to real-world driving complexities, our framework utilizes dynamic optimization techniques for assimilating and learning from expert human driving strategies.","These strategies are compiled into a comprehensive library, serving as a reference for future decision-making processes.","Our approach is validated through extensive driving datasets, and the results demonstrate marked enhancements in decision timing, precision."],"url":"http://arxiv.org/abs/2312.11843v1"}
{"created":"2023-12-19 04:07:18","title":"An All-Analog in-Memory Computing Architecture for Multi-Bit and Large-Scale Vector Matrix Multiplication","abstract":"Analog in-memory computing (AiMC) is an emerging technology that shows fantastic performance superiority for neural network acceleration. However, as the computational bit-width and scale increase, high-precision data conversion and long-distance data routing will result in unacceptable energy and latency overheads in the AiMC system. In this work, we focus on the potential of in-charge computing and in-time interconnection and show an innovative AiMC architecture, named AiDAC, with three key contributions: (1) AiDAC enhances multibit computing efficiency and reduces data conversion times by grouping capacitors technology; (2) AiDAC first adopts row drivers and column time accumulators to achieve large-scale AiMC arrays integration while minimizing the energy cost of data movements. (3) AiDAC is the first work to support large-scale all-analog multibit vector-matrix multiplication (VMM) operations. The evaluation shows that AiDAC maintains high-precision calculation (less than 0.79% total computing error) while also possessing excellent performance features, such as high parallelism (up to 26.2TOPS), low latency (<20ns/VMM), and high energy efficiency (123.8TOPS/W), for 8bits VMM with 1024 input channels.","sentences":["Analog in-memory computing (AiMC) is an emerging technology that shows fantastic performance superiority for neural network acceleration.","However, as the computational bit-width and scale increase, high-precision data conversion and long-distance data routing will result in unacceptable energy and latency overheads in the AiMC system.","In this work, we focus on the potential of in-charge computing and in-time interconnection and show an innovative AiMC architecture, named AiDAC, with three key contributions: (1) AiDAC enhances multibit computing efficiency and reduces data conversion times by grouping capacitors technology; (2) AiDAC first adopts row drivers and column time accumulators to achieve large-scale AiMC arrays integration while minimizing the energy cost of data movements.","(3) AiDAC is the first work to support large-scale all-analog multibit vector-matrix multiplication (VMM) operations.","The evaluation shows that AiDAC maintains high-precision calculation (less than 0.79% total computing error) while also possessing excellent performance features, such as high parallelism (up to 26.2TOPS), low latency (<20ns/VMM), and high energy efficiency (123.8TOPS/W), for 8bits VMM with 1024 input channels."],"url":"http://arxiv.org/abs/2312.11836v1"}
{"created":"2023-12-19 03:15:50","title":"A Dual-way Enhanced Framework from Text Matching Point of View for Multimodal Entity Linking","abstract":"Multimodal Entity Linking (MEL) aims at linking ambiguous mentions with multimodal information to entity in Knowledge Graph (KG) such as Wikipedia, which plays a key role in many applications. However, existing methods suffer from shortcomings, including modality impurity such as noise in raw image and ambiguous textual entity representation, which puts obstacles to MEL. We formulate multimodal entity linking as a neural text matching problem where each multimodal information (text and image) is treated as a query, and the model learns the mapping from each query to the relevant entity from candidate entities. This paper introduces a dual-way enhanced (DWE) framework for MEL: (1) our model refines queries with multimodal data and addresses semantic gaps using cross-modal enhancers between text and image information. Besides, DWE innovatively leverages fine-grained image attributes, including facial characteristic and scene feature, to enhance and refine visual features. (2)By using Wikipedia descriptions, DWE enriches entity semantics and obtains more comprehensive textual representation, which reduces between textual representation and the entities in KG. Extensive experiments on three public benchmarks demonstrate that our method achieves state-of-the-art (SOTA) performance, indicating the superiority of our model. The code is released on https://github.com/season1blue/DWE","sentences":["Multimodal Entity Linking (MEL) aims at linking ambiguous mentions with multimodal information to entity in Knowledge Graph (KG) such as Wikipedia, which plays a key role in many applications.","However, existing methods suffer from shortcomings, including modality impurity such as noise in raw image and ambiguous textual entity representation, which puts obstacles to MEL.","We formulate multimodal entity linking as a neural text matching problem where each multimodal information (text and image) is treated as a query, and the model learns the mapping from each query to the relevant entity from candidate entities.","This paper introduces a dual-way enhanced (DWE) framework for MEL: (1) our model refines queries with multimodal data and addresses semantic gaps using cross-modal enhancers between text and image information.","Besides, DWE innovatively leverages fine-grained image attributes, including facial characteristic and scene feature, to enhance and refine visual features.","(2)By using Wikipedia descriptions, DWE enriches entity semantics and obtains more comprehensive textual representation, which reduces between textual representation and the entities in KG.","Extensive experiments on three public benchmarks demonstrate that our method achieves state-of-the-art (SOTA) performance, indicating the superiority of our model.","The code is released on https://github.com/season1blue/DWE"],"url":"http://arxiv.org/abs/2312.11816v1"}
{"created":"2023-12-19 03:12:13","title":"Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment","abstract":"Urban environments, characterized by their complex, multi-layered networks encompassing physical, social, economic, and environmental dimensions, face significant challenges in the face of rapid urbanization. These challenges, ranging from traffic congestion and pollution to social inequality, call for advanced technological interventions. Recent developments in big data, artificial intelligence, urban computing, and digital twins have laid the groundwork for sophisticated city modeling and simulation. However, a gap persists between these technological capabilities and their practical implementation in addressing urban challenges in an systemic-intelligent way. This paper proposes Urban Generative Intelligence (UGI), a novel foundational platform integrating Large Language Models (LLMs) into urban systems to foster a new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model trained on city-specific multi-source data, to create embodied agents for various urban tasks. These agents, operating within a textual urban environment emulated by city simulator and urban knowledge graph, interact through a natural language interface, offering an open platform for diverse intelligent and embodied agent development. This platform not only addresses specific urban issues but also simulates complex urban systems, providing a multidisciplinary approach to understand and manage urban complexity. This work signifies a transformative step in city science and urban intelligence, harnessing the power of LLMs to unravel and address the intricate dynamics of urban systems. The code repository with demonstrations will soon be released here https://github.com/tsinghua-fib-lab/UGI.","sentences":["Urban environments, characterized by their complex, multi-layered networks encompassing physical, social, economic, and environmental dimensions, face significant challenges in the face of rapid urbanization.","These challenges, ranging from traffic congestion and pollution to social inequality, call for advanced technological interventions.","Recent developments in big data, artificial intelligence, urban computing, and digital twins have laid the groundwork for sophisticated city modeling and simulation.","However, a gap persists between these technological capabilities and their practical implementation in addressing urban challenges in an systemic-intelligent way.","This paper proposes Urban Generative Intelligence (UGI), a novel foundational platform integrating Large Language Models (LLMs) into urban systems to foster a new paradigm of urban intelligence.","UGI leverages CityGPT, a foundation model trained on city-specific multi-source data, to create embodied agents for various urban tasks.","These agents, operating within a textual urban environment emulated by city simulator and urban knowledge graph, interact through a natural language interface, offering an open platform for diverse intelligent and embodied agent development.","This platform not only addresses specific urban issues but also simulates complex urban systems, providing a multidisciplinary approach to understand and manage urban complexity.","This work signifies a transformative step in city science and urban intelligence, harnessing the power of LLMs to unravel and address the intricate dynamics of urban systems.","The code repository with demonstrations will soon be released here https://github.com/tsinghua-fib-lab/UGI."],"url":"http://arxiv.org/abs/2312.11813v1"}
{"created":"2023-12-19 03:01:31","title":"Advancements and Challenges in Arabic Optical Character Recognition: A Comprehensive Survey","abstract":"Optical character recognition (OCR) is a vital process that involves the extraction of handwritten or printed text from scanned or printed images, converting it into a format that can be understood and processed by machines. This enables further data processing activities such as searching and editing. The automatic extraction of text through OCR plays a crucial role in digitizing documents, enhancing productivity, improving accessibility, and preserving historical records. This paper seeks to offer an exhaustive review of contemporary applications, methodologies, and challenges associated with Arabic Optical Character Recognition (OCR). A thorough analysis is conducted on prevailing techniques utilized throughout the OCR process, with a dedicated effort to discern the most efficacious approaches that demonstrate enhanced outcomes. To ensure a thorough evaluation, a meticulous keyword-search methodology is adopted, encompassing a comprehensive analysis of articles relevant to Arabic OCR, including both backward and forward citation reviews. In addition to presenting cutting-edge techniques and methods, this paper critically identifies research gaps within the realm of Arabic OCR. By highlighting these gaps, we shed light on potential areas for future exploration and development, thereby guiding researchers toward promising avenues in the field of Arabic OCR. The outcomes of this study provide valuable insights for researchers, practitioners, and stakeholders involved in Arabic OCR, ultimately fostering advancements in the field and facilitating the creation of more accurate and efficient OCR systems for the Arabic language.","sentences":["Optical character recognition (OCR) is a vital process that involves the extraction of handwritten or printed text from scanned or printed images, converting it into a format that can be understood and processed by machines.","This enables further data processing activities such as searching and editing.","The automatic extraction of text through OCR plays a crucial role in digitizing documents, enhancing productivity, improving accessibility, and preserving historical records.","This paper seeks to offer an exhaustive review of contemporary applications, methodologies, and challenges associated with Arabic Optical Character Recognition (OCR).","A thorough analysis is conducted on prevailing techniques utilized throughout the OCR process, with a dedicated effort to discern the most efficacious approaches that demonstrate enhanced outcomes.","To ensure a thorough evaluation, a meticulous keyword-search methodology is adopted, encompassing a comprehensive analysis of articles relevant to Arabic OCR, including both backward and forward citation reviews.","In addition to presenting cutting-edge techniques and methods, this paper critically identifies research gaps within the realm of Arabic OCR.","By highlighting these gaps, we shed light on potential areas for future exploration and development, thereby guiding researchers toward promising avenues in the field of Arabic OCR.","The outcomes of this study provide valuable insights for researchers, practitioners, and stakeholders involved in Arabic OCR, ultimately fostering advancements in the field and facilitating the creation of more accurate and efficient OCR systems for the Arabic language."],"url":"http://arxiv.org/abs/2312.11812v1"}
{"created":"2023-12-19 02:11:42","title":"QuanShield: Protecting against Side-Channels Attacks using Self-Destructing Enclaves","abstract":"Trusted Execution Environments (TEEs) allow user processes to create enclaves that protect security-sensitive computation against access from the OS kernel and the hypervisor. Recent work has shown that TEEs are vulnerable to side-channel attacks that allow an adversary to learn secrets shielded in enclaves. The majority of such attacks trigger exceptions or interrupts to trace the control or data flow of enclave execution.   We propose QuanShield, a system that protects enclaves from side-channel attacks that interrupt enclave execution. The main idea behind QuanShield is to strengthen resource isolation by creating an interrupt-free environment on a dedicated CPU core for running enclaves in which enclaves terminate when interrupts occur. QuanShield avoids interrupts by exploiting the tickless scheduling mode supported by recent OS kernels. QuanShield then uses the save area (SA) of the enclave, which is used by the hardware to support interrupt handling, as a second stack. Through an LLVM-based compiler pass, QuanShield modifies enclave instructions to store/load memory references, such as function frame base addresses, to/from the SA. When an interrupt occurs, the hardware overwrites the data in the SA with CPU state, thus ensuring that enclave execution fails. Our evaluation shows that QuanShield significantly raises the bar for interrupt-based attacks with practical overhead.","sentences":["Trusted Execution Environments (TEEs) allow user processes to create enclaves that protect security-sensitive computation against access from the OS kernel and the hypervisor.","Recent work has shown that TEEs are vulnerable to side-channel attacks that allow an adversary to learn secrets shielded in enclaves.","The majority of such attacks trigger exceptions or interrupts to trace the control or data flow of enclave execution.   ","We propose QuanShield, a system that protects enclaves from side-channel attacks that interrupt enclave execution.","The main idea behind QuanShield is to strengthen resource isolation by creating an interrupt-free environment on a dedicated CPU core for running enclaves in which enclaves terminate when interrupts occur.","QuanShield avoids interrupts by exploiting the tickless scheduling mode supported by recent OS kernels.","QuanShield then uses the save area (SA) of the enclave, which is used by the hardware to support interrupt handling, as a second stack.","Through an LLVM-based compiler pass, QuanShield modifies enclave instructions to store/load memory references, such as function frame base addresses, to/from the SA.","When an interrupt occurs, the hardware overwrites the data in the SA with CPU state, thus ensuring that enclave execution fails.","Our evaluation shows that QuanShield significantly raises the bar for interrupt-based attacks with practical overhead."],"url":"http://arxiv.org/abs/2312.11796v1"}
{"created":"2023-12-19 01:57:48","title":"Improvement of inter-protocol fairness for BBR congestion control using machine learning","abstract":"Google's BBR (Bottleneck Bandwidth and Round-trip Propagation Time) approach is used to enhance internet network transmission. It is particularly intended to efficiently handle enormous amounts of data. Traditional TCP (Transmission Control Protocol) algorithms confront the most difficulty in calculating the proper quantity of data to send in order to prevent congestion and bottlenecks. This wastes bandwidth and causes network delays. BBR addresses this issue by adaptively assessing the available bandwidth (also known as bottleneck bandwidth) along the network channel and calculating the round-trip time (RTT) between the sender and receiver. Although when several flows compete for bandwidth, BBR may supply more bandwidth to one flow at the expense of another, resulting in unequal resource distribution. This paper proposes to integrate machine learning with BBR to enhance fairness in resource allocation. This novel strategy can improve bandwidth allocation and provide a more equal distribution of resources among competing flows by using historical BBR data to train an ML model. Further we also implemented a classifier model that is graphic neural network in the congestion control method.","sentences":["Google's BBR (Bottleneck Bandwidth and Round-trip Propagation Time) approach is used to enhance internet network transmission.","It is particularly intended to efficiently handle enormous amounts of data.","Traditional TCP (Transmission Control Protocol) algorithms confront the most difficulty in calculating the proper quantity of data to send in order to prevent congestion and bottlenecks.","This wastes bandwidth and causes network delays.","BBR addresses this issue by adaptively assessing the available bandwidth (also known as bottleneck bandwidth) along the network channel and calculating the round-trip time (RTT) between the sender and receiver.","Although when several flows compete for bandwidth, BBR may supply more bandwidth to one flow at the expense of another, resulting in unequal resource distribution.","This paper proposes to integrate machine learning with BBR to enhance fairness in resource allocation.","This novel strategy can improve bandwidth allocation and provide a more equal distribution of resources among competing flows by using historical BBR data to train an ML model.","Further we also implemented a classifier model that is graphic neural network in the congestion control method."],"url":"http://arxiv.org/abs/2312.11790v1"}
{"created":"2023-12-19 01:48:31","title":"Zero-Shot Fact-Checking with Semantic Triples and Knowledge Graphs","abstract":"Despite progress in automated fact-checking, most systems require a significant amount of labeled training data, which is expensive. In this paper, we propose a novel zero-shot method, which instead of operating directly on the claim and evidence sentences, decomposes them into semantic triples augmented using external knowledge graphs, and uses large language models trained for natural language inference. This allows it to generalize to adversarial datasets and domains that supervised models require specific training data for. Our empirical results show that our approach outperforms previous zero-shot approaches on FEVER, FEVER-Symmetric, FEVER 2.0, and Climate-FEVER, while being comparable or better than supervised models on the adversarial and the out-of-domain datasets.","sentences":["Despite progress in automated fact-checking, most systems require a significant amount of labeled training data, which is expensive.","In this paper, we propose a novel zero-shot method, which instead of operating directly on the claim and evidence sentences, decomposes them into semantic triples augmented using external knowledge graphs, and uses large language models trained for natural language inference.","This allows it to generalize to adversarial datasets and domains that supervised models require specific training data for.","Our empirical results show that our approach outperforms previous zero-shot approaches on FEVER, FEVER-Symmetric, FEVER 2.0, and Climate-FEVER, while being comparable or better than supervised models on the adversarial and the out-of-domain datasets."],"url":"http://arxiv.org/abs/2312.11785v1"}
{"created":"2023-12-19 01:33:46","title":"Learning Object State Changes in Videos: An Open-World Perspective","abstract":"Object State Changes (OSCs) are pivotal for video understanding. While humans can effortlessly generalize OSC understanding from familiar to unknown objects, current approaches are confined to a closed vocabulary. Addressing this gap, we introduce a novel open-world formulation for the video OSC problem. The goal is to temporally localize the three stages of an OSC -- the object's initial state, its transitioning state, and its end state -- whether or not the object has been observed during training. Towards this end, we develop VidOSC, a holistic learning approach that: (1) leverages text and vision-language models for supervisory signals to obviate manually labeling OSC training data, and (2) abstracts fine-grained shared state representations from objects to enhance generalization. Furthermore, we present HowToChange, the first open-world benchmark for video OSC localization, which offers an order of magnitude increase in the label space and annotation volume compared to the best existing benchmark. Experimental results demonstrate the efficacy of our approach, in both traditional closed-world and open-world scenarios.","sentences":["Object State Changes (OSCs) are pivotal for video understanding.","While humans can effortlessly generalize OSC understanding from familiar to unknown objects, current approaches are confined to a closed vocabulary.","Addressing this gap, we introduce a novel open-world formulation for the video OSC problem.","The goal is to temporally localize the three stages of an OSC -- the object's initial state, its transitioning state, and its end state -- whether or not the object has been observed during training.","Towards this end, we develop VidOSC, a holistic learning approach that: (1) leverages text and vision-language models for supervisory signals to obviate manually labeling OSC training data, and (2) abstracts fine-grained shared state representations from objects to enhance generalization.","Furthermore, we present HowToChange, the first open-world benchmark for video OSC localization, which offers an order of magnitude increase in the label space and annotation volume compared to the best existing benchmark.","Experimental results demonstrate the efficacy of our approach, in both traditional closed-world and open-world scenarios."],"url":"http://arxiv.org/abs/2312.11782v1"}
{"created":"2023-12-19 01:28:46","title":"Are you talking to ['xem'] or ['x', 'em']? On Tokenization and Addressing Misgendering in LLMs with Pronoun Tokenization Parity","abstract":"A large body of NLP research has documented the ways gender biases manifest and amplify within large language models (LLMs), though this research has predominantly operated within a gender binary-centric context. A growing body of work has identified the harmful limitations of this gender-exclusive framing; many LLMs cannot correctly and consistently refer to persons outside the gender binary, especially if they use neopronouns. While data scarcity has been identified as a possible culprit, the precise mechanisms through which it influences LLM misgendering remain underexplored. Our work addresses this gap by studying data scarcity's role in subword tokenization and, consequently, the formation of LLM word representations. We uncover how the Byte-Pair Encoding (BPE) tokenizer, a backbone for many popular LLMs, contributes to neopronoun misgendering through out-of-vocabulary behavior. We introduce pronoun tokenization parity (PTP), a novel approach to reduce LLM neopronoun misgendering by preserving a token's functional structure. We evaluate PTP's efficacy using pronoun consistency-based metrics and a novel syntax-based metric. Through several controlled experiments, finetuning LLMs with PTP improves neopronoun consistency from 14.5% to 58.4%, highlighting the significant role tokenization plays in LLM pronoun consistency.","sentences":["A large body of NLP research has documented the ways gender biases manifest and amplify within large language models (LLMs), though this research has predominantly operated within a gender binary-centric context.","A growing body of work has identified the harmful limitations of this gender-exclusive framing; many LLMs cannot correctly and consistently refer to persons outside the gender binary, especially if they use neopronouns.","While data scarcity has been identified as a possible culprit, the precise mechanisms through which it influences LLM misgendering remain underexplored.","Our work addresses this gap by studying data scarcity's role in subword tokenization and, consequently, the formation of LLM word representations.","We uncover how the Byte-Pair Encoding (BPE) tokenizer, a backbone for many popular LLMs, contributes to neopronoun misgendering through out-of-vocabulary behavior.","We introduce pronoun tokenization parity (PTP), a novel approach to reduce LLM neopronoun misgendering by preserving a token's functional structure.","We evaluate PTP's efficacy using pronoun consistency-based metrics and a novel syntax-based metric.","Through several controlled experiments, finetuning LLMs with PTP improves neopronoun consistency from 14.5% to 58.4%, highlighting the significant role tokenization plays in LLM pronoun consistency."],"url":"http://arxiv.org/abs/2312.11779v1"}
{"created":"2023-12-19 01:09:49","title":"Text-Image Conditioned Diffusion for Consistent Text-to-3D Generation","abstract":"By lifting the pre-trained 2D diffusion models into Neural Radiance Fields (NeRFs), text-to-3D generation methods have made great progress. Many state-of-the-art approaches usually apply score distillation sampling (SDS) to optimize the NeRF representations, which supervises the NeRF optimization with pre-trained text-conditioned 2D diffusion models such as Imagen. However, the supervision signal provided by such pre-trained diffusion models only depends on text prompts and does not constrain the multi-view consistency. To inject the cross-view consistency into diffusion priors, some recent works finetune the 2D diffusion model with multi-view data, but still lack fine-grained view coherence. To tackle this challenge, we incorporate multi-view image conditions into the supervision signal of NeRF optimization, which explicitly enforces fine-grained view consistency. With such stronger supervision, our proposed text-to-3D method effectively mitigates the generation of floaters (due to excessive densities) and completely empty spaces (due to insufficient densities). Our quantitative evaluations on the T$^3$Bench dataset demonstrate that our method achieves state-of-the-art performance over existing text-to-3D methods. We will make the code publicly available.","sentences":["By lifting the pre-trained 2D diffusion models into Neural Radiance Fields (NeRFs), text-to-3D generation methods have made great progress.","Many state-of-the-art approaches usually apply score distillation sampling (SDS) to optimize the NeRF representations, which supervises the NeRF optimization with pre-trained text-conditioned 2D diffusion models such as Imagen.","However, the supervision signal provided by such pre-trained diffusion models only depends on text prompts and does not constrain the multi-view consistency.","To inject the cross-view consistency into diffusion priors, some recent works finetune the 2D diffusion model with multi-view data, but still lack fine-grained view coherence.","To tackle this challenge, we incorporate multi-view image conditions into the supervision signal of NeRF optimization, which explicitly enforces fine-grained view consistency.","With such stronger supervision, our proposed text-to-3D method effectively mitigates the generation of floaters (due to excessive densities) and completely empty spaces (due to insufficient densities).","Our quantitative evaluations on the T$^3$Bench dataset demonstrate that our method achieves state-of-the-art performance over existing text-to-3D methods.","We will make the code publicly available."],"url":"http://arxiv.org/abs/2312.11774v1"}
{"created":"2023-12-19 01:07:36","title":"CAManim: Animating end-to-end network activation maps","abstract":"Deep neural networks have been widely adopted in numerous domains due to their high performance and accessibility to developers and application-specific end-users. Fundamental to image-based applications is the development of Convolutional Neural Networks (CNNs), which possess the ability to automatically extract features from data. However, comprehending these complex models and their learned representations, which typically comprise millions of parameters and numerous layers, remains a challenge for both developers and end-users. This challenge arises due to the absence of interpretable and transparent tools to make sense of black-box models. There exists a growing body of Explainable Artificial Intelligence (XAI) literature, including a collection of methods denoted Class Activation Maps (CAMs), that seek to demystify what representations the model learns from the data, how it informs a given prediction, and why it, at times, performs poorly in certain tasks. We propose a novel XAI visualization method denoted CAManim that seeks to simultaneously broaden and focus end-user understanding of CNN predictions by animating the CAM-based network activation maps through all layers, effectively depicting from end-to-end how a model progressively arrives at the final layer activation. Herein, we demonstrate that CAManim works with any CAM-based method and various CNN architectures. Beyond qualitative model assessments, we additionally propose a novel quantitative assessment that expands upon the Remove and Debias (ROAD) metric, pairing the qualitative end-to-end network visual explanations assessment with our novel quantitative \"yellow brick ROAD\" assessment (ybROAD). This builds upon prior research to address the increasing demand for interpretable, robust, and transparent model assessment methodology, ultimately improving an end-user's trust in a given model's predictions.","sentences":["Deep neural networks have been widely adopted in numerous domains due to their high performance and accessibility to developers and application-specific end-users.","Fundamental to image-based applications is the development of Convolutional Neural Networks (CNNs), which possess the ability to automatically extract features from data.","However, comprehending these complex models and their learned representations, which typically comprise millions of parameters and numerous layers, remains a challenge for both developers and end-users.","This challenge arises due to the absence of interpretable and transparent tools to make sense of black-box models.","There exists a growing body of Explainable Artificial Intelligence (XAI) literature, including a collection of methods denoted Class Activation Maps (CAMs), that seek to demystify what representations the model learns from the data, how it informs a given prediction, and why it, at times, performs poorly in certain tasks.","We propose a novel XAI visualization method denoted CAManim that seeks to simultaneously broaden and focus end-user understanding of CNN predictions by animating the CAM-based network activation maps through all layers, effectively depicting from end-to-end how a model progressively arrives at the final layer activation.","Herein, we demonstrate that CAManim works with any CAM-based method and various CNN architectures.","Beyond qualitative model assessments, we additionally propose a novel quantitative assessment that expands upon the Remove and Debias (ROAD) metric, pairing the qualitative end-to-end network visual explanations assessment with our novel quantitative \"yellow brick ROAD\" assessment (ybROAD).","This builds upon prior research to address the increasing demand for interpretable, robust, and transparent model assessment methodology, ultimately improving an end-user's trust in a given model's predictions."],"url":"http://arxiv.org/abs/2312.11772v1"}
{"created":"2023-12-19 01:03:19","title":"Bridging the Gap: Generalising State-of-the-Art U-Net Models to Sub-Saharan African Populations","abstract":"A critical challenge for tumour segmentation models is the ability to adapt to diverse clinical settings, particularly when applied to poor-quality neuroimaging data. The uncertainty surrounding this adaptation stems from the lack of representative datasets, leaving top-performing models without exposure to common artifacts found in MRI data throughout Sub-Saharan Africa (SSA). We replicated a framework that secured the 2nd position in the 2022 BraTS competition to investigate the impact of dataset composition on model performance and pursued four distinct approaches through training a model with: 1) BraTS-Africa data only (train_SSA, N=60), 2) BraTS-Adult Glioma data only (train_GLI, N=1251), 3) both datasets together (train_ALL, N=1311), and 4) through further training the train_GLI model with BraTS-Africa data (train_ftSSA). Notably, training on a smaller low-quality dataset alone (train_SSA) yielded subpar results, and training on a larger high-quality dataset alone (train_GLI) struggled to delineate oedematous tissue in the low-quality validation set. The most promising approach (train_ftSSA) involved pre-training a model on high-quality neuroimages and then fine-tuning it on the smaller, low-quality dataset. This approach outperformed the others, ranking second in the MICCAI BraTS Africa global challenge external testing phase. These findings underscore the significance of larger sample sizes and broad exposure to data in improving segmentation performance. Furthermore, we demonstrated that there is potential for improving such models by fine-tuning them with a wider range of data locally.","sentences":["A critical challenge for tumour segmentation models is the ability to adapt to diverse clinical settings, particularly when applied to poor-quality neuroimaging data.","The uncertainty surrounding this adaptation stems from the lack of representative datasets, leaving top-performing models without exposure to common artifacts found in MRI data throughout Sub-Saharan Africa (SSA).","We replicated a framework that secured the 2nd position in the 2022 BraTS competition to investigate the impact of dataset composition on model performance and pursued four distinct approaches through training a model with: 1) BraTS-Africa data only (train_SSA, N=60), 2) BraTS-Adult Glioma data only (train_GLI, N=1251), 3) both datasets together (train_ALL, N=1311), and 4) through further training the train_GLI model with BraTS-Africa data (train_ftSSA).","Notably, training on a smaller low-quality dataset alone (train_SSA) yielded subpar results, and training on a larger high-quality dataset alone (train_GLI) struggled to delineate oedematous tissue in the low-quality validation set.","The most promising approach (train_ftSSA) involved pre-training a model on high-quality neuroimages and then fine-tuning it on the smaller, low-quality dataset.","This approach outperformed the others, ranking second in the MICCAI BraTS Africa global challenge external testing phase.","These findings underscore the significance of larger sample sizes and broad exposure to data in improving segmentation performance.","Furthermore, we demonstrated that there is potential for improving such models by fine-tuning them with a wider range of data locally."],"url":"http://arxiv.org/abs/2312.11770v1"}
{"created":"2023-12-19 01:01:53","title":"Clustering Mixtures of Bounded Covariance Distributions Under Optimal Separation","abstract":"We study the clustering problem for mixtures of bounded covariance distributions, under a fine-grained separation assumption. Specifically, given samples from a $k$-component mixture distribution $D = \\sum_{i =1}^k w_i P_i$, where each $w_i \\ge \\alpha$ for some known parameter $\\alpha$, and each $P_i$ has unknown covariance $\\Sigma_i \\preceq \\sigma^2_i \\cdot I_d$ for some unknown $\\sigma_i$, the goal is to cluster the samples assuming a pairwise mean separation in the order of $(\\sigma_i+\\sigma_j)/\\sqrt{\\alpha}$ between every pair of components $P_i$ and $P_j$. Our contributions are as follows:   For the special case of nearly uniform mixtures, we give the first poly-time algorithm for this clustering task. Prior work either required separation scaling with the maximum cluster standard deviation (i.e. $\\max_i \\sigma_i$) [DKK+22b] or required both additional structural assumptions and mean separation scaling as a large degree polynomial in $1/\\alpha$ [BKK22].   For general-weight mixtures, we point out that accurate clustering is information-theoretically impossible under our fine-grained mean separation assumptions. We introduce the notion of a clustering refinement -- a list of not-too-small subsets satisfying a similar separation, and which can be merged into a clustering approximating the ground truth -- and show that it is possible to efficiently compute an accurate clustering refinement of the samples. Furthermore, under a variant of the \"no large sub-cluster'' condition from in prior work [BKK22], we show that our algorithm outputs an accurate clustering, not just a refinement, even for general-weight mixtures. As a corollary, we obtain efficient clustering algorithms for mixtures of well-conditioned high-dimensional log-concave distributions.   Moreover, our algorithm is robust to $\\Omega(\\alpha)$-fraction of adversarial outliers.","sentences":["We study the clustering problem for mixtures of bounded covariance distributions, under a fine-grained separation assumption.","Specifically, given samples from a $k$-component mixture distribution $D = \\sum_{i =1}^k w_i","P_i$, where each $w_i \\ge \\alpha$ for some known parameter $\\alpha$, and each $P_i$ has unknown covariance $\\Sigma_i \\preceq \\sigma^2_i \\cdot I_d$ for some unknown $\\sigma_i$, the goal is to cluster the samples assuming a pairwise mean separation in the order of $(\\sigma_i+\\sigma_j)/\\sqrt{\\alpha}$ between every pair of components $P_i$ and $P_j$. Our contributions are as follows:   ","For the special case of nearly uniform mixtures, we give the first poly-time algorithm for this clustering task.","Prior work either required separation scaling with the maximum cluster standard deviation (i.e. $\\max_i \\sigma_i$)","[DKK+22b] or required both additional structural assumptions and mean separation scaling as a large degree polynomial in $1/\\alpha$ [BKK22].   ","For general-weight mixtures, we point out that accurate clustering is information-theoretically impossible under our fine-grained mean separation assumptions.","We introduce the notion of a clustering refinement -- a list of not-too-small subsets satisfying a similar separation, and which can be merged into a clustering approximating the ground truth -- and show that it is possible to efficiently compute an accurate clustering refinement of the samples.","Furthermore, under a variant of the \"no large sub-cluster'' condition from in prior work [BKK22], we show that our algorithm outputs an accurate clustering, not just a refinement, even for general-weight mixtures.","As a corollary, we obtain efficient clustering algorithms for mixtures of well-conditioned high-dimensional log-concave distributions.   ","Moreover, our algorithm is robust to $\\Omega(\\alpha)$-fraction of adversarial outliers."],"url":"http://arxiv.org/abs/2312.11769v1"}
{"created":"2023-12-18 23:40:56","title":"A Bayesian Spatial Model to Correct Under-Reporting in Urban Crowdsourcing","abstract":"Decision-makers often observe the occurrence of events through a reporting process. City governments, for example, rely on resident reports to find and then resolve urban infrastructural problems such as fallen street trees, flooded basements, or rat infestations. Without additional assumptions, there is no way to distinguish events that occur but are not reported from events that truly did not occur--a fundamental problem in settings with positive-unlabeled data. Because disparities in reporting rates correlate with resident demographics, addressing incidents only on the basis of reports leads to systematic neglect in neighborhoods that are less likely to report events. We show how to overcome this challenge by leveraging the fact that events are spatially correlated. Our framework uses a Bayesian spatial latent variable model to infer event occurrence probabilities and applies it to storm-induced flooding reports in New York City, further pooling results across multiple storms. We show that a model accounting for under-reporting and spatial correlation predicts future reports more accurately than other models, and further induces a more equitable set of inspections: its allocations better reflect the population and provide equitable service to non-white, less traditionally educated, and lower-income residents. This finding reflects heterogeneous reporting behavior learned by the model: reporting rates are higher in Census tracts with higher populations, proportions of white residents, and proportions of owner-occupied households. Our work lays the groundwork for more equitable proactive government services, even with disparate reporting behavior.","sentences":["Decision-makers often observe the occurrence of events through a reporting process.","City governments, for example, rely on resident reports to find and then resolve urban infrastructural problems such as fallen street trees, flooded basements, or rat infestations.","Without additional assumptions, there is no way to distinguish events that occur but are not reported from events that truly did not occur--a fundamental problem in settings with positive-unlabeled data.","Because disparities in reporting rates correlate with resident demographics, addressing incidents only on the basis of reports leads to systematic neglect in neighborhoods that are less likely to report events.","We show how to overcome this challenge by leveraging the fact that events are spatially correlated.","Our framework uses a Bayesian spatial latent variable model to infer event occurrence probabilities and applies it to storm-induced flooding reports in New York City, further pooling results across multiple storms.","We show that a model accounting for under-reporting and spatial correlation predicts future reports more accurately than other models, and further induces a more equitable set of inspections: its allocations better reflect the population and provide equitable service to non-white, less traditionally educated, and lower-income residents.","This finding reflects heterogeneous reporting behavior learned by the model: reporting rates are higher in Census tracts with higher populations, proportions of white residents, and proportions of owner-occupied households.","Our work lays the groundwork for more equitable proactive government services, even with disparate reporting behavior."],"url":"http://arxiv.org/abs/2312.11754v1"}
{"created":"2023-12-18 23:27:28","title":"A Heterogeneous Chiplet Architecture for Accelerating End-to-End Transformer Models","abstract":"Transformers have revolutionized deep learning and generative modeling, enabling unprecedented advancements in natural language processing tasks. However, the size of transformer models is increasing continuously, driven by enhanced capabilities across various deep-learning tasks. This trend of ever-increasing model size has given rise to new challenges in terms of memory and computing requirements. Conventional computing platforms, including GPUs, suffer from suboptimal performance due to the memory demands imposed by models with millions/billions of parameters. The emerging chiplet-based platforms provide a new avenue for compute- and data-intensive machine learning (ML) applications enabled by a Network-on-Interposer (NoI). However, designing suitable hardware accelerators for executing Transformer inference workloads is challenging due to a wide variety of complex computing kernels in the Transformer architecture. In this paper, we leverage chiplet-based heterogeneous integration (HI) to design a high-performance and energy-efficient multi-chiplet platform to accelerate transformer workloads. We demonstrate that the proposed NoI architecture caters to the data access patterns inherent in a transformer model. The optimized placement of the chiplets and the associated NoI links and routers enable superior performance compared to the state-of-the-art hardware accelerators. The proposed NoI-based architecture demonstrates scalability across varying transformer models and improves latency and energy efficiency by up to 22.8x and 5.36x respectively.","sentences":["Transformers have revolutionized deep learning and generative modeling, enabling unprecedented advancements in natural language processing tasks.","However, the size of transformer models is increasing continuously, driven by enhanced capabilities across various deep-learning tasks.","This trend of ever-increasing model size has given rise to new challenges in terms of memory and computing requirements.","Conventional computing platforms, including GPUs, suffer from suboptimal performance due to the memory demands imposed by models with millions/billions of parameters.","The emerging chiplet-based platforms provide a new avenue for compute- and data-intensive machine learning (ML) applications enabled by a Network-on-Interposer (NoI).","However, designing suitable hardware accelerators for executing Transformer inference workloads is challenging due to a wide variety of complex computing kernels in the Transformer architecture.","In this paper, we leverage chiplet-based heterogeneous integration (HI) to design a high-performance and energy-efficient multi-chiplet platform to accelerate transformer workloads.","We demonstrate that the proposed NoI architecture caters to the data access patterns inherent in a transformer model.","The optimized placement of the chiplets and the associated NoI links and routers enable superior performance compared to the state-of-the-art hardware accelerators.","The proposed NoI-based architecture demonstrates scalability across varying transformer models and improves latency and energy efficiency by up to 22.8x and 5.36x respectively."],"url":"http://arxiv.org/abs/2312.11750v1"}
{"created":"2023-12-18 22:40:56","title":"TPTO: A Transformer-PPO based Task Offloading Solution for Edge Computing Environments","abstract":"Emerging applications in healthcare, autonomous vehicles, and wearable assistance require interactive and low-latency data analysis services. Unfortunately, cloud-centric architectures cannot fulfill the low-latency demands of these applications, as user devices are often distant from cloud data centers. Edge computing aims to reduce the latency by enabling processing tasks to be offloaded to resources located at the network's edge. However, determining which tasks must be offloaded to edge servers to reduce the latency of application requests is not trivial, especially if the tasks present dependencies. This paper proposes a DRL approach called TPTO, which leverages Transformer Networks and PPO to offload dependent tasks of IoT applications in edge computing. We consider users with various preferences, where devices can offload computation to an edge server via wireless channels. Performance evaluation results demonstrate that under fat application graphs, TPTO is more effective than state-of-the-art methods, such as Greedy, HEFT, and MRLCO, by reducing latency by 30.24%, 29.61%, and 12.41%, respectively. In addition, TPTO presents a training time approximately 2.5 times faster than an existing DRL approach.","sentences":["Emerging applications in healthcare, autonomous vehicles, and wearable assistance require interactive and low-latency data analysis services.","Unfortunately, cloud-centric architectures cannot fulfill the low-latency demands of these applications, as user devices are often distant from cloud data centers.","Edge computing aims to reduce the latency by enabling processing tasks to be offloaded to resources located at the network's edge.","However, determining which tasks must be offloaded to edge servers to reduce the latency of application requests is not trivial, especially if the tasks present dependencies.","This paper proposes a DRL approach called TPTO, which leverages Transformer Networks and PPO to offload dependent tasks of IoT applications in edge computing.","We consider users with various preferences, where devices can offload computation to an edge server via wireless channels.","Performance evaluation results demonstrate that under fat application graphs, TPTO is more effective than state-of-the-art methods, such as Greedy, HEFT, and MRLCO, by reducing latency by 30.24%, 29.61%, and 12.41%, respectively.","In addition, TPTO presents a training time approximately 2.5 times faster than an existing DRL approach."],"url":"http://arxiv.org/abs/2312.11739v1"}
{"created":"2023-12-18 22:12:26","title":"Stronger Graph Transformer with Regularized Attention Scores","abstract":"Graph Neural Networks are notorious for its memory consumption. A recent Transformer based GNN called Graph Transformer are shown to obtain superior performances when long range dependencies exist. However, combining graph data and Transformer architecture led to a combinationally worse memory issue. We propose a novel version of \"edge regularization technique\" that alleviates the need for Positional Encoding and ultimately alleviate GT's out of memory issue. We observe that it is not clear whether having an edge regularization on top of positional encoding is helpful. However, it seems evident when no positional encoding is applied, edge regularization technique indeed stably improves GT's performance.","sentences":["Graph Neural Networks are notorious for its memory consumption.","A recent Transformer based GNN called Graph Transformer are shown to obtain superior performances when long range dependencies exist.","However, combining graph data and Transformer architecture led to a combinationally worse memory issue.","We propose a novel version of \"edge regularization technique\" that alleviates the need for Positional Encoding and ultimately alleviate GT's out of memory issue.","We observe that it is not clear whether having an edge regularization on top of positional encoding is helpful.","However, it seems evident when no positional encoding is applied, edge regularization technique indeed stably improves GT's performance."],"url":"http://arxiv.org/abs/2312.11730v1"}
{"created":"2023-12-18 22:03:32","title":"A review of Energy Efficient Routing Protocols in Underwater Internet of Things","abstract":"Oceans, covering 70% of Earth's surface, arelargely unexplored, with about 95% remaining a mystery.Underwater wireless communication is pivotal in various domains,such as real-time aquatic data collection, marine surveillance,disaster prevention, archaeological exploration, andenvironmental monitoring. The Internet of Things has openednew avenues in underwater exploration through the underwaterInternet of Things concept. This innovative technology facilitatessmart ocean research, from small case studies to large-scaleoperations. UIoT networks utilise underwater equipment andsensors to gather and transmit data in aquatic environments.However, the dynamic nature of these environments poseschallenges to the network's structure and communication,necessitating efficient routing solutions. Quality-of-service-awarerouting is vital as it minimises energy usage, extends battery life,and enhances network performance. This paper delves into thechallenges and limitations of UIoT networks, highlighting recentrouting methodologies. It also proposes a comparison frameworkfor routing methods, focusing on the quality of service inunderwater IoT networks, to foster more optimal route selectionand better resource management.","sentences":["Oceans, covering 70% of Earth's surface, arelargely unexplored, with about 95% remaining a mystery.","Underwater wireless communication is pivotal in various domains,such as real-time aquatic data collection, marine surveillance,disaster prevention, archaeological exploration, andenvironmental monitoring.","The Internet of Things has openednew avenues in underwater exploration through the underwaterInternet of Things concept.","This innovative technology facilitatessmart ocean research, from small case studies to large-scaleoperations.","UIoT networks utilise underwater equipment andsensors to gather and transmit data in aquatic environments.","However, the dynamic nature of these environments poseschallenges to the network's structure and communication,necessitating efficient routing solutions.","Quality-of-service-awarerouting is vital as it minimises energy usage, extends battery life,and enhances network performance.","This paper delves into thechallenges and limitations of UIoT networks, highlighting recentrouting methodologies.","It also proposes a comparison frameworkfor routing methods, focusing on the quality of service inunderwater IoT networks, to foster more optimal route selectionand better resource management."],"url":"http://arxiv.org/abs/2312.11725v1"}
{"created":"2023-12-18 21:22:38","title":"Time-Transformer: Integrating Local and Global Features for Better Time Series Generation","abstract":"Generating time series data is a promising approach to address data deficiency problems. However, it is also challenging due to the complex temporal properties of time series data, including local correlations as well as global dependencies. Most existing generative models have failed to effectively learn both the local and global properties of time series data. To address this open problem, we propose a novel time series generative model named 'Time-Transformer AAE', which consists of an adversarial autoencoder (AAE) and a newly designed architecture named 'Time-Transformer' within the decoder. The Time-Transformer first simultaneously learns local and global features in a layer-wise parallel design, combining the abilities of Temporal Convolutional Networks and Transformer in extracting local features and global dependencies respectively. Second, a bidirectional cross attention is proposed to provide complementary guidance across the two branches and achieve proper fusion between local and global features. Experimental results demonstrate that our model can outperform existing state-of-the-art models in 5 out of 6 datasets, specifically on those with data containing both global and local properties. Furthermore, we highlight our model's advantage on handling this kind of data via an artificial dataset. Finally, we show our model's ability to address a real-world problem: data augmentation to support learning with small datasets and imbalanced datasets.","sentences":["Generating time series data is a promising approach to address data deficiency problems.","However, it is also challenging due to the complex temporal properties of time series data, including local correlations as well as global dependencies.","Most existing generative models have failed to effectively learn both the local and global properties of time series data.","To address this open problem, we propose a novel time series generative model named 'Time-Transformer AAE', which consists of an adversarial autoencoder (AAE) and a newly designed architecture named 'Time-Transformer' within the decoder.","The Time-Transformer first simultaneously learns local and global features in a layer-wise parallel design, combining the abilities of Temporal Convolutional Networks and Transformer in extracting local features and global dependencies respectively.","Second, a bidirectional cross attention is proposed to provide complementary guidance across the two branches and achieve proper fusion between local and global features.","Experimental results demonstrate that our model can outperform existing state-of-the-art models in 5 out of 6 datasets, specifically on those with data containing both global and local properties.","Furthermore, we highlight our model's advantage on handling this kind of data via an artificial dataset.","Finally, we show our model's ability to address a real-world problem: data augmentation to support learning with small datasets and imbalanced datasets."],"url":"http://arxiv.org/abs/2312.11714v1"}
{"created":"2023-12-18 21:20:28","title":"Indoor and Outdoor 3D Scene Graph Generation via Language-Enabled Spatial Ontologies","abstract":"This paper proposes an approach to build 3D scene graphs in arbitrary (indoor and outdoor) environments. Such extension is challenging; the hierarchy of concepts that describe an outdoor environment is more complex than for indoors, and manually defining such hierarchy is time-consuming and does not scale. Furthermore, the lack of training data prevents the straightforward application of learning-based tools used in indoor settings. To address these challenges, we propose two novel extensions. First, we develop methods to build a spatial ontology defining concepts and relations relevant for indoor and outdoor robot operation. In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required. Second, we leverage the spatial ontology for 3D scene graph construction using Logic Tensor Networks (LTN) to add logical rules, or axioms (e.g., \"a beach contains sand\"), which provide additional supervisory signals at training time thus reducing the need for labelled data, providing better predictions, and even allowing predicting concepts unseen at training time. We test our approach in a variety of datasets, including indoor, rural, and coastal environments, and show that it leads to a significant increase in the quality of the 3D scene graph generation with sparsely annotated data.","sentences":["This paper proposes an approach to build 3D scene graphs in arbitrary (indoor and outdoor) environments.","Such extension is challenging; the hierarchy of concepts that describe an outdoor environment is more complex than for indoors, and manually defining such hierarchy is time-consuming and does not scale.","Furthermore, the lack of training data prevents the straightforward application of learning-based tools used in indoor settings.","To address these challenges, we propose two novel extensions.","First, we develop methods to build a spatial ontology defining concepts and relations relevant for indoor and outdoor robot operation.","In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required.","Second, we leverage the spatial ontology for 3D scene graph construction using Logic Tensor Networks (LTN) to add logical rules, or axioms (e.g., \"a beach contains sand\"), which provide additional supervisory signals at training time thus reducing the need for labelled data, providing better predictions, and even allowing predicting concepts unseen at training time.","We test our approach in a variety of datasets, including indoor, rural, and coastal environments, and show that it leads to a significant increase in the quality of the 3D scene graph generation with sparsely annotated data."],"url":"http://arxiv.org/abs/2312.11713v1"}
{"created":"2023-12-18 21:19:35","title":"A Simple and Practical Method for Reducing the Disparate Impact of Differential Privacy","abstract":"Differentially private (DP) mechanisms have been deployed in a variety of high-impact social settings (perhaps most notably by the U.S. Census). Since all DP mechanisms involve adding noise to results of statistical queries, they are expected to impact our ability to accurately analyze and learn from data, in effect trading off privacy with utility. Alarmingly, the impact of DP on utility can vary significantly among different sub-populations. A simple way to reduce this disparity is with stratification. First compute an independent private estimate for each group in the data set (which may be the intersection of several protected classes), then, to compute estimates of global statistics, appropriately recombine these group estimates. Our main observation is that naive stratification often yields high-accuracy estimates of population-level statistics, without the need for additional privacy budget. We support this observation theoretically and empirically. Our theoretical results center on the private mean estimation problem, while our empirical results center on extensive experiments on private data synthesis to demonstrate the effectiveness of stratification on a variety of private mechanisms. Overall, we argue that this straightforward approach provides a strong baseline against which future work on reducing utility disparities of DP mechanisms should be compared.","sentences":["Differentially private (DP) mechanisms have been deployed in a variety of high-impact social settings (perhaps most notably by the U.S. Census).","Since all DP mechanisms involve adding noise to results of statistical queries, they are expected to impact our ability to accurately analyze and learn from data, in effect trading off privacy with utility.","Alarmingly, the impact of DP on utility can vary significantly among different sub-populations.","A simple way to reduce this disparity is with stratification.","First compute an independent private estimate for each group in the data set (which may be the intersection of several protected classes), then, to compute estimates of global statistics, appropriately recombine these group estimates.","Our main observation is that naive stratification often yields high-accuracy estimates of population-level statistics, without the need for additional privacy budget.","We support this observation theoretically and empirically.","Our theoretical results center on the private mean estimation problem, while our empirical results center on extensive experiments on private data synthesis to demonstrate the effectiveness of stratification on a variety of private mechanisms.","Overall, we argue that this straightforward approach provides a strong baseline against which future work on reducing utility disparities of DP mechanisms should be compared."],"url":"http://arxiv.org/abs/2312.11712v1"}
{"created":"2023-12-18 21:07:03","title":"Unified framework for diffusion generative models in SO(3): applications in computer vision and astrophysics","abstract":"Diffusion-based generative models represent the current state-of-the-art for image generation. However, standard diffusion models are based on Euclidean geometry and do not translate directly to manifold-valued data. In this work, we develop extensions of both score-based generative models (SGMs) and Denoising Diffusion Probabilistic Models (DDPMs) to the Lie group of 3D rotations, SO(3). SO(3) is of particular interest in many disciplines such as robotics, biochemistry and astronomy/cosmology science. Contrary to more general Riemannian manifolds, SO(3) admits a tractable solution to heat diffusion, and allows us to implement efficient training of diffusion models. We apply both SO(3) DDPMs and SGMs to synthetic densities on SO(3) and demonstrate state-of-the-art results. Additionally, we demonstrate the practicality of our model on pose estimation tasks and in predicting correlated galaxy orientations for astrophysics/cosmology.","sentences":["Diffusion-based generative models represent the current state-of-the-art for image generation.","However, standard diffusion models are based on Euclidean geometry and do not translate directly to manifold-valued data.","In this work, we develop extensions of both score-based generative models (SGMs) and Denoising Diffusion Probabilistic Models (DDPMs) to the Lie group of 3D rotations, SO(3).","SO(3) is of particular interest in many disciplines such as robotics, biochemistry and astronomy/cosmology science.","Contrary to more general Riemannian manifolds, SO(3) admits a tractable solution to heat diffusion, and allows us to implement efficient training of diffusion models.","We apply both SO(3) DDPMs and SGMs to synthetic densities on SO(3) and demonstrate state-of-the-art results.","Additionally, we demonstrate the practicality of our model on pose estimation tasks and in predicting correlated galaxy orientations for astrophysics/cosmology."],"url":"http://arxiv.org/abs/2312.11707v1"}
{"created":"2023-12-18 20:29:58","title":"Agent-based Learning of Materials Datasets from Scientific Literature","abstract":"Advancements in machine learning and artificial intelligence are transforming materials discovery. Yet, the availability of structured experimental data remains a bottleneck. The vast corpus of scientific literature presents a valuable and rich resource of such data. However, manual dataset creation from these resources is challenging due to issues in maintaining quality and consistency, scalability limitations, and the risk of human error and bias. Therefore, in this work, we develop a chemist AI agent, powered by large language models (LLMs), to overcome these challenges by autonomously creating structured datasets from natural language text, ranging from sentences and paragraphs to extensive scientific research articles. Our chemist AI agent, Eunomia, can plan and execute actions by leveraging the existing knowledge from decades of scientific research articles, scientists, the Internet and other tools altogether. We benchmark the performance of our approach in three different information extraction tasks with various levels of complexity, including solid-state impurity doping, metal-organic framework (MOF) chemical formula, and property relations. Our results demonstrate that our zero-shot agent, with the appropriate tools, is capable of attaining performance that is either superior or comparable to the state-of-the-art fine-tuned materials information extraction methods. This approach simplifies compilation of machine learning-ready datasets for various materials discovery applications, and significantly ease the accessibility of advanced natural language processing tools for novice users in natural language. The methodology in this work is developed as an open-source software on https://github.com/AI4ChemS/Eunomia.","sentences":["Advancements in machine learning and artificial intelligence are transforming materials discovery.","Yet, the availability of structured experimental data remains a bottleneck.","The vast corpus of scientific literature presents a valuable and rich resource of such data.","However, manual dataset creation from these resources is challenging due to issues in maintaining quality and consistency, scalability limitations, and the risk of human error and bias.","Therefore, in this work, we develop a chemist AI agent, powered by large language models (LLMs), to overcome these challenges by autonomously creating structured datasets from natural language text, ranging from sentences and paragraphs to extensive scientific research articles.","Our chemist AI agent, Eunomia, can plan and execute actions by leveraging the existing knowledge from decades of scientific research articles, scientists, the Internet and other tools altogether.","We benchmark the performance of our approach in three different information extraction tasks with various levels of complexity, including solid-state impurity doping, metal-organic framework (MOF) chemical formula, and property relations.","Our results demonstrate that our zero-shot agent, with the appropriate tools, is capable of attaining performance that is either superior or comparable to the state-of-the-art fine-tuned materials information extraction methods.","This approach simplifies compilation of machine learning-ready datasets for various materials discovery applications, and significantly ease the accessibility of advanced natural language processing tools for novice users in natural language.","The methodology in this work is developed as an open-source software on https://github.com/AI4ChemS/Eunomia."],"url":"http://arxiv.org/abs/2312.11690v1"}
{"created":"2023-12-18 20:21:52","title":"Bilinear Expectation Propagation for Distributed Semi-Blind Joint Channel Estimation and Data Detection in Cell-Free Massive MIMO","abstract":"We consider a cell-free massive multiple-input multiple-output (CF-MaMIMO) communication system in the uplink transmission and propose a novel algorithm for blind or semi-blind joint channel estimation and data detection (JCD). We formulate the problem in the framework of bilinear inference and develop a solution based on the expectation propagation (EP) method for both channel estimation and data detection. We propose a new approximation of the joint a posteriori distribution of the channel and data whose representation as a factor graph enables the application of the EP approach using the message-passing technique, local low-complexity computations at the nodes, and an effective modeling of channel-data interplay. The derived algorithm, called bilinear-EP JCD, allows for a distributed implementation among access points (APs) and the central processing unit (CPU) and has polynomial complexity. Our simulation results show that it outperforms other EP-based state-of-the-art polynomial time algorithms.","sentences":["We consider a cell-free massive multiple-input multiple-output (CF-MaMIMO) communication system in the uplink transmission and propose a novel algorithm for blind or semi-blind joint channel estimation and data detection (JCD).","We formulate the problem in the framework of bilinear inference and develop a solution based on the expectation propagation (EP) method for both channel estimation and data detection.","We propose a new approximation of the joint a posteriori distribution of the channel and data whose representation as a factor graph enables the application of the EP approach using the message-passing technique, local low-complexity computations at the nodes, and an effective modeling of channel-data interplay.","The derived algorithm, called bilinear-EP JCD, allows for a distributed implementation among access points (APs) and the central processing unit (CPU) and has polynomial complexity.","Our simulation results show that it outperforms other EP-based state-of-the-art polynomial time algorithms."],"url":"http://arxiv.org/abs/2312.11688v1"}
{"created":"2023-12-18 19:14:42","title":"Eliciting Kemeny Rankings","abstract":"We formulate the problem of eliciting agents' preferences with the goal of finding a Kemeny ranking as a Dueling Bandits problem. Here the bandits' arms correspond to alternatives that need to be ranked and the feedback corresponds to a pairwise comparison between alternatives by a randomly sampled agent. We consider both sampling with and without replacement, i.e., the possibility to ask the same agent about some comparison multiple times or not.   We find approximation bounds for Kemeny rankings dependant on confidence intervals over estimated winning probabilities of arms. Based on these we state algorithms to find Probably Approximately Correct (PAC) solutions and elaborate on their sample complexity for sampling with or without replacement. Furthermore, if all agents' preferences are strict rankings over the alternatives, we provide means to prune confidence intervals and thereby guide a more efficient elicitation. We formulate several adaptive sampling methods that use look-aheads to estimate how much confidence intervals (and thus approximation guarantees) might be tightened. All described methods are compared on synthetic data.","sentences":["We formulate the problem of eliciting agents' preferences with the goal of finding a Kemeny ranking as a Dueling Bandits problem.","Here the bandits' arms correspond to alternatives that need to be ranked and the feedback corresponds to a pairwise comparison between alternatives by a randomly sampled agent.","We consider both sampling with and without replacement, i.e., the possibility to ask the same agent about some comparison multiple times or not.   ","We find approximation bounds for Kemeny rankings dependant on confidence intervals over estimated winning probabilities of arms.","Based on these we state algorithms to find Probably Approximately Correct (PAC) solutions and elaborate on their sample complexity for sampling with or without replacement.","Furthermore, if all agents' preferences are strict rankings over the alternatives, we provide means to prune confidence intervals and thereby guide a more efficient elicitation.","We formulate several adaptive sampling methods that use look-aheads to estimate how much confidence intervals (and thus approximation guarantees) might be tightened.","All described methods are compared on synthetic data."],"url":"http://arxiv.org/abs/2312.11663v1"}
{"created":"2023-12-18 19:12:58","title":"Traces of Memorisation in Large Language Models for Code","abstract":"Large language models have gained significant popularity because of their ability to generate human-like text and potential applications in various fields, such as Software Engineering. Large language models for code are commonly trained on large unsanitised corpora of source code scraped from the internet. The content of these datasets is memorised and can be extracted by attackers with data extraction attacks. In this work, we explore memorisation in large language models for code and compare the rate of memorisation with large language models trained on natural language. We adopt an existing benchmark for natural language and construct a benchmark for code by identifying samples that are vulnerable to attack. We run both benchmarks against a variety of models, and perform a data extraction attack. We find that large language models for code are vulnerable to data extraction attacks, like their natural language counterparts. From the training data that was identified to be potentially extractable we were able to extract 47% from a CodeGen-Mono-16B code completion model. We also observe that models memorise more, as their parameter count grows, and that their pre-training data are also vulnerable to attack. We also find that data carriers are memorised at a higher rate than regular code or documentation and that different model architectures memorise different samples. Data leakage has severe outcomes, so we urge the research community to further investigate the extent of this phenomenon using a wider range of models and extraction techniques in order to build safeguards to mitigate this issue.","sentences":["Large language models have gained significant popularity because of their ability to generate human-like text and potential applications in various fields, such as Software Engineering.","Large language models for code are commonly trained on large unsanitised corpora of source code scraped from the internet.","The content of these datasets is memorised and can be extracted by attackers with data extraction attacks.","In this work, we explore memorisation in large language models for code and compare the rate of memorisation with large language models trained on natural language.","We adopt an existing benchmark for natural language and construct a benchmark for code by identifying samples that are vulnerable to attack.","We run both benchmarks against a variety of models, and perform a data extraction attack.","We find that large language models for code are vulnerable to data extraction attacks, like their natural language counterparts.","From the training data that was identified to be potentially extractable we were able to extract 47% from a CodeGen-Mono-16B code completion model.","We also observe that models memorise more, as their parameter count grows, and that their pre-training data are also vulnerable to attack.","We also find that data carriers are memorised at a higher rate than regular code or documentation and that different model architectures memorise different samples.","Data leakage has severe outcomes, so we urge the research community to further investigate the extent of this phenomenon using a wider range of models and extraction techniques in order to build safeguards to mitigate this issue."],"url":"http://arxiv.org/abs/2312.11658v1"}
{"created":"2023-12-18 19:06:00","title":"Bridging Logic and Learning: A Neural-Symbolic Approach for Enhanced Reasoning in Neural Models (ASPER)","abstract":"Neural-symbolic learning, an intersection of neural networks and symbolic reasoning, aims to blend neural networks' learning capabilities with symbolic AI's interpretability and reasoning. This paper introduces an approach designed to improve the performance of neural models in learning reasoning tasks. It achieves this by integrating Answer Set Programming (ASP) solvers and domain-specific expertise, which is an approach that diverges from traditional complex neural-symbolic models. In this paper, a shallow artificial neural network (ANN) is specifically trained to solve Sudoku puzzles with minimal training data. The model has a unique loss function that integrates losses calculated using the ASP solver outputs, effectively enhancing its training efficiency. Most notably, the model shows a significant improvement in solving Sudoku puzzles using only 12 puzzles for training and testing without hyperparameter tuning. This advancement indicates that the model's enhanced reasoning capabilities have practical applications, extending well beyond Sudoku puzzles to potentially include a variety of other domains. The code can be found on GitHub: https://github.com/Fadi2200/ASPEN.","sentences":["Neural-symbolic learning, an intersection of neural networks and symbolic reasoning, aims to blend neural networks' learning capabilities with symbolic AI's interpretability and reasoning.","This paper introduces an approach designed to improve the performance of neural models in learning reasoning tasks.","It achieves this by integrating Answer Set Programming (ASP) solvers and domain-specific expertise, which is an approach that diverges from traditional complex neural-symbolic models.","In this paper, a shallow artificial neural network (ANN) is specifically trained to solve Sudoku puzzles with minimal training data.","The model has a unique loss function that integrates losses calculated using the ASP solver outputs, effectively enhancing its training efficiency.","Most notably, the model shows a significant improvement in solving Sudoku puzzles using only 12 puzzles for training and testing without hyperparameter tuning.","This advancement indicates that the model's enhanced reasoning capabilities have practical applications, extending well beyond Sudoku puzzles to potentially include a variety of other domains.","The code can be found on GitHub: https://github.com/Fadi2200/ASPEN."],"url":"http://arxiv.org/abs/2312.11651v1"}
{"created":"2023-12-18 19:04:11","title":"Experiment-informed finite-strain inverse design of spinodal metamaterials","abstract":"This study presents a novel physics-enhanced machine learning (ML) and optimization framework tailored to address the challenges of designing intricate spinodal metamaterials with customized mechanical properties in scenarios where computational modeling is restricted, and experimental data is sparse. By utilizing sparse experimental data directly, our approach facilitates the inverse design of spinodal structures with precise finite-strain mechanical responses. Leveraging physics-based inductive biases to compensate for limited data availability, the framework sheds light on instability-induced pattern formation in periodic metamaterials, attributing it to nonconvex energetic potentials. Inspired by phase transformation modeling, the method integrates multiple partial input convex neural networks to create nonconvex potentials, effectively capturing complex nonlinear stress-strain behavior, even under extreme deformations.","sentences":["This study presents a novel physics-enhanced machine learning (ML) and optimization framework tailored to address the challenges of designing intricate spinodal metamaterials with customized mechanical properties in scenarios where computational modeling is restricted, and experimental data is sparse.","By utilizing sparse experimental data directly, our approach facilitates the inverse design of spinodal structures with precise finite-strain mechanical responses.","Leveraging physics-based inductive biases to compensate for limited data availability, the framework sheds light on instability-induced pattern formation in periodic metamaterials, attributing it to nonconvex energetic potentials.","Inspired by phase transformation modeling, the method integrates multiple partial input convex neural networks to create nonconvex potentials, effectively capturing complex nonlinear stress-strain behavior, even under extreme deformations."],"url":"http://arxiv.org/abs/2312.11648v1"}
