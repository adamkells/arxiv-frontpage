{"created":"2024-09-12 17:59:49","title":"DreamHOI: Subject-Driven Generation of 3D Human-Object Interactions with Diffusion Priors","abstract":"We present DreamHOI, a novel method for zero-shot synthesis of human-object interactions (HOIs), enabling a 3D human model to realistically interact with any given object based on a textual description. This task is complicated by the varying categories and geometries of real-world objects and the scarcity of datasets encompassing diverse HOIs. To circumvent the need for extensive data, we leverage text-to-image diffusion models trained on billions of image-caption pairs. We optimize the articulation of a skinned human mesh using Score Distillation Sampling (SDS) gradients obtained from these models, which predict image-space edits. However, directly backpropagating image-space gradients into complex articulation parameters is ineffective due to the local nature of such gradients. To overcome this, we introduce a dual implicit-explicit representation of a skinned mesh, combining (implicit) neural radiance fields (NeRFs) with (explicit) skeleton-driven mesh articulation. During optimization, we transition between implicit and explicit forms, grounding the NeRF generation while refining the mesh articulation. We validate our approach through extensive experiments, demonstrating its effectiveness in generating realistic HOIs.","sentences":["We present DreamHOI, a novel method for zero-shot synthesis of human-object interactions (HOIs), enabling a 3D human model to realistically interact with any given object based on a textual description.","This task is complicated by the varying categories and geometries of real-world objects and the scarcity of datasets encompassing diverse HOIs.","To circumvent the need for extensive data, we leverage text-to-image diffusion models trained on billions of image-caption pairs.","We optimize the articulation of a skinned human mesh using Score Distillation Sampling (SDS) gradients obtained from these models, which predict image-space edits.","However, directly backpropagating image-space gradients into complex articulation parameters is ineffective due to the local nature of such gradients.","To overcome this, we introduce a dual implicit-explicit representation of a skinned mesh, combining (implicit) neural radiance fields (NeRFs) with (explicit) skeleton-driven mesh articulation.","During optimization, we transition between implicit and explicit forms, grounding the NeRF generation while refining the mesh articulation.","We validate our approach through extensive experiments, demonstrating its effectiveness in generating realistic HOIs."],"url":"http://arxiv.org/abs/2409.08278v1"}
{"created":"2024-09-12 17:59:44","title":"AnySkin: Plug-and-play Skin Sensing for Robotic Touch","abstract":"While tactile sensing is widely accepted as an important and useful sensing modality, its use pales in comparison to other sensory modalities like vision and proprioception. AnySkin addresses the critical challenges that impede the use of tactile sensing -- versatility, replaceability, and data reusability. Building on the simplistic design of ReSkin, and decoupling the sensing electronics from the sensing interface, AnySkin simplifies integration making it as straightforward as putting on a phone case and connecting a charger. Furthermore, AnySkin is the first uncalibrated tactile-sensor with cross-instance generalizability of learned manipulation policies. To summarize, this work makes three key contributions: first, we introduce a streamlined fabrication process and a design tool for creating an adhesive-free, durable and easily replaceable magnetic tactile sensor; second, we characterize slip detection and policy learning with the AnySkin sensor; and third, we demonstrate zero-shot generalization of models trained on one instance of AnySkin to new instances, and compare it with popular existing tactile solutions like DIGIT and ReSkin.https://any-skin.github.io/","sentences":["While tactile sensing is widely accepted as an important and useful sensing modality, its use pales in comparison to other sensory modalities like vision and proprioception.","AnySkin addresses the critical challenges that impede the use of tactile sensing -- versatility, replaceability, and data reusability.","Building on the simplistic design of ReSkin, and decoupling the sensing electronics from the sensing interface, AnySkin simplifies integration making it as straightforward as putting on a phone case and connecting a charger.","Furthermore, AnySkin is the first uncalibrated tactile-sensor with cross-instance generalizability of learned manipulation policies.","To summarize, this work makes three key contributions: first, we introduce a streamlined fabrication process and a design tool for creating an adhesive-free, durable and easily replaceable magnetic tactile sensor; second, we characterize slip detection and policy learning with the AnySkin sensor; and third, we demonstrate zero-shot generalization of models trained on one instance of AnySkin to new instances, and compare it with popular existing tactile solutions like DIGIT and ReSkin.https://any-skin.github.io/"],"url":"http://arxiv.org/abs/2409.08276v1"}
{"created":"2024-09-12 17:59:07","title":"Hand-Object Interaction Pretraining from Videos","abstract":"We present an approach to learn general robot manipulation priors from 3D hand-object interaction trajectories. We build a framework to use in-the-wild videos to generate sensorimotor robot trajectories. We do so by lifting both the human hand and the manipulated object in a shared 3D space and retargeting human motions to robot actions. Generative modeling on this data gives us a task-agnostic base policy. This policy captures a general yet flexible manipulation prior. We empirically demonstrate that finetuning this policy, with both reinforcement learning (RL) and behavior cloning (BC), enables sample-efficient adaptation to downstream tasks and simultaneously improves robustness and generalizability compared to prior approaches. Qualitative experiments are available at: \\url{https://hgaurav2k.github.io/hop/}.","sentences":["We present an approach to learn general robot manipulation priors from 3D hand-object interaction trajectories.","We build a framework to use in-the-wild videos to generate sensorimotor robot trajectories.","We do so by lifting both the human hand and the manipulated object in a shared 3D space and retargeting human motions to robot actions.","Generative modeling on this data gives us a task-agnostic base policy.","This policy captures a general yet flexible manipulation prior.","We empirically demonstrate that finetuning this policy, with both reinforcement learning (RL) and behavior cloning (BC), enables sample-efficient adaptation to downstream tasks and simultaneously improves robustness and generalizability compared to prior approaches.","Qualitative experiments are available at: \\url{https://hgaurav2k.github.io/hop/}."],"url":"http://arxiv.org/abs/2409.08273v1"}
{"created":"2024-09-12 17:56:43","title":"Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale","abstract":"Large language models (LLMs) show remarkable potential to act as computer agents, enhancing human productivity and software accessibility in multi-modal tasks that require planning and reasoning. However, measuring agent performance in realistic environments remains a challenge since: (i) most benchmarks are limited to specific modalities or domains (e.g. text-only, web navigation, Q&A, coding) and (ii) full benchmark evaluations are slow (on order of magnitude of days) given the multi-step sequential nature of tasks. To address these challenges, we introduce the Windows Agent Arena: a reproducible, general environment focusing exclusively on the Windows operating system (OS) where agents can operate freely within a real Windows OS and use the same wide range of applications, tools, and web browsers available to human users when solving tasks. We adapt the OSWorld framework (Xie et al., 2024) to create 150+ diverse Windows tasks across representative domains that require agent abilities in planning, screen understanding, and tool usage. Our benchmark is scalable and can be seamlessly parallelized in Azure for a full benchmark evaluation in as little as 20 minutes. To demonstrate Windows Agent Arena's capabilities, we also introduce a new multi-modal agent, Navi. Our agent achieves a success rate of 19.5% in the Windows domain, compared to 74.5% performance of an unassisted human. Navi also demonstrates strong performance on another popular web-based benchmark, Mind2Web. We offer extensive quantitative and qualitative analysis of Navi's performance, and provide insights into the opportunities for future research in agent development and data generation using Windows Agent Arena.   Webpage: https://microsoft.github.io/WindowsAgentArena   Code: https://github.com/microsoft/WindowsAgentArena","sentences":["Large language models (LLMs) show remarkable potential to act as computer agents, enhancing human productivity and software accessibility in multi-modal tasks that require planning and reasoning.","However, measuring agent performance in realistic environments remains a challenge since: (i) most benchmarks are limited to specific modalities or domains (e.g. text-only, web navigation, Q&A, coding) and (ii) full benchmark evaluations are slow (on order of magnitude of days) given the multi-step sequential nature of tasks.","To address these challenges, we introduce the Windows Agent Arena: a reproducible, general environment focusing exclusively on the Windows operating system (OS) where agents can operate freely within a real Windows OS and use the same wide range of applications, tools, and web browsers available to human users when solving tasks.","We adapt the OSWorld framework (Xie et al., 2024) to create 150+ diverse Windows tasks across representative domains that require agent abilities in planning, screen understanding, and tool usage.","Our benchmark is scalable and can be seamlessly parallelized in Azure for a full benchmark evaluation in as little as 20 minutes.","To demonstrate Windows Agent Arena's capabilities, we also introduce a new multi-modal agent, Navi.","Our agent achieves a success rate of 19.5% in the Windows domain, compared to 74.5% performance of an unassisted human.","Navi also demonstrates strong performance on another popular web-based benchmark, Mind2Web.","We offer extensive quantitative and qualitative analysis of Navi's performance, and provide insights into the opportunities for future research in agent development and data generation using Windows Agent Arena.   ","Webpage: https://microsoft.github.io/WindowsAgentArena   Code: https://github.com/microsoft/WindowsAgentArena"],"url":"http://arxiv.org/abs/2409.08264v1"}
{"created":"2024-09-12 17:55:44","title":"Learning incomplete factorization preconditioners for GMRES","abstract":"In this paper, we develop a data-driven approach to generate incomplete LU factorizations of large-scale sparse matrices. The learned approximate factorization is utilized as a preconditioner for the corresponding linear equation system in the GMRES method. Incomplete factorization methods are one of the most commonly applied algebraic preconditioners for sparse linear equation systems and are able to speed up the convergence of Krylov subspace methods. However, they are sensitive to hyper-parameters and might suffer from numerical breakdown or lead to slow convergence when not properly applied. We replace the typically hand-engineered algorithms with a graph neural network based approach that is trained against data to predict an approximate factorization. This allows us to learn preconditioners tailored for a specific problem distribution. We analyze and empirically evaluate different loss functions to train the learned preconditioners and show their effectiveness to decrease the number of GMRES iterations and improve the spectral properties on our synthetic dataset. The code is available at https://github.com/paulhausner/neural-incomplete-factorization.","sentences":["In this paper, we develop a data-driven approach to generate incomplete LU factorizations of large-scale sparse matrices.","The learned approximate factorization is utilized as a preconditioner for the corresponding linear equation system in the GMRES method.","Incomplete factorization methods are one of the most commonly applied algebraic preconditioners for sparse linear equation systems and are able to speed up the convergence of Krylov subspace methods.","However, they are sensitive to hyper-parameters and might suffer from numerical breakdown or lead to slow convergence when not properly applied.","We replace the typically hand-engineered algorithms with a graph neural network based approach that is trained against data to predict an approximate factorization.","This allows us to learn preconditioners tailored for a specific problem distribution.","We analyze and empirically evaluate different loss functions to train the learned preconditioners and show their effectiveness to decrease the number of GMRES iterations and improve the spectral properties on our synthetic dataset.","The code is available at https://github.com/paulhausner/neural-incomplete-factorization."],"url":"http://arxiv.org/abs/2409.08262v1"}
{"created":"2024-09-12 17:48:08","title":"OmniQuery: Contextually Augmenting Captured Multimodal Memory to Enable Personal Question Answering","abstract":"People often capture memories through photos, screenshots, and videos. While existing AI-based tools enable querying this data using natural language, they mostly only support retrieving individual pieces of information like certain objects in photos and struggle with answering more complex queries that involve interpreting interconnected memories like event sequences. We conducted a one-month diary study to collect realistic user queries and generated a taxonomy of necessary contextual information for integrating with captured memories. We then introduce OmniQuery, a novel system that is able to answer complex personal memory-related questions that require extracting and inferring contextual information. OmniQuery augments single captured memories through integrating scattered contextual information from multiple interconnected memories, retrieves relevant memories, and uses a large language model (LLM) to comprehensive answers. In human evaluations, we show the effectiveness of OmniQuery with an accuracy of 71.5%, and it outperformed a conventional RAG system, winning or tying in 74.5% of the time.","sentences":["People often capture memories through photos, screenshots, and videos.","While existing AI-based tools enable querying this data using natural language, they mostly only support retrieving individual pieces of information like certain objects in photos and struggle with answering more complex queries that involve interpreting interconnected memories like event sequences.","We conducted a one-month diary study to collect realistic user queries and generated a taxonomy of necessary contextual information for integrating with captured memories.","We then introduce OmniQuery, a novel system that is able to answer complex personal memory-related questions that require extracting and inferring contextual information.","OmniQuery augments single captured memories through integrating scattered contextual information from multiple interconnected memories, retrieves relevant memories, and uses a large language model (LLM) to comprehensive answers.","In human evaluations, we show the effectiveness of OmniQuery with an accuracy of 71.5%, and it outperformed a conventional RAG system, winning or tying in 74.5% of the time."],"url":"http://arxiv.org/abs/2409.08250v1"}
{"created":"2024-09-12 17:47:56","title":"Quantifying Aleatoric and Epistemic Dynamics Uncertainty via Local Conformal Calibration","abstract":"Whether learned, simulated, or analytical, approximations of a robot's dynamics can be inaccurate when encountering novel environments. Many approaches have been proposed to quantify the aleatoric uncertainty of such methods, i.e. uncertainty resulting from stochasticity, however these estimates alone are not enough to properly estimate the uncertainty of a model in a novel environment, where the actual dynamics can change. Such changes can induce epistemic uncertainty, i.e. uncertainty due to a lack of information/data. Accounting for both epistemic and aleatoric dynamics uncertainty in a theoretically-grounded way remains an open problem. We introduce Local Uncertainty Conformal Calibration (LUCCa), a conformal prediction-based approach that calibrates the aleatoric uncertainty estimates provided by dynamics models to generate probabilistically-valid prediction regions of the system's state. We account for both epistemic and aleatoric uncertainty non-asymptotically, without strong assumptions about the form of the true dynamics or how it changes. The calibration is performed locally in the state-action space, leading to uncertainty estimates that are useful for planning. We validate our method by constructing probabilistically-safe plans for a double-integrator under significant changes in dynamics.","sentences":["Whether learned, simulated, or analytical, approximations of a robot's dynamics can be inaccurate when encountering novel environments.","Many approaches have been proposed to quantify the aleatoric uncertainty of such methods, i.e. uncertainty resulting from stochasticity, however these estimates alone are not enough to properly estimate the uncertainty of a model in a novel environment, where the actual dynamics can change.","Such changes can induce epistemic uncertainty, i.e. uncertainty due to a lack of information/data.","Accounting for both epistemic and aleatoric dynamics uncertainty in a theoretically-grounded way remains an open problem.","We introduce Local Uncertainty Conformal Calibration (LUCCa), a conformal prediction-based approach that calibrates the aleatoric uncertainty estimates provided by dynamics models to generate probabilistically-valid prediction regions of the system's state.","We account for both epistemic and aleatoric uncertainty non-asymptotically, without strong assumptions about the form of the true dynamics or how it changes.","The calibration is performed locally in the state-action space, leading to uncertainty estimates that are useful for planning.","We validate our method by constructing probabilistically-safe plans for a double-integrator under significant changes in dynamics."],"url":"http://arxiv.org/abs/2409.08249v1"}
{"created":"2024-09-12 17:39:08","title":"Source2Synth: Synthetic Data Generation and Curation Grounded in Real Data Sources","abstract":"Large Language Models still struggle in challenging scenarios that leverage structured data, complex reasoning, or tool usage. In this paper, we propose Source2Synth: a new method that can be used for teaching LLMs new skills without relying on costly human annotations. Source2Synth takes as input a custom data source and produces synthetic data points with intermediate reasoning steps grounded in real-world sources. Source2Synth improves the dataset quality by discarding low-quality generations based on their answerability. We demonstrate the generality of this approach by applying it to two challenging domains: we test reasoning abilities in multi-hop question answering (MHQA), and tool usage in tabular question answering (TQA). Our method improves performance by 25.51% for TQA on WikiSQL and 22.57% for MHQA on HotPotQA compared to the fine-tuned baselines.","sentences":["Large Language Models still struggle in challenging scenarios that leverage structured data, complex reasoning, or tool usage.","In this paper, we propose Source2Synth: a new method that can be used for teaching LLMs new skills without relying on costly human annotations.","Source2Synth takes as input a custom data source and produces synthetic data points with intermediate reasoning steps grounded in real-world sources.","Source2Synth improves the dataset quality by discarding low-quality generations based on their answerability.","We demonstrate the generality of this approach by applying it to two challenging domains: we test reasoning abilities in multi-hop question answering (MHQA), and tool usage in tabular question answering (TQA).","Our method improves performance by 25.51% for TQA on WikiSQL and 22.57% for MHQA on HotPotQA compared to the fine-tuned baselines."],"url":"http://arxiv.org/abs/2409.08239v1"}
{"created":"2024-09-12 17:36:26","title":"Multi-Model based Federated Learning Against Model Poisoning Attack: A Deep Learning Based Model Selection for MEC Systems","abstract":"Federated Learning (FL) enables training of a global model from distributed data, while preserving data privacy. However, the singular-model based operation of FL is open with uploading poisoned models compatible with the global model structure and can be exploited as a vulnerability to conduct model poisoning attacks. This paper proposes a multi-model based FL as a proactive mechanism to enhance the opportunity of model poisoning attack mitigation. A master model is trained by a set of slave models. To enhance the opportunity of attack mitigation, the structure of client models dynamically change within learning epochs, and the supporter FL protocol is provided. For a MEC system, the model selection problem is modeled as an optimization to minimize loss and recognition time, while meeting a robustness confidence. In adaption with dynamic network condition, a deep reinforcement learning based model selection is proposed. For a DDoS attack detection scenario, results illustrate a competitive accuracy gain under poisoning attack with the scenario that the system is without attack, and also a potential of recognition time improvement.","sentences":["Federated Learning (FL) enables training of a global model from distributed data, while preserving data privacy.","However, the singular-model based operation of FL is open with uploading poisoned models compatible with the global model structure and can be exploited as a vulnerability to conduct model poisoning attacks.","This paper proposes a multi-model based FL as a proactive mechanism to enhance the opportunity of model poisoning attack mitigation.","A master model is trained by a set of slave models.","To enhance the opportunity of attack mitigation, the structure of client models dynamically change within learning epochs, and the supporter FL protocol is provided.","For a MEC system, the model selection problem is modeled as an optimization to minimize loss and recognition time, while meeting a robustness confidence.","In adaption with dynamic network condition, a deep reinforcement learning based model selection is proposed.","For a DDoS attack detection scenario, results illustrate a competitive accuracy gain under poisoning attack with the scenario that the system is without attack, and also a potential of recognition time improvement."],"url":"http://arxiv.org/abs/2409.08237v1"}
{"created":"2024-09-12 17:33:06","title":"LLM Honeypot: Leveraging Large Language Models as Advanced Interactive Honeypot Systems","abstract":"The rapid evolution of cyber threats necessitates innovative solutions for detecting and analyzing malicious activity. Honeypots, which are decoy systems designed to lure and interact with attackers, have emerged as a critical component in cybersecurity. In this paper, we present a novel approach to creating realistic and interactive honeypot systems using Large Language Models (LLMs). By fine-tuning a pre-trained open-source language model on a diverse dataset of attacker-generated commands and responses, we developed a honeypot capable of sophisticated engagement with attackers. Our methodology involved several key steps: data collection and processing, prompt engineering, model selection, and supervised fine-tuning to optimize the model's performance. Evaluation through similarity metrics and live deployment demonstrated that our approach effectively generates accurate and informative responses. The results highlight the potential of LLMs to revolutionize honeypot technology, providing cybersecurity professionals with a powerful tool to detect and analyze malicious activity, thereby enhancing overall security infrastructure.","sentences":["The rapid evolution of cyber threats necessitates innovative solutions for detecting and analyzing malicious activity.","Honeypots, which are decoy systems designed to lure and interact with attackers, have emerged as a critical component in cybersecurity.","In this paper, we present a novel approach to creating realistic and interactive honeypot systems using Large Language Models (LLMs).","By fine-tuning a pre-trained open-source language model on a diverse dataset of attacker-generated commands and responses, we developed a honeypot capable of sophisticated engagement with attackers.","Our methodology involved several key steps: data collection and processing, prompt engineering, model selection, and supervised fine-tuning to optimize the model's performance.","Evaluation through similarity metrics and live deployment demonstrated that our approach effectively generates accurate and informative responses.","The results highlight the potential of LLMs to revolutionize honeypot technology, providing cybersecurity professionals with a powerful tool to detect and analyze malicious activity, thereby enhancing overall security infrastructure."],"url":"http://arxiv.org/abs/2409.08234v1"}
{"created":"2024-09-12 17:11:17","title":"Towards Instance-Optimal Euclidean Spanners","abstract":"Euclidean spanners are important geometric objects that have been extensively studied since the 1980s. The two most basic \"compactness'' measures of a Euclidean spanner $E$ are the size (number of edges) $|E|$ and the weight (sum of edge weights) $\\|E\\|$. In this paper, we initiate the study of instance optimal Euclidean spanners. Our results are two-fold.   We demonstrate that the greedy spanner is far from being instance optimal, even when allowing its stretch to grow. More concretely, we design two hard instances of point sets in the plane, where the greedy $(1+x \\epsilon)$-spanner (for basically any parameter $x \\geq 1$) has $\\Omega_x(\\epsilon^{-1/2}) \\cdot |E_\\mathrm{spa}|$ edges and weight $\\Omega_x(\\epsilon^{-1}) \\cdot \\|E_\\mathrm{light}\\|$, where $E_\\mathrm{spa}$ and $E_\\mathrm{light}$ denote the per-instance sparsest and lightest $(1+\\epsilon)$-spanners, respectively, and the $\\Omega_x$ notation suppresses a polynomial dependence on $1/x$.   As our main contribution, we design a new construction of Euclidean spanners, which is inherently different from known constructions, achieving the following bounds: a stretch of $1+\\epsilon\\cdot 2^{O(\\log^*(d/\\epsilon))}$ with $O(1) \\cdot |E_\\mathrm{spa}|$ edges and weight $O(1) \\cdot \\|E_\\mathrm{light}\\|$. In other words, we show that a slight increase to the stretch suffices for obtaining instance optimality up to an absolute constant for both sparsity and lightness. Remarkably, there is only a log-star dependence on the dimension in the stretch, and there is no dependence on it whatsoever in the number of edges and weight.","sentences":["Euclidean spanners are important geometric objects that have been extensively studied since the 1980s.","The two most basic \"compactness'' measures of a Euclidean spanner $E$ are the size (number of edges) $|E|$ and the weight (sum of edge weights) $\\|E\\|$. In this paper, we initiate the study of instance optimal Euclidean spanners.","Our results are two-fold.   ","We demonstrate that the greedy spanner is far from being instance optimal, even when allowing its stretch to grow.","More concretely, we design two hard instances of point sets in the plane, where the greedy $(1+x \\epsilon)$-spanner (for basically any parameter $x \\geq 1$) has $\\Omega_x(\\epsilon^{-1/2})","\\cdot |E_\\mathrm{spa}|$ edges and weight $\\Omega_x(\\epsilon^{-1}) \\cdot \\|E_\\mathrm{light}\\|$, where $E_\\mathrm{spa}$ and $E_\\mathrm{light}$ denote the per-instance sparsest and lightest $(1+\\epsilon)$-spanners, respectively, and the $\\Omega_x$ notation suppresses a polynomial dependence on $1/x$.   ","As our main contribution, we design a new construction of Euclidean spanners, which is inherently different from known constructions, achieving the following bounds: a stretch of $1+\\epsilon\\cdot 2^{O(\\log^*(d/\\epsilon))}$ with $O(1) \\cdot |E_\\mathrm{spa}|$ edges and weight $O(1) \\cdot \\|E_\\mathrm{light}\\|$.","In other words, we show that a slight increase to the stretch suffices for obtaining instance optimality up to an absolute constant for both sparsity and lightness.","Remarkably, there is only a log-star dependence on the dimension in the stretch, and there is no dependence on it whatsoever in the number of edges and weight."],"url":"http://arxiv.org/abs/2409.08227v1"}
{"created":"2024-09-12 17:01:03","title":"Graph Inspection for Robotic Motion Planning: Do Arithmetic Circuits Help?","abstract":"We investigate whether algorithms based on arithmetic circuits are a viable alternative to existing solvers for Graph Inspection, a problem with direct application in robotic motion planning. Specifically, we seek to address the high memory usage of existing solvers. Aided by novel theoretical results enabling fast solution recovery, we implement a circuit-based solver for Graph Inspection which uses only polynomial space and test it on several realistic robotic motion planning datasets. In particular, we provide a comprehensive experimental evaluation of a suite of engineered algorithms for three key subroutines. While this evaluation demonstrates that circuit-based methods are not yet practically competitive for our robotics application, it also provides insights which may guide future efforts to bring circuit-based algorithms from theory to practice.","sentences":["We investigate whether algorithms based on arithmetic circuits are a viable alternative to existing solvers for Graph Inspection, a problem with direct application in robotic motion planning.","Specifically, we seek to address the high memory usage of existing solvers.","Aided by novel theoretical results enabling fast solution recovery, we implement a circuit-based solver for Graph Inspection which uses only polynomial space and test it on several realistic robotic motion planning datasets.","In particular, we provide a comprehensive experimental evaluation of a suite of engineered algorithms for three key subroutines.","While this evaluation demonstrates that circuit-based methods are not yet practically competitive for our robotics application, it also provides insights which may guide future efforts to bring circuit-based algorithms from theory to practice."],"url":"http://arxiv.org/abs/2409.08219v1"}
{"created":"2024-09-12 16:56:26","title":"CliquePH: Higher-Order Information for Graph Neural Networks through Persistent Homology on Clique Graphs","abstract":"Graph neural networks have become the default choice by practitioners for graph learning tasks such as graph classification and node classification. Nevertheless, popular graph neural network models still struggle to capture higher-order information, i.e., information that goes \\emph{beyond} pairwise interactions. Recent work has shown that persistent homology, a tool from topological data analysis, can enrich graph neural networks with topological information that they otherwise could not capture. Calculating such features is efficient for dimension 0 (connected components) and dimension 1 (cycles). However, when it comes to higher-order structures, it does not scale well, with a complexity of $O(n^d)$, where $n$ is the number of nodes and $d$ is the order of the structures. In this work, we introduce a novel method that extracts information about higher-order structures in the graph while still using the efficient low-dimensional persistent homology algorithm. On standard benchmark datasets, we show that our method can lead to up to $31\\%$ improvements in test accuracy.","sentences":["Graph neural networks have become the default choice by practitioners for graph learning tasks such as graph classification and node classification.","Nevertheless, popular graph neural network models still struggle to capture higher-order information, i.e., information that goes \\emph{beyond} pairwise interactions.","Recent work has shown that persistent homology, a tool from topological data analysis, can enrich graph neural networks with topological information that they otherwise could not capture.","Calculating such features is efficient for dimension 0 (connected components) and dimension 1 (cycles).","However, when it comes to higher-order structures, it does not scale well, with a complexity of $O(n^d)$, where $n$ is the number of nodes and $d$ is the order of the structures.","In this work, we introduce a novel method that extracts information about higher-order structures in the graph while still using the efficient low-dimensional persistent homology algorithm.","On standard benchmark datasets, we show that our method can lead to up to $31\\%$ improvements in test accuracy."],"url":"http://arxiv.org/abs/2409.08217v1"}
{"created":"2024-09-12 16:51:55","title":"Graph Laplacian-based Bayesian Multi-fidelity Modeling","abstract":"We present a novel probabilistic approach for generating multi-fidelity data while accounting for errors inherent in both low- and high-fidelity data. In this approach a graph Laplacian constructed from the low-fidelity data is used to define a multivariate Gaussian prior density for the coordinates of the true data points. In addition, few high-fidelity data points are used to construct a conjugate likelihood term. Thereafter, Bayes rule is applied to derive an explicit expression for the posterior density which is also multivariate Gaussian. The maximum \\textit{a posteriori} (MAP) estimate of this density is selected to be the optimal multi-fidelity estimate. It is shown that the MAP estimate and the covariance of the posterior density can be determined through the solution of linear systems of equations. Thereafter, two methods, one based on spectral truncation and another based on a low-rank approximation, are developed to solve these equations efficiently. The multi-fidelity approach is tested on a variety of problems in solid and fluid mechanics with data that represents vectors of quantities of interest and discretized spatial fields in one and two dimensions. The results demonstrate that by utilizing a small fraction of high-fidelity data, the multi-fidelity approach can significantly improve the accuracy of a large collection of low-fidelity data points.","sentences":["We present a novel probabilistic approach for generating multi-fidelity data while accounting for errors inherent in both low- and high-fidelity data.","In this approach a graph Laplacian constructed from the low-fidelity data is used to define a multivariate Gaussian prior density for the coordinates of the true data points.","In addition, few high-fidelity data points are used to construct a conjugate likelihood term.","Thereafter, Bayes rule is applied to derive an explicit expression for the posterior density which is also multivariate Gaussian.","The maximum \\textit{a posteriori} (MAP) estimate of this density is selected to be the optimal multi-fidelity estimate.","It is shown that the MAP estimate and the covariance of the posterior density can be determined through the solution of linear systems of equations.","Thereafter, two methods, one based on spectral truncation and another based on a low-rank approximation, are developed to solve these equations efficiently.","The multi-fidelity approach is tested on a variety of problems in solid and fluid mechanics with data that represents vectors of quantities of interest and discretized spatial fields in one and two dimensions.","The results demonstrate that by utilizing a small fraction of high-fidelity data, the multi-fidelity approach can significantly improve the accuracy of a large collection of low-fidelity data points."],"url":"http://arxiv.org/abs/2409.08211v1"}
{"created":"2024-09-12 16:38:20","title":"Machine Learning for Two-Sample Testing under Right-Censored Data: A Simulation Study","abstract":"The focus of this study is to evaluate the effectiveness of Machine Learning (ML) methods for two-sample testing with right-censored observations. To achieve this, we develop several ML-based methods with varying architectures and implement them as two-sample tests. Each method is an ensemble (stacking) that combines predictions from classical two-sample tests. This paper presents the results of training the proposed ML methods, examines their statistical power compared to classical two-sample tests, analyzes the distribution of test statistics for the proposed methods when the null hypothesis is true, and evaluates the significance of the features incorporated into the proposed methods. All results from numerical experiments were obtained from a synthetic dataset generated using the Smirnov transform (Inverse Transform Sampling) and replicated multiple times through Monte Carlo simulation. To test the two-sample problem with right-censored observations, one can use the proposed two-sample methods. All necessary materials (source code, example scripts, dataset, and samples) are available on GitHub and Hugging Face.","sentences":["The focus of this study is to evaluate the effectiveness of Machine Learning (ML) methods for two-sample testing with right-censored observations.","To achieve this, we develop several ML-based methods with varying architectures and implement them as two-sample tests.","Each method is an ensemble (stacking) that combines predictions from classical two-sample tests.","This paper presents the results of training the proposed ML methods, examines their statistical power compared to classical two-sample tests, analyzes the distribution of test statistics for the proposed methods when the null hypothesis is true, and evaluates the significance of the features incorporated into the proposed methods.","All results from numerical experiments were obtained from a synthetic dataset generated using the Smirnov transform (Inverse Transform Sampling) and replicated multiple times through Monte Carlo simulation.","To test the two-sample problem with right-censored observations, one can use the proposed two-sample methods.","All necessary materials (source code, example scripts, dataset, and samples) are available on GitHub and Hugging Face."],"url":"http://arxiv.org/abs/2409.08201v1"}
{"created":"2024-09-12 16:20:57","title":"Fine-tuning Large Language Models for Entity Matching","abstract":"Generative large language models (LLMs) are a promising alternative to pre-trained language models for entity matching due to their high zero-shot performance and their ability to generalize to unseen entities. Existing research on using LLMs for entity matching has focused on prompt engineering and in-context learning. This paper explores the potential of fine-tuning LLMs for entity matching. We analyze fine-tuning along two dimensions: 1) The representation of training examples, where we experiment with adding different types of LLM-generated explanations to the training set, and 2) the selection and generation of training examples using LLMs. In addition to the matching performance on the source dataset, we investigate how fine-tuning affects the model's ability to generalize to other in-domain datasets as well as across topical domains. Our experiments show that fine-tuning significantly improves the performance of the smaller models while the results for the larger models are mixed. Fine-tuning also improves the generalization to in-domain datasets while hurting cross-domain transfer. We show that adding structured explanations to the training set has a positive impact on the performance of three out of four LLMs, while the proposed example selection and generation methods only improve the performance of Llama 3.1 8B while decreasing the performance of GPT-4o Mini.","sentences":["Generative large language models (LLMs) are a promising alternative to pre-trained language models for entity matching due to their high zero-shot performance and their ability to generalize to unseen entities.","Existing research on using LLMs for entity matching has focused on prompt engineering and in-context learning.","This paper explores the potential of fine-tuning LLMs for entity matching.","We analyze fine-tuning along two dimensions: 1) The representation of training examples, where we experiment with adding different types of LLM-generated explanations to the training set, and 2) the selection and generation of training examples using LLMs.","In addition to the matching performance on the source dataset, we investigate how fine-tuning affects the model's ability to generalize to other in-domain datasets as well as across topical domains.","Our experiments show that fine-tuning significantly improves the performance of the smaller models while the results for the larger models are mixed.","Fine-tuning also improves the generalization to in-domain datasets while hurting cross-domain transfer.","We show that adding structured explanations to the training set has a positive impact on the performance of three out of four LLMs, while the proposed example selection and generation methods only improve the performance of Llama 3.1 8B while decreasing the performance of GPT-4o Mini."],"url":"http://arxiv.org/abs/2409.08185v1"}
{"created":"2024-09-12 16:13:07","title":"Enhancing Canine Musculoskeletal Diagnoses: Leveraging Synthetic Image Data for Pre-Training AI-Models on Visual Documentations","abstract":"The examination of the musculoskeletal system in dogs is a challenging task in veterinary practice. In this work, a novel method has been developed that enables efficient documentation of a dog's condition through a visual representation. However, since the visual documentation is new, there is no existing training data. The objective of this work is therefore to mitigate the impact of data scarcity in order to develop an AI-based diagnostic support system. To this end, the potential of synthetic data that mimics realistic visual documentations of diseases for pre-training AI models is investigated. We propose a method for generating synthetic image data that mimics realistic visual documentations. Initially, a basic dataset containing three distinct classes is generated, followed by the creation of a more sophisticated dataset containing 36 different classes. Both datasets are used for the pre-training of an AI model. Subsequently, an evaluation dataset is created, consisting of 250 manually created visual documentations for five different diseases. This dataset, along with a subset containing 25 examples. The obtained results on the evaluation dataset containing 25 examples demonstrate a significant enhancement of approximately 10% in diagnosis accuracy when utilizing generated synthetic images that mimic real-world visual documentations. However, these results do not hold true for the larger evaluation dataset containing 250 examples, indicating that the advantages of using synthetic data for pre-training an AI model emerge primarily when dealing with few examples of visual documentations for a given disease. Overall, this work provides valuable insights into mitigating the limitations imposed by limited training data through the strategic use of generated synthetic data, presenting an approach applicable beyond the canine musculoskeletal assessment domain.","sentences":["The examination of the musculoskeletal system in dogs is a challenging task in veterinary practice.","In this work, a novel method has been developed that enables efficient documentation of a dog's condition through a visual representation.","However, since the visual documentation is new, there is no existing training data.","The objective of this work is therefore to mitigate the impact of data scarcity in order to develop an AI-based diagnostic support system.","To this end, the potential of synthetic data that mimics realistic visual documentations of diseases for pre-training AI models is investigated.","We propose a method for generating synthetic image data that mimics realistic visual documentations.","Initially, a basic dataset containing three distinct classes is generated, followed by the creation of a more sophisticated dataset containing 36 different classes.","Both datasets are used for the pre-training of an AI model.","Subsequently, an evaluation dataset is created, consisting of 250 manually created visual documentations for five different diseases.","This dataset, along with a subset containing 25 examples.","The obtained results on the evaluation dataset containing 25 examples demonstrate a significant enhancement of approximately 10% in diagnosis accuracy when utilizing generated synthetic images that mimic real-world visual documentations.","However, these results do not hold true for the larger evaluation dataset containing 250 examples, indicating that the advantages of using synthetic data for pre-training an AI model emerge primarily when dealing with few examples of visual documentations for a given disease.","Overall, this work provides valuable insights into mitigating the limitations imposed by limited training data through the strategic use of generated synthetic data, presenting an approach applicable beyond the canine musculoskeletal assessment domain."],"url":"http://arxiv.org/abs/2409.08181v1"}
{"created":"2024-09-12 16:06:45","title":"Co-badge: An Activity for Collaborative Engagement with Data Visualization Design Concepts","abstract":"As data visualization gains popularity and projects become more interdisciplinary, there is a growing need for methods that foster creative collaboration and inform diverse audiences about data visualisation. In this paper, we introduce Co-Badge, a 90-minute design activity where participants collaboratively construct visualizations by ideating and prioritizing relevant data types, mapping them to visual variables, and constructing data badges with stationery materials. We conducted three workshops in diverse settings with participants of different backgrounds. Our findings indicate that Co-badge facilitates a playful and engaging way to gain awareness about data visualization design principles without formal training while navigating the challenges of collaboration. Our work contributes to the field of data visualization education for diverse actors. We believe Co-Badge can serve as an engaging activity that introduces basic concepts of data visualization and collaboration.","sentences":["As data visualization gains popularity and projects become more interdisciplinary, there is a growing need for methods that foster creative collaboration and inform diverse audiences about data visualisation.","In this paper, we introduce Co-Badge, a 90-minute design activity where participants collaboratively construct visualizations by ideating and prioritizing relevant data types, mapping them to visual variables, and constructing data badges with stationery materials.","We conducted three workshops in diverse settings with participants of different backgrounds.","Our findings indicate that Co-badge facilitates a playful and engaging way to gain awareness about data visualization design principles without formal training while navigating the challenges of collaboration.","Our work contributes to the field of data visualization education for diverse actors.","We believe Co-Badge can serve as an engaging activity that introduces basic concepts of data visualization and collaboration."],"url":"http://arxiv.org/abs/2409.08175v1"}
{"created":"2024-09-12 16:03:56","title":"Low-Cost Tree Crown Dieback Estimation Using Deep Learning-Based Segmentation","abstract":"The global increase in observed forest dieback, characterised by the death of tree foliage, heralds widespread decline in forest ecosystems. This degradation causes significant changes to ecosystem services and functions, including habitat provision and carbon sequestration, which can be difficult to detect using traditional monitoring techniques, highlighting the need for large-scale and high-frequency monitoring. Contemporary developments in the instruments and methods to gather and process data at large-scales mean this monitoring is now possible. In particular, the advancement of low-cost drone technology and deep learning on consumer-level hardware provide new opportunities. Here, we use an approach based on deep learning and vegetation indices to assess crown dieback from RGB aerial data without the need for expensive instrumentation such as LiDAR. We use an iterative approach to match crown footprints predicted by deep learning with field-based inventory data from a Mediterranean ecosystem exhibiting drought-induced dieback, and compare expert field-based crown dieback estimation with vegetation index-based estimates. We obtain high overall segmentation accuracy (mAP: 0.519) without the need for additional technical development of the underlying Mask R-CNN model, underscoring the potential of these approaches for non-expert use and proving their applicability to real-world conservation. We also find colour-coordinate based estimates of dieback correlate well with expert field-based estimation. Substituting ground truth for Mask R-CNN model predictions showed negligible impact on dieback estimates, indicating robustness. Our findings demonstrate the potential of automated data collection and processing, including the application of deep learning, to improve the coverage, speed and cost of forest dieback monitoring.","sentences":["The global increase in observed forest dieback, characterised by the death of tree foliage, heralds widespread decline in forest ecosystems.","This degradation causes significant changes to ecosystem services and functions, including habitat provision and carbon sequestration, which can be difficult to detect using traditional monitoring techniques, highlighting the need for large-scale and high-frequency monitoring.","Contemporary developments in the instruments and methods to gather and process data at large-scales mean this monitoring is now possible.","In particular, the advancement of low-cost drone technology and deep learning on consumer-level hardware provide new opportunities.","Here, we use an approach based on deep learning and vegetation indices to assess crown dieback from RGB aerial data without the need for expensive instrumentation such as LiDAR.","We use an iterative approach to match crown footprints predicted by deep learning with field-based inventory data from a Mediterranean ecosystem exhibiting drought-induced dieback, and compare expert field-based crown dieback estimation with vegetation index-based estimates.","We obtain high overall segmentation accuracy (mAP: 0.519) without the need for additional technical development of the underlying Mask R-CNN model, underscoring the potential of these approaches for non-expert use and proving their applicability to real-world conservation.","We also find colour-coordinate based estimates of dieback correlate well with expert field-based estimation.","Substituting ground truth for Mask R-CNN model predictions showed negligible impact on dieback estimates, indicating robustness.","Our findings demonstrate the potential of automated data collection and processing, including the application of deep learning, to improve the coverage, speed and cost of forest dieback monitoring."],"url":"http://arxiv.org/abs/2409.08171v1"}
{"created":"2024-09-12 15:58:28","title":"High-Frequency Anti-DreamBooth: Robust Defense Against Image Synthesis","abstract":"Recently, text-to-image generative models have been misused to create unauthorized malicious images of individuals, posing a growing social problem. Previous solutions, such as Anti-DreamBooth, add adversarial noise to images to protect them from being used as training data for malicious generation. However, we found that the adversarial noise can be removed by adversarial purification methods such as DiffPure. Therefore, we propose a new adversarial attack method that adds strong perturbation on the high-frequency areas of images to make it more robust to adversarial purification. Our experiment showed that the adversarial images retained noise even after adversarial purification, hindering malicious image generation.","sentences":["Recently, text-to-image generative models have been misused to create unauthorized malicious images of individuals, posing a growing social problem.","Previous solutions, such as Anti-DreamBooth, add adversarial noise to images to protect them from being used as training data for malicious generation.","However, we found that the adversarial noise can be removed by adversarial purification methods such as DiffPure.","Therefore, we propose a new adversarial attack method that adds strong perturbation on the high-frequency areas of images to make it more robust to adversarial purification.","Our experiment showed that the adversarial images retained noise even after adversarial purification, hindering malicious image generation."],"url":"http://arxiv.org/abs/2409.08167v1"}
{"created":"2024-09-12 15:57:08","title":"Collaborating for Success: Optimizing System Efficiency and Resilience Under Agile Industrial Settings","abstract":"Designing an efficient and resilient human-robot collaboration strategy that not only upholds the safety and ergonomics of shared workspace but also enhances the performance and agility of collaborative setup presents significant challenges concerning environment perception and robot control. In this research, we introduce a novel approach for collaborative environment monitoring and robot motion regulation to address this multifaceted problem. Our study proposes novel computation and division of safety monitoring zones, adhering to ISO 13855 and TS 15066 standards, utilizing 2D lasers information. These zones are not only configured in the standard three-layer arrangement but are also expanded into two adjacent quadrants, thereby enhancing system uptime and preventing unnecessary deadlocks. Moreover, we also leverage 3D visual information to track dynamic human articulations and extended intrusions. Drawing upon the fused sensory data from 2D and 3D perceptual spaces, our proposed hierarchical controller stably regulates robot velocity, validated using Lasalle in-variance principle. Empirical evaluations demonstrate that our approach significantly reduces task execution time and system response delay, resulting in improved efficiency and resilience within collaborative settings.","sentences":["Designing an efficient and resilient human-robot collaboration strategy that not only upholds the safety and ergonomics of shared workspace but also enhances the performance and agility of collaborative setup presents significant challenges concerning environment perception and robot control.","In this research, we introduce a novel approach for collaborative environment monitoring and robot motion regulation to address this multifaceted problem.","Our study proposes novel computation and division of safety monitoring zones, adhering to ISO 13855 and TS 15066 standards, utilizing 2D lasers information.","These zones are not only configured in the standard three-layer arrangement but are also expanded into two adjacent quadrants, thereby enhancing system uptime and preventing unnecessary deadlocks.","Moreover, we also leverage 3D visual information to track dynamic human articulations and extended intrusions.","Drawing upon the fused sensory data from 2D and 3D perceptual spaces, our proposed hierarchical controller stably regulates robot velocity, validated using Lasalle in-variance principle.","Empirical evaluations demonstrate that our approach significantly reduces task execution time and system response delay, resulting in improved efficiency and resilience within collaborative settings."],"url":"http://arxiv.org/abs/2409.08166v1"}
{"created":"2024-09-12 15:34:23","title":"Rethinking Programmed I/O for Fast Devices, Cheap Cores, and Coherent Interconnects","abstract":"Conventional wisdom holds that an efficient interface between an OS running on a CPU and a high-bandwidth I/O device should be based on Direct Memory Access (DMA), descriptor rings, and interrupts: DMA offloads transfers from the CPU, descriptor rings provide buffering and queuing, and interrupts facilitate asynchronous interaction between cores and device with a lightweight notification mechanism. In this paper we question this wisdom in the light of modern hardware and workloads, particularly in cloud servers. We argue that the assumptions that led to this model are obsolete, and in many use-cases use of programmed I/O, where the CPU explicitly transfers data and control information to and from a device via loads and stores, actually results in a more efficient system. We quantitatively demonstrate these advantages using three use-cases: fine-grained RPC-style invocation of functions on an accelerator, offloading of operators in a streaming dataflow engine, and a network interface targeting for serverless functions. Moreover, we show that while these advantages are significant over a modern PCIe peripheral bus, a truly cache-coherent interconnect offers significant additional efficiency gains.","sentences":["Conventional wisdom holds that an efficient interface between an OS running on a CPU and a high-bandwidth I/O device should be based on Direct Memory Access (DMA), descriptor rings, and interrupts: DMA offloads transfers from the CPU, descriptor rings provide buffering and queuing, and interrupts facilitate asynchronous interaction between cores and device with a lightweight notification mechanism.","In this paper we question this wisdom in the light of modern hardware and workloads, particularly in cloud servers.","We argue that the assumptions that led to this model are obsolete, and in many use-cases use of programmed I/O, where the CPU explicitly transfers data and control information to and from a device via loads and stores, actually results in a more efficient system.","We quantitatively demonstrate these advantages using three use-cases: fine-grained RPC-style invocation of functions on an accelerator, offloading of operators in a streaming dataflow engine, and a network interface targeting for serverless functions.","Moreover, we show that while these advantages are significant over a modern PCIe peripheral bus, a truly cache-coherent interconnect offers significant additional efficiency gains."],"url":"http://arxiv.org/abs/2409.08141v1"}
{"created":"2024-09-12 15:27:09","title":"Reducing Population-level Inequality Can Improve Demographic Group Fairness: a Twitter Case Study","abstract":"Many existing fairness metrics measure group-wise demographic disparities in system behavior or model performance. Calculating these metrics requires access to demographic information, which, in industrial settings, is often unavailable. By contrast, economic inequality metrics, such as the Gini coefficient, require no demographic data to measure. However, reductions in economic inequality do not necessarily correspond to reductions in demographic disparities. In this paper, we empirically explore the relationship between demographic-free inequality metrics -- such as the Gini coefficient -- and standard demographic bias metrics that measure group-wise model performance disparities specifically in the case of engagement inequality on Twitter. We analyze tweets from 174K users over the duration of 2021 and find that demographic-free impression inequality metrics are positively correlated with gender, race, and age disparities in the average case, and weakly (but still positively) correlated with demographic bias in the worst case. We therefore recommend inequality metrics as a potentially useful proxy measure of average group-wise disparities, especially in cases where such disparities cannot be measured directly. Based on these results, we believe they can be used as part of broader efforts to improve fairness between demographic groups in scenarios like content recommendation on social media.","sentences":["Many existing fairness metrics measure group-wise demographic disparities in system behavior or model performance.","Calculating these metrics requires access to demographic information, which, in industrial settings, is often unavailable.","By contrast, economic inequality metrics, such as the Gini coefficient, require no demographic data to measure.","However, reductions in economic inequality do not necessarily correspond to reductions in demographic disparities.","In this paper, we empirically explore the relationship between demographic-free inequality metrics -- such as the Gini coefficient -- and standard demographic bias metrics that measure group-wise model performance disparities specifically in the case of engagement inequality on Twitter.","We analyze tweets from 174K users over the duration of 2021 and find that demographic-free impression inequality metrics are positively correlated with gender, race, and age disparities in the average case, and weakly (but still positively) correlated with demographic bias in the worst case.","We therefore recommend inequality metrics as a potentially useful proxy measure of average group-wise disparities, especially in cases where such disparities cannot be measured directly.","Based on these results, we believe they can be used as part of broader efforts to improve fairness between demographic groups in scenarios like content recommendation on social media."],"url":"http://arxiv.org/abs/2409.08135v1"}
{"created":"2024-09-12 15:07:16","title":"Anonymized Network Sensing Graph Challenge","abstract":"The MIT/IEEE/Amazon GraphChallenge encourages community approaches to developing new solutions for analyzing graphs and sparse data derived from social media, sensor feeds, and scientific data to discover relationships between events as they unfold in the field. The anonymized network sensing Graph Challenge seeks to enable large, open, community-based approaches to protecting networks. Many large-scale networking problems can only be solved with community access to very broad data sets with the highest regard for privacy and strong community buy-in. Such approaches often require community-based data sharing. In the broader networking community (commercial, federal, and academia) anonymized source-to-destination traffic matrices with standard data sharing agreements have emerged as a data product that can meet many of these requirements. This challenge provides an opportunity to highlight novel approaches for optimizing the construction and analysis of anonymized traffic matrices using over 100 billion network packets derived from the largest Internet telescope in the world (CAIDA). This challenge specifies the anonymization, construction, and analysis of these traffic matrices. A GraphBLAS reference implementation is provided, but the use of GraphBLAS is not required in this Graph Challenge. As with prior Graph Challenges the goal is to provide a well-defined context for demonstrating innovation. Graph Challenge participants are free to select (with accompanying explanation) the Graph Challenge elements that are appropriate for highlighting their innovations.","sentences":["The MIT/IEEE/Amazon GraphChallenge encourages community approaches to developing new solutions for analyzing graphs and sparse data derived from social media, sensor feeds, and scientific data to discover relationships between events as they unfold in the field.","The anonymized network sensing Graph Challenge seeks to enable large, open, community-based approaches to protecting networks.","Many large-scale networking problems can only be solved with community access to very broad data sets with the highest regard for privacy and strong community buy-in.","Such approaches often require community-based data sharing.","In the broader networking community (commercial, federal, and academia) anonymized source-to-destination traffic matrices with standard data sharing agreements have emerged as a data product that can meet many of these requirements.","This challenge provides an opportunity to highlight novel approaches for optimizing the construction and analysis of anonymized traffic matrices using over 100 billion network packets derived from the largest Internet telescope in the world (CAIDA).","This challenge specifies the anonymization, construction, and analysis of these traffic matrices.","A GraphBLAS reference implementation is provided, but the use of GraphBLAS is not required in this Graph Challenge.","As with prior Graph Challenges the goal is to provide a well-defined context for demonstrating innovation.","Graph Challenge participants are free to select (with accompanying explanation) the Graph Challenge elements that are appropriate for highlighting their innovations."],"url":"http://arxiv.org/abs/2409.08115v1"}
{"created":"2024-09-12 15:04:34","title":"Towards a graph-based foundation model for network traffic analysis","abstract":"Foundation models have shown great promise in various fields of study. A potential application of such models is in computer network traffic analysis, where these models can grasp the complexities of network traffic dynamics and adapt to any specific task or network environment with minimal fine-tuning. Previous approaches have used tokenized hex-level packet data and the model architecture of large language transformer models. We propose a new, efficient graph-based alternative at the flow-level. Our approach represents network traffic as a dynamic spatio-temporal graph, employing a self-supervised link prediction pretraining task to capture the spatial and temporal dynamics in this network graph framework. To evaluate the effectiveness of our approach, we conduct a few-shot learning experiment for three distinct downstream network tasks: intrusion detection, traffic classification, and botnet classification. Models finetuned from our pretrained base achieve an average performance increase of 6.87\\% over training from scratch, demonstrating their ability to effectively learn general network traffic dynamics during pretraining. This success suggests the potential for a large-scale version to serve as an operational foundational model.","sentences":["Foundation models have shown great promise in various fields of study.","A potential application of such models is in computer network traffic analysis, where these models can grasp the complexities of network traffic dynamics and adapt to any specific task or network environment with minimal fine-tuning.","Previous approaches have used tokenized hex-level packet data and the model architecture of large language transformer models.","We propose a new, efficient graph-based alternative at the flow-level.","Our approach represents network traffic as a dynamic spatio-temporal graph, employing a self-supervised link prediction pretraining task to capture the spatial and temporal dynamics in this network graph framework.","To evaluate the effectiveness of our approach, we conduct a few-shot learning experiment for three distinct downstream network tasks: intrusion detection, traffic classification, and botnet classification.","Models finetuned from our pretrained base achieve an average performance increase of 6.87\\% over training from scratch, demonstrating their ability to effectively learn general network traffic dynamics during pretraining.","This success suggests the potential for a large-scale version to serve as an operational foundational model."],"url":"http://arxiv.org/abs/2409.08111v1"}
{"created":"2024-09-12 15:00:07","title":"Hypergraph Change Point Detection using Adapted Cardinality-Based Gadgets: Applications in Dynamic Legal Structures","abstract":"Hypergraphs provide a robust framework for modeling complex systems with higher-order interactions. However, analyzing them in dynamic settings presents significant computational challenges. To address this, we introduce a novel method that adapts the cardinality-based gadget to convert hypergraphs into strongly connected weighted directed graphs, complemented by a symmetrized combinatorial Laplacian. We demonstrate that the harmonic mean of the conductance and edge expansion of the original hypergraph can be upper-bounded by the conductance of the transformed directed graph, effectively preserving crucial cut information. Additionally, we analyze how the resulting Laplacian relates to that derived from the star expansion. Our approach was validated through change point detection experiments on both synthetic and real datasets, showing superior performance over clique and star expansions in maintaining spectral information in dynamic settings. Finally, we applied our method to analyze a dynamic legal hypergraph constructed from extensive United States court opinion data.","sentences":["Hypergraphs provide a robust framework for modeling complex systems with higher-order interactions.","However, analyzing them in dynamic settings presents significant computational challenges.","To address this, we introduce a novel method that adapts the cardinality-based gadget to convert hypergraphs into strongly connected weighted directed graphs, complemented by a symmetrized combinatorial Laplacian.","We demonstrate that the harmonic mean of the conductance and edge expansion of the original hypergraph can be upper-bounded by the conductance of the transformed directed graph, effectively preserving crucial cut information.","Additionally, we analyze how the resulting Laplacian relates to that derived from the star expansion.","Our approach was validated through change point detection experiments on both synthetic and real datasets, showing superior performance over clique and star expansions in maintaining spectral information in dynamic settings.","Finally, we applied our method to analyze a dynamic legal hypergraph constructed from extensive United States court opinion data."],"url":"http://arxiv.org/abs/2409.08106v1"}
{"created":"2024-09-12 14:55:45","title":"Designing a Collaborative Platform for Advancing Supply Chain Transparency","abstract":"Enabling supply chain transparency (SCT) is essential for regulatory compliance and meeting sustainability standards. Multi-tier SCT plays a pivotal role in identifying and mitigating an organization's operational, environmental, and social (ESG) risks. While research observes increasing efforts towards SCT, a minority of companies are currently publishing supply chain information. Using the Design Science Research approach, we develop a collaborative platform for supply chain transparency. We derive design requirements, formulate design principles, and evaluate the artefact with industry experts. Our artefact is initialized with publicly available supply chain data through an automated pipeline designed to onboard future participants to our platform. This work contributes to SCT research by providing insights into the challenges and opportunities of implementing multi-tier SCT and offers a practical solution that encourages organizations to participate in a transparent ecosystem.","sentences":["Enabling supply chain transparency (SCT) is essential for regulatory compliance and meeting sustainability standards.","Multi-tier SCT plays a pivotal role in identifying and mitigating an organization's operational, environmental, and social (ESG) risks.","While research observes increasing efforts towards SCT, a minority of companies are currently publishing supply chain information.","Using the Design Science Research approach, we develop a collaborative platform for supply chain transparency.","We derive design requirements, formulate design principles, and evaluate the artefact with industry experts.","Our artefact is initialized with publicly available supply chain data through an automated pipeline designed to onboard future participants to our platform.","This work contributes to SCT research by providing insights into the challenges and opportunities of implementing multi-tier SCT and offers a practical solution that encourages organizations to participate in a transparent ecosystem."],"url":"http://arxiv.org/abs/2409.08104v1"}
{"created":"2024-09-12 14:54:31","title":"Bayesian Self-Training for Semi-Supervised 3D Segmentation","abstract":"3D segmentation is a core problem in computer vision and, similarly to many other dense prediction tasks, it requires large amounts of annotated data for adequate training. However, densely labeling 3D point clouds to employ fully-supervised training remains too labor intensive and expensive. Semi-supervised training provides a more practical alternative, where only a small set of labeled data is given, accompanied by a larger unlabeled set. This area thus studies the effective use of unlabeled data to reduce the performance gap that arises due to the lack of annotations. In this work, inspired by Bayesian deep learning, we first propose a Bayesian self-training framework for semi-supervised 3D semantic segmentation. Employing stochastic inference, we generate an initial set of pseudo-labels and then filter these based on estimated point-wise uncertainty. By constructing a heuristic $n$-partite matching algorithm, we extend the method to semi-supervised 3D instance segmentation, and finally, with the same building blocks, to dense 3D visual grounding. We demonstrate state-of-the-art results for our semi-supervised method on SemanticKITTI and ScribbleKITTI for 3D semantic segmentation and on ScanNet and S3DIS for 3D instance segmentation. We further achieve substantial improvements in dense 3D visual grounding over supervised-only baselines on ScanRefer. Our project page is available at ouenal.github.io/bst/.","sentences":["3D segmentation is a core problem in computer vision and, similarly to many other dense prediction tasks, it requires large amounts of annotated data for adequate training.","However, densely labeling 3D point clouds to employ fully-supervised training remains too labor intensive and expensive.","Semi-supervised training provides a more practical alternative, where only a small set of labeled data is given, accompanied by a larger unlabeled set.","This area thus studies the effective use of unlabeled data to reduce the performance gap that arises due to the lack of annotations.","In this work, inspired by Bayesian deep learning, we first propose a Bayesian self-training framework for semi-supervised 3D semantic segmentation.","Employing stochastic inference, we generate an initial set of pseudo-labels and then filter these based on estimated point-wise uncertainty.","By constructing a heuristic $n$-partite matching algorithm, we extend the method to semi-supervised 3D instance segmentation, and finally, with the same building blocks, to dense 3D visual grounding.","We demonstrate state-of-the-art results for our semi-supervised method on SemanticKITTI and ScribbleKITTI for 3D semantic segmentation and on ScanNet and S3DIS for 3D instance segmentation.","We further achieve substantial improvements in dense 3D visual grounding over supervised-only baselines on ScanRefer.","Our project page is available at ouenal.github.io/bst/."],"url":"http://arxiv.org/abs/2409.08102v1"}
{"created":"2024-09-12 14:51:43","title":"The CLC-UKET Dataset: Benchmarking Case Outcome Prediction for the UK Employment Tribunal","abstract":"This paper explores the intersection of technological innovation and access to justice by developing a benchmark for predicting case outcomes in the UK Employment Tribunal (UKET). To address the challenge of extensive manual annotation, the study employs a large language model (LLM) for automatic annotation, resulting in the creation of the CLC-UKET dataset. The dataset consists of approximately 19,000 UKET cases and their metadata. Comprehensive legal annotations cover facts, claims, precedent references, statutory references, case outcomes, reasons and jurisdiction codes. Facilitated by the CLC-UKET data, we examine a multi-class case outcome prediction task in the UKET. Human predictions are collected to establish a performance reference for model comparison. Empirical results from baseline models indicate that finetuned transformer models outperform zero-shot and few-shot LLMs on the UKET prediction task. The performance of zero-shot LLMs can be enhanced by integrating task-related information into few-shot examples. We hope that the CLC-UKET dataset, along with human annotations and empirical findings, can serve as a valuable benchmark for employment-related dispute resolution.","sentences":["This paper explores the intersection of technological innovation and access to justice by developing a benchmark for predicting case outcomes in the UK Employment Tribunal (UKET).","To address the challenge of extensive manual annotation, the study employs a large language model (LLM) for automatic annotation, resulting in the creation of the CLC-UKET dataset.","The dataset consists of approximately 19,000 UKET cases and their metadata.","Comprehensive legal annotations cover facts, claims, precedent references, statutory references, case outcomes, reasons and jurisdiction codes.","Facilitated by the CLC-UKET data, we examine a multi-class case outcome prediction task in the UKET.","Human predictions are collected to establish a performance reference for model comparison.","Empirical results from baseline models indicate that finetuned transformer models outperform zero-shot and few-shot LLMs on the UKET prediction task.","The performance of zero-shot LLMs can be enhanced by integrating task-related information into few-shot examples.","We hope that the CLC-UKET dataset, along with human annotations and empirical findings, can serve as a valuable benchmark for employment-related dispute resolution."],"url":"http://arxiv.org/abs/2409.08098v1"}
{"created":"2024-09-12 14:44:45","title":"EZIGen: Enhancing zero-shot subject-driven image generation with precise subject encoding and decoupled guidance","abstract":"Zero-shot subject-driven image generation aims to produce images that incorporate a subject from a given example image. The challenge lies in preserving the subject's identity while aligning with the text prompt, which often requires modifying certain aspects of the subject's appearance. Despite advancements in diffusion model based methods, existing approaches still struggle to balance identity preservation with text prompt alignment. In this study, we conducted an in-depth investigation into this issue and uncovered key insights for achieving effective identity preservation while maintaining a strong balance. Our key findings include: (1) the design of the subject image encoder significantly impacts identity preservation quality, and (2) generating an initial layout is crucial for both text alignment and identity preservation. Building on these insights, we introduce a new approach called EZIGen, which employs two main strategies: a carefully crafted subject image Encoder based on the UNet architecture of the pretrained Stable Diffusion model to ensure high-quality identity transfer, following a process that decouples the guidance stages and iteratively refines the initial image layout. Through these strategies, EZIGen achieves state-of-the-art results on multiple subject-driven benchmarks with a unified model and 100 times less training data.","sentences":["Zero-shot subject-driven image generation aims to produce images that incorporate a subject from a given example image.","The challenge lies in preserving the subject's identity while aligning with the text prompt, which often requires modifying certain aspects of the subject's appearance.","Despite advancements in diffusion model based methods, existing approaches still struggle to balance identity preservation with text prompt alignment.","In this study, we conducted an in-depth investigation into this issue and uncovered key insights for achieving effective identity preservation while maintaining a strong balance.","Our key findings include: (1) the design of the subject image encoder significantly impacts identity preservation quality, and (2) generating an initial layout is crucial for both text alignment and identity preservation.","Building on these insights, we introduce a new approach called EZIGen, which employs two main strategies: a carefully crafted subject image Encoder based on the UNet architecture of the pretrained Stable Diffusion model to ensure high-quality identity transfer, following a process that decouples the guidance stages and iteratively refines the initial image layout.","Through these strategies, EZIGen achieves state-of-the-art results on multiple subject-driven benchmarks with a unified model and 100 times less training data."],"url":"http://arxiv.org/abs/2409.08091v1"}
{"created":"2024-09-12 14:38:21","title":"SimMAT: Exploring Transferability from Vision Foundation Models to Any Image Modality","abstract":"Foundation models like ChatGPT and Sora that are trained on a huge scale of data have made a revolutionary social impact. However, it is extremely challenging for sensors in many different fields to collect similar scales of natural images to train strong foundation models. To this end, this work presents a simple and effective framework SimMAT to study an open problem: the transferability from vision foundation models trained on natural RGB images to other image modalities of different physical properties (e.g., polarization). SimMAT consists of a modality-agnostic transfer layer (MAT) and a pretrained foundation model. We apply SimMAT to a representative vision foundation model Segment Anything Model (SAM) to support any evaluated new image modality. Given the absence of relevant benchmarks, we construct a new benchmark to evaluate the transfer learning performance. Our experiments confirm the intriguing potential of transferring vision foundation models in enhancing other sensors' performance. Specifically, SimMAT can improve the segmentation performance (mIoU) from 22.15% to 53.88% on average for evaluated modalities and consistently outperforms other baselines. We hope that SimMAT can raise awareness of cross-modal transfer learning and benefit various fields for better results with vision foundation models.","sentences":["Foundation models like ChatGPT and Sora that are trained on a huge scale of data have made a revolutionary social impact.","However, it is extremely challenging for sensors in many different fields to collect similar scales of natural images to train strong foundation models.","To this end, this work presents a simple and effective framework SimMAT to study an open problem: the transferability from vision foundation models trained on natural RGB images to other image modalities of different physical properties (e.g., polarization).","SimMAT consists of a modality-agnostic transfer layer (MAT) and a pretrained foundation model.","We apply SimMAT to a representative vision foundation model Segment Anything Model (SAM) to support any evaluated new image modality.","Given the absence of relevant benchmarks, we construct a new benchmark to evaluate the transfer learning performance.","Our experiments confirm the intriguing potential of transferring vision foundation models in enhancing other sensors' performance.","Specifically, SimMAT can improve the segmentation performance (mIoU) from 22.15% to 53.88% on average for evaluated modalities and consistently outperforms other baselines.","We hope that SimMAT can raise awareness of cross-modal transfer learning and benefit various fields for better results with vision foundation models."],"url":"http://arxiv.org/abs/2409.08083v1"}
{"created":"2024-09-12 14:35:55","title":"SoVAR: Building Generalizable Scenarios from Accident Reports for Autonomous Driving Testing","abstract":"Autonomous driving systems (ADSs) have undergone remarkable development and are increasingly employed in safety-critical applications. However, recently reported data on fatal accidents involving ADSs suggests that the desired level of safety has not yet been fully achieved. Consequently, there is a growing need for more comprehensive and targeted testing approaches to ensure safe driving. Scenarios from real-world accident reports provide valuable resources for ADS testing, including critical scenarios and high-quality seeds. However, existing scenario reconstruction methods from accident reports often exhibit limited accuracy in information extraction. Moreover, due to the diversity and complexity of road environments, matching current accident information with the simulation map data for reconstruction poses significant challenges. In this paper, we design and implement SoVAR, a tool for automatically generating road-generalizable scenarios from accident reports. SoVAR utilizes well-designed prompts with linguistic patterns to guide the large language model in extracting accident information from textual data. Subsequently, it formulates and solves accident-related constraints in conjunction with the extracted accident information to generate accident trajectories. Finally, SoVAR reconstructs accident scenarios on various map structures and converts them into test scenarios to evaluate its capability to detect defects in industrial ADSs. We experiment with SoVAR, using accident reports from the National Highway Traffic Safety Administration's database to generate test scenarios for the industrial-grade ADS Apollo. The experimental findings demonstrate that SoVAR can effectively generate generalized accident scenarios across different road structures. Furthermore, the results confirm that SoVAR identified 5 distinct safety violation types that contributed to the crash of Baidu Apollo.","sentences":["Autonomous driving systems (ADSs) have undergone remarkable development and are increasingly employed in safety-critical applications.","However, recently reported data on fatal accidents involving ADSs suggests that the desired level of safety has not yet been fully achieved.","Consequently, there is a growing need for more comprehensive and targeted testing approaches to ensure safe driving.","Scenarios from real-world accident reports provide valuable resources for ADS testing, including critical scenarios and high-quality seeds.","However, existing scenario reconstruction methods from accident reports often exhibit limited accuracy in information extraction.","Moreover, due to the diversity and complexity of road environments, matching current accident information with the simulation map data for reconstruction poses significant challenges.","In this paper, we design and implement SoVAR, a tool for automatically generating road-generalizable scenarios from accident reports.","SoVAR utilizes well-designed prompts with linguistic patterns to guide the large language model in extracting accident information from textual data.","Subsequently, it formulates and solves accident-related constraints in conjunction with the extracted accident information to generate accident trajectories.","Finally, SoVAR reconstructs accident scenarios on various map structures and converts them into test scenarios to evaluate its capability to detect defects in industrial ADSs.","We experiment with SoVAR, using accident reports from the National Highway Traffic Safety Administration's database to generate test scenarios for the industrial-grade ADS Apollo.","The experimental findings demonstrate that SoVAR can effectively generate generalized accident scenarios across different road structures.","Furthermore, the results confirm that SoVAR identified 5 distinct safety violation types that contributed to the crash of Baidu Apollo."],"url":"http://arxiv.org/abs/2409.08081v1"}
{"created":"2024-09-12 14:10:22","title":"Q-value Regularized Decision ConvFormer for Offline Reinforcement Learning","abstract":"As a data-driven paradigm, offline reinforcement learning (Offline RL) has been formulated as sequence modeling, where the Decision Transformer (DT) has demonstrated exceptional capabilities. Unlike previous reinforcement learning methods that fit value functions or compute policy gradients, DT adjusts the autoregressive model based on the expected returns, past states, and actions, using a causally masked Transformer to output the optimal action. However, due to the inconsistency between the sampled returns within a single trajectory and the optimal returns across multiple trajectories, it is challenging to set an expected return to output the optimal action and stitch together suboptimal trajectories. Decision ConvFormer (DC) is easier to understand in the context of modeling RL trajectories within a Markov Decision Process compared to DT. We propose the Q-value Regularized Decision ConvFormer (QDC), which combines the understanding of RL trajectories by DC and incorporates a term that maximizes action values using dynamic programming methods during training. This ensures that the expected returns of the sampled actions are consistent with the optimal returns. QDC achieves excellent performance on the D4RL benchmark, outperforming or approaching the optimal level in all tested environments. It particularly demonstrates outstanding competitiveness in trajectory stitching capability.","sentences":["As a data-driven paradigm, offline reinforcement learning (Offline RL) has been formulated as sequence modeling, where the Decision Transformer (DT) has demonstrated exceptional capabilities.","Unlike previous reinforcement learning methods that fit value functions or compute policy gradients, DT adjusts the autoregressive model based on the expected returns, past states, and actions, using a causally masked Transformer to output the optimal action.","However, due to the inconsistency between the sampled returns within a single trajectory and the optimal returns across multiple trajectories, it is challenging to set an expected return to output the optimal action and stitch together suboptimal trajectories.","Decision ConvFormer (DC) is easier to understand in the context of modeling RL trajectories within a Markov Decision Process compared to DT.","We propose the Q-value Regularized Decision ConvFormer (QDC), which combines the understanding of RL trajectories by DC and incorporates a term that maximizes action values using dynamic programming methods during training.","This ensures that the expected returns of the sampled actions are consistent with the optimal returns.","QDC achieves excellent performance on the D4RL benchmark, outperforming or approaching the optimal level in all tested environments.","It particularly demonstrates outstanding competitiveness in trajectory stitching capability."],"url":"http://arxiv.org/abs/2409.08062v1"}
{"created":"2024-09-12 13:51:06","title":"On the challenges of studying bias in Recommender Systems: A UserKNN case study","abstract":"Statements on the propagation of bias by recommender systems are often hard to verify or falsify. Research on bias tends to draw from a small pool of publicly available datasets and is therefore bound by their specific properties. Additionally, implementation choices are often not explicitly described or motivated in research, while they may have an effect on bias propagation. In this paper, we explore the challenges of measuring and reporting popularity bias. We showcase the impact of data properties and algorithm configurations on popularity bias by combining synthetic data with well known recommender systems frameworks that implement UserKNN. First, we identify data characteristics that might impact popularity bias, based on the functionality of UserKNN. Accordingly, we generate various datasets that combine these characteristics. Second, we locate UserKNN configurations that vary across implementations in literature. We evaluate popularity bias for five synthetic datasets and five UserKNN configurations, and offer insights on their joint effect. We find that, depending on the data characteristics, various UserKNN configurations can lead to different conclusions regarding the propagation of popularity bias. These results motivate the need for explicitly addressing algorithmic configuration and data properties when reporting and interpreting bias in recommender systems.","sentences":["Statements on the propagation of bias by recommender systems are often hard to verify or falsify.","Research on bias tends to draw from a small pool of publicly available datasets and is therefore bound by their specific properties.","Additionally, implementation choices are often not explicitly described or motivated in research, while they may have an effect on bias propagation.","In this paper, we explore the challenges of measuring and reporting popularity bias.","We showcase the impact of data properties and algorithm configurations on popularity bias by combining synthetic data with well known recommender systems frameworks that implement UserKNN.","First, we identify data characteristics that might impact popularity bias, based on the functionality of UserKNN.","Accordingly, we generate various datasets that combine these characteristics.","Second, we locate UserKNN configurations that vary across implementations in literature.","We evaluate popularity bias for five synthetic datasets and five UserKNN configurations, and offer insights on their joint effect.","We find that, depending on the data characteristics, various UserKNN configurations can lead to different conclusions regarding the propagation of popularity bias.","These results motivate the need for explicitly addressing algorithmic configuration and data properties when reporting and interpreting bias in recommender systems."],"url":"http://arxiv.org/abs/2409.08046v1"}
{"created":"2024-09-12 13:50:22","title":"Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking","abstract":"In this paper, we show that with the ability to jailbreak a GenAI model, attackers can escalate the outcome of attacks against RAG-based GenAI-powered applications in severity and scale. In the first part of the paper, we show that attackers can escalate RAG membership inference attacks and RAG entity extraction attacks to RAG documents extraction attacks, forcing a more severe outcome compared to existing attacks. We evaluate the results obtained from three extraction methods, the influence of the type and the size of five embeddings algorithms employed, the size of the provided context, and the GenAI engine. We show that attackers can extract 80%-99.8% of the data stored in the database used by the RAG of a Q&A chatbot. In the second part of the paper, we show that attackers can escalate the scale of RAG data poisoning attacks from compromising a single GenAI-powered application to compromising the entire GenAI ecosystem, forcing a greater scale of damage. This is done by crafting an adversarial self-replicating prompt that triggers a chain reaction of a computer worm within the ecosystem and forces each affected application to perform a malicious activity and compromise the RAG of additional applications. We evaluate the performance of the worm in creating a chain of confidential data extraction about users within a GenAI ecosystem of GenAI-powered email assistants and analyze how the performance of the worm is affected by the size of the context, the adversarial self-replicating prompt used, the type and size of the embeddings algorithm employed, and the number of hops in the propagation. Finally, we review and analyze guardrails to protect RAG-based inference and discuss the tradeoffs.","sentences":["In this paper, we show that with the ability to jailbreak a GenAI model, attackers can escalate the outcome of attacks against RAG-based GenAI-powered applications in severity and scale.","In the first part of the paper, we show that attackers can escalate RAG membership inference attacks and RAG entity extraction attacks to RAG documents extraction attacks, forcing a more severe outcome compared to existing attacks.","We evaluate the results obtained from three extraction methods, the influence of the type and the size of five embeddings algorithms employed, the size of the provided context, and the GenAI engine.","We show that attackers can extract 80%-99.8% of the data stored in the database used by the RAG of a Q&A chatbot.","In the second part of the paper, we show that attackers can escalate the scale of RAG data poisoning attacks from compromising a single GenAI-powered application to compromising the entire GenAI ecosystem, forcing a greater scale of damage.","This is done by crafting an adversarial self-replicating prompt that triggers a chain reaction of a computer worm within the ecosystem and forces each affected application to perform a malicious activity and compromise the RAG of additional applications.","We evaluate the performance of the worm in creating a chain of confidential data extraction about users within a GenAI ecosystem of GenAI-powered email assistants and analyze how the performance of the worm is affected by the size of the context, the adversarial self-replicating prompt used, the type and size of the embeddings algorithm employed, and the number of hops in the propagation.","Finally, we review and analyze guardrails to protect RAG-based inference and discuss the tradeoffs."],"url":"http://arxiv.org/abs/2409.08045v1"}
{"created":"2024-09-12 13:47:18","title":"External Memories of PDP Switches for In-Network Implementable Functions Placement: Deep Learning Based Reconfiguration of SFCs","abstract":"Network function virtualization leverages programmable data plane switches to deploy in-network implementable functions, to improve QoS. The memories of switches can be extended through remote direct memory access to access external memories. This paper exploits the switches external memories to place VNFs at time intervals with ultra-low latency and high bandwidth demands. The reconfiguration decision is modeled as an optimization to minimize the deployment and reconfiguration cost, while meeting the SFCs deadlines. A DRL based method is proposed to reconfigure service chains adoptable with dynamic network and traffic characteristics. To deal with slow convergence due to the complexity of deployment scenarios, static and dynamic filters are used in policy networks construction to diminish unfeasible placement exploration. Results illustrate improvement in convergence, acceptance ratio and cost.","sentences":["Network function virtualization leverages programmable data plane switches to deploy in-network implementable functions, to improve QoS.","The memories of switches can be extended through remote direct memory access to access external memories.","This paper exploits the switches external memories to place VNFs at time intervals with ultra-low latency and high bandwidth demands.","The reconfiguration decision is modeled as an optimization to minimize the deployment and reconfiguration cost, while meeting the SFCs deadlines.","A DRL based method is proposed to reconfigure service chains adoptable with dynamic network and traffic characteristics.","To deal with slow convergence due to the complexity of deployment scenarios, static and dynamic filters are used in policy networks construction to diminish unfeasible placement exploration.","Results illustrate improvement in convergence, acceptance ratio and cost."],"url":"http://arxiv.org/abs/2409.08043v1"}
{"created":"2024-09-12 13:46:53","title":"Thermal3D-GS: Physics-induced 3D Gaussians for Thermal Infrared Novel-view Synthesis","abstract":"Novel-view synthesis based on visible light has been extensively studied. In comparison to visible light imaging, thermal infrared imaging offers the advantage of all-weather imaging and strong penetration, providing increased possibilities for reconstruction in nighttime and adverse weather scenarios. However, thermal infrared imaging is influenced by physical characteristics such as atmospheric transmission effects and thermal conduction, hindering the precise reconstruction of intricate details in thermal infrared scenes, manifesting as issues of floaters and indistinct edge features in synthesized images. To address these limitations, this paper introduces a physics-induced 3D Gaussian splatting method named Thermal3D-GS. Thermal3D-GS begins by modeling atmospheric transmission effects and thermal conduction in three-dimensional media using neural networks. Additionally, a temperature consistency constraint is incorporated into the optimization objective to enhance the reconstruction accuracy of thermal infrared images. Furthermore, to validate the effectiveness of our method, the first large-scale benchmark dataset for this field named Thermal Infrared Novel-view Synthesis Dataset (TI-NSD) is created. This dataset comprises 20 authentic thermal infrared video scenes, covering indoor, outdoor, and UAV(Unmanned Aerial Vehicle) scenarios, totaling 6,664 frames of thermal infrared image data. Based on this dataset, this paper experimentally verifies the effectiveness of Thermal3D-GS. The results indicate that our method outperforms the baseline method with a 3.03 dB improvement in PSNR and significantly addresses the issues of floaters and indistinct edge features present in the baseline method. Our dataset and codebase will be released in \\href{https://github.com/mzzcdf/Thermal3DGS}{\\textcolor{red}{Thermal3DGS}}.","sentences":["Novel-view synthesis based on visible light has been extensively studied.","In comparison to visible light imaging, thermal infrared imaging offers the advantage of all-weather imaging and strong penetration, providing increased possibilities for reconstruction in nighttime and adverse weather scenarios.","However, thermal infrared imaging is influenced by physical characteristics such as atmospheric transmission effects and thermal conduction, hindering the precise reconstruction of intricate details in thermal infrared scenes, manifesting as issues of floaters and indistinct edge features in synthesized images.","To address these limitations, this paper introduces a physics-induced 3D Gaussian splatting method named Thermal3D-GS.","Thermal3D-GS begins by modeling atmospheric transmission effects and thermal conduction in three-dimensional media using neural networks.","Additionally, a temperature consistency constraint is incorporated into the optimization objective to enhance the reconstruction accuracy of thermal infrared images.","Furthermore, to validate the effectiveness of our method, the first large-scale benchmark dataset for this field named Thermal Infrared Novel-view Synthesis Dataset (TI-NSD) is created.","This dataset comprises 20 authentic thermal infrared video scenes, covering indoor, outdoor, and UAV(Unmanned Aerial Vehicle) scenarios, totaling 6,664 frames of thermal infrared image data.","Based on this dataset, this paper experimentally verifies the effectiveness of Thermal3D-GS.","The results indicate that our method outperforms the baseline method with a 3.03 dB improvement in PSNR and significantly addresses the issues of floaters and indistinct edge features present in the baseline method.","Our dataset and codebase will be released in \\href{https://github.com/mzzcdf/Thermal3DGS}{\\textcolor{red}{Thermal3DGS}}."],"url":"http://arxiv.org/abs/2409.08042v1"}
{"created":"2024-09-12 13:38:47","title":"Fine-Grained Complexity of Multiple Domination and Dominating Patterns in Sparse Graphs","abstract":"The study of domination in graphs has led to a variety of domination problems studied in the literature. Most of these follow the following general framework: Given a graph $G$ and an integer $k$, decide if there is a set $S$ of $k$ vertices such that (1) some inner property $\\phi(S)$ (e.g., connectedness) is satisfied, and (2) each vertex $v$ satisfies some domination property $\\rho(S, v)$ (e.g., there is an $s\\in S$ that is adjacent to $v$).   Since many real-world graphs are sparse, we seek to determine the optimal running time of such problems in both the number $n$ of vertices and the number $m$ of edges in $G$. While the classic dominating set problem admits a rather limited improvement in sparse graphs (Fischer, K\\\"unnemann, Redzic SODA'24), we show that natural variants studied in the literature admit much larger speed-ups, with a diverse set of possible running times. Specifically, we obtain conditionally optimal algorithms for:   1) $r$-Multiple $k$-Dominating Set (each vertex must be adjacent to at least $r$ vertices in $S$): If $r\\le k-2$, we obtain a running time of $(m/n)^{r} n^{k-r+o(1)}$ that is conditionally optimal assuming the 3-uniform hyperclique hypothesis. In sparse graphs, this fully interpolates between $n^{k-1\\pm o(1)}$ and $n^{2\\pm o(1)}$, depending on $r$. Curiously, when $r=k-1$, we obtain a randomized algorithm beating $(m/n)^{k-1} n^{1+o(1)}$ and we show that this algorithm is close to optimal under the $k$-clique hypothesis.   2) $H$-Dominating Set ($S$ must induce a pattern $H$). We conditionally settle the complexity of three such problems: (a) Dominating Clique ($H$ is a $k$-clique), (b) Maximal Independent Set of size $k$ ($H$ is an independent set on $k$ vertices), (c) Dominating Induced Matching ($H$ is a perfect matching on $k$ vertices).","sentences":["The study of domination in graphs has led to a variety of domination problems studied in the literature.","Most of these follow the following general framework: Given a graph $G$ and an integer $k$, decide if there is a set $S$ of $k$ vertices such that (1) some inner property $\\phi(S)$ (e.g., connectedness) is satisfied, and (2) each vertex $v$ satisfies some domination property $\\rho(S, v)$ (e.g., there is an $s\\in S$ that is adjacent to $v$).   ","Since many real-world graphs are sparse, we seek to determine the optimal running time of such problems in both the number $n$ of vertices and the number $m$ of edges in $G$. While the classic dominating set problem admits a rather limited improvement in sparse graphs (Fischer, K\\\"unnemann, Redzic SODA'24), we show that natural variants studied in the literature admit much larger speed-ups, with a diverse set of possible running times.","Specifically, we obtain conditionally optimal algorithms for:   1) $r$-Multiple $k$-Dominating Set (each vertex must be adjacent to at least $r$ vertices in $S$): If $r\\le k-2$, we obtain a running time of $(m/n)^{r} n^{k-r+o(1)}$ that is conditionally optimal assuming the 3-uniform hyperclique hypothesis.","In sparse graphs, this fully interpolates between $n^{k-1\\pm o(1)}$ and $n^{2\\pm o(1)}$, depending on $r$. Curiously, when $r=k-1$, we obtain a randomized algorithm beating $(m/n)^{k-1} n^{1+o(1)}$ and we show that this algorithm is close to optimal under the $k$-clique hypothesis.   2) $H$-Dominating Set ($S$ must induce a pattern $H$).","We conditionally settle the complexity of three such problems: (a) Dominating Clique ($H$ is a $k$-clique), (b) Maximal Independent Set of size $k$ ($H$ is an independent set on $k$ vertices), (c) Dominating Induced Matching ($H$ is a perfect matching on $k$ vertices)."],"url":"http://arxiv.org/abs/2409.08037v1"}
{"created":"2024-09-12 13:38:08","title":"Heterogeneous Sheaf Neural Networks","abstract":"Heterogeneous graphs, with nodes and edges of different types, are commonly used to model relational structures in many real-world applications. Standard Graph Neural Networks (GNNs) struggle to process heterogeneous data due to oversmoothing. Instead, current approaches have focused on accounting for the heterogeneity in the model architecture, leading to increasingly complex models. Inspired by recent work, we propose using cellular sheaves to model the heterogeneity in the graph's underlying topology. Instead of modelling the data as a graph, we represent it as cellular sheaves, which allows us to encode the different data types directly in the data structure, eliminating the need to inject them into the architecture. We introduce HetSheaf, a general framework for heterogeneous sheaf neural networks, and a series of heterogeneous sheaf predictors to better encode the data's heterogeneity into the sheaf structure. Finally, we empirically evaluate HetSheaf on several standard heterogeneous graph benchmarks, achieving competitive results whilst being more parameter-efficient.","sentences":["Heterogeneous graphs, with nodes and edges of different types, are commonly used to model relational structures in many real-world applications.","Standard Graph Neural Networks (GNNs) struggle to process heterogeneous data due to oversmoothing.","Instead, current approaches have focused on accounting for the heterogeneity in the model architecture, leading to increasingly complex models.","Inspired by recent work, we propose using cellular sheaves to model the heterogeneity in the graph's underlying topology.","Instead of modelling the data as a graph, we represent it as cellular sheaves, which allows us to encode the different data types directly in the data structure, eliminating the need to inject them into the architecture.","We introduce HetSheaf, a general framework for heterogeneous sheaf neural networks, and a series of heterogeneous sheaf predictors to better encode the data's heterogeneity into the sheaf structure.","Finally, we empirically evaluate HetSheaf on several standard heterogeneous graph benchmarks, achieving competitive results whilst being more parameter-efficient."],"url":"http://arxiv.org/abs/2409.08036v1"}
{"created":"2024-09-12 13:31:09","title":"A three-dimensional force estimation method for the cable-driven soft robot based on monocular images","abstract":"Soft manipulators are known for their superiority in coping with high-safety-demanding interaction tasks, e.g., robot-assisted surgeries, elderly caring, etc. Yet the challenges residing in real-time contact feedback have hindered further applications in precise manipulation. This paper proposes an end-to-end network to estimate the 3D contact force of the soft robot, with the aim of enhancing its capabilities in interactive tasks. The presented method features directly utilizing monocular images fused with multidimensional actuation information as the network inputs. This approach simplifies the preprocessing of raw data compared to related studies that utilize 3D shape information for network inputs, consequently reducing configuration reconstruction errors. The unified feature representation module is devised to elevate low-dimensional features from the system's actuation signals to the same level as image features, facilitating smoother integration of multimodal information. The proposed method has been experimentally validated in the soft robot testbed, achieving satisfying accuracy in 3D force estimation (with a mean relative error of 0.84% compared to the best-reported result of 2.2% in the related works).","sentences":["Soft manipulators are known for their superiority in coping with high-safety-demanding interaction tasks, e.g., robot-assisted surgeries, elderly caring, etc.","Yet the challenges residing in real-time contact feedback have hindered further applications in precise manipulation.","This paper proposes an end-to-end network to estimate the 3D contact force of the soft robot, with the aim of enhancing its capabilities in interactive tasks.","The presented method features directly utilizing monocular images fused with multidimensional actuation information as the network inputs.","This approach simplifies the preprocessing of raw data compared to related studies that utilize 3D shape information for network inputs, consequently reducing configuration reconstruction errors.","The unified feature representation module is devised to elevate low-dimensional features from the system's actuation signals to the same level as image features, facilitating smoother integration of multimodal information.","The proposed method has been experimentally validated in the soft robot testbed, achieving satisfying accuracy in 3D force estimation (with a mean relative error of 0.84% compared to the best-reported result of 2.2% in the related works)."],"url":"http://arxiv.org/abs/2409.08033v1"}
{"created":"2024-09-12 13:23:24","title":"LED: Light Enhanced Depth Estimation at Night","abstract":"Nighttime camera-based depth estimation is a highly challenging task, especially for autonomous driving applications, where accurate depth perception is essential for ensuring safe navigation. We aim to improve the reliability of perception systems at night time, where models trained on daytime data often fail in the absence of precise but costly LiDAR sensors. In this work, we introduce Light Enhanced Depth (LED), a novel cost-effective approach that significantly improves depth estimation in low-light environments by harnessing a pattern projected by high definition headlights available in modern vehicles. LED leads to significant performance boosts across multiple depth-estimation architectures (encoder-decoder, Adabins, DepthFormer) both on synthetic and real datasets. Furthermore, increased performances beyond illuminated areas reveal a holistic enhancement in scene understanding. Finally, we release the Nighttime Synthetic Drive Dataset, a new synthetic and photo-realistic nighttime dataset, which comprises 49,990 comprehensively annotated images.","sentences":["Nighttime camera-based depth estimation is a highly challenging task, especially for autonomous driving applications, where accurate depth perception is essential for ensuring safe navigation.","We aim to improve the reliability of perception systems at night time, where models trained on daytime data often fail in the absence of precise but costly LiDAR sensors.","In this work, we introduce Light Enhanced Depth (LED), a novel cost-effective approach that significantly improves depth estimation in low-light environments by harnessing a pattern projected by high definition headlights available in modern vehicles.","LED leads to significant performance boosts across multiple depth-estimation architectures (encoder-decoder, Adabins, DepthFormer) both on synthetic and real datasets.","Furthermore, increased performances beyond illuminated areas reveal a holistic enhancement in scene understanding.","Finally, we release the Nighttime Synthetic Drive Dataset, a new synthetic and photo-realistic nighttime dataset, which comprises 49,990 comprehensively annotated images."],"url":"http://arxiv.org/abs/2409.08031v1"}
{"created":"2024-09-12 13:05:28","title":"Edge-Wise Graph-Instructed Neural Networks","abstract":"The problem of multi-task regression over graph nodes has been recently approached through Graph-Instructed Neural Network (GINN), which is a promising architecture belonging to the subset of message-passing graph neural networks. In this work, we discuss the limitations of the Graph-Instructed (GI) layer, and we formalize a novel edge-wise GI (EWGI) layer. We discuss the advantages of the EWGI layer and we provide numerical evidence that EWGINNs perform better than GINNs over graph-structured input data with chaotic connectivity, like the ones inferred from the Erdos-R\\'enyi graph.","sentences":["The problem of multi-task regression over graph nodes has been recently approached through Graph-Instructed Neural Network (GINN), which is a promising architecture belonging to the subset of message-passing graph neural networks.","In this work, we discuss the limitations of the Graph-Instructed (GI) layer, and we formalize a novel edge-wise GI (EWGI) layer.","We discuss the advantages of the EWGI layer and we provide numerical evidence that EWGINNs perform better than GINNs over graph-structured input data with chaotic connectivity, like the ones inferred from the Erdos-R\\'enyi graph."],"url":"http://arxiv.org/abs/2409.08023v1"}
{"created":"2024-09-12 12:56:24","title":"Learning Causally Invariant Reward Functions from Diverse Demonstrations","abstract":"Inverse reinforcement learning methods aim to retrieve the reward function of a Markov decision process based on a dataset of expert demonstrations. The commonplace scarcity and heterogeneous sources of such demonstrations can lead to the absorption of spurious correlations in the data by the learned reward function. Consequently, this adaptation often exhibits behavioural overfitting to the expert data set when a policy is trained on the obtained reward function under distribution shift of the environment dynamics. In this work, we explore a novel regularization approach for inverse reinforcement learning methods based on the causal invariance principle with the goal of improved reward function generalization. By applying this regularization to both exact and approximate formulations of the learning task, we demonstrate superior policy performance when trained using the recovered reward functions in a transfer setting","sentences":["Inverse reinforcement learning methods aim to retrieve the reward function of a Markov decision process based on a dataset of expert demonstrations.","The commonplace scarcity and heterogeneous sources of such demonstrations can lead to the absorption of spurious correlations in the data by the learned reward function.","Consequently, this adaptation often exhibits behavioural overfitting to the expert data set when a policy is trained on the obtained reward function under distribution shift of the environment dynamics.","In this work, we explore a novel regularization approach for inverse reinforcement learning methods based on the causal invariance principle with the goal of improved reward function generalization.","By applying this regularization to both exact and approximate formulations of the learning task, we demonstrate superior policy performance when trained using the recovered reward functions in a transfer setting"],"url":"http://arxiv.org/abs/2409.08012v1"}
{"created":"2024-09-12 12:55:49","title":"Multiplex Graph Contrastive Learning with Soft Negatives","abstract":"Graph Contrastive Learning (GCL) seeks to learn nodal or graph representations that contain maximal consistent information from graph-structured data. While node-level contrasting modes are dominating, some efforts commence to explore consistency across different scales. Yet, they tend to lose consistent information and be contaminated by disturbing features. Here, we introduce MUX-GCL, a novel cross-scale contrastive learning paradigm that utilizes multiplex representations as effective patches. While this learning mode minimizes contaminating noises, a commensurate contrasting strategy using positional affinities further avoids information loss by correcting false negative pairs across scales. Extensive downstream experiments demonstrate that MUX-GCL yields multiple state-of-the-art results on public datasets. Our theoretical analysis further guarantees the new objective function as a stricter lower bound of mutual information of raw input features and output embeddings, which rationalizes this paradigm. Code is available at https://github.com/MUX-GCL/Code.","sentences":["Graph Contrastive Learning (GCL) seeks to learn nodal or graph representations that contain maximal consistent information from graph-structured data.","While node-level contrasting modes are dominating, some efforts commence to explore consistency across different scales.","Yet, they tend to lose consistent information and be contaminated by disturbing features.","Here, we introduce MUX-GCL, a novel cross-scale contrastive learning paradigm that utilizes multiplex representations as effective patches.","While this learning mode minimizes contaminating noises, a commensurate contrasting strategy using positional affinities further avoids information loss by correcting false negative pairs across scales.","Extensive downstream experiments demonstrate that MUX-GCL yields multiple state-of-the-art results on public datasets.","Our theoretical analysis further guarantees the new objective function as a stricter lower bound of mutual information of raw input features and output embeddings, which rationalizes this paradigm.","Code is available at https://github.com/MUX-GCL/Code."],"url":"http://arxiv.org/abs/2409.08010v1"}
{"created":"2024-09-12 12:41:58","title":"Privacy-preserving federated prediction of pain intensity change based on multi-center survey data","abstract":"Background: Patient-reported survey data are used to train prognostic models aimed at improving healthcare. However, such data are typically available multi-centric and, for privacy reasons, cannot easily be centralized in one data repository. Models trained locally are less accurate, robust, and generalizable. We present and apply privacy-preserving federated machine learning techniques for prognostic model building, where local survey data never leaves the legally safe harbors of the medical centers. Methods: We used centralized, local, and federated learning techniques on two healthcare datasets (GLA:D data from the five health regions of Denmark and international SHARE data of 27 countries) to predict two different health outcomes. We compared linear regression, random forest regression, and random forest classification models trained on local data with those trained on the entire data in a centralized and in a federated fashion. Results: In GLA:D data, federated linear regression (R2 0.34, RMSE 18.2) and federated random forest regression (R2 0.34, RMSE 18.3) models outperform their local counterparts (i.e., R2 0.32, RMSE 18.6, R2 0.30, RMSE 18.8) with statistical significance. We also found that centralized models (R2 0.34, RMSE 18.2, R2 0.32, RMSE 18.5, respectively) did not perform significantly better than the federated models. In SHARE, the federated model (AC 0.78, AUROC: 0.71) and centralized model (AC 0.84, AUROC: 0.66) perform significantly better than the local models (AC: 0.74, AUROC: 0.69). Conclusion: Federated learning enables the training of prognostic models from multi-center surveys without compromising privacy and with only minimal or no compromise regarding model performance.","sentences":["Background: Patient-reported survey data are used to train prognostic models aimed at improving healthcare.","However, such data are typically available multi-centric and, for privacy reasons, cannot easily be centralized in one data repository.","Models trained locally are less accurate, robust, and generalizable.","We present and apply privacy-preserving federated machine learning techniques for prognostic model building, where local survey data never leaves the legally safe harbors of the medical centers.","Methods: We used centralized, local, and federated learning techniques on two healthcare datasets (GLA:D data from the five health regions of Denmark and international SHARE data of 27 countries) to predict two different health outcomes.","We compared linear regression, random forest regression, and random forest classification models trained on local data with those trained on the entire data in a centralized and in a federated fashion.","Results:","In GLA:D data, federated linear regression (R2 0.34, RMSE 18.2) and federated random forest regression (R2 0.34, RMSE 18.3) models outperform their local counterparts (i.e., R2 0.32, RMSE 18.6, R2 0.30, RMSE 18.8) with statistical significance.","We also found that centralized models (R2 0.34, RMSE 18.2, R2 0.32, RMSE 18.5, respectively) did not perform significantly better than the federated models.","In SHARE, the federated model (AC 0.78, AUROC: 0.71) and centralized model (AC 0.84, AUROC: 0.66) perform significantly better than the local models (AC: 0.74, AUROC: 0.69).","Conclusion:","Federated learning enables the training of prognostic models from multi-center surveys without compromising privacy and with only minimal or no compromise regarding model performance."],"url":"http://arxiv.org/abs/2409.07997v1"}
{"created":"2024-09-12 12:39:34","title":"Depth Matters: Exploring Deep Interactions of RGB-D for Semantic Segmentation in Traffic Scenes","abstract":"RGB-D has gradually become a crucial data source for understanding complex scenes in assisted driving. However, existing studies have paid insufficient attention to the intrinsic spatial properties of depth maps. This oversight significantly impacts the attention representation, leading to prediction errors caused by attention shift issues. To this end, we propose a novel learnable Depth interaction Pyramid Transformer (DiPFormer) to explore the effectiveness of depth. Firstly, we introduce Depth Spatial-Aware Optimization (Depth SAO) as offset to represent real-world spatial relationships. Secondly, the similarity in the feature space of RGB-D is learned by Depth Linear Cross-Attention (Depth LCA) to clarify spatial differences at the pixel level. Finally, an MLP Decoder is utilized to effectively fuse multi-scale features for meeting real-time requirements. Comprehensive experiments demonstrate that the proposed DiPFormer significantly addresses the issue of attention misalignment in both road detection (+7.5%) and semantic segmentation (+4.9% / +1.5%) tasks. DiPFormer achieves state-of-the-art performance on the KITTI (97.57% F-score on KITTI road and 68.74% mIoU on KITTI-360) and Cityscapes (83.4% mIoU) datasets.","sentences":["RGB-D has gradually become a crucial data source for understanding complex scenes in assisted driving.","However, existing studies have paid insufficient attention to the intrinsic spatial properties of depth maps.","This oversight significantly impacts the attention representation, leading to prediction errors caused by attention shift issues.","To this end, we propose a novel learnable Depth interaction Pyramid Transformer (DiPFormer) to explore the effectiveness of depth.","Firstly, we introduce Depth Spatial-Aware Optimization (Depth SAO) as offset to represent real-world spatial relationships.","Secondly, the similarity in the feature space of RGB-D is learned by Depth Linear Cross-Attention (Depth LCA) to clarify spatial differences at the pixel level.","Finally, an MLP Decoder is utilized to effectively fuse multi-scale features for meeting real-time requirements.","Comprehensive experiments demonstrate that the proposed DiPFormer significantly addresses the issue of attention misalignment in both road detection (+7.5%) and semantic segmentation (+4.9% / +1.5%) tasks.","DiPFormer achieves state-of-the-art performance on the KITTI (97.57% F-score on KITTI road and 68.74% mIoU on KITTI-360) and Cityscapes (83.4% mIoU) datasets."],"url":"http://arxiv.org/abs/2409.07995v1"}
{"created":"2024-09-12 11:54:25","title":"Locality-aware Cross-modal Correspondence Learning for Dense Audio-Visual Events Localization","abstract":"Dense-localization Audio-Visual Events (DAVE) aims to identify time boundaries and corresponding categories for events that can be heard and seen concurrently in an untrimmed video. Existing methods typically encode audio and visual representation separately without any explicit cross-modal alignment constraint. Then they adopt dense cross-modal attention to integrate multimodal information for DAVE. Thus these methods inevitably aggregate irrelevant noise and events, especially in complex and long videos, leading to imprecise detection. In this paper, we present LOCO, a Locality-aware cross-modal Correspondence learning framework for DAVE. The core idea is to explore local temporal continuity nature of audio-visual events, which serves as informative yet free supervision signals to guide the filtering of irrelevant information and inspire the extraction of complementary multimodal information during both unimodal and cross-modal learning stages. i) Specifically, LOCO applies Locality-aware Correspondence Correction (LCC) to uni-modal features via leveraging cross-modal local-correlated properties without any extra annotations. This enforces uni-modal encoders to highlight similar semantics shared by audio and visual features. ii) To better aggregate such audio and visual features, we further customize Cross-modal Dynamic Perception layer (CDP) in cross-modal feature pyramid to understand local temporal patterns of audio-visual events by imposing local consistency within multimodal features in a data-driven manner. By incorporating LCC and CDP, LOCO provides solid performance gains and outperforms existing methods for DAVE. The source code will be released.","sentences":["Dense-localization Audio-Visual Events (DAVE) aims to identify time boundaries and corresponding categories for events that can be heard and seen concurrently in an untrimmed video.","Existing methods typically encode audio and visual representation separately without any explicit cross-modal alignment constraint.","Then they adopt dense cross-modal attention to integrate multimodal information for DAVE.","Thus these methods inevitably aggregate irrelevant noise and events, especially in complex and long videos, leading to imprecise detection.","In this paper, we present LOCO, a Locality-aware cross-modal Correspondence learning framework for DAVE.","The core idea is to explore local temporal continuity nature of audio-visual events, which serves as informative yet free supervision signals to guide the filtering of irrelevant information and inspire the extraction of complementary multimodal information during both unimodal and cross-modal learning stages.","i) Specifically, LOCO applies Locality-aware Correspondence Correction (LCC) to uni-modal features via leveraging cross-modal local-correlated properties without any extra annotations.","This enforces uni-modal encoders to highlight similar semantics shared by audio and visual features.","ii) To better aggregate such audio and visual features, we further customize Cross-modal Dynamic Perception layer (CDP) in cross-modal feature pyramid to understand local temporal patterns of audio-visual events by imposing local consistency within multimodal features in a data-driven manner.","By incorporating LCC and CDP, LOCO provides solid performance gains and outperforms existing methods for DAVE.","The source code will be released."],"url":"http://arxiv.org/abs/2409.07967v1"}
{"created":"2024-09-12 11:53:05","title":"ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE","abstract":"Audio-driven 3D facial animation synthesis has been an active field of research with attention from both academia and industry. While there are promising results in this area, recent approaches largely focus on lip-sync and identity control, neglecting the role of emotions and emotion control in the generative process. That is mainly due to the lack of emotionally rich facial animation data and algorithms that can synthesize speech animations with emotional expressions at the same time. In addition, majority of the models are deterministic, meaning given the same audio input, they produce the same output motion. We argue that emotions and non-determinism are crucial to generate diverse and emotionally-rich facial animations. In this paper, we propose ProbTalk3D a non-deterministic neural network approach for emotion controllable speech-driven 3D facial animation synthesis using a two-stage VQ-VAE model and an emotionally rich facial animation dataset 3DMEAD. We provide an extensive comparative analysis of our model against the recent 3D facial animation synthesis approaches, by evaluating the results objectively, qualitatively, and with a perceptual user study. We highlight several objective metrics that are more suitable for evaluating stochastic outputs and use both in-the-wild and ground truth data for subjective evaluation. To our knowledge, that is the first non-deterministic 3D facial animation synthesis method incorporating a rich emotion dataset and emotion control with emotion labels and intensity levels. Our evaluation demonstrates that the proposed model achieves superior performance compared to state-of-the-art emotion-controlled, deterministic and non-deterministic models. We recommend watching the supplementary video for quality judgement. The entire codebase is publicly available (https://github.com/uuembodiedsocialai/ProbTalk3D/).","sentences":["Audio-driven 3D facial animation synthesis has been an active field of research with attention from both academia and industry.","While there are promising results in this area, recent approaches largely focus on lip-sync and identity control, neglecting the role of emotions and emotion control in the generative process.","That is mainly due to the lack of emotionally rich facial animation data and algorithms that can synthesize speech animations with emotional expressions at the same time.","In addition, majority of the models are deterministic, meaning given the same audio input, they produce the same output motion.","We argue that emotions and non-determinism are crucial to generate diverse and emotionally-rich facial animations.","In this paper, we propose ProbTalk3D a non-deterministic neural network approach for emotion controllable speech-driven 3D facial animation synthesis using a two-stage VQ-VAE model and an emotionally rich facial animation dataset 3DMEAD.","We provide an extensive comparative analysis of our model against the recent 3D facial animation synthesis approaches, by evaluating the results objectively, qualitatively, and with a perceptual user study.","We highlight several objective metrics that are more suitable for evaluating stochastic outputs and use both in-the-wild and ground truth data for subjective evaluation.","To our knowledge, that is the first non-deterministic 3D facial animation synthesis method incorporating a rich emotion dataset and emotion control with emotion labels and intensity levels.","Our evaluation demonstrates that the proposed model achieves superior performance compared to state-of-the-art emotion-controlled, deterministic and non-deterministic models.","We recommend watching the supplementary video for quality judgement.","The entire codebase is publicly available (https://github.com/uuembodiedsocialai/ProbTalk3D/)."],"url":"http://arxiv.org/abs/2409.07966v1"}
{"created":"2024-09-12 11:50:06","title":"Autonomous Vehicle Controllers From End-to-End Differentiable Simulation","abstract":"Current methods to learn controllers for autonomous vehicles (AVs) focus on behavioural cloning. Being trained only on exact historic data, the resulting agents often generalize poorly to novel scenarios. Simulators provide the opportunity to go beyond offline datasets, but they are still treated as complicated black boxes, only used to update the global simulation state. As a result, these RL algorithms are slow, sample-inefficient, and prior-agnostic. In this work, we leverage a differentiable simulator and design an analytic policy gradients (APG) approach to training AV controllers on the large-scale Waymo Open Motion Dataset. Our proposed framework brings the differentiable simulator into an end-to-end training loop, where gradients of the environment dynamics serve as a useful prior to help the agent learn a more grounded policy. We combine this setup with a recurrent architecture that can efficiently propagate temporal information across long simulated trajectories. This APG method allows us to learn robust, accurate, and fast policies, while only requiring widely-available expert trajectories, instead of scarce expert actions. We compare to behavioural cloning and find significant improvements in performance and robustness to noise in the dynamics, as well as overall more intuitive human-like handling.","sentences":["Current methods to learn controllers for autonomous vehicles (AVs) focus on behavioural cloning.","Being trained only on exact historic data, the resulting agents often generalize poorly to novel scenarios.","Simulators provide the opportunity to go beyond offline datasets, but they are still treated as complicated black boxes, only used to update the global simulation state.","As a result, these RL algorithms are slow, sample-inefficient, and prior-agnostic.","In this work, we leverage a differentiable simulator and design an analytic policy gradients (APG) approach to training AV controllers on the large-scale Waymo Open Motion Dataset.","Our proposed framework brings the differentiable simulator into an end-to-end training loop, where gradients of the environment dynamics serve as a useful prior to help the agent learn a more grounded policy.","We combine this setup with a recurrent architecture that can efficiently propagate temporal information across long simulated trajectories.","This APG method allows us to learn robust, accurate, and fast policies, while only requiring widely-available expert trajectories, instead of scarce expert actions.","We compare to behavioural cloning and find significant improvements in performance and robustness to noise in the dynamics, as well as overall more intuitive human-like handling."],"url":"http://arxiv.org/abs/2409.07965v1"}
{"created":"2024-09-12 11:48:01","title":"WirelessAgent: Large Language Model Agents for Intelligent Wireless Networks","abstract":"Wireless networks are increasingly facing challenges due to their expanding scale and complexity. These challenges underscore the need for advanced AI-driven strategies, particularly in the upcoming 6G networks. In this article, we introduce WirelessAgent, a novel approach leveraging large language models (LLMs) to develop AI agents capable of managing complex tasks in wireless networks. It can effectively improve network performance through advanced reasoning, multimodal data processing, and autonomous decision making. Thereafter, we demonstrate the practical applicability and benefits of WirelessAgent for network slicing management. The experimental results show that WirelessAgent is capable of accurately understanding user intent, effectively allocating slice resources, and consistently maintaining optimal performance.","sentences":["Wireless networks are increasingly facing challenges due to their expanding scale and complexity.","These challenges underscore the need for advanced AI-driven strategies, particularly in the upcoming 6G networks.","In this article, we introduce WirelessAgent, a novel approach leveraging large language models (LLMs) to develop AI agents capable of managing complex tasks in wireless networks.","It can effectively improve network performance through advanced reasoning, multimodal data processing, and autonomous decision making.","Thereafter, we demonstrate the practical applicability and benefits of WirelessAgent for network slicing management.","The experimental results show that WirelessAgent is capable of accurately understanding user intent, effectively allocating slice resources, and consistently maintaining optimal performance."],"url":"http://arxiv.org/abs/2409.07964v1"}
{"created":"2024-09-12 11:42:40","title":"Estimating atmospheric variables from Digital Typhoon Satellite Images via Conditional Denoising Diffusion Models","abstract":"This study explores the application of diffusion models in the field of typhoons, predicting multiple ERA5 meteorological variables simultaneously from Digital Typhoon satellite images. The focus of this study is taken to be Taiwan, an area very vulnerable to typhoons. By comparing the performance of Conditional Denoising Diffusion Probability Model (CDDPM) with Convolutional Neural Networks (CNN) and Squeeze-and-Excitation Networks (SENet), results suggest that the CDDPM performs best in generating accurate and realistic meteorological data. Specifically, CDDPM achieved a PSNR of 32.807, which is approximately 7.9% higher than CNN and 5.5% higher than SENet. Furthermore, CDDPM recorded an RMSE of 0.032, showing a 11.1% improvement over CNN and 8.6% improvement over SENet. A key application of this research can be for imputation purposes in missing meteorological datasets and generate additional high-quality meteorological data using satellite images. It is hoped that the results of this analysis will enable more robust and detailed forecasting, reducing the impact of severe weather events on vulnerable regions. Code accessible at https://github.com/TammyLing/Typhoon-forecasting.","sentences":["This study explores the application of diffusion models in the field of typhoons, predicting multiple ERA5 meteorological variables simultaneously from Digital Typhoon satellite images.","The focus of this study is taken to be Taiwan, an area very vulnerable to typhoons.","By comparing the performance of Conditional Denoising Diffusion Probability Model (CDDPM) with Convolutional Neural Networks (CNN) and Squeeze-and-Excitation Networks (SENet), results suggest that the CDDPM performs best in generating accurate and realistic meteorological data.","Specifically, CDDPM achieved a PSNR of 32.807, which is approximately 7.9% higher than CNN and 5.5% higher than SENet.","Furthermore, CDDPM recorded an RMSE of 0.032, showing a 11.1% improvement over CNN and 8.6% improvement over SENet.","A key application of this research can be for imputation purposes in missing meteorological datasets and generate additional high-quality meteorological data using satellite images.","It is hoped that the results of this analysis will enable more robust and detailed forecasting, reducing the impact of severe weather events on vulnerable regions.","Code accessible at https://github.com/TammyLing/Typhoon-forecasting."],"url":"http://arxiv.org/abs/2409.07961v1"}
{"created":"2024-09-12 11:41:35","title":"Do Vision Foundation Models Enhance Domain Generalization in Medical Image Segmentation?","abstract":"Neural networks achieve state-of-the-art performance in many supervised learning tasks when the training data distribution matches the test data distribution. However, their performance drops significantly under domain (covariate) shift, a prevalent issue in medical image segmentation due to varying acquisition settings across different scanner models and protocols. Recently, foundational models (FMs) trained on large datasets have gained attention for their ability to be adapted for downstream tasks and achieve state-of-the-art performance with excellent generalization capabilities on natural images. However, their effectiveness in medical image segmentation remains underexplored. In this paper, we investigate the domain generalization performance of various FMs, including DinoV2, SAM, MedSAM, and MAE, when fine-tuned using various parameter-efficient fine-tuning (PEFT) techniques such as Ladder and Rein (+LoRA) and decoder heads. We introduce a novel decode head architecture, HQHSAM, which simply integrates elements from two state-of-the-art decoder heads, HSAM and HQSAM, to enhance segmentation performance. Our extensive experiments on multiple datasets, encompassing various anatomies and modalities, reveal that FMs, particularly with the HQHSAM decode head, improve domain generalization for medical image segmentation. Moreover, we found that the effectiveness of PEFT techniques varies across different FMs. These findings underscore the potential of FMs to enhance the domain generalization performance of neural networks in medical image segmentation across diverse clinical settings, providing a solid foundation for future research. Code and models are available for research purposes at \\url{https://github.com/kerem-cekmeceli/Foundation-Models-for-Medical-Imagery}.","sentences":["Neural networks achieve state-of-the-art performance in many supervised learning tasks when the training data distribution matches the test data distribution.","However, their performance drops significantly under domain (covariate) shift, a prevalent issue in medical image segmentation due to varying acquisition settings across different scanner models and protocols.","Recently, foundational models (FMs) trained on large datasets have gained attention for their ability to be adapted for downstream tasks and achieve state-of-the-art performance with excellent generalization capabilities on natural images.","However, their effectiveness in medical image segmentation remains underexplored.","In this paper, we investigate the domain generalization performance of various FMs, including DinoV2, SAM, MedSAM, and MAE, when fine-tuned using various parameter-efficient fine-tuning (PEFT) techniques such as Ladder and Rein (+LoRA) and decoder heads.","We introduce a novel decode head architecture, HQHSAM, which simply integrates elements from two state-of-the-art decoder heads, HSAM and HQSAM, to enhance segmentation performance.","Our extensive experiments on multiple datasets, encompassing various anatomies and modalities, reveal that FMs, particularly with the HQHSAM decode head, improve domain generalization for medical image segmentation.","Moreover, we found that the effectiveness of PEFT techniques varies across different FMs.","These findings underscore the potential of FMs to enhance the domain generalization performance of neural networks in medical image segmentation across diverse clinical settings, providing a solid foundation for future research.","Code and models are available for research purposes at \\url{https://github.com/kerem-cekmeceli/Foundation-Models-for-Medical-Imagery}."],"url":"http://arxiv.org/abs/2409.07960v1"}
{"created":"2024-09-12 11:22:04","title":"Repr Types: One Abstraction to Rule Them All","abstract":"The choice of how to represent an abstract type can have a major impact on the performance of a program, yet mainstream compilers cannot perform optimizations at such a high level. When dealing with optimizations of data type representations, an important feature is having extensible representation-flexible data types; the ability for a programmer to add new abstract types and operations, as well as concrete implementations of these, without modifying the compiler or a previously defined library. Many research projects support high-level optimizations through static analysis, instrumentation, or benchmarking, but they are all restricted in at least one aspect of extensibility.   This paper presents a new approach to representation-flexible data types without such restrictions and which still finds efficient optimizations. Our approach centers around a single built-in type $\\texttt{repr}$ and function overloading with cost annotations for operation implementations. We evaluate our approach (i) by defining a universal collection type as a library, a single type for all conventional collections, and (ii) by designing and implementing a representation-flexible graph library. Programs using $\\texttt{repr}$ types are typically faster than programs with idiomatic representation choices -- sometimes dramatically so -- as long as the compiler finds good implementations for all operations. Our compiler performs the analysis efficiently by finding optimized solutions quickly and by reusing previous results to avoid recomputations.","sentences":["The choice of how to represent an abstract type can have a major impact on the performance of a program, yet mainstream compilers cannot perform optimizations at such a high level.","When dealing with optimizations of data type representations, an important feature is having extensible representation-flexible data types; the ability for a programmer to add new abstract types and operations, as well as concrete implementations of these, without modifying the compiler or a previously defined library.","Many research projects support high-level optimizations through static analysis, instrumentation, or benchmarking, but they are all restricted in at least one aspect of extensibility.   ","This paper presents a new approach to representation-flexible data types without such restrictions and which still finds efficient optimizations.","Our approach centers around a single built-in type $\\texttt{repr}$ and function overloading with cost annotations for operation implementations.","We evaluate our approach (i) by defining a universal collection type as a library, a single type for all conventional collections, and (ii) by designing and implementing a representation-flexible graph library.","Programs using $\\texttt{repr}$ types are typically faster than programs with idiomatic representation choices -- sometimes dramatically so -- as long as the compiler finds good implementations for all operations.","Our compiler performs the analysis efficiently by finding optimized solutions quickly and by reusing previous results to avoid recomputations."],"url":"http://arxiv.org/abs/2409.07950v1"}
{"created":"2024-09-12 11:14:25","title":"Collaborative Automatic Modulation Classification via Deep Edge Inference for Hierarchical Cognitive Radio Networks","abstract":"In hierarchical cognitive radio networks, edge or cloud servers utilize the data collected by edge devices for modulation classification, which, however, is faced with problems of the transmission overhead, data privacy, and computation load. In this article, an edge learning (EL) based framework jointly mobilizing the edge device and the edge server for intelligent co-inference is proposed to realize the collaborative automatic modulation classification (C-AMC) between them. A spectrum semantic compression neural network (SSCNet) with the lightweight structure is designed for the edge device to compress the collected raw data into a compact semantic message that is then sent to the edge server via the wireless channel. On the edge server side, a modulation classification neural network (MCNet) combining bidirectional long short-term memory (Bi?LSTM) and multi-head attention layers is elaborated to deter?mine the modulation type from the noisy semantic message. By leveraging the computation resources of both the edge device and the edge server, high transmission overhead and risks of data privacy leakage are avoided. The simulation results verify the effectiveness of the proposed C-AMC framework, significantly reducing the model size and computational complexity.","sentences":["In hierarchical cognitive radio networks, edge or cloud servers utilize the data collected by edge devices for modulation classification, which, however, is faced with problems of the transmission overhead, data privacy, and computation load.","In this article, an edge learning (EL) based framework jointly mobilizing the edge device and the edge server for intelligent co-inference is proposed to realize the collaborative automatic modulation classification (C-AMC) between them.","A spectrum semantic compression neural network (SSCNet) with the lightweight structure is designed for the edge device to compress the collected raw data into a compact semantic message that is then sent to the edge server via the wireless channel.","On the edge server side, a modulation classification neural network (MCNet) combining bidirectional long short-term memory (Bi?LSTM) and multi-head attention layers is elaborated to deter?mine the modulation type from the noisy semantic message.","By leveraging the computation resources of both the edge device and the edge server, high transmission overhead and risks of data privacy leakage are avoided.","The simulation results verify the effectiveness of the proposed C-AMC framework, significantly reducing the model size and computational complexity."],"url":"http://arxiv.org/abs/2409.07946v1"}
{"created":"2024-09-12 11:10:27","title":"Taylor-Sensus Network: Embracing Noise to Enlighten Uncertainty for Scientific Data","abstract":"Uncertainty estimation is crucial in scientific data for machine learning. Current uncertainty estimation methods mainly focus on the model's inherent uncertainty, while neglecting the explicit modeling of noise in the data. Furthermore, noise estimation methods typically rely on temporal or spatial dependencies, which can pose a significant challenge in structured scientific data where such dependencies among samples are often absent. To address these challenges in scientific research, we propose the Taylor-Sensus Network (TSNet). TSNet innovatively uses a Taylor series expansion to model complex, heteroscedastic noise and proposes a deep Taylor block for aware noise distribution. TSNet includes a noise-aware contrastive learning module and a data density perception module for aleatoric and epistemic uncertainty. Additionally, an uncertainty combination operator is used to integrate these uncertainties, and the network is trained using a novel heteroscedastic mean square error loss. TSNet demonstrates superior performance over mainstream and state-of-the-art methods in experiments, highlighting its potential in scientific research and noise resistance. It will be open-source to facilitate the community of \"AI for Science\".","sentences":["Uncertainty estimation is crucial in scientific data for machine learning.","Current uncertainty estimation methods mainly focus on the model's inherent uncertainty, while neglecting the explicit modeling of noise in the data.","Furthermore, noise estimation methods typically rely on temporal or spatial dependencies, which can pose a significant challenge in structured scientific data where such dependencies among samples are often absent.","To address these challenges in scientific research, we propose the Taylor-Sensus Network (TSNet).","TSNet innovatively uses a Taylor series expansion to model complex, heteroscedastic noise and proposes a deep Taylor block for aware noise distribution.","TSNet includes a noise-aware contrastive learning module and a data density perception module for aleatoric and epistemic uncertainty.","Additionally, an uncertainty combination operator is used to integrate these uncertainties, and the network is trained using a novel heteroscedastic mean square error loss.","TSNet demonstrates superior performance over mainstream and state-of-the-art methods in experiments, highlighting its potential in scientific research and noise resistance.","It will be open-source to facilitate the community of \"AI for Science\"."],"url":"http://arxiv.org/abs/2409.07942v1"}
{"created":"2024-09-12 11:07:53","title":"Control+Shift: Generating Controllable Distribution Shifts","abstract":"We propose a new method for generating realistic datasets with distribution shifts using any decoder-based generative model. Our approach systematically creates datasets with varying intensities of distribution shifts, facilitating a comprehensive analysis of model performance degradation. We then use these generated datasets to evaluate the performance of various commonly used networks and observe a consistent decline in performance with increasing shift intensity, even when the effect is almost perceptually unnoticeable to the human eye. We see this degradation even when using data augmentations. We also find that enlarging the training dataset beyond a certain point has no effect on the robustness and that stronger inductive biases increase robustness.","sentences":["We propose a new method for generating realistic datasets with distribution shifts using any decoder-based generative model.","Our approach systematically creates datasets with varying intensities of distribution shifts, facilitating a comprehensive analysis of model performance degradation.","We then use these generated datasets to evaluate the performance of various commonly used networks and observe a consistent decline in performance with increasing shift intensity, even when the effect is almost perceptually unnoticeable to the human eye.","We see this degradation even when using data augmentations.","We also find that enlarging the training dataset beyond a certain point has no effect on the robustness and that stronger inductive biases increase robustness."],"url":"http://arxiv.org/abs/2409.07940v1"}
{"created":"2024-09-12 10:58:26","title":"Modeling Human Responses by Ordinal Archetypal Analysis","abstract":"This paper introduces a novel framework for Archetypal Analysis (AA) tailored to ordinal data, particularly from questionnaires. Unlike existing methods, the proposed method, Ordinal Archetypal Analysis (OAA), bypasses the two-step process of transforming ordinal data into continuous scales and operates directly on the ordinal data. We extend traditional AA methods to handle the subjective nature of questionnaire-based data, acknowledging individual differences in scale perception. We introduce the Response Bias Ordinal Archetypal Analysis (RBOAA), which learns individualized scales for each subject during optimization. The effectiveness of these methods is demonstrated on synthetic data and the European Social Survey dataset, highlighting their potential to provide deeper insights into human behavior and perception. The study underscores the importance of considering response bias in cross-national research and offers a principled approach to analyzing ordinal data through Archetypal Analysis.","sentences":["This paper introduces a novel framework for Archetypal Analysis (AA) tailored to ordinal data, particularly from questionnaires.","Unlike existing methods, the proposed method, Ordinal Archetypal Analysis (OAA), bypasses the two-step process of transforming ordinal data into continuous scales and operates directly on the ordinal data.","We extend traditional AA methods to handle the subjective nature of questionnaire-based data, acknowledging individual differences in scale perception.","We introduce the Response Bias Ordinal Archetypal Analysis (RBOAA), which learns individualized scales for each subject during optimization.","The effectiveness of these methods is demonstrated on synthetic data and the European Social Survey dataset, highlighting their potential to provide deeper insights into human behavior and perception.","The study underscores the importance of considering response bias in cross-national research and offers a principled approach to analyzing ordinal data through Archetypal Analysis."],"url":"http://arxiv.org/abs/2409.07934v1"}
{"created":"2024-09-12 10:56:11","title":"Task-Augmented Cross-View Imputation Network for Partial Multi-View Incomplete Multi-Label Classification","abstract":"In real-world scenarios, multi-view multi-label learning often encounters the challenge of incomplete training data due to limitations in data collection and unreliable annotation processes. The absence of multi-view features impairs the comprehensive understanding of samples, omitting crucial details essential for classification. To address this issue, we present a task-augmented cross-view imputation network (TACVI-Net) for the purpose of handling partial multi-view incomplete multi-label classification. Specifically, we employ a two-stage network to derive highly task-relevant features to recover the missing views. In the first stage, we leverage the information bottleneck theory to obtain a discriminative representation of each view by extracting task-relevant information through a view-specific encoder-classifier architecture. In the second stage, an autoencoder based multi-view reconstruction network is utilized to extract high-level semantic representation of the augmented features and recover the missing data, thereby aiding the final classification task. Extensive experiments on five datasets demonstrate that our TACVI-Net outperforms other state-of-the-art methods.","sentences":["In real-world scenarios, multi-view multi-label learning often encounters the challenge of incomplete training data due to limitations in data collection and unreliable annotation processes.","The absence of multi-view features impairs the comprehensive understanding of samples, omitting crucial details essential for classification.","To address this issue, we present a task-augmented cross-view imputation network (TACVI-Net) for the purpose of handling partial multi-view incomplete multi-label classification.","Specifically, we employ a two-stage network to derive highly task-relevant features to recover the missing views.","In the first stage, we leverage the information bottleneck theory to obtain a discriminative representation of each view by extracting task-relevant information through a view-specific encoder-classifier architecture.","In the second stage, an autoencoder based multi-view reconstruction network is utilized to extract high-level semantic representation of the augmented features and recover the missing data, thereby aiding the final classification task.","Extensive experiments on five datasets demonstrate that our TACVI-Net outperforms other state-of-the-art methods."],"url":"http://arxiv.org/abs/2409.07931v1"}
{"created":"2024-09-12 10:45:45","title":"Mobile App Security Trends and Topics: An Examination of Questions From Stack Overflow","abstract":"The widespread use of smartphones and tablets has made society heavily reliant on mobile applications (apps) for accessing various resources and services. These apps often handle sensitive personal, financial, and health data, making app security a critical concern for developers. While there is extensive research on software security topics like malware and vulnerabilities, less is known about the practical security challenges mobile app developers face and the guidance they seek. \\rev{In this study, we mine Stack Overflow for questions on mobile app security, which we analyze using quantitative and qualitative techniques.} The findings reveal that Stack Overflow is a major resource for developers seeking help with mobile app security, especially for Android apps, and identifies seven main categories of security questions: Secured Communications, Database, App Distribution Service, Encryption, Permissions, File-Specific, and General Security. Insights from this research can inform the development of tools, techniques, and resources by the research and vendor community to better support developers in securing their mobile apps.","sentences":["The widespread use of smartphones and tablets has made society heavily reliant on mobile applications (apps) for accessing various resources and services.","These apps often handle sensitive personal, financial, and health data, making app security a critical concern for developers.","While there is extensive research on software security topics like malware and vulnerabilities, less is known about the practical security challenges mobile app developers face and the guidance they seek.","\\rev{In this study, we mine Stack Overflow for questions on mobile app security, which we analyze using quantitative and qualitative techniques.}","The findings reveal that Stack Overflow is a major resource for developers seeking help with mobile app security, especially for Android apps, and identifies seven main categories of security questions: Secured Communications, Database, App Distribution Service, Encryption, Permissions, File-Specific, and General Security.","Insights from this research can inform the development of tools, techniques, and resources by the research and vendor community to better support developers in securing their mobile apps."],"url":"http://arxiv.org/abs/2409.07926v1"}
{"created":"2024-09-12 10:29:37","title":"UGAD: Universal Generative AI Detector utilizing Frequency Fingerprints","abstract":"In the wake of a fabricated explosion image at the Pentagon, an ability to discern real images from fake counterparts has never been more critical. Our study introduces a novel multi-modal approach to detect AI-generated images amidst the proliferation of new generation methods such as Diffusion models. Our method, UGAD, encompasses three key detection steps: First, we transform the RGB images into YCbCr channels and apply an Integral Radial Operation to emphasize salient radial features. Secondly, the Spatial Fourier Extraction operation is used for a spatial shift, utilizing a pre-trained deep learning network for optimal feature extraction. Finally, the deep neural network classification stage processes the data through dense layers using softmax for classification. Our approach significantly enhances the accuracy of differentiating between real and AI-generated images, as evidenced by a 12.64% increase in accuracy and 28.43% increase in AUC compared to existing state-of-the-art methods.","sentences":["In the wake of a fabricated explosion image at the Pentagon, an ability to discern real images from fake counterparts has never been more critical.","Our study introduces a novel multi-modal approach to detect AI-generated images amidst the proliferation of new generation methods such as Diffusion models.","Our method, UGAD, encompasses three key detection steps:","First, we transform the RGB images into YCbCr channels and apply an Integral Radial Operation to emphasize salient radial features.","Secondly, the Spatial Fourier Extraction operation is used for a spatial shift, utilizing a pre-trained deep learning network for optimal feature extraction.","Finally, the deep neural network classification stage processes the data through dense layers using softmax for classification.","Our approach significantly enhances the accuracy of differentiating between real and AI-generated images, as evidenced by a 12.64% increase in accuracy and 28.43% increase in AUC compared to existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2409.07913v1"}
{"created":"2024-09-12 10:26:17","title":"Tera-SpaceCom: GNN-based Deep Reinforcement Learning for Joint Resource Allocation and Task Offloading in TeraHertz Band Space Networks","abstract":"Terahertz (THz) space communications (Tera-SpaceCom) is envisioned as a promising technology to enable various space science and communication applications. Mainly, the realm of Tera-SpaceCom consists of THz sensing for space exploration, data centers in space providing cloud services for space exploration tasks, and a low earth orbit (LEO) mega-constellation relaying these tasks to ground stations (GSs) or data centers via THz links. Moreover, to reduce the computational burden on data centers as well as resource consumption and latency in the relaying process, the LEO mega-constellation provides satellite edge computing (SEC) services to directly compute space exploration tasks without relaying these tasks to data centers. The LEO satellites that receive space exploration tasks offload (i.e., distribute) partial tasks to their neighboring LEO satellites, to further reduce their computational burden. However, efficient joint communication resource allocation and computing task offloading for the Tera-SpaceCom SEC network is an NP-hard mixed-integer nonlinear programming problem (MINLP), due to the discrete nature of space exploration tasks and sub-arrays as well as the continuous nature of transmit power. To tackle this challenge, a graph neural network (GNN)-deep reinforcement learning (DRL)-based joint resource allocation and task offloading (GRANT) algorithm is proposed with the target of long-term resource efficiency (RE). Particularly, GNNs learn relationships among different satellites from their connectivity information. Furthermore, multi-agent and multi-task mechanisms cooperatively train task offloading and resource allocation. Compared with benchmark solutions, GRANT not only achieves the highest RE with relatively low latency, but realizes the fewest trainable parameters and the shortest running time.","sentences":["Terahertz (THz) space communications (Tera-SpaceCom) is envisioned as a promising technology to enable various space science and communication applications.","Mainly, the realm of Tera-SpaceCom consists of THz sensing for space exploration, data centers in space providing cloud services for space exploration tasks, and a low earth orbit (LEO) mega-constellation relaying these tasks to ground stations (GSs) or data centers via THz links.","Moreover, to reduce the computational burden on data centers as well as resource consumption and latency in the relaying process, the LEO mega-constellation provides satellite edge computing (SEC) services to directly compute space exploration tasks without relaying these tasks to data centers.","The LEO satellites that receive space exploration tasks offload (i.e., distribute) partial tasks to their neighboring LEO satellites, to further reduce their computational burden.","However, efficient joint communication resource allocation and computing task offloading for the Tera-SpaceCom SEC network is an NP-hard mixed-integer nonlinear programming problem (MINLP), due to the discrete nature of space exploration tasks and sub-arrays as well as the continuous nature of transmit power.","To tackle this challenge, a graph neural network (GNN)-deep reinforcement learning (DRL)-based joint resource allocation and task offloading (GRANT) algorithm is proposed with the target of long-term resource efficiency (RE).","Particularly, GNNs learn relationships among different satellites from their connectivity information.","Furthermore, multi-agent and multi-task mechanisms cooperatively train task offloading and resource allocation.","Compared with benchmark solutions, GRANT not only achieves the highest RE with relatively low latency, but realizes the fewest trainable parameters and the shortest running time."],"url":"http://arxiv.org/abs/2409.07911v1"}
{"created":"2024-09-12 10:14:29","title":"Dynamic Simultaneous Multithreaded Arch","abstract":"This paper presents the Dynamic Simultaneous Multi-threaded Architecture (DSMT). DSMT efficiently exe-cutes multiple threads from a single program on a SMT processor core. To accomplish this, threads are generated dynamically from a predictable flow of control and then executed speculatively. Data obtained during the single context non-speculative execution phase of DSMT is used as a hint to speculate the posterior behavior of multiple threads. DSMT employs simple mechanisms based on state bits that keep track of inter-thread dependencies in registers and memory, synchronize thread execution, and control recovery from misspeculation. Moreover, DSMT utilizes a novel greedy policy for choosing those sections of code which provide the highest performance based on their past execution history. The DSMT architecture was simulated with a new cycle-accurate, execution-driven simulator. Our simulation results show that DSMT has very good potential to improve SMT performance, even when only a single program is available. However, we found that dynamic thread behavior together with fre-quent misspeculation may also produce diminishing re-turns in performance. Therefore, the challenge is to max-imize the amount of thread-level parallelism that DSMT is capable of exploiting and at the same time reduce the fre-quency of misspeculations.","sentences":["This paper presents the Dynamic Simultaneous Multi-threaded Architecture (DSMT).","DSMT efficiently exe-cutes multiple threads from a single program on a SMT processor core.","To accomplish this, threads are generated dynamically from a predictable flow of control and then executed speculatively.","Data obtained during the single context non-speculative execution phase of DSMT is used as a hint to speculate the posterior behavior of multiple threads.","DSMT employs simple mechanisms based on state bits that keep track of inter-thread dependencies in registers and memory, synchronize thread execution, and control recovery from misspeculation.","Moreover, DSMT utilizes a novel greedy policy for choosing those sections of code which provide the highest performance based on their past execution history.","The DSMT architecture was simulated with a new cycle-accurate, execution-driven simulator.","Our simulation results show that DSMT has very good potential to improve SMT performance, even when only a single program is available.","However, we found that dynamic thread behavior together with fre-quent misspeculation may also produce diminishing re-turns in performance.","Therefore, the challenge is to max-imize the amount of thread-level parallelism that DSMT is capable of exploiting and at the same time reduce the fre-quency of misspeculations."],"url":"http://arxiv.org/abs/2409.07903v1"}
{"created":"2024-09-12 09:41:29","title":"Non-negative Weighted DAG Structure Learning","abstract":"We address the problem of learning the topology of directed acyclic graphs (DAGs) from nodal observations, which adhere to a linear structural equation model. Recent advances framed the combinatorial DAG structure learning task as a continuous optimization problem, yet existing methods must contend with the complexities of non-convex optimization. To overcome this limitation, we assume that the latent DAG contains only non-negative edge weights. Leveraging this additional structure, we argue that cycles can be effectively characterized (and prevented) using a convex acyclicity function based on the log-determinant of the adjacency matrix. This convexity allows us to relax the task of learning the non-negative weighted DAG as an abstract convex optimization problem. We propose a DAG recovery algorithm based on the method of multipliers, that is guaranteed to return a global minimizer. Furthermore, we prove that in the infinite sample size regime, the convexity of our approach ensures the recovery of the true DAG structure. We empirically validate the performance of our algorithm in several reproducible synthetic-data test cases, showing that it outperforms state-of-the-art alternatives.","sentences":["We address the problem of learning the topology of directed acyclic graphs (DAGs) from nodal observations, which adhere to a linear structural equation model.","Recent advances framed the combinatorial DAG structure learning task as a continuous optimization problem, yet existing methods must contend with the complexities of non-convex optimization.","To overcome this limitation, we assume that the latent DAG contains only non-negative edge weights.","Leveraging this additional structure, we argue that cycles can be effectively characterized (and prevented) using a convex acyclicity function based on the log-determinant of the adjacency matrix.","This convexity allows us to relax the task of learning the non-negative weighted DAG as an abstract convex optimization problem.","We propose a DAG recovery algorithm based on the method of multipliers, that is guaranteed to return a global minimizer.","Furthermore, we prove that in the infinite sample size regime, the convexity of our approach ensures the recovery of the true DAG structure.","We empirically validate the performance of our algorithm in several reproducible synthetic-data test cases, showing that it outperforms state-of-the-art alternatives."],"url":"http://arxiv.org/abs/2409.07880v1"}
{"created":"2024-09-12 09:27:36","title":"Learning Rules from KGs Guided by Language Models","abstract":"Advances in information extraction have enabled the automatic construction of large knowledge graphs (e.g., Yago, Wikidata or Google KG), which are widely used in many applications like semantic search or data analytics. However, due to their semi-automatic construction, KGs are often incomplete. Rule learning methods, concerned with the extraction of frequent patterns from KGs and casting them into rules, can be applied to predict potentially missing facts. A crucial step in this process is rule ranking. Ranking of rules is especially challenging over highly incomplete or biased KGs (e.g., KGs predominantly storing facts about famous people), as in this case biased rules might fit the data best and be ranked at the top based on standard statistical metrics like rule confidence. To address this issue, prior works proposed to rank rules not only relying on the original KG but also facts predicted by a KG embedding model. At the same time, with the recent rise of Language Models (LMs), several works have claimed that LMs can be used as alternative means for KG completion. In this work, our goal is to verify to which extent the exploitation of LMs is helpful for improving the quality of rule learning systems.","sentences":["Advances in information extraction have enabled the automatic construction of large knowledge graphs (e.g., Yago, Wikidata or Google KG), which are widely used in many applications like semantic search or data analytics.","However, due to their semi-automatic construction, KGs are often incomplete.","Rule learning methods, concerned with the extraction of frequent patterns from KGs and casting them into rules, can be applied to predict potentially missing facts.","A crucial step in this process is rule ranking.","Ranking of rules is especially challenging over highly incomplete or biased KGs (e.g., KGs predominantly storing facts about famous people), as in this case biased rules might fit the data best and be ranked at the top based on standard statistical metrics like rule confidence.","To address this issue, prior works proposed to rank rules not only relying on the original KG but also facts predicted by a KG embedding model.","At the same time, with the recent rise of Language Models (LMs), several works have claimed that LMs can be used as alternative means for KG completion.","In this work, our goal is to verify to which extent the exploitation of LMs is helpful for improving the quality of rule learning systems."],"url":"http://arxiv.org/abs/2409.07869v1"}
{"created":"2024-09-12 09:26:25","title":"An Optimal Algorithm for Sorting Pattern-Avoiding Sequences","abstract":"We present a deterministic comparison-based algorithm that sorts sequences avoiding a fixed permutation $\\pi$ in linear time, even if $\\pi$ is a priori unkown. Moreover, the dependence of the multiplicative constant on the pattern $\\pi$ matches the information-theoretic lower bound. A crucial ingredient is an algorithm for performing efficient multi-way merge based on the Marcus-Tardos theorem. As a direct corollary, we obtain a linear-time algorithm for sorting permutations of bounded twin-width.","sentences":["We present a deterministic comparison-based algorithm that sorts sequences avoiding a fixed permutation $\\pi$ in linear time, even if $\\pi$ is a priori unkown.","Moreover, the dependence of the multiplicative constant on the pattern $\\pi$ matches the information-theoretic lower bound.","A crucial ingredient is an algorithm for performing efficient multi-way merge based on the Marcus-Tardos theorem.","As a direct corollary, we obtain a linear-time algorithm for sorting permutations of bounded twin-width."],"url":"http://arxiv.org/abs/2409.07868v1"}
{"created":"2024-09-12 09:00:56","title":"MSMF: Multi-Scale Multi-Modal Fusion for Enhanced Stock Market Prediction","abstract":"This paper presents MSMF (Multi-Scale Multi-Modal Fusion), a novel approach for enhanced stock market prediction. MSMF addresses key challenges in multi-modal stock analysis by integrating a modality completion encoder, multi-scale feature extraction, and an innovative fusion mechanism. Our model leverages blank learning and progressive fusion to balance complementarity and redundancy across modalities, while multi-scale alignment facilitates direct correlations between heterogeneous data types. We introduce Multi-Granularity Gates and a specialized architecture to optimize the integration of local and global information for different tasks. Additionally, a Task-targeted Prediction layer is employed to preserve both coarse and fine-grained features during fusion. Experimental results demonstrate that MSMF outperforms existing methods, achieving significant improvements in accuracy and reducing prediction errors across various stock market forecasting tasks. This research contributes valuable insights to the field of multi-modal financial analysis and offers a robust framework for enhanced market prediction.","sentences":["This paper presents MSMF (Multi-Scale Multi-Modal Fusion), a novel approach for enhanced stock market prediction.","MSMF addresses key challenges in multi-modal stock analysis by integrating a modality completion encoder, multi-scale feature extraction, and an innovative fusion mechanism.","Our model leverages blank learning and progressive fusion to balance complementarity and redundancy across modalities, while multi-scale alignment facilitates direct correlations between heterogeneous data types.","We introduce Multi-Granularity Gates and a specialized architecture to optimize the integration of local and global information for different tasks.","Additionally, a Task-targeted Prediction layer is employed to preserve both coarse and fine-grained features during fusion.","Experimental results demonstrate that MSMF outperforms existing methods, achieving significant improvements in accuracy and reducing prediction errors across various stock market forecasting tasks.","This research contributes valuable insights to the field of multi-modal financial analysis and offers a robust framework for enhanced market prediction."],"url":"http://arxiv.org/abs/2409.07855v1"}
{"created":"2024-09-12 08:59:53","title":"Improve Machine Learning carbon footprint using Nvidia GPU and Mixed Precision training for classification algorithms","abstract":"This study was part of my dissertation for my master degree and compares the power consumption using the default floating point (32bit) and Nvidia mixed precision (16bit and 32bit) while training a classification ML model. A custom PC with specific hardware was built to perform the experiments, and different ML hyper-parameters, such as batch size, neurons, and epochs, were chosen to build Deep Neural Networks (DNN). Additionally, various software was used during the experiments to collect the power consumption data in Watts from the Graphics Processing Unit (GPU), Central Processing Unit (CPU), Random Access Memory (RAM) and manually from a wattmeter connected to the wall. A benchmarking test with default hyper parameter values for the DNN was used as a reference, while the experiments used a combination of different settings. The results were recorded in Excel, and descriptive statistics were chosen to calculate the mean between the groups and compare them using graphs and tables. The outcome was positive when using mixed precision combined with specific hyper-parameters. Compared to the benchmarking, the optimisation for the classification reduced the power consumption between 7 and 11 Watts. Similarly, the carbon footprint is reduced because the calculation uses the same power consumption data. Still, a consideration is required when configuring hyper-parameters because it can negatively affect hardware performance. However, this research required inferential statistics, specifically ANOVA and T-test, to compare the relationship between the means. Furthermore, tests indicated no statistical significance of the relationship between the benchmarking and experiments. However, a more extensive implementation with a cluster of GPUs can increase the sample size significantly, as it is an essential factor and can change the outcome of the statistical analysis.","sentences":["This study was part of my dissertation for my master degree and compares the power consumption using the default floating point (32bit) and Nvidia mixed precision (16bit and 32bit) while training a classification ML model.","A custom PC with specific hardware was built to perform the experiments, and different ML hyper-parameters, such as batch size, neurons, and epochs, were chosen to build Deep Neural Networks (DNN).","Additionally, various software was used during the experiments to collect the power consumption data in Watts from the Graphics Processing Unit (GPU), Central Processing Unit (CPU), Random Access Memory (RAM) and manually from a wattmeter connected to the wall.","A benchmarking test with default hyper parameter values for the DNN was used as a reference, while the experiments used a combination of different settings.","The results were recorded in Excel, and descriptive statistics were chosen to calculate the mean between the groups and compare them using graphs and tables.","The outcome was positive when using mixed precision combined with specific hyper-parameters.","Compared to the benchmarking, the optimisation for the classification reduced the power consumption between 7 and 11 Watts.","Similarly, the carbon footprint is reduced because the calculation uses the same power consumption data.","Still, a consideration is required when configuring hyper-parameters because it can negatively affect hardware performance.","However, this research required inferential statistics, specifically ANOVA and T-test, to compare the relationship between the means.","Furthermore, tests indicated no statistical significance of the relationship between the benchmarking and experiments.","However, a more extensive implementation with a cluster of GPUs can increase the sample size significantly, as it is an essential factor and can change the outcome of the statistical analysis."],"url":"http://arxiv.org/abs/2409.07853v1"}
{"created":"2024-09-12 08:53:11","title":"Enhancing Cross-Market Recommendation System with Graph Isomorphism Networks: A Novel Approach to Personalized User Experience","abstract":"In today's world of globalized commerce, cross-market recommendation systems (CMRs) are crucial for providing personalized user experiences across diverse market segments. However, traditional recommendation algorithms have difficulties dealing with market specificity and data sparsity, especially in new or emerging markets. In this paper, we propose the CrossGR model, which utilizes Graph Isomorphism Networks (GINs) to improve CMR systems. It outperforms existing benchmarks in NDCG@10 and HR@10 metrics, demonstrating its adaptability and accuracy in handling diverse market segments. The CrossGR model is adaptable and accurate, making it well-suited for handling the complexities of cross-market recommendation tasks. Its robustness is demonstrated by consistent performance across different evaluation timeframes, indicating its potential to cater to evolving market trends and user preferences. Our findings suggest that GINs represent a promising direction for CMRs, paving the way for more sophisticated, personalized, and context-aware recommendation systems in the dynamic landscape of global e-commerce.","sentences":["In today's world of globalized commerce, cross-market recommendation systems (CMRs) are crucial for providing personalized user experiences across diverse market segments.","However, traditional recommendation algorithms have difficulties dealing with market specificity and data sparsity, especially in new or emerging markets.","In this paper, we propose the CrossGR model, which utilizes Graph Isomorphism Networks (GINs) to improve CMR systems.","It outperforms existing benchmarks in NDCG@10 and HR@10 metrics, demonstrating its adaptability and accuracy in handling diverse market segments.","The CrossGR model is adaptable and accurate, making it well-suited for handling the complexities of cross-market recommendation tasks.","Its robustness is demonstrated by consistent performance across different evaluation timeframes, indicating its potential to cater to evolving market trends and user preferences.","Our findings suggest that GINs represent a promising direction for CMRs, paving the way for more sophisticated, personalized, and context-aware recommendation systems in the dynamic landscape of global e-commerce."],"url":"http://arxiv.org/abs/2409.07850v1"}
{"created":"2024-09-12 08:44:35","title":"Real-time Multi-view Omnidirectional Depth Estimation System for Robots and Autonomous Driving on Real Scenes","abstract":"Omnidirectional Depth Estimation has broad application prospects in fields such as robotic navigation and autonomous driving. In this paper, we propose a robotic prototype system and corresponding algorithm designed to validate omnidirectional depth estimation for navigation and obstacle avoidance in real-world scenarios for both robots and vehicles. The proposed HexaMODE system captures 360$^\\circ$ depth maps using six surrounding arranged fisheye cameras. We introduce a combined spherical sweeping method and optimize the model architecture for proposed RtHexa-OmniMVS algorithm to achieve real-time omnidirectional depth estimation. To ensure high accuracy, robustness, and generalization in real-world environments, we employ a teacher-student self-training strategy, utilizing large-scale unlabeled real-world data for model training. The proposed algorithm demonstrates high accuracy in various complex real-world scenarios, both indoors and outdoors, achieving an inference speed of 15 fps on edge computing platforms.","sentences":["Omnidirectional Depth Estimation has broad application prospects in fields such as robotic navigation and autonomous driving.","In this paper, we propose a robotic prototype system and corresponding algorithm designed to validate omnidirectional depth estimation for navigation and obstacle avoidance in real-world scenarios for both robots and vehicles.","The proposed HexaMODE system captures 360$^\\circ$ depth maps using six surrounding arranged fisheye cameras.","We introduce a combined spherical sweeping method and optimize the model architecture for proposed RtHexa-OmniMVS algorithm to achieve real-time omnidirectional depth estimation.","To ensure high accuracy, robustness, and generalization in real-world environments, we employ a teacher-student self-training strategy, utilizing large-scale unlabeled real-world data for model training.","The proposed algorithm demonstrates high accuracy in various complex real-world scenarios, both indoors and outdoors, achieving an inference speed of 15 fps on edge computing platforms."],"url":"http://arxiv.org/abs/2409.07843v1"}
{"created":"2024-09-12 08:39:39","title":"Computing the LZ-End parsing: Easy to implement and practically efficient","abstract":"The LZ-End parsing [Kreft & Navarro, 2011] of an input string yields compression competitive with the popular Lempel-Ziv 77 scheme, but also allows for efficient random access. Kempa and Kosolobov showed that the parsing can be computed in time and space linear in the input length [Kempa & Kosolobov, 2017], however, the corresponding algorithm is hardly practical. We put the spotlight on their suboptimal algorithm that computes the parsing in time $\\mathcal{O}(n \\lg\\lg n)$. It requires a comparatively small toolset and is therefore easy to implement, but at the same time very efficient in practice. We give a detailed and simplified description with a full listing that incorporates undocumented tricks from the original implementation, but also uses lazy evaluation to reduce the workload in practice and requires less working memory by removing a level of indirection. We legitimize our algorithm in a brief benchmark, obtaining the parsing faster than the state of the art.","sentences":["The LZ-End parsing [Kreft & Navarro, 2011] of an input string yields compression competitive with the popular Lempel-Ziv 77 scheme, but also allows for efficient random access.","Kempa and Kosolobov showed that the parsing can be computed in time and space linear in the input length [Kempa & Kosolobov, 2017], however, the corresponding algorithm is hardly practical.","We put the spotlight on their suboptimal algorithm that computes the parsing in time $\\mathcal{O}(n \\lg\\lg n)$. It requires a comparatively small toolset and is therefore easy to implement, but at the same time very efficient in practice.","We give a detailed and simplified description with a full listing that incorporates undocumented tricks from the original implementation, but also uses lazy evaluation to reduce the workload in practice and requires less working memory by removing a level of indirection.","We legitimize our algorithm in a brief benchmark, obtaining the parsing faster than the state of the art."],"url":"http://arxiv.org/abs/2409.07840v1"}
{"created":"2024-09-12 08:38:42","title":"FPMT: Enhanced Semi-Supervised Model for Traffic Incident Detection","abstract":"For traffic incident detection, the acquisition of data and labels is notably resource-intensive, rendering semi-supervised traffic incident detection both a formidable and consequential challenge. Thus, this paper focuses on traffic incident detection with a semi-supervised learning way. It proposes a semi-supervised learning model named FPMT within the framework of MixText. The data augmentation module introduces Generative Adversarial Networks to balance and expand the dataset. During the mix-up process in the hidden space, it employs a probabilistic pseudo-mixing mechanism to enhance regularization and elevate model precision. In terms of training strategy, it initiates with unsupervised training on all data, followed by supervised fine-tuning on a subset of labeled data, and ultimately completing the goal of semi-supervised training. Through empirical validation on four authentic datasets, our FPMT model exhibits outstanding performance across various metrics. Particularly noteworthy is its robust performance even in scenarios with low label rates.","sentences":["For traffic incident detection, the acquisition of data and labels is notably resource-intensive, rendering semi-supervised traffic incident detection both a formidable and consequential challenge.","Thus, this paper focuses on traffic incident detection with a semi-supervised learning way.","It proposes a semi-supervised learning model named FPMT within the framework of MixText.","The data augmentation module introduces Generative Adversarial Networks to balance and expand the dataset.","During the mix-up process in the hidden space, it employs a probabilistic pseudo-mixing mechanism to enhance regularization and elevate model precision.","In terms of training strategy, it initiates with unsupervised training on all data, followed by supervised fine-tuning on a subset of labeled data, and ultimately completing the goal of semi-supervised training.","Through empirical validation on four authentic datasets, our FPMT model exhibits outstanding performance across various metrics.","Particularly noteworthy is its robust performance even in scenarios with low label rates."],"url":"http://arxiv.org/abs/2409.07839v1"}
{"created":"2024-09-12 08:36:02","title":"Maximum And- vs. Even-SAT","abstract":"A (multi)set of literals, called a clause, is strongly satisfied by an assignment if no literal evaluates to false. Finding an assignment that maximises the number of strongly satisfied clauses is NP-hard. We present a simple algorithm that finds, given a set of clauses that admits an assignment that strongly satisfies a $\\rho$-fraction of the clauses, an assignment in which at least a $\\rho$-fraction of the clauses is weakly satisfied, in the sense that an even number of literals evaluates to false. In particular, this implies an efficient algorithm for finding an undirected cut of value $\\rho$ in a graph given that a directed cut of value $\\rho$ in the graph is promised to exist.","sentences":["A (multi)set of literals, called a clause, is strongly satisfied by an assignment if no literal evaluates to false.","Finding an assignment that maximises the number of strongly satisfied clauses is NP-hard.","We present a simple algorithm that finds, given a set of clauses that admits an assignment that strongly satisfies a $\\rho$-fraction of the clauses, an assignment in which at least a $\\rho$-fraction of the clauses is weakly satisfied, in the sense that an even number of literals evaluates to false.","In particular, this implies an efficient algorithm for finding an undirected cut of value $\\rho$ in a graph given that a directed cut of value $\\rho$ in the graph is promised to exist."],"url":"http://arxiv.org/abs/2409.07837v1"}
{"created":"2024-09-12 08:29:37","title":"Efficient and Reliable Vector Similarity Search Using Asymmetric Encoding with NAND-Flash for Many-Class Few-Shot Learning","abstract":"While memory-augmented neural networks (MANNs) offer an effective solution for few-shot learning (FSL) by integrating deep neural networks with external memory, the capacity requirements and energy overhead of data movement become enormous due to the large number of support vectors in many-class FSL scenarios. Various in-memory search solutions have emerged to improve the energy efficiency of MANNs. NAND-based multi-bit content addressable memory (MCAM) is a promising option due to its high density and large capacity. Despite its potential, MCAM faces limitations such as a restricted number of word lines, limited quantization levels, and non-ideal effects like varying string currents and bottleneck effects, which lead to significant accuracy drops. To address these issues, we propose several innovative methods. First, the Multi-bit Thermometer Code (MTMC) leverages the extensive capacity of MCAM to enhance vector precision using cumulative encoding rules, thereby mitigating the bottleneck effect. Second, the Asymmetric vector similarity search (AVSS) reduces the precision of the query vector while maintaining that of the support vectors, thereby minimizing the search iterations and improving efficiency in many-class scenarios. Finally, the Hardware-Aware Training (HAT) method optimizes controller training by modeling the hardware characteristics of MCAM, thus enhancing the reliability of the system. Our integrated framework reduces search iterations by up to 32 times, and increases overall accuracy by 1.58% to 6.94%.","sentences":["While memory-augmented neural networks (MANNs) offer an effective solution for few-shot learning (FSL) by integrating deep neural networks with external memory, the capacity requirements and energy overhead of data movement become enormous due to the large number of support vectors in many-class FSL scenarios.","Various in-memory search solutions have emerged to improve the energy efficiency of MANNs.","NAND-based multi-bit content addressable memory (MCAM) is a promising option due to its high density and large capacity.","Despite its potential, MCAM faces limitations such as a restricted number of word lines, limited quantization levels, and non-ideal effects like varying string currents and bottleneck effects, which lead to significant accuracy drops.","To address these issues, we propose several innovative methods.","First, the Multi-bit Thermometer Code (MTMC) leverages the extensive capacity of MCAM to enhance vector precision using cumulative encoding rules, thereby mitigating the bottleneck effect.","Second, the Asymmetric vector similarity search (AVSS) reduces the precision of the query vector while maintaining that of the support vectors, thereby minimizing the search iterations and improving efficiency in many-class scenarios.","Finally, the Hardware-Aware Training (HAT) method optimizes controller training by modeling the hardware characteristics of MCAM, thus enhancing the reliability of the system.","Our integrated framework reduces search iterations by up to 32 times, and increases overall accuracy by 1.58% to 6.94%."],"url":"http://arxiv.org/abs/2409.07832v1"}
{"created":"2024-09-12 08:26:33","title":"ReGentS: Real-World Safety-Critical Driving Scenario Generation Made Stable","abstract":"Machine learning based autonomous driving systems often face challenges with safety-critical scenarios that are rare in real-world data, hindering their large-scale deployment. While increasing real-world training data coverage could address this issue, it is costly and dangerous. This work explores generating safety-critical driving scenarios by modifying complex real-world regular scenarios through trajectory optimization. We propose ReGentS, which stabilizes generated trajectories and introduces heuristics to avoid obvious collisions and optimization problems. Our approach addresses unrealistic diverging trajectories and unavoidable collision scenarios that are not useful for training robust planner. We also extend the scenario generation framework to handle real-world data with up to 32 agents. Additionally, by using a differentiable simulator, our approach simplifies gradient descent-based optimization involving a simulator, paving the way for future advancements. The code is available at https://github.com/valeoai/ReGentS.","sentences":["Machine learning based autonomous driving systems often face challenges with safety-critical scenarios that are rare in real-world data, hindering their large-scale deployment.","While increasing real-world training data coverage could address this issue, it is costly and dangerous.","This work explores generating safety-critical driving scenarios by modifying complex real-world regular scenarios through trajectory optimization.","We propose ReGentS, which stabilizes generated trajectories and introduces heuristics to avoid obvious collisions and optimization problems.","Our approach addresses unrealistic diverging trajectories and unavoidable collision scenarios that are not useful for training robust planner.","We also extend the scenario generation framework to handle real-world data with up to 32 agents.","Additionally, by using a differentiable simulator, our approach simplifies gradient descent-based optimization involving a simulator, paving the way for future advancements.","The code is available at https://github.com/valeoai/ReGentS."],"url":"http://arxiv.org/abs/2409.07830v1"}
{"created":"2024-09-12 08:19:25","title":"Bridging Paintings and Music -- Exploring Emotion based Music Generation through Paintings","abstract":"Rapid advancements in artificial intelligence have significantly enhanced generative tasks involving music and images, employing both unimodal and multimodal approaches. This research develops a model capable of generating music that resonates with the emotions depicted in visual arts, integrating emotion labeling, image captioning, and language models to transform visual inputs into musical compositions. Addressing the scarcity of aligned art and music data, we curated the Emotion Painting Music Dataset, pairing paintings with corresponding music for effective training and evaluation. Our dual-stage framework converts images to text descriptions of emotional content and then transforms these descriptions into music, facilitating efficient learning with minimal data. Performance is evaluated using metrics such as Fr\\'echet Audio Distance (FAD), Total Harmonic Distortion (THD), Inception Score (IS), and KL divergence, with audio-emotion text similarity confirmed by the pre-trained CLAP model to demonstrate high alignment between generated music and text. This synthesis tool bridges visual art and music, enhancing accessibility for the visually impaired and opening avenues in educational and therapeutic applications by providing enriched multi-sensory experiences.","sentences":["Rapid advancements in artificial intelligence have significantly enhanced generative tasks involving music and images, employing both unimodal and multimodal approaches.","This research develops a model capable of generating music that resonates with the emotions depicted in visual arts, integrating emotion labeling, image captioning, and language models to transform visual inputs into musical compositions.","Addressing the scarcity of aligned art and music data, we curated the Emotion Painting Music Dataset, pairing paintings with corresponding music for effective training and evaluation.","Our dual-stage framework converts images to text descriptions of emotional content and then transforms these descriptions into music, facilitating efficient learning with minimal data.","Performance is evaluated using metrics such as Fr\\'echet Audio Distance (FAD), Total Harmonic Distortion (THD), Inception Score (IS), and KL divergence, with audio-emotion text similarity confirmed by the pre-trained CLAP model to demonstrate high alignment between generated music and text.","This synthesis tool bridges visual art and music, enhancing accessibility for the visually impaired and opening avenues in educational and therapeutic applications by providing enriched multi-sensory experiences."],"url":"http://arxiv.org/abs/2409.07827v1"}
{"created":"2024-09-12 08:15:39","title":"A Comprehensive Survey on Deep Multimodal Learning with Missing Modality","abstract":"During multimodal model training and reasoning, data samples may miss certain modalities and lead to compromised model performance due to sensor limitations, cost constraints, privacy concerns, data loss, and temporal and spatial factors. This survey provides an overview of recent progress in Multimodal Learning with Missing Modality (MLMM), focusing on deep learning techniques. It is the first comprehensive survey that covers the historical background and the distinction between MLMM and standard multimodal learning setups, followed by a detailed analysis of current MLMM methods, applications, and datasets, concluding with a discussion about challenges and potential future directions in the field.","sentences":["During multimodal model training and reasoning, data samples may miss certain modalities and lead to compromised model performance due to sensor limitations, cost constraints, privacy concerns, data loss, and temporal and spatial factors.","This survey provides an overview of recent progress in Multimodal Learning with Missing Modality (MLMM), focusing on deep learning techniques.","It is the first comprehensive survey that covers the historical background and the distinction between MLMM and standard multimodal learning setups, followed by a detailed analysis of current MLMM methods, applications, and datasets, concluding with a discussion about challenges and potential future directions in the field."],"url":"http://arxiv.org/abs/2409.07825v1"}
{"created":"2024-09-12 07:38:34","title":"Controllable Synthetic Clinical Note Generation with Privacy Guarantees","abstract":"In the field of machine learning, domain-specific annotated data is an invaluable resource for training effective models. However, in the medical domain, this data often includes Personal Health Information (PHI), raising significant privacy concerns. The stringent regulations surrounding PHI limit the availability and sharing of medical datasets, which poses a substantial challenge for researchers and practitioners aiming to develop advanced machine learning models. In this paper, we introduce a novel method to \"clone\" datasets containing PHI. Our approach ensures that the cloned datasets retain the essential characteristics and utility of the original data without compromising patient privacy. By leveraging differential-privacy techniques and a novel fine-tuning task, our method produces datasets that are free from identifiable information while preserving the statistical properties necessary for model training. We conduct utility testing to evaluate the performance of machine learning models trained on the cloned datasets. The results demonstrate that our cloned datasets not only uphold privacy standards but also enhance model performance compared to those trained on traditional anonymized datasets. This work offers a viable solution for the ethical and effective utilization of sensitive medical data in machine learning, facilitating progress in medical research and the development of robust predictive models.","sentences":["In the field of machine learning, domain-specific annotated data is an invaluable resource for training effective models.","However, in the medical domain, this data often includes Personal Health Information (PHI), raising significant privacy concerns.","The stringent regulations surrounding PHI limit the availability and sharing of medical datasets, which poses a substantial challenge for researchers and practitioners aiming to develop advanced machine learning models.","In this paper, we introduce a novel method to \"clone\" datasets containing PHI.","Our approach ensures that the cloned datasets retain the essential characteristics and utility of the original data without compromising patient privacy.","By leveraging differential-privacy techniques and a novel fine-tuning task, our method produces datasets that are free from identifiable information while preserving the statistical properties necessary for model training.","We conduct utility testing to evaluate the performance of machine learning models trained on the cloned datasets.","The results demonstrate that our cloned datasets not only uphold privacy standards but also enhance model performance compared to those trained on traditional anonymized datasets.","This work offers a viable solution for the ethical and effective utilization of sensitive medical data in machine learning, facilitating progress in medical research and the development of robust predictive models."],"url":"http://arxiv.org/abs/2409.07809v1"}
{"created":"2024-09-12 07:37:49","title":"FedHide: Federated Learning by Hiding in the Neighbors","abstract":"We propose a prototype-based federated learning method designed for embedding networks in classification or verification tasks. Our focus is on scenarios where each client has data from a single class. The main challenge is to develop an embedding network that can distinguish between different classes while adhering to privacy constraints. Sharing true class prototypes with the server or other clients could potentially compromise sensitive information. To tackle this issue, we propose a proxy class prototype that will be shared among clients instead of the true class prototype. Our approach generates proxy class prototypes by linearly combining them with their nearest neighbors. This technique conceals the true class prototype while enabling clients to learn discriminative embedding networks. We compare our method to alternative techniques, such as adding random Gaussian noise and using random selection with cosine similarity constraints. Furthermore, we evaluate the robustness of our approach against gradient inversion attacks and introduce a measure for prototype leakage. This measure quantifies the extent of private information revealed when sharing the proposed proxy class prototype. Moreover, we provide a theoretical analysis of the convergence properties of our approach. Our proposed method for federated learning from scratch demonstrates its effectiveness through empirical results on three benchmark datasets: CIFAR-100, VoxCeleb1, and VGGFace2.","sentences":["We propose a prototype-based federated learning method designed for embedding networks in classification or verification tasks.","Our focus is on scenarios where each client has data from a single class.","The main challenge is to develop an embedding network that can distinguish between different classes while adhering to privacy constraints.","Sharing true class prototypes with the server or other clients could potentially compromise sensitive information.","To tackle this issue, we propose a proxy class prototype that will be shared among clients instead of the true class prototype.","Our approach generates proxy class prototypes by linearly combining them with their nearest neighbors.","This technique conceals the true class prototype while enabling clients to learn discriminative embedding networks.","We compare our method to alternative techniques, such as adding random Gaussian noise and using random selection with cosine similarity constraints.","Furthermore, we evaluate the robustness of our approach against gradient inversion attacks and introduce a measure for prototype leakage.","This measure quantifies the extent of private information revealed when sharing the proposed proxy class prototype.","Moreover, we provide a theoretical analysis of the convergence properties of our approach.","Our proposed method for federated learning from scratch demonstrates its effectiveness through empirical results on three benchmark datasets: CIFAR-100, VoxCeleb1, and VGGFace2."],"url":"http://arxiv.org/abs/2409.07808v1"}
{"created":"2024-09-12 06:56:52","title":"In-Situ Fine-Tuning of Wildlife Models in IoT-Enabled Camera Traps for Efficient Adaptation","abstract":"Wildlife monitoring via camera traps has become an essential tool in ecology, but the deployment of machine learning models for on-device animal classification faces significant challenges due to domain shifts and resource constraints. This paper introduces WildFit, a novel approach that reconciles the conflicting goals of achieving high domain generalization performance and ensuring efficient inference for camera trap applications. WildFit leverages continuous background-aware model fine-tuning to deploy ML models tailored to the current location and time window, allowing it to maintain robust classification accuracy in the new environment without requiring significant computational resources. This is achieved by background-aware data synthesis, which generates training images representing the new domain by blending background images with animal images from the source domain. We further enhance fine-tuning effectiveness through background drift detection and class distribution drift detection, which optimize the quality of synthesized data and improve generalization performance. Our extensive evaluation across multiple camera trap datasets demonstrates that WildFit achieves significant improvements in classification accuracy and computational efficiency compared to traditional approaches.","sentences":["Wildlife monitoring via camera traps has become an essential tool in ecology, but the deployment of machine learning models for on-device animal classification faces significant challenges due to domain shifts and resource constraints.","This paper introduces WildFit, a novel approach that reconciles the conflicting goals of achieving high domain generalization performance and ensuring efficient inference for camera trap applications.","WildFit leverages continuous background-aware model fine-tuning to deploy ML models tailored to the current location and time window, allowing it to maintain robust classification accuracy in the new environment without requiring significant computational resources.","This is achieved by background-aware data synthesis, which generates training images representing the new domain by blending background images with animal images from the source domain.","We further enhance fine-tuning effectiveness through background drift detection and class distribution drift detection, which optimize the quality of synthesized data and improve generalization performance.","Our extensive evaluation across multiple camera trap datasets demonstrates that WildFit achieves significant improvements in classification accuracy and computational efficiency compared to traditional approaches."],"url":"http://arxiv.org/abs/2409.07796v1"}
{"created":"2024-09-12 06:53:50","title":"Efficient Learning of Balanced Signed Graphs via Iterative Linear Programming","abstract":"Signed graphs are equipped with both positive and negative edge weights, encoding pairwise correlations as well as anti-correlations in data. A balanced signed graph has no cycles of odd number of negative edges. Laplacian of a balanced signed graph has eigenvectors that map simply to ones in a similarity-transformed positive graph Laplacian, thus enabling reuse of well-studied spectral filters designed for positive graphs. We propose a fast method to learn a balanced signed graph Laplacian directly from data. Specifically, for each node $i$, to determine its polarity $\\beta_i \\in \\{-1,1\\}$ and edge weights $\\{w_{i,j}\\}_{j=1}^N$, we extend a sparse inverse covariance formulation based on linear programming (LP) called CLIME, by adding linear constraints to enforce ``consistent\" signs of edge weights $\\{w_{i,j}\\}_{j=1}^N$ with the polarities of connected nodes -- i.e., positive/negative edges connect nodes of same/opposing polarities. For each LP, we adapt projections on convex set (POCS) to determine a suitable CLIME parameter $\\rho > 0$ that guarantees LP feasibility. We solve the resulting LP via an off-the-shelf LP solver in $\\mathcal{O}(N^{2.055})$. Experiments on synthetic and real-world datasets show that our balanced graph learning method outperforms competing methods and enables the use of spectral filters and graph convolutional networks (GCNs) designed for positive graphs on signed graphs.","sentences":["Signed graphs are equipped with both positive and negative edge weights, encoding pairwise correlations as well as anti-correlations in data.","A balanced signed graph has no cycles of odd number of negative edges.","Laplacian of a balanced signed graph has eigenvectors that map simply to ones in a similarity-transformed positive graph Laplacian, thus enabling reuse of well-studied spectral filters designed for positive graphs.","We propose a fast method to learn a balanced signed graph Laplacian directly from data.","Specifically, for each node $i$, to determine its polarity $\\beta_i \\in \\{-1,1\\}$ and edge weights $\\{w_{i,j}\\}_{j=1}^N$, we extend a sparse inverse covariance formulation based on linear programming (LP) called CLIME, by adding linear constraints to enforce ``consistent\" signs of edge weights $\\{w_{i,j}\\}_{j=1}^N$ with the polarities of connected nodes -- i.e., positive/negative edges connect nodes of same/opposing polarities.","For each LP, we adapt projections on convex set (POCS) to determine a suitable CLIME parameter $\\rho > 0$ that guarantees LP feasibility.","We solve the resulting LP via an off-the-shelf LP solver in $\\mathcal{O}(N^{2.055})$. Experiments on synthetic and real-world datasets show that our balanced graph learning method outperforms competing methods and enables the use of spectral filters and graph convolutional networks (GCNs) designed for positive graphs on signed graphs."],"url":"http://arxiv.org/abs/2409.07794v1"}
{"created":"2024-09-12 06:52:46","title":"Lagrange Duality and Compound Multi-Attention Transformer for Semi-Supervised Medical Image Segmentation","abstract":"Medical image segmentation, a critical application of semantic segmentation in healthcare, has seen significant advancements through specialized computer vision techniques. While deep learning-based medical image segmentation is essential for assisting in medical diagnosis, the lack of diverse training data causes the long-tail problem. Moreover, most previous hybrid CNN-ViT architectures have limited ability to combine various attentions in different layers of the Convolutional Neural Network. To address these issues, we propose a Lagrange Duality Consistency (LDC) Loss, integrated with Boundary-Aware Contrastive Loss, as the overall training objective for semi-supervised learning to mitigate the long-tail problem. Additionally, we introduce CMAformer, a novel network that synergizes the strengths of ResUNet and Transformer. The cross-attention block in CMAformer effectively integrates spatial attention and channel attention for multi-scale feature fusion. Overall, our results indicate that CMAformer, combined with the feature fusion framework and the new consistency loss, demonstrates strong complementarity in semi-supervised learning ensembles. We achieve state-of-the-art results on multiple public medical image datasets. Example code are available at: \\url{https://github.com/lzeeorno/Lagrange-Duality-and-CMAformer}.","sentences":["Medical image segmentation, a critical application of semantic segmentation in healthcare, has seen significant advancements through specialized computer vision techniques.","While deep learning-based medical image segmentation is essential for assisting in medical diagnosis, the lack of diverse training data causes the long-tail problem.","Moreover, most previous hybrid CNN-ViT architectures have limited ability to combine various attentions in different layers of the Convolutional Neural Network.","To address these issues, we propose a Lagrange Duality Consistency (LDC) Loss, integrated with Boundary-Aware Contrastive Loss, as the overall training objective for semi-supervised learning to mitigate the long-tail problem.","Additionally, we introduce CMAformer, a novel network that synergizes the strengths of ResUNet and Transformer.","The cross-attention block in CMAformer effectively integrates spatial attention and channel attention for multi-scale feature fusion.","Overall, our results indicate that CMAformer, combined with the feature fusion framework and the new consistency loss, demonstrates strong complementarity in semi-supervised learning ensembles.","We achieve state-of-the-art results on multiple public medical image datasets.","Example code are available at: \\url{https://github.com/lzeeorno/Lagrange-Duality-and-CMAformer}."],"url":"http://arxiv.org/abs/2409.07793v1"}
{"created":"2024-09-12 06:50:45","title":"Full-text Error Correction for Chinese Speech Recognition with Large Language Model","abstract":"Large Language Models (LLMs) have demonstrated substantial potential for error correction in Automatic Speech Recognition (ASR). However, most research focuses on utterances from short-duration speech recordings, which are the predominant form of speech data for supervised ASR training. This paper investigates the effectiveness of LLMs for error correction in full-text generated by ASR systems from longer speech recordings, such as transcripts from podcasts, news broadcasts, and meetings. First, we develop a Chinese dataset for full-text error correction, named ChFT, utilizing a pipeline that involves text-to-speech synthesis, ASR, and error-correction pair extractor. This dataset enables us to correct errors across contexts, including both full-text and segment, and to address a broader range of error types, such as punctuation restoration and inverse text normalization, thus making the correction process comprehensive. Second, we fine-tune a pre-trained LLM on the constructed dataset using a diverse set of prompts and target formats, and evaluate its performance on full-text error correction. Specifically, we design prompts based on full-text and segment, considering various output formats, such as directly corrected text and JSON-based error-correction pairs. Through various test settings, including homogeneous, up-to-date, and hard test sets, we find that the fine-tuned LLMs perform well in the full-text setting with different prompts, each presenting its own strengths and weaknesses. This establishes a promising baseline for further research. The dataset is available on the website.","sentences":["Large Language Models (LLMs) have demonstrated substantial potential for error correction in Automatic Speech Recognition (ASR).","However, most research focuses on utterances from short-duration speech recordings, which are the predominant form of speech data for supervised ASR training.","This paper investigates the effectiveness of LLMs for error correction in full-text generated by ASR systems from longer speech recordings, such as transcripts from podcasts, news broadcasts, and meetings.","First, we develop a Chinese dataset for full-text error correction, named ChFT, utilizing a pipeline that involves text-to-speech synthesis, ASR, and error-correction pair extractor.","This dataset enables us to correct errors across contexts, including both full-text and segment, and to address a broader range of error types, such as punctuation restoration and inverse text normalization, thus making the correction process comprehensive.","Second, we fine-tune a pre-trained LLM on the constructed dataset using a diverse set of prompts and target formats, and evaluate its performance on full-text error correction.","Specifically, we design prompts based on full-text and segment, considering various output formats, such as directly corrected text and JSON-based error-correction pairs.","Through various test settings, including homogeneous, up-to-date, and hard test sets, we find that the fine-tuned LLMs perform well in the full-text setting with different prompts, each presenting its own strengths and weaknesses.","This establishes a promising baseline for further research.","The dataset is available on the website."],"url":"http://arxiv.org/abs/2409.07790v1"}
{"created":"2024-09-12 06:13:07","title":"PDC-FRS: Privacy-preserving Data Contribution for Federated Recommender System","abstract":"Federated recommender systems (FedRecs) have emerged as a popular research direction for protecting users' privacy in on-device recommendations. In FedRecs, users keep their data locally and only contribute their local collaborative information by uploading model parameters to a central server. While this rigid framework protects users' raw data during training, it severely compromises the recommendation model's performance due to the following reasons: (1) Due to the power law distribution nature of user behavior data, individual users have few data points to train a recommendation model, resulting in uploaded model updates that may be far from optimal; (2) As each user's uploaded parameters are learned from local data, which lacks global collaborative information, relying solely on parameter aggregation methods such as FedAvg to fuse global collaborative information may be suboptimal. To bridge this performance gap, we propose a novel federated recommendation framework, PDC-FRS. Specifically, we design a privacy-preserving data contribution mechanism that allows users to share their data with a differential privacy guarantee. Based on the shared but perturbed data, an auxiliary model is trained in parallel with the original federated recommendation process. This auxiliary model enhances FedRec by augmenting each user's local dataset and integrating global collaborative information. To demonstrate the effectiveness of PDC-FRS, we conduct extensive experiments on two widely used recommendation datasets. The empirical results showcase the superiority of PDC-FRS compared to baseline methods.","sentences":["Federated recommender systems (FedRecs) have emerged as a popular research direction for protecting users' privacy in on-device recommendations.","In FedRecs, users keep their data locally and only contribute their local collaborative information by uploading model parameters to a central server.","While this rigid framework protects users' raw data during training, it severely compromises the recommendation model's performance due to the following reasons: (1) Due to the power law distribution nature of user behavior data, individual users have few data points to train a recommendation model, resulting in uploaded model updates that may be far from optimal; (2) As each user's uploaded parameters are learned from local data, which lacks global collaborative information, relying solely on parameter aggregation methods such as FedAvg to fuse global collaborative information may be suboptimal.","To bridge this performance gap, we propose a novel federated recommendation framework, PDC-FRS.","Specifically, we design a privacy-preserving data contribution mechanism that allows users to share their data with a differential privacy guarantee.","Based on the shared but perturbed data, an auxiliary model is trained in parallel with the original federated recommendation process.","This auxiliary model enhances FedRec by augmenting each user's local dataset and integrating global collaborative information.","To demonstrate the effectiveness of PDC-FRS, we conduct extensive experiments on two widely used recommendation datasets.","The empirical results showcase the superiority of PDC-FRS compared to baseline methods."],"url":"http://arxiv.org/abs/2409.07773v1"}
{"created":"2024-09-12 05:36:40","title":"Reimagining Linear Probing: Kolmogorov-Arnold Networks in Transfer Learning","abstract":"This paper introduces Kolmogorov-Arnold Networks (KAN) as an enhancement to the traditional linear probing method in transfer learning. Linear probing, often applied to the final layer of pre-trained models, is limited by its inability to model complex relationships in data. To address this, we propose substituting the linear probing layer with KAN, which leverages spline-based representations to approximate intricate functions. In this study, we integrate KAN with a ResNet-50 model pre-trained on ImageNet and evaluate its performance on the CIFAR-10 dataset. We perform a systematic hyperparameter search, focusing on grid size and spline degree (k), to optimize KAN's flexibility and accuracy. Our results demonstrate that KAN consistently outperforms traditional linear probing, achieving significant improvements in accuracy and generalization across a range of configurations. These findings indicate that KAN offers a more powerful and adaptable alternative to conventional linear probing techniques in transfer learning.","sentences":["This paper introduces Kolmogorov-Arnold Networks (KAN) as an enhancement to the traditional linear probing method in transfer learning.","Linear probing, often applied to the final layer of pre-trained models, is limited by its inability to model complex relationships in data.","To address this, we propose substituting the linear probing layer with KAN, which leverages spline-based representations to approximate intricate functions.","In this study, we integrate KAN with a ResNet-50 model pre-trained on ImageNet and evaluate its performance on the CIFAR-10 dataset.","We perform a systematic hyperparameter search, focusing on grid size and spline degree (k), to optimize KAN's flexibility and accuracy.","Our results demonstrate that KAN consistently outperforms traditional linear probing, achieving significant improvements in accuracy and generalization across a range of configurations.","These findings indicate that KAN offers a more powerful and adaptable alternative to conventional linear probing techniques in transfer learning."],"url":"http://arxiv.org/abs/2409.07763v1"}
{"created":"2024-09-12 05:35:37","title":"Exploring Kolmogorov-Arnold networks for realistic image sharpness assessment","abstract":"Score prediction is crucial in realistic image sharpness assessment after informative features are collected. Recently, Kolmogorov-Arnold networks (KANs) have been developed and witnessed remarkable success in data fitting. This study presents Taylor series based KAN (TaylorKAN). Then, different KANs are explored on four realistic image databases (BID2011, CID2013, CLIVE, and KonIQ-10k) for score prediction by using 15 mid-level features and 2048 high-level features. When setting support vector regression as the baseline, experimental results indicate KANs are generally better or competitive, TaylorKAN is the best on three databases using mid-level feature input, while KANs are inferior on CLIVE when high-level features are used. This is the first study that explores KANs for image quality assessment. It sheds lights on how to select and improve KANs on related tasks.","sentences":["Score prediction is crucial in realistic image sharpness assessment after informative features are collected.","Recently, Kolmogorov-Arnold networks (KANs) have been developed and witnessed remarkable success in data fitting.","This study presents Taylor series based KAN (TaylorKAN).","Then, different KANs are explored on four realistic image databases (BID2011, CID2013, CLIVE, and KonIQ-10k) for score prediction by using 15 mid-level features and 2048 high-level features.","When setting support vector regression as the baseline, experimental results indicate KANs are generally better or competitive, TaylorKAN is the best on three databases using mid-level feature input, while KANs are inferior on CLIVE when high-level features are used.","This is the first study that explores KANs for image quality assessment.","It sheds lights on how to select and improve KANs on related tasks."],"url":"http://arxiv.org/abs/2409.07762v1"}
{"created":"2024-09-12 05:22:45","title":"From Uncertainty to Clarity: Uncertainty-Guided Class-Incremental Learning for Limited Biomedical Samples via Semantic Expansion","abstract":"In real-world clinical settings, data distributions evolve over time, with a continuous influx of new, limited disease cases. Therefore, class incremental learning is of great significance, i.e., deep learning models are required to learn new class knowledge while maintaining accurate recognition of previous diseases. However, traditional deep neural networks often suffer from severe forgetting of prior knowledge when adapting to new data unless trained from scratch, which undesirably costs much time and computational burden. Additionally, the sample sizes for different diseases can be highly imbalanced, with newly emerging diseases typically having much fewer instances, consequently causing the classification bias. To tackle these challenges, we are the first to propose a class-incremental learning method under limited samples in the biomedical field. First, we propose a novel cumulative entropy prediction module to measure the uncertainty of the samples, of which the most uncertain samples are stored in a memory bank as exemplars for the model's later review. Furthermore, we theoretically demonstrate its effectiveness in measuring uncertainty. Second, we developed a fine-grained semantic expansion module through various augmentations, leading to more compact distributions within the feature space and creating sufficient room for generalization to new classes. Besides, a cosine classifier is utilized to mitigate classification bias caused by imbalanced datasets. Across four imbalanced data distributions over two datasets, our method achieves optimal performance, surpassing state-of-the-art methods by as much as 53.54% in accuracy.","sentences":["In real-world clinical settings, data distributions evolve over time, with a continuous influx of new, limited disease cases.","Therefore, class incremental learning is of great significance, i.e., deep learning models are required to learn new class knowledge while maintaining accurate recognition of previous diseases.","However, traditional deep neural networks often suffer from severe forgetting of prior knowledge when adapting to new data unless trained from scratch, which undesirably costs much time and computational burden.","Additionally, the sample sizes for different diseases can be highly imbalanced, with newly emerging diseases typically having much fewer instances, consequently causing the classification bias.","To tackle these challenges, we are the first to propose a class-incremental learning method under limited samples in the biomedical field.","First, we propose a novel cumulative entropy prediction module to measure the uncertainty of the samples, of which the most uncertain samples are stored in a memory bank as exemplars for the model's later review.","Furthermore, we theoretically demonstrate its effectiveness in measuring uncertainty.","Second, we developed a fine-grained semantic expansion module through various augmentations, leading to more compact distributions within the feature space and creating sufficient room for generalization to new classes.","Besides, a cosine classifier is utilized to mitigate classification bias caused by imbalanced datasets.","Across four imbalanced data distributions over two datasets, our method achieves optimal performance, surpassing state-of-the-art methods by as much as 53.54% in accuracy."],"url":"http://arxiv.org/abs/2409.07757v1"}
{"created":"2024-09-12 05:18:57","title":"DiTAS: Quantizing Diffusion Transformers via Enhanced Activation Smoothing","abstract":"Diffusion Transformers (DiTs) have recently attracted significant interest from both industry and academia due to their enhanced capabilities in visual generation, surpassing the performance of traditional diffusion models that employ U-Net. However, the improved performance of DiTs comes at the expense of higher parameter counts and implementation costs, which significantly limits their deployment on resource-constrained devices like mobile phones. We propose DiTAS, a data-free post-training quantization (PTQ) method for efficient DiT inference. DiTAS relies on the proposed temporal-aggregated smoothing techniques to mitigate the impact of the channel-wise outliers within the input activations, leading to much lower quantization error under extremely low bitwidth. To further enhance the performance of the quantized DiT, we adopt the layer-wise grid search strategy to optimize the smoothing factor. Experimental results demonstrate that our approach enables 4-bit weight, 8-bit activation (W4A8) quantization for DiTs while maintaining comparable performance as the full-precision model.","sentences":["Diffusion Transformers (DiTs) have recently attracted significant interest from both industry and academia due to their enhanced capabilities in visual generation, surpassing the performance of traditional diffusion models that employ U-Net.","However, the improved performance of DiTs comes at the expense of higher parameter counts and implementation costs, which significantly limits their deployment on resource-constrained devices like mobile phones.","We propose DiTAS, a data-free post-training quantization (PTQ) method for efficient DiT inference.","DiTAS relies on the proposed temporal-aggregated smoothing techniques to mitigate the impact of the channel-wise outliers within the input activations, leading to much lower quantization error under extremely low bitwidth.","To further enhance the performance of the quantized DiT, we adopt the layer-wise grid search strategy to optimize the smoothing factor.","Experimental results demonstrate that our approach enables 4-bit weight, 8-bit activation (W4A8) quantization for DiTs while maintaining comparable performance as the full-precision model."],"url":"http://arxiv.org/abs/2409.07756v1"}
{"created":"2024-09-12 04:51:27","title":"Efficient Privacy-Preserving KAN Inference Using Homomorphic Encryption","abstract":"The recently proposed Kolmogorov-Arnold Networks (KANs) offer enhanced interpretability and greater model expressiveness. However, KANs also present challenges related to privacy leakage during inference. Homomorphic encryption (HE) facilitates privacy-preserving inference for deep learning models, enabling resource-limited users to benefit from deep learning services while ensuring data security. Yet, the complex structure of KANs, incorporating nonlinear elements like the SiLU activation function and B-spline functions, renders existing privacy-preserving inference techniques inadequate. To address this issue, we propose an accurate and efficient privacy-preserving inference scheme tailored for KANs. Our approach introduces a task-specific polynomial approximation for the SiLU activation function, dynamically adjusting the approximation range to ensure high accuracy on real-world datasets. Additionally, we develop an efficient method for computing B-spline functions within the HE domain, leveraging techniques such as repeat packing, lazy combination, and comparison functions. We evaluate the effectiveness of our privacy-preserving KAN inference scheme on both symbolic formula evaluation and image classification. The experimental results show that our model achieves accuracy comparable to plaintext KANs across various datasets and outperforms plaintext MLPs. Additionally, on the CIFAR-10 dataset, our inference latency achieves over 7 times speedup compared to the naive method.","sentences":["The recently proposed Kolmogorov-Arnold Networks (KANs) offer enhanced interpretability and greater model expressiveness.","However, KANs also present challenges related to privacy leakage during inference.","Homomorphic encryption (HE) facilitates privacy-preserving inference for deep learning models, enabling resource-limited users to benefit from deep learning services while ensuring data security.","Yet, the complex structure of KANs, incorporating nonlinear elements like the SiLU activation function and B-spline functions, renders existing privacy-preserving inference techniques inadequate.","To address this issue, we propose an accurate and efficient privacy-preserving inference scheme tailored for KANs.","Our approach introduces a task-specific polynomial approximation for the SiLU activation function, dynamically adjusting the approximation range to ensure high accuracy on real-world datasets.","Additionally, we develop an efficient method for computing B-spline functions within the HE domain, leveraging techniques such as repeat packing, lazy combination, and comparison functions.","We evaluate the effectiveness of our privacy-preserving KAN inference scheme on both symbolic formula evaluation and image classification.","The experimental results show that our model achieves accuracy comparable to plaintext KANs across various datasets and outperforms plaintext MLPs.","Additionally, on the CIFAR-10 dataset, our inference latency achieves over 7 times speedup compared to the naive method."],"url":"http://arxiv.org/abs/2409.07751v1"}
{"created":"2024-09-12 04:36:50","title":"Learning Brain Tumor Representation in 3D High-Resolution MR Images via Interpretable State Space Models","abstract":"Learning meaningful and interpretable representations from high-dimensional volumetric magnetic resonance (MR) images is essential for advancing personalized medicine. While Vision Transformers (ViTs) have shown promise in handling image data, their application to 3D multi-contrast MR images faces challenges due to computational complexity and interpretability. To address this, we propose a novel state-space-model (SSM)-based masked autoencoder which scales ViT-like models to handle high-resolution data effectively while also enhancing the interpretability of learned representations. We propose a latent-to-spatial mapping technique that enables direct visualization of how latent features correspond to specific regions in the input volumes in the context of SSM. We validate our method on two key neuro-oncology tasks: identification of isocitrate dehydrogenase mutation status and 1p/19q co-deletion classification, achieving state-of-the-art accuracy. Our results highlight the potential of SSM-based self-supervised learning to transform radiomics analysis by combining efficiency and interpretability.","sentences":["Learning meaningful and interpretable representations from high-dimensional volumetric magnetic resonance (MR) images is essential for advancing personalized medicine.","While Vision Transformers (ViTs) have shown promise in handling image data, their application to 3D multi-contrast MR images faces challenges due to computational complexity and interpretability.","To address this, we propose a novel state-space-model (SSM)-based masked autoencoder which scales ViT-like models to handle high-resolution data effectively while also enhancing the interpretability of learned representations.","We propose a latent-to-spatial mapping technique that enables direct visualization of how latent features correspond to specific regions in the input volumes in the context of SSM.","We validate our method on two key neuro-oncology tasks: identification of isocitrate dehydrogenase mutation status and 1p/19q co-deletion classification, achieving state-of-the-art accuracy.","Our results highlight the potential of SSM-based self-supervised learning to transform radiomics analysis by combining efficiency and interpretability."],"url":"http://arxiv.org/abs/2409.07746v1"}
{"created":"2024-09-12 03:59:15","title":"Transfer Learning Applied to Computer Vision Problems: Survey on Current Progress, Limitations, and Opportunities","abstract":"The field of Computer Vision (CV) has faced challenges. Initially, it relied on handcrafted features and rule-based algorithms, resulting in limited accuracy. The introduction of machine learning (ML) has brought progress, particularly Transfer Learning (TL), which addresses various CV problems by reusing pre-trained models. TL requires less data and computing while delivering nearly equal accuracy, making it a prominent technique in the CV landscape. Our research focuses on TL development and how CV applications use it to solve real-world problems. We discuss recent developments, limitations, and opportunities.","sentences":["The field of Computer Vision (CV) has faced challenges.","Initially, it relied on handcrafted features and rule-based algorithms, resulting in limited accuracy.","The introduction of machine learning (ML) has brought progress, particularly Transfer Learning (TL), which addresses various CV problems by reusing pre-trained models.","TL requires less data and computing while delivering nearly equal accuracy, making it a prominent technique in the CV landscape.","Our research focuses on TL development and how CV applications use it to solve real-world problems.","We discuss recent developments, limitations, and opportunities."],"url":"http://arxiv.org/abs/2409.07736v1"}
{"created":"2024-09-12 03:44:30","title":"DFDG: Data-Free Dual-Generator Adversarial Distillation for One-Shot Federated Learning","abstract":"Federated Learning (FL) is a distributed machine learning scheme in which clients jointly participate in the collaborative training of a global model by sharing model information rather than their private datasets. In light of concerns associated with communication and privacy, one-shot FL with a single communication round has emerged as a de facto promising solution. However, existing one-shot FL methods either require public datasets, focus on model homogeneous settings, or distill limited knowledge from local models, making it difficult or even impractical to train a robust global model. To address these limitations, we propose a new data-free dual-generator adversarial distillation method (namely DFDG) for one-shot FL, which can explore a broader local models' training space via training dual generators. DFDG is executed in an adversarial manner and comprises two parts: dual-generator training and dual-model distillation. In dual-generator training, we delve into each generator concerning fidelity, transferability and diversity to ensure its utility, and additionally tailor the cross-divergence loss to lessen the overlap of dual generators' output spaces. In dual-model distillation, the trained dual generators work together to provide the training data for updates of the global model. At last, our extensive experiments on various image classification tasks show that DFDG achieves significant performance gains in accuracy compared to SOTA baselines.","sentences":["Federated Learning (FL) is a distributed machine learning scheme in which clients jointly participate in the collaborative training of a global model by sharing model information rather than their private datasets.","In light of concerns associated with communication and privacy, one-shot FL with a single communication round has emerged as a de facto promising solution.","However, existing one-shot FL methods either require public datasets, focus on model homogeneous settings, or distill limited knowledge from local models, making it difficult or even impractical to train a robust global model.","To address these limitations, we propose a new data-free dual-generator adversarial distillation method (namely DFDG) for one-shot FL, which can explore a broader local models' training space via training dual generators.","DFDG is executed in an adversarial manner and comprises two parts: dual-generator training and dual-model distillation.","In dual-generator training, we delve into each generator concerning fidelity, transferability and diversity to ensure its utility, and additionally tailor the cross-divergence loss to lessen the overlap of dual generators' output spaces.","In dual-model distillation, the trained dual generators work together to provide the training data for updates of the global model.","At last, our extensive experiments on various image classification tasks show that DFDG achieves significant performance gains in accuracy compared to SOTA baselines."],"url":"http://arxiv.org/abs/2409.07734v1"}
{"created":"2024-09-12 03:41:39","title":"Large Language Models are Pattern Matchers: Editing Semi-Structured and Structured Documents with ChatGPT","abstract":"Large Language Models (LLMs) offer numerous applications, the full extent of which is not yet understood. This paper investigates if LLMs can be applied for editing structured and semi-structured documents with minimal effort. Using a qualitative research approach, we conduct two case studies with ChatGPT and thoroughly analyze the results. Our experiments indicate that LLMs can effectively edit structured and semi-structured documents when provided with basic, straightforward prompts. ChatGPT demonstrates a strong ability to recognize and process the structure of annotated documents. This suggests that explicitly structuring tasks and data in prompts might enhance an LLM's ability to understand and solve tasks. Furthermore, the experiments also reveal impressive pattern matching skills in ChatGPT. This observation deserves further investigation, as it may contribute to understanding the processes leading to hallucinations in LLMs.","sentences":["Large Language Models (LLMs) offer numerous applications, the full extent of which is not yet understood.","This paper investigates if LLMs can be applied for editing structured and semi-structured documents with minimal effort.","Using a qualitative research approach, we conduct two case studies with ChatGPT and thoroughly analyze the results.","Our experiments indicate that LLMs can effectively edit structured and semi-structured documents when provided with basic, straightforward prompts.","ChatGPT demonstrates a strong ability to recognize and process the structure of annotated documents.","This suggests that explicitly structuring tasks and data in prompts might enhance an LLM's ability to understand and solve tasks.","Furthermore, the experiments also reveal impressive pattern matching skills in ChatGPT.","This observation deserves further investigation, as it may contribute to understanding the processes leading to hallucinations in LLMs."],"url":"http://arxiv.org/abs/2409.07732v1"}
{"created":"2024-09-12 03:09:05","title":"GRE^2-MDCL: Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning","abstract":"Graph representation learning has emerged as a powerful tool for preserving graph topology when mapping nodes to vector representations, enabling various downstream tasks such as node classification and community detection. However, most current graph neural network models face the challenge of requiring extensive labeled data, which limits their practical applicability in real-world scenarios where labeled data is scarce. To address this challenge, researchers have explored Graph Contrastive Learning (GCL), which leverages enhanced graph data and contrastive learning techniques. While promising, existing GCL methods often struggle with effectively capturing both local and global graph structures, and balancing the trade-off between nodelevel and graph-level representations. In this work, we propose Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning (GRE2-MDCL). Our model introduces a novel triple network architecture with a multi-head attention GNN as the core. GRE2-MDCL first globally and locally augments the input graph using SVD and LAGNN techniques. It then constructs a multidimensional contrastive loss, incorporating cross-network, cross-view, and neighbor contrast, to optimize the model. Extensive experiments on benchmark datasets Cora, Citeseer, and PubMed demonstrate that GRE2-MDCL achieves state-of-the-art performance, with average accuracies of 82.5%, 72.5%, and 81.6% respectively. Visualizations further show tighter intra-cluster aggregation and clearer inter-cluster boundaries, highlighting the effectiveness of our framework in improving upon baseline GCL models.","sentences":["Graph representation learning has emerged as a powerful tool for preserving graph topology when mapping nodes to vector representations, enabling various downstream tasks such as node classification and community detection.","However, most current graph neural network models face the challenge of requiring extensive labeled data, which limits their practical applicability in real-world scenarios where labeled data is scarce.","To address this challenge, researchers have explored Graph Contrastive Learning (GCL), which leverages enhanced graph data and contrastive learning techniques.","While promising, existing GCL methods often struggle with effectively capturing both local and global graph structures, and balancing the trade-off between nodelevel and graph-level representations.","In this work, we propose Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning (GRE2-MDCL).","Our model introduces a novel triple network architecture with a multi-head attention GNN as the core.","GRE2-MDCL first globally and locally augments the input graph using SVD and LAGNN techniques.","It then constructs a multidimensional contrastive loss, incorporating cross-network, cross-view, and neighbor contrast, to optimize the model.","Extensive experiments on benchmark datasets Cora, Citeseer, and PubMed demonstrate that GRE2-MDCL achieves state-of-the-art performance, with average accuracies of 82.5%, 72.5%, and 81.6% respectively.","Visualizations further show tighter intra-cluster aggregation and clearer inter-cluster boundaries, highlighting the effectiveness of our framework in improving upon baseline GCL models."],"url":"http://arxiv.org/abs/2409.07725v1"}
{"created":"2024-09-12 03:02:52","title":"Keeping it Authentic: The Social Footprint of the Trolls Network","abstract":"In 2016, a network of social media accounts animated by Russian operatives attempted to divert political discourse within the American public around the presidential elections. This was a coordinated effort, part of a Russian-led complex information operation. Utilizing the anonymity and outreach of social media platforms Russian operatives created an online astroturf that is in direct contact with regular Americans, promoting Russian agenda and goals. The elusiveness of this type of adversarial approach rendered security agencies helpless, stressing the unique challenges this type of intervention presents. Building on existing scholarship on the functions within influence networks on social media, we suggest a new approach to map those types of operations. We argue that pretending to be legitimate social actors obliges the network to adhere to social expectations, leaving a social footprint. To test the robustness of this social footprint we train artificial intelligence to identify it and create a predictive model. We use Twitter data identified as part of the Russian influence network for training the artificial intelligence and to test the prediction. Our model attains 88% prediction accuracy for the test set. Testing our prediction on two additional models results in 90.7% and 90.5% accuracy, validating our model. The predictive and validation results suggest that building a machine learning model around social functions within the Russian influence network can be used to map its actors and functions.","sentences":["In 2016, a network of social media accounts animated by Russian operatives attempted to divert political discourse within the American public around the presidential elections.","This was a coordinated effort, part of a Russian-led complex information operation.","Utilizing the anonymity and outreach of social media platforms Russian operatives created an online astroturf that is in direct contact with regular Americans, promoting Russian agenda and goals.","The elusiveness of this type of adversarial approach rendered security agencies helpless, stressing the unique challenges this type of intervention presents.","Building on existing scholarship on the functions within influence networks on social media, we suggest a new approach to map those types of operations.","We argue that pretending to be legitimate social actors obliges the network to adhere to social expectations, leaving a social footprint.","To test the robustness of this social footprint we train artificial intelligence to identify it and create a predictive model.","We use Twitter data identified as part of the Russian influence network for training the artificial intelligence and to test the prediction.","Our model attains 88% prediction accuracy for the test set.","Testing our prediction on two additional models results in 90.7% and 90.5% accuracy, validating our model.","The predictive and validation results suggest that building a machine learning model around social functions within the Russian influence network can be used to map its actors and functions."],"url":"http://arxiv.org/abs/2409.07720v1"}
{"created":"2024-09-12 02:59:35","title":"Static Pricing for Single Sample Multi-unit Prophet Inequalities","abstract":"In this paper, we study $k$-unit single sample prophet inequalities. A seller has $k$ identical, indivisible items to sell. A sequence of buyers arrive one-by-one, with each buyer's private value for the item, $X_i$, revealed to the seller when they arrive. While the seller is unaware of the distribution from which $X_i$ is drawn, they have access to a single sample, $Y_i$ drawn from the same distribution as $X_i$. What strategies can the seller adopt so as to maximize social welfare?   Previous work has demonstrated that when $k = 1$, if the seller sets a price equal to the maximum of the samples, they can achieve a competitive ratio of $\\frac{1}{2}$ of the social welfare, and recently Pashkovich and Sayutina established an analogous result for $k = 2$. In this paper, we prove that for $k \\geq 3$, setting a (static) price equal to the $k^{\\text{th}}$ largest sample also obtains a competitive ratio of $\\frac{1}{2}$, resolving a conjecture Pashkovich and Sayutina pose.   We then consider the situation where $k$ is large. We demonstrate that setting a price equal to the $(k-\\sqrt{2k\\log k})^{\\text{th}}$ largest sample obtains a competitive ratio of $1 - \\sqrt{\\frac{2\\log k}{k}} - o\\left(\\sqrt{\\frac{\\log k}{k}}\\right)$, and that this is the optimal possible ratio achievable with a static pricing scheme that sets one of the samples as a price.","sentences":["In this paper, we study $k$-unit single sample prophet inequalities.","A seller has $k$ identical, indivisible items to sell.","A sequence of buyers arrive one-by-one, with each buyer's private value for the item, $X_i$, revealed to the seller when they arrive.","While the seller is unaware of the distribution from which $X_i$ is drawn, they have access to a single sample, $Y_i$ drawn from the same distribution as $X_i$. What strategies can the seller adopt so as to maximize social welfare?   ","Previous work has demonstrated that when $k = 1$, if the seller sets a price equal to the maximum of the samples, they can achieve a competitive ratio of $\\frac{1}{2}$ of the social welfare, and recently Pashkovich and Sayutina established an analogous result for $k = 2$.","In this paper, we prove that for $k \\geq 3$, setting a (static) price equal to the $k^{\\text{th}}$ largest sample also obtains a competitive ratio of $\\frac{1}{2}$, resolving a conjecture Pashkovich and Sayutina pose.   ","We then consider the situation where $k$ is large.","We demonstrate that setting a price equal to the $(k-\\sqrt{2k\\log k})^{\\text{th}}$ largest sample obtains a competitive ratio of $1 - \\sqrt{\\frac{2\\log k}{k}} - o\\left(\\sqrt{\\frac{\\log k}{k}}\\right)$, and that this is the optimal possible ratio achievable with a static pricing scheme that sets one of the samples as a price."],"url":"http://arxiv.org/abs/2409.07719v1"}
{"created":"2024-09-12 02:40:28","title":"Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice","abstract":"Generative AI models, such as the GPT and Llama series, have significant potential to assist laypeople in answering legal questions. However, little prior work focuses on the data sourcing, inference, and evaluation of these models in the context of laypersons. To this end, we propose a human-centric legal NLP pipeline, covering data sourcing, inference, and evaluation. We introduce and release a dataset, LegalQA, with real and specific legal questions spanning from employment law to criminal law, corresponding answers written by legal experts, and citations for each answer. We develop an automatic evaluation protocol for this dataset, then show that retrieval-augmented generation from only 850 citations in the train set can match or outperform internet-wide retrieval, despite containing 9 orders of magnitude less data. Finally, we propose future directions for open-sourced efforts, which fall behind closed-sourced models.","sentences":["Generative AI models, such as the GPT and Llama series, have significant potential to assist laypeople in answering legal questions.","However, little prior work focuses on the data sourcing, inference, and evaluation of these models in the context of laypersons.","To this end, we propose a human-centric legal NLP pipeline, covering data sourcing, inference, and evaluation.","We introduce and release a dataset, LegalQA, with real and specific legal questions spanning from employment law to criminal law, corresponding answers written by legal experts, and citations for each answer.","We develop an automatic evaluation protocol for this dataset, then show that retrieval-augmented generation from only 850 citations in the train set can match or outperform internet-wide retrieval, despite containing 9 orders of magnitude less data.","Finally, we propose future directions for open-sourced efforts, which fall behind closed-sourced models."],"url":"http://arxiv.org/abs/2409.07713v1"}
{"created":"2024-09-12 02:36:44","title":"Virtual Node Generation for Node Classification in Sparsely-Labeled Graphs","abstract":"In the broader machine learning literature, data-generation methods demonstrate promising results by generating additional informative training examples via augmenting sparse labels. Such methods are less studied in graphs due to the intricate dependencies among nodes in complex topology structures. This paper presents a novel node generation method that infuses a small set of high-quality synthesized nodes into the graph as additional labeled nodes to optimally expand the propagation of labeled information. By simply infusing additional nodes, the framework is orthogonal to the graph learning and downstream classification techniques, and thus is compatible with most popular graph pre-training (self-supervised learning), semi-supervised learning, and meta-learning methods. The contribution lies in designing the generated node set by solving a novel optimization problem. The optimization places the generated nodes in a manner that: (1) minimizes the classification loss to guarantee training accuracy and (2) maximizes label propagation to low-confidence nodes in the downstream task to ensure high-quality propagation. Theoretically, we show that the above dual optimization maximizes the global confidence of node classification. Our Experiments demonstrate statistically significant performance improvements over 14 baselines on 10 publicly available datasets.","sentences":["In the broader machine learning literature, data-generation methods demonstrate promising results by generating additional informative training examples via augmenting sparse labels.","Such methods are less studied in graphs due to the intricate dependencies among nodes in complex topology structures.","This paper presents a novel node generation method that infuses a small set of high-quality synthesized nodes into the graph as additional labeled nodes to optimally expand the propagation of labeled information.","By simply infusing additional nodes, the framework is orthogonal to the graph learning and downstream classification techniques, and thus is compatible with most popular graph pre-training (self-supervised learning), semi-supervised learning, and meta-learning methods.","The contribution lies in designing the generated node set by solving a novel optimization problem.","The optimization places the generated nodes in a manner that: (1) minimizes the classification loss to guarantee training accuracy and (2) maximizes label propagation to low-confidence nodes in the downstream task to ensure high-quality propagation.","Theoretically, we show that the above dual optimization maximizes the global confidence of node classification.","Our Experiments demonstrate statistically significant performance improvements over 14 baselines on 10 publicly available datasets."],"url":"http://arxiv.org/abs/2409.07712v1"}
{"created":"2024-09-12 02:25:41","title":"Harnessing TI Feeds for Exploitation Detection","abstract":"Many organizations rely on Threat Intelligence (TI) feeds to assess the risk associated with security threats. Due to the volume and heterogeneity of data, it is prohibitive to manually analyze the threat information available in different loosely structured TI feeds. Thus, there is a need to develop automated methods to vet and extract actionable information from TI feeds. To this end, we present a machine learning pipeline to automatically detect vulnerability exploitation from TI feeds. We first model threat vocabulary in loosely structured TI feeds using state-of-the-art embedding techniques (Doc2Vec and BERT) and then use it to train a supervised machine learning classifier to detect exploitation of security vulnerabilities. We use our approach to identify exploitation events in 191 different TI feeds. Our longitudinal evaluation shows that it is able to accurately identify exploitation events from TI feeds only using past data for training and even on TI feeds withheld from training. Our proposed approach is useful for a variety of downstream tasks such as data-driven vulnerability risk assessment.","sentences":["Many organizations rely on Threat Intelligence (TI) feeds to assess the risk associated with security threats.","Due to the volume and heterogeneity of data, it is prohibitive to manually analyze the threat information available in different loosely structured TI feeds.","Thus, there is a need to develop automated methods to vet and extract actionable information from TI feeds.","To this end, we present a machine learning pipeline to automatically detect vulnerability exploitation from TI feeds.","We first model threat vocabulary in loosely structured TI feeds using state-of-the-art embedding techniques (Doc2Vec and BERT) and then use it to train a supervised machine learning classifier to detect exploitation of security vulnerabilities.","We use our approach to identify exploitation events in 191 different TI feeds.","Our longitudinal evaluation shows that it is able to accurately identify exploitation events from TI feeds only using past data for training and even on TI feeds withheld from training.","Our proposed approach is useful for a variety of downstream tasks such as data-driven vulnerability risk assessment."],"url":"http://arxiv.org/abs/2409.07709v1"}
{"created":"2024-09-12 02:08:00","title":"DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?","abstract":"Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have demonstrated impressive language/vision reasoning abilities, igniting the recent trend of building agents for targeted applications such as shopping assistants or AI software engineers. Recently, many data science benchmarks have been proposed to investigate their performance in the data science domain. However, existing data science benchmarks still fall short when compared to real-world data science applications due to their simplified settings. To bridge this gap, we introduce DSBench, a comprehensive benchmark designed to evaluate data science agents with realistic tasks. This benchmark includes 466 data analysis tasks and 74 data modeling tasks, sourced from Eloquence and Kaggle competitions. DSBench offers a realistic setting by encompassing long contexts, multimodal task backgrounds, reasoning with large data files and multi-table structures, and performing end-to-end data modeling tasks. Our evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle with most tasks, with the best agent solving only 34.12% of data analysis tasks and achieving a 34.74% Relative Performance Gap (RPG). These findings underscore the need for further advancements in developing more practical, intelligent, and autonomous data science agents.","sentences":["Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have demonstrated impressive language/vision reasoning abilities, igniting the recent trend of building agents for targeted applications such as shopping assistants or AI software engineers.","Recently, many data science benchmarks have been proposed to investigate their performance in the data science domain.","However, existing data science benchmarks still fall short when compared to real-world data science applications due to their simplified settings.","To bridge this gap, we introduce DSBench, a comprehensive benchmark designed to evaluate data science agents with realistic tasks.","This benchmark includes 466 data analysis tasks and 74 data modeling tasks, sourced from Eloquence and Kaggle competitions.","DSBench offers a realistic setting by encompassing long contexts, multimodal task backgrounds, reasoning with large data files and multi-table structures, and performing end-to-end data modeling tasks.","Our evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle with most tasks, with the best agent solving only 34.12% of data analysis tasks and achieving a 34.74% Relative Performance Gap (RPG).","These findings underscore the need for further advancements in developing more practical, intelligent, and autonomous data science agents."],"url":"http://arxiv.org/abs/2409.07703v1"}
{"created":"2024-09-12 01:58:35","title":"Visualization in Motion in Video Games for Different Types of Data","abstract":"We contribute an analysis of situated visualizations in motion in video games for different types of data, with a focus on quantitative and categorical data representations. Video games convey a lot of data to players, to help them succeed in the game. These visualizations frequently move across the screen due to camera changes or because the game elements themselves move. Our ultimate goal is to understand how motion factors affect visualization readability in video games and subsequently the players' performance in the game. We started our work by surveying the characteristics of how motion currently influences which kind of data representations in video games. We conducted a systematic review of 160 visualizations in motion in video games and extracted patterns and considerations regarding was what, and how visualizations currently exhibit motion factors in video games.","sentences":["We contribute an analysis of situated visualizations in motion in video games for different types of data, with a focus on quantitative and categorical data representations.","Video games convey a lot of data to players, to help them succeed in the game.","These visualizations frequently move across the screen due to camera changes or because the game elements themselves move.","Our ultimate goal is to understand how motion factors affect visualization readability in video games and subsequently the players' performance in the game.","We started our work by surveying the characteristics of how motion currently influences which kind of data representations in video games.","We conducted a systematic review of 160 visualizations in motion in video games and extracted patterns and considerations regarding was what, and how visualizations currently exhibit motion factors in video games."],"url":"http://arxiv.org/abs/2409.07696v1"}
{"created":"2024-09-12 01:58:25","title":"Situated Visualization in Motion for Swimming","abstract":"Competitive sports coverage increasingly includes information on athlete or team statistics and records. Sports video coverage has traditionally embedded representations of this data in fixed locations on the screen, but more recently also attached representations to athletes or other targets in motion. These publicly used representations so far have been rather simple and systematic investigations of the research space of embedded visualizations in motion are still missing. Here we report on our preliminary research in the domain of professional and amateur swimming. We analyzed how visualizations are currently added to the coverage of Olympics swimming competitions and then plan to derive a design space for embedded data representations for swimming competitions. We are currently conducting a crowdsourced survey to explore which kind of swimming-related data general audiences are interested in, in order to identify opportunities for additional visualizations to be added to swimming competition coverage.","sentences":["Competitive sports coverage increasingly includes information on athlete or team statistics and records.","Sports video coverage has traditionally embedded representations of this data in fixed locations on the screen, but more recently also attached representations to athletes or other targets in motion.","These publicly used representations so far have been rather simple and systematic investigations of the research space of embedded visualizations in motion are still missing.","Here we report on our preliminary research in the domain of professional and amateur swimming.","We analyzed how visualizations are currently added to the coverage of Olympics swimming competitions and then plan to derive a design space for embedded data representations for swimming competitions.","We are currently conducting a crowdsourced survey to explore which kind of swimming-related data general audiences are interested in, in order to identify opportunities for additional visualizations to be added to swimming competition coverage."],"url":"http://arxiv.org/abs/2409.07695v1"}
{"created":"2024-09-12 01:58:06","title":"Learn from Balance: Rectifying Knowledge Transfer for Long-Tailed Scenarios","abstract":"Knowledge Distillation (KD) transfers knowledge from a large pre-trained teacher network to a compact and efficient student network, making it suitable for deployment on resource-limited media terminals. However, traditional KD methods require balanced data to ensure robust training, which is often unavailable in practical applications. In such scenarios, a few head categories occupy a substantial proportion of examples. This imbalance biases the trained teacher network towards the head categories, resulting in severe performance degradation on the less represented tail categories for both the teacher and student networks. In this paper, we propose a novel framework called Knowledge Rectification Distillation (KRDistill) to address the imbalanced knowledge inherited in the teacher network through the incorporation of the balanced category priors. Furthermore, we rectify the biased predictions produced by the teacher network, particularly focusing on the tail categories. Consequently, the teacher network can provide balanced and accurate knowledge to train a reliable student network. Intensive experiments conducted on various long-tailed datasets demonstrate that our KRDistill can effectively train reliable student networks in realistic scenarios of data imbalance.","sentences":["Knowledge Distillation (KD) transfers knowledge from a large pre-trained teacher network to a compact and efficient student network, making it suitable for deployment on resource-limited media terminals.","However, traditional KD methods require balanced data to ensure robust training, which is often unavailable in practical applications.","In such scenarios, a few head categories occupy a substantial proportion of examples.","This imbalance biases the trained teacher network towards the head categories, resulting in severe performance degradation on the less represented tail categories for both the teacher and student networks.","In this paper, we propose a novel framework called Knowledge Rectification Distillation (KRDistill) to address the imbalanced knowledge inherited in the teacher network through the incorporation of the balanced category priors.","Furthermore, we rectify the biased predictions produced by the teacher network, particularly focusing on the tail categories.","Consequently, the teacher network can provide balanced and accurate knowledge to train a reliable student network.","Intensive experiments conducted on various long-tailed datasets demonstrate that our KRDistill can effectively train reliable student networks in realistic scenarios of data imbalance."],"url":"http://arxiv.org/abs/2409.07694v1"}
{"created":"2024-09-12 00:27:31","title":"An Unsupervised Dialogue Topic Segmentation Model Based on Utterance Rewriting","abstract":"Dialogue topic segmentation plays a crucial role in various types of dialogue modeling tasks. The state-of-the-art unsupervised DTS methods learn topic-aware discourse representations from conversation data through adjacent discourse matching and pseudo segmentation to further mine useful clues in unlabeled conversational relations. However, in multi-round dialogs, discourses often have co-references or omissions, leading to the fact that direct use of these discourses for representation learning may negatively affect the semantic similarity computation in the neighboring discourse matching task. In order to fully utilize the useful cues in conversational relations, this study proposes a novel unsupervised dialog topic segmentation method that combines the Utterance Rewriting (UR) technique with an unsupervised learning algorithm to efficiently utilize the useful cues in unlabeled dialogs by rewriting the dialogs in order to recover the co-referents and omitted words. Compared with existing unsupervised models, the proposed Discourse Rewriting Topic Segmentation Model (UR-DTS) significantly improves the accuracy of topic segmentation. The main finding is that the performance on DialSeg711 improves by about 6% in terms of absolute error score and WD, achieving 11.42% in terms of absolute error score and 12.97% in terms of WD. on Doc2Dial the absolute error score and WD improves by about 3% and 2%, respectively, resulting in SOTA reaching 35.17% in terms of absolute error score and 38.49% in terms of WD. This shows that the model is very effective in capturing the nuances of conversational topics, as well as the usefulness and challenges of utilizing unlabeled conversations.","sentences":["Dialogue topic segmentation plays a crucial role in various types of dialogue modeling tasks.","The state-of-the-art unsupervised DTS methods learn topic-aware discourse representations from conversation data through adjacent discourse matching and pseudo segmentation to further mine useful clues in unlabeled conversational relations.","However, in multi-round dialogs, discourses often have co-references or omissions, leading to the fact that direct use of these discourses for representation learning may negatively affect the semantic similarity computation in the neighboring discourse matching task.","In order to fully utilize the useful cues in conversational relations, this study proposes a novel unsupervised dialog topic segmentation method that combines the Utterance Rewriting (UR) technique with an unsupervised learning algorithm to efficiently utilize the useful cues in unlabeled dialogs by rewriting the dialogs in order to recover the co-referents and omitted words.","Compared with existing unsupervised models, the proposed Discourse Rewriting Topic Segmentation Model (UR-DTS) significantly improves the accuracy of topic segmentation.","The main finding is that the performance on DialSeg711 improves by about 6% in terms of absolute error score and WD, achieving 11.42% in terms of absolute error score and 12.97% in terms of WD.","on Doc2Dial the absolute error score and WD improves by about 3% and 2%, respectively, resulting in SOTA reaching 35.17% in terms of absolute error score and 38.49% in terms of WD.","This shows that the model is very effective in capturing the nuances of conversational topics, as well as the usefulness and challenges of utilizing unlabeled conversations."],"url":"http://arxiv.org/abs/2409.07672v1"}
{"created":"2024-09-12 00:15:21","title":"A Deep Dive Into How Open-Source Project Maintainers Review and Resolve Bug Bounty Reports","abstract":"Researchers have investigated the bug bounty ecosystem from the lens of platforms, programs, and bug hunters. Understanding the perspectives of bug bounty report reviewers, especially those who historically lack a security background and little to no funding for bug hunters, is currently understudied. In this paper, we primarily investigate the perspective of open-source software (OSS) maintainers who have used \\texttt{huntr}, a bug bounty platform that pays bounties to bug hunters who find security bugs in GitHub projects and have had valid vulnerabilities patched as a result. We address this area by conducting three studies: identifying characteristics through a listing survey ($n_1=51$), their ranked importance with Likert-scale survey data ($n_2=90$), and conducting semi-structured interviews to dive deeper into real-world experiences ($n_3=17$). As a result, we categorize 40 identified characteristics into benefits, challenges, helpful features, and wanted features. We find that private disclosure and project visibility are the most important benefits, while hunters focused on money or CVEs and pressure to review are the most challenging to overcome. Surprisingly, lack of communication with bug hunters is the least challenging, and CVE creation support is the second-least helpful feature for OSS maintainers when reviewing bug bounty reports. We present recommendations to make the bug bounty review process more accommodating to open-source maintainers and identify areas for future work.","sentences":["Researchers have investigated the bug bounty ecosystem from the lens of platforms, programs, and bug hunters.","Understanding the perspectives of bug bounty report reviewers, especially those who historically lack a security background and little to no funding for bug hunters, is currently understudied.","In this paper, we primarily investigate the perspective of open-source software (OSS) maintainers who have used \\texttt{huntr}, a bug bounty platform that pays bounties to bug hunters who find security bugs in GitHub projects and have had valid vulnerabilities patched as a result.","We address this area by conducting three studies: identifying characteristics through a listing survey ($n_1=51$), their ranked importance with Likert-scale survey data ($n_2=90$), and conducting semi-structured interviews to dive deeper into real-world experiences ($n_3=17$).","As a result, we categorize 40 identified characteristics into benefits, challenges, helpful features, and wanted features.","We find that private disclosure and project visibility are the most important benefits, while hunters focused on money or CVEs and pressure to review are the most challenging to overcome.","Surprisingly, lack of communication with bug hunters is the least challenging, and CVE creation support is the second-least helpful feature for OSS maintainers when reviewing bug bounty reports.","We present recommendations to make the bug bounty review process more accommodating to open-source maintainers and identify areas for future work."],"url":"http://arxiv.org/abs/2409.07670v1"}
{"created":"2024-09-11 22:56:30","title":"Passed the Turing Test: Living in Turing Futures","abstract":"The world has seen the emergence of machines based on pretrained models, transformers, also known as generative artificial intelligences for their ability to produce various types of content, including text, images, audio, and synthetic data. Without resorting to preprogramming or special tricks, their intelligence grows as they learn from experience, and to ordinary people, they can appear human-like in conversation. This means that they can pass the Turing test, and that we are now living in one of many possible Turing futures where machines can pass for what they are not. However, the learning machines that Turing imagined would pass his imitation tests were machines inspired by the natural development of the low-energy human cortex. They would be raised like human children and naturally learn the ability to deceive an observer. These ``child machines,'' Turing hoped, would be powerful enough to have an impact on society and nature.","sentences":["The world has seen the emergence of machines based on pretrained models, transformers, also known as generative artificial intelligences for their ability to produce various types of content, including text, images, audio, and synthetic data.","Without resorting to preprogramming or special tricks, their intelligence grows as they learn from experience, and to ordinary people, they can appear human-like in conversation.","This means that they can pass the Turing test, and that we are now living in one of many possible Turing futures where machines can pass for what they are not.","However, the learning machines that Turing imagined would pass his imitation tests were machines inspired by the natural development of the low-energy human cortex.","They would be raised like human children and naturally learn the ability to deceive an observer.","These ``child machines,'' Turing hoped, would be powerful enough to have an impact on society and nature."],"url":"http://arxiv.org/abs/2409.07656v1"}
{"created":"2024-09-11 22:49:38","title":"STAND: Data-Efficient and Self-Aware Precondition Induction for Interactive Task Learning","abstract":"STAND is a data-efficient and computationally efficient machine learning approach that produces better classification accuracy than popular approaches like XGBoost on small-data tabular classification problems like learning rule preconditions from interactive training. STAND accounts for a complete set of good candidate generalizations instead of selecting a single generalization by breaking ties randomly. STAND can use any greedy concept construction strategy, like decision tree learning or sequential covering, and build a structure that approximates a version space over disjunctive normal logical statements. Unlike candidate elimination approaches to version-space learning, STAND does not suffer from issues of version-space collapse from noisy data nor is it restricted to learning strictly conjunctive concepts. More importantly, STAND can produce a measure called instance certainty that can predict increases in holdout set performance and has high utility as an active-learning heuristic. Instance certainty enables STAND to be self-aware of its own learning: it knows when it learns and what example will help it learn the most. We illustrate that instance certainty has desirable properties that can help users select next training problems, and estimate when training is complete in applications where users interactively teach an AI a complex program.","sentences":["STAND is a data-efficient and computationally efficient machine learning approach that produces better classification accuracy than popular approaches like XGBoost on small-data tabular classification problems like learning rule preconditions from interactive training.","STAND accounts for a complete set of good candidate generalizations instead of selecting a single generalization by breaking ties randomly.","STAND can use any greedy concept construction strategy, like decision tree learning or sequential covering, and build a structure that approximates a version space over disjunctive normal logical statements.","Unlike candidate elimination approaches to version-space learning, STAND does not suffer from issues of version-space collapse from noisy data nor is it restricted to learning strictly conjunctive concepts.","More importantly, STAND can produce a measure called instance certainty that can predict increases in holdout set performance and has high utility as an active-learning heuristic.","Instance certainty enables STAND to be self-aware of its own learning: it knows when it learns and what example will help it learn the most.","We illustrate that instance certainty has desirable properties that can help users select next training problems, and estimate when training is complete in applications where users interactively teach an AI a complex program."],"url":"http://arxiv.org/abs/2409.07653v1"}
{"created":"2024-09-11 21:48:33","title":"Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities","abstract":"In this paper we explore evaluation of LLM capabilities. We present measurements of GPT-4 performance on several deterministic tasks; each task involves a basic calculation and takes as input parameter some element drawn from a large well-defined population (e.g., count elements in a list, multiply two k-digit numbers, etc). We examine several conditions per-task and perform enough trials so that statistically significant differences can be detected. This allows us to investigate the sensitivity of task-accuracy both to query phrasing and input parameter population. We find that seemingly trivial modifications in the task-prompt or input population can yield differences far larger than can be explained by sampling effects. For example, performance on a simple list-counting task varies with query-phrasing and list-length, but also with list composition (i.e., the thing-to-be-counted) and object frequency (e.g., success when an element accounts for $\\approx$ 50\\% of a list is different from when it accounts for $\\approx$ 70\\% etc).   We conclude that efforts to quantify LLM capabilities easily succumb to the language-as-fixed-effect fallacy, where experimental observations are improperly generalized beyond what the data supports. A consequence appears to be that intuitions that have been formed based on interactions with humans form a very unreliable guide as to which input modifications should ``make no difference'' to LLM performance.","sentences":["In this paper we explore evaluation of LLM capabilities.","We present measurements of GPT-4 performance on several deterministic tasks; each task involves a basic calculation and takes as input parameter some element drawn from a large well-defined population (e.g., count elements in a list, multiply two k-digit numbers, etc).","We examine several conditions per-task and perform enough trials so that statistically significant differences can be detected.","This allows us to investigate the sensitivity of task-accuracy both to query phrasing and input parameter population.","We find that seemingly trivial modifications in the task-prompt or input population can yield differences far larger than can be explained by sampling effects.","For example, performance on a simple list-counting task varies with query-phrasing and list-length, but also with list composition (i.e., the thing-to-be-counted) and object frequency (e.g., success when an element accounts for $\\approx$ 50\\% of a list is different from when it accounts for $\\approx$ 70\\% etc).   ","We conclude that efforts to quantify LLM capabilities easily succumb to the language-as-fixed-effect fallacy, where experimental observations are improperly generalized beyond what the data supports.","A consequence appears to be that intuitions that have been formed based on interactions with humans form a very unreliable guide as to which input modifications should ``make no difference'' to LLM performance."],"url":"http://arxiv.org/abs/2409.07638v1"}
{"created":"2024-09-11 21:26:23","title":"HERL: Tiered Federated Learning with Adaptive Homomorphic Encryption using Reinforcement Learning","abstract":"Federated Learning is a well-researched approach for collaboratively training machine learning models across decentralized data while preserving privacy. However, integrating Homomorphic Encryption to ensure data confidentiality introduces significant computational and communication overheads, particularly in heterogeneous environments where clients have varying computational capacities and security needs. In this paper, we propose HERL, a Reinforcement Learning-based approach that uses Q-Learning to dynamically optimize encryption parameters, specifically the polynomial modulus degree, $N$, and the coefficient modulus, $q$, across different client tiers. Our proposed method involves first profiling and tiering clients according to the chosen clustering approach, followed by dynamically selecting the most suitable encryption parameters using an RL-agent. Experimental results demonstrate that our approach significantly reduces the computational overhead while maintaining utility and a high level of security. Empirical results show that HERL improves utility by 17%, reduces the convergence time by up to 24%, and increases convergence efficiency by up to 30%, with minimal security loss.","sentences":["Federated Learning is a well-researched approach for collaboratively training machine learning models across decentralized data while preserving privacy.","However, integrating Homomorphic Encryption to ensure data confidentiality introduces significant computational and communication overheads, particularly in heterogeneous environments where clients have varying computational capacities and security needs.","In this paper, we propose HERL, a Reinforcement Learning-based approach that uses Q-Learning to dynamically optimize encryption parameters, specifically the polynomial modulus degree, $N$, and the coefficient modulus, $q$, across different client tiers.","Our proposed method involves first profiling and tiering clients according to the chosen clustering approach, followed by dynamically selecting the most suitable encryption parameters using an RL-agent.","Experimental results demonstrate that our approach significantly reduces the computational overhead while maintaining utility and a high level of security.","Empirical results show that HERL improves utility by 17%, reduces the convergence time by up to 24%, and increases convergence efficiency by up to 30%, with minimal security loss."],"url":"http://arxiv.org/abs/2409.07631v1"}
{"created":"2024-09-11 21:23:23","title":"Dividable Configuration Performance Learning","abstract":"Machine/deep learning models have been widely adopted for predicting the configuration performance of software systems. However, a crucial yet unaddressed challenge is how to cater for the sparsity inherited from the configuration landscape: the influence of configuration options (features) and the distribution of data samples are highly sparse. In this paper, we propose a model-agnostic and sparsity-robust framework for predicting configuration performance, dubbed DaL, based on the new paradigm of dividable learning that builds a model via \"divide-and-learn\". To handle sample sparsity, the samples from the configuration landscape are divided into distant divisions, for each of which we build a sparse local model, e.g., regularized Hierarchical Interaction Neural Network, to deal with the feature sparsity. A newly given configuration would then be assigned to the right model of division for the final prediction. Further, DaL adaptively determines the optimal number of divisions required for a system and sample size without any extra training or profiling. Experiment results from 12 real-world systems and five sets of training data reveal that, compared with the state-of-the-art approaches, DaL performs no worse than the best counterpart on 44 out of 60 cases with up to 1.61x improvement on accuracy; requires fewer samples to reach the same/better accuracy; and producing acceptable training overhead. In particular, the mechanism that adapted the parameter d can reach the optimal value for 76.43% of the individual runs. The result also confirms that the paradigm of dividable learning is more suitable than other similar paradigms such as ensemble learning for predicting configuration performance. Practically, DaL considerably improves different global models when using them as the underlying local models, which further strengthens its flexibility.","sentences":["Machine/deep learning models have been widely adopted for predicting the configuration performance of software systems.","However, a crucial yet unaddressed challenge is how to cater for the sparsity inherited from the configuration landscape: the influence of configuration options (features) and the distribution of data samples are highly sparse.","In this paper, we propose a model-agnostic and sparsity-robust framework for predicting configuration performance, dubbed DaL, based on the new paradigm of dividable learning that builds a model via \"divide-and-learn\".","To handle sample sparsity, the samples from the configuration landscape are divided into distant divisions, for each of which we build a sparse local model, e.g., regularized Hierarchical Interaction Neural Network, to deal with the feature sparsity.","A newly given configuration would then be assigned to the right model of division for the final prediction.","Further, DaL adaptively determines the optimal number of divisions required for a system and sample size without any extra training or profiling.","Experiment results from 12 real-world systems and five sets of training data reveal that, compared with the state-of-the-art approaches, DaL performs no worse than the best counterpart on 44 out of 60 cases with up to 1.61x improvement on accuracy; requires fewer samples to reach the same/better accuracy; and producing acceptable training overhead.","In particular, the mechanism that adapted the parameter d can reach the optimal value for 76.43% of the individual runs.","The result also confirms that the paradigm of dividable learning is more suitable than other similar paradigms such as ensemble learning for predicting configuration performance.","Practically, DaL considerably improves different global models when using them as the underlying local models, which further strengthens its flexibility."],"url":"http://arxiv.org/abs/2409.07629v1"}
{"created":"2024-09-11 20:59:32","title":"Ensemble Methods for Sequence Classification with Hidden Markov Models","abstract":"We present a lightweight approach to sequence classification using Ensemble Methods for Hidden Markov Models (HMMs). HMMs offer significant advantages in scenarios with imbalanced or smaller datasets due to their simplicity, interpretability, and efficiency. These models are particularly effective in domains such as finance and biology, where traditional methods struggle with high feature dimensionality and varied sequence lengths. Our ensemble-based scoring method enables the comparison of sequences of any length and improves performance on imbalanced datasets.   This study focuses on the binary classification problem, particularly in scenarios with data imbalance, where the negative class is the majority (e.g., normal data) and the positive class is the minority (e.g., anomalous data), often with extreme distribution skews. We propose a novel training approach for HMM Ensembles that generalizes to multi-class problems and supports classification and anomaly detection. Our method fits class-specific groups of diverse models using random data subsets, and compares likelihoods across classes to produce composite scores, achieving high average precisions and AUCs.   In addition, we compare our approach with neural network-based methods such as Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks (LSTMs), highlighting the efficiency and robustness of HMMs in data-scarce environments. Motivated by real-world use cases, our method demonstrates robust performance across various benchmarks, offering a flexible framework for diverse applications.","sentences":["We present a lightweight approach to sequence classification using Ensemble Methods for Hidden Markov Models (HMMs).","HMMs offer significant advantages in scenarios with imbalanced or smaller datasets due to their simplicity, interpretability, and efficiency.","These models are particularly effective in domains such as finance and biology, where traditional methods struggle with high feature dimensionality and varied sequence lengths.","Our ensemble-based scoring method enables the comparison of sequences of any length and improves performance on imbalanced datasets.   ","This study focuses on the binary classification problem, particularly in scenarios with data imbalance, where the negative class is the majority (e.g., normal data) and the positive class is the minority (e.g., anomalous data), often with extreme distribution skews.","We propose a novel training approach for HMM Ensembles that generalizes to multi-class problems and supports classification and anomaly detection.","Our method fits class-specific groups of diverse models using random data subsets, and compares likelihoods across classes to produce composite scores, achieving high average precisions and AUCs.   ","In addition, we compare our approach with neural network-based methods such as Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks (LSTMs), highlighting the efficiency and robustness of HMMs in data-scarce environments.","Motivated by real-world use cases, our method demonstrates robust performance across various benchmarks, offering a flexible framework for diverse applications."],"url":"http://arxiv.org/abs/2409.07619v1"}
{"created":"2024-09-11 20:54:23","title":"FlowSep: Language-Queried Sound Separation with Rectified Flow Matching","abstract":"Language-queried audio source separation (LASS) focuses on separating sounds using textual descriptions of the desired sources. Current methods mainly use discriminative approaches, such as time-frequency masking, to separate target sounds and minimize interference from other sources. However, these models face challenges when separating overlapping soundtracks, which may lead to artifacts such as spectral holes or incomplete separation. Rectified flow matching (RFM), a generative model that establishes linear relations between the distribution of data and noise, offers superior theoretical properties and simplicity, but has not yet been explored in sound separation. In this work, we introduce FlowSep, a new generative model based on RFM for LASS tasks. FlowSep learns linear flow trajectories from noise to target source features within the variational autoencoder (VAE) latent space. During inference, the RFM-generated latent features are reconstructed into a mel-spectrogram via the pre-trained VAE decoder, followed by a pre-trained vocoder to synthesize the waveform. Trained on 1,680 hours of audio data, FlowSep outperforms the state-of-the-art models across multiple benchmarks, as evaluated with subjective and objective metrics. Additionally, our results show that FlowSep surpasses a diffusion-based LASS model in both separation quality and inference efficiency, highlighting its strong potential for audio source separation tasks. Code, pre-trained models and demos can be found at: https://audio-agi.github.io/FlowSep_demo/.","sentences":["Language-queried audio source separation (LASS) focuses on separating sounds using textual descriptions of the desired sources.","Current methods mainly use discriminative approaches, such as time-frequency masking, to separate target sounds and minimize interference from other sources.","However, these models face challenges when separating overlapping soundtracks, which may lead to artifacts such as spectral holes or incomplete separation.","Rectified flow matching (RFM), a generative model that establishes linear relations between the distribution of data and noise, offers superior theoretical properties and simplicity, but has not yet been explored in sound separation.","In this work, we introduce FlowSep, a new generative model based on RFM for LASS tasks.","FlowSep learns linear flow trajectories from noise to target source features within the variational autoencoder (VAE) latent space.","During inference, the RFM-generated latent features are reconstructed into a mel-spectrogram via the pre-trained VAE decoder, followed by a pre-trained vocoder to synthesize the waveform.","Trained on 1,680 hours of audio data, FlowSep outperforms the state-of-the-art models across multiple benchmarks, as evaluated with subjective and objective metrics.","Additionally, our results show that FlowSep surpasses a diffusion-based LASS model in both separation quality and inference efficiency, highlighting its strong potential for audio source separation tasks.","Code, pre-trained models and demos can be found at: https://audio-agi.github.io/FlowSep_demo/."],"url":"http://arxiv.org/abs/2409.07614v1"}
{"created":"2024-09-11 20:43:59","title":"A Cost-Aware Approach to Adversarial Robustness in Neural Networks","abstract":"Considering the growing prominence of production-level AI and the threat of adversarial attacks that can evade a model at run-time, evaluating the robustness of models to these evasion attacks is of critical importance. Additionally, testing model changes likely means deploying the models to (e.g. a car or a medical imaging device), or a drone to see how it affects performance, making un-tested changes a public problem that reduces development speed, increases cost of development, and makes it difficult (if not impossible) to parse cause from effect. In this work, we used survival analysis as a cloud-native, time-efficient and precise method for predicting model performance in the presence of adversarial noise. For neural networks in particular, the relationships between the learning rate, batch size, training time, convergence time, and deployment cost are highly complex, so researchers generally rely on benchmark datasets to assess the ability of a model to generalize beyond the training data. To address this, we propose using accelerated failure time models to measure the effect of hardware choice, batch size, number of epochs, and test-set accuracy by using adversarial attacks to induce failures on a reference model architecture before deploying the model to the real world. We evaluate several GPU types and use the Tree Parzen Estimator to maximize model robustness and minimize model run-time simultaneously. This provides a way to evaluate the model and optimise it in a single step, while simultaneously allowing us to model the effect of model parameters on training time, prediction time, and accuracy. Using this technique, we demonstrate that newer, more-powerful hardware does decrease the training time, but with a monetary and power cost that far outpaces the marginal gains in accuracy.","sentences":["Considering the growing prominence of production-level AI and the threat of adversarial attacks that can evade a model at run-time, evaluating the robustness of models to these evasion attacks is of critical importance.","Additionally, testing model changes likely means deploying the models to (e.g. a car or a medical imaging device), or a drone to see how it affects performance, making un-tested changes a public problem that reduces development speed, increases cost of development, and makes it difficult (if not impossible) to parse cause from effect.","In this work, we used survival analysis as a cloud-native, time-efficient and precise method for predicting model performance in the presence of adversarial noise.","For neural networks in particular, the relationships between the learning rate, batch size, training time, convergence time, and deployment cost are highly complex, so researchers generally rely on benchmark datasets to assess the ability of a model to generalize beyond the training data.","To address this, we propose using accelerated failure time models to measure the effect of hardware choice, batch size, number of epochs, and test-set accuracy by using adversarial attacks to induce failures on a reference model architecture before deploying the model to the real world.","We evaluate several GPU types and use the Tree Parzen Estimator to maximize model robustness and minimize model run-time simultaneously.","This provides a way to evaluate the model and optimise it in a single step, while simultaneously allowing us to model the effect of model parameters on training time, prediction time, and accuracy.","Using this technique, we demonstrate that newer, more-powerful hardware does decrease the training time, but with a monetary and power cost that far outpaces the marginal gains in accuracy."],"url":"http://arxiv.org/abs/2409.07609v1"}
{"created":"2024-09-11 19:53:50","title":"Automated Discovery of Pairwise Interactions from Unstructured Data","abstract":"Pairwise interactions between perturbations to a system can provide evidence for the causal dependencies of the underlying underlying mechanisms of a system. When observations are low dimensional, hand crafted measurements, detecting interactions amounts to simple statistical tests, but it is not obvious how to detect interactions between perturbations affecting latent variables. We derive two interaction tests that are based on pairwise interventions, and show how these tests can be integrated into an active learning pipeline to efficiently discover pairwise interactions between perturbations. We illustrate the value of these tests in the context of biology, where pairwise perturbation experiments are frequently used to reveal interactions that are not observable from any single perturbation. Our tests can be run on unstructured data, such as the pixels in an image, which enables a more general notion of interaction than typical cell viability experiments, and can be run on cheaper experimental assays. We validate on several synthetic and real biological experiments that our tests are able to identify interacting pairs effectively. We evaluate our approach on a real biological experiment where we knocked out 50 pairs of genes and measured the effect with microscopy images. We show that we are able to recover significantly more known biological interactions than random search and standard active learning baselines.","sentences":["Pairwise interactions between perturbations to a system can provide evidence for the causal dependencies of the underlying underlying mechanisms of a system.","When observations are low dimensional, hand crafted measurements, detecting interactions amounts to simple statistical tests, but it is not obvious how to detect interactions between perturbations affecting latent variables.","We derive two interaction tests that are based on pairwise interventions, and show how these tests can be integrated into an active learning pipeline to efficiently discover pairwise interactions between perturbations.","We illustrate the value of these tests in the context of biology, where pairwise perturbation experiments are frequently used to reveal interactions that are not observable from any single perturbation.","Our tests can be run on unstructured data, such as the pixels in an image, which enables a more general notion of interaction than typical cell viability experiments, and can be run on cheaper experimental assays.","We validate on several synthetic and real biological experiments that our tests are able to identify interacting pairs effectively.","We evaluate our approach on a real biological experiment where we knocked out 50 pairs of genes and measured the effect with microscopy images.","We show that we are able to recover significantly more known biological interactions than random search and standard active learning baselines."],"url":"http://arxiv.org/abs/2409.07594v1"}
