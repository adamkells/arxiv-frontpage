{"created":"2024-02-28 18:59:31","title":"UniMODE: Unified Monocular 3D Object Detection","abstract":"Realizing unified monocular 3D object detection, including both indoor and outdoor scenes, holds great importance in applications like robot navigation. However, involving various scenarios of data to train models poses challenges due to their significantly different characteristics, e.g., diverse geometry properties and heterogeneous domain distributions. To address these challenges, we build a detector based on the bird's-eye-view (BEV) detection paradigm, where the explicit feature projection is beneficial to addressing the geometry learning ambiguity when employing multiple scenarios of data to train detectors. Then, we split the classical BEV detection architecture into two stages and propose an uneven BEV grid design to handle the convergence instability caused by the aforementioned challenges. Moreover, we develop a sparse BEV feature projection strategy to reduce computational cost and a unified domain alignment method to handle heterogeneous domains. Combining these techniques, a unified detector UniMODE is derived, which surpasses the previous state-of-the-art on the challenging Omni3D dataset (a large-scale dataset including both indoor and outdoor scenes) by 4.9% AP_3D, revealing the first successful generalization of a BEV detector to unified 3D object detection.","sentences":["Realizing unified monocular 3D object detection, including both indoor and outdoor scenes, holds great importance in applications like robot navigation.","However, involving various scenarios of data to train models poses challenges due to their significantly different characteristics, e.g., diverse geometry properties and heterogeneous domain distributions.","To address these challenges, we build a detector based on the bird's-eye-view (BEV) detection paradigm, where the explicit feature projection is beneficial to addressing the geometry learning ambiguity when employing multiple scenarios of data to train detectors.","Then, we split the classical BEV detection architecture into two stages and propose an uneven BEV grid design to handle the convergence instability caused by the aforementioned challenges.","Moreover, we develop a sparse BEV feature projection strategy to reduce computational cost and a unified domain alignment method to handle heterogeneous domains.","Combining these techniques, a unified detector UniMODE is derived, which surpasses the previous state-of-the-art on the challenging Omni3D dataset (a large-scale dataset including both indoor and outdoor scenes) by 4.9% AP_3D, revealing the first successful generalization of a BEV detector to unified 3D object detection."],"url":"http://arxiv.org/abs/2402.18573v1"}
{"created":"2024-02-28 18:56:56","title":"A Categorization of Complexity Classes for Information Retrieval and Synthesis Using Natural Logic","abstract":"Given the emergent reasoning abilities of large language models, information retrieval is becoming more complex. Rather than just retrieve a document, modern information retrieval systems advertise that they can synthesize an answer based on potentially many different documents, conflicting data sources, and using reasoning. But, different kinds of questions have different answers, and different answers have different complexities. In this paper, we introduce a novel framework for analyzing the complexity of a question answer based on the natural deduction calculus as presented in Prawitz (1965). Our framework is novel both in that no one to our knowledge has used this logic as a basis for complexity classes, and also in that no other existing complexity classes to these have been delineated using any analogous methods either. We identify three decidable fragments in particular called the forward, query and planning fragments, and we compare this to what would be needed to do proofs for the complete first-order calculus, for which theorem-proving is long known to be undecidable.","sentences":["Given the emergent reasoning abilities of large language models, information retrieval is becoming more complex.","Rather than just retrieve a document, modern information retrieval systems advertise that they can synthesize an answer based on potentially many different documents, conflicting data sources, and using reasoning.","But, different kinds of questions have different answers, and different answers have different complexities.","In this paper, we introduce a novel framework for analyzing the complexity of a question answer based on the natural deduction calculus as presented in Prawitz (1965).","Our framework is novel both in that no one to our knowledge has used this logic as a basis for complexity classes, and also in that no other existing complexity classes to these have been delineated using any analogous methods either.","We identify three decidable fragments in particular called the forward, query and planning fragments, and we compare this to what would be needed to do proofs for the complete first-order calculus, for which theorem-proving is long known to be undecidable."],"url":"http://arxiv.org/abs/2402.18566v1"}
{"created":"2024-02-28 18:35:59","title":"Selection of appropriate multispectral camera exposure settings and radiometric calibration methods for applications in phenotyping and precision agriculture","abstract":"Radiometric accuracy of data is crucial in quantitative precision agriculture, to produce reliable and repeatable data for modeling and decision making. The effect of exposure time and gain settings on the radiometric accuracy of multispectral images was not explored enough. The goal of this study was to determine if having a fixed exposure (FE) time during image acquisition improved radiometric accuracy of images, compared to the default auto-exposure (AE) settings. This involved quantifying the errors from auto-exposure and determining ideal exposure values within which radiometric mean absolute percentage error (MAPE) were minimal (< 5%). The results showed that FE orthomosaic was closer to ground-truth (higher R2 and lower MAPE) than AE orthomosaic. An ideal exposure range was determined for capturing canopy and soil objects, without loss of information from under-exposure or saturation from over-exposure. A simulation of errors from AE showed that MAPE < 5% for the blue, green, red, and NIR bands and < 7% for the red edge band for exposure settings within the determined ideal ranges and increased exponentially beyond the ideal exposure upper limit. Further, prediction of total plant nitrogen uptake (g/plant) using vegetation indices (VIs) from two different growing seasons were closer to the ground truth (mostly, R2 > 0.40, and MAPE = 12 to 14%, p < 0.05) when FE was used, compared to the prediction from AE images (mostly, R2 < 0.13, MAPE = 15 to 18%, p >= 0.05).","sentences":["Radiometric accuracy of data is crucial in quantitative precision agriculture, to produce reliable and repeatable data for modeling and decision making.","The effect of exposure time and gain settings on the radiometric accuracy of multispectral images was not explored enough.","The goal of this study was to determine if having a fixed exposure (FE) time during image acquisition improved radiometric accuracy of images, compared to the default auto-exposure (AE) settings.","This involved quantifying the errors from auto-exposure and determining ideal exposure values within which radiometric mean absolute percentage error (MAPE) were minimal (< 5%).","The results showed that FE orthomosaic was closer to ground-truth (higher R2 and lower MAPE) than AE orthomosaic.","An ideal exposure range was determined for capturing canopy and soil objects, without loss of information from under-exposure or saturation from over-exposure.","A simulation of errors from AE showed that MAPE < 5% for the blue, green, red, and NIR bands and < 7% for the red edge band for exposure settings within the determined ideal ranges and increased exponentially beyond the ideal exposure upper limit.","Further, prediction of total plant nitrogen uptake (g/plant) using vegetation indices (VIs) from two different growing seasons were closer to the ground truth (mostly, R2 > 0.40, and MAPE = 12 to 14%, p < 0.05) when FE was used, compared to the prediction from AE images (mostly, R2 < 0.13, MAPE = 15 to 18%, p >= 0.05)."],"url":"http://arxiv.org/abs/2402.18553v1"}
{"created":"2024-02-28 18:34:53","title":"Implicit Bias of Next-Token Prediction","abstract":"Next-token prediction (NTP), the go-to training paradigm in training large language models, involves predicting the next token in a sequence. Departing from traditional one-hot classification, in NTP, multiple tokens with varying frequencies follow each given context. This work frames NTP training as cross-entropy minimization over distinct contexts, each associated with a sparse empirical probability vector across a finite vocabulary. It then addresses the following question: do gradient-based optimizers exhibit a bias towards solutions with specific structure as the NTP training loss reaches its lower bound (entropy)? Specifically, for linear NTP models trained using gradient descent (GD), we make the following contributions: Firstly, we determine NTP-separability conditions on the data, under which GD can attain its lower bound. We also demonstrate that these conditions hold under overparameterization. Secondly, we establish that the parameters of GD projected onto an appropriate data subspace converge to the unique solution of a system of linear equations, which requires the logits' difference of in-support tokens to be equal to the log-ratio of their respective probabilities. Meanwhile, on the orthogonal subspace, the parameters diverge and converge in the direction of the solution of a max-margin quadratic program, minimizing the Euclidean norm of parameters satisfying the \\NTP-separability conditions. Akin to prior research on implicit bias of one-hot classification, our work opens exciting avenues for future research that can lead to better understanding optimization, generalization and robustness principles of models trained with NTP.","sentences":["Next-token prediction (NTP), the go-to training paradigm in training large language models, involves predicting the next token in a sequence.","Departing from traditional one-hot classification, in NTP, multiple tokens with varying frequencies follow each given context.","This work frames NTP training as cross-entropy minimization over distinct contexts, each associated with a sparse empirical probability vector across a finite vocabulary.","It then addresses the following question: do gradient-based optimizers exhibit a bias towards solutions with specific structure as the NTP training loss reaches its lower bound (entropy)?","Specifically, for linear NTP models trained using gradient descent (GD), we make the following contributions: Firstly, we determine NTP-separability conditions on the data, under which GD can attain its lower bound.","We also demonstrate that these conditions hold under overparameterization.","Secondly, we establish that the parameters of GD projected onto an appropriate data subspace converge to the unique solution of a system of linear equations, which requires the logits' difference of in-support tokens to be equal to the log-ratio of their respective probabilities.","Meanwhile, on the orthogonal subspace, the parameters diverge and converge in the direction of the solution of a max-margin quadratic program, minimizing the Euclidean norm of parameters satisfying the \\NTP-separability conditions.","Akin to prior research on implicit bias of one-hot classification, our work opens exciting avenues for future research that can lead to better understanding optimization, generalization and robustness principles of models trained with NTP."],"url":"http://arxiv.org/abs/2402.18551v1"}
{"created":"2024-02-28 18:29:25","title":"Generalizability Under Sensor Failure: Tokenization + Transformers Enable More Robust Latent Spaces","abstract":"A major goal in neuroscience is to discover neural data representations that generalize. This goal is challenged by variability along recording sessions (e.g. environment), subjects (e.g. varying neural structures), and sensors (e.g. sensor noise), among others. Recent work has begun to address generalization across sessions and subjects, but few study robustness to sensor failure which is highly prevalent in neuroscience experiments. In order to address these generalizability dimensions we first collect our own electroencephalography dataset with numerous sessions, subjects, and sensors, then study two time series models: EEGNet (Lawhern et al., 2018) and TOTEM (Talukder et al., 2024). EEGNet is a widely used convolutional neural network, while TOTEM is a discrete time series tokenizer and transformer model. We find that TOTEM outperforms or matches EEGNet across all generalizability cases. Finally through analysis of TOTEM's latent codebook we observe that tokenization enables generalization.","sentences":["A major goal in neuroscience is to discover neural data representations that generalize.","This goal is challenged by variability along recording sessions (e.g. environment), subjects (e.g. varying neural structures), and sensors (e.g. sensor noise), among others.","Recent work has begun to address generalization across sessions and subjects, but few study robustness to sensor failure which is highly prevalent in neuroscience experiments.","In order to address these generalizability dimensions we first collect our own electroencephalography dataset with numerous sessions, subjects, and sensors, then study two time series models: EEGNet (Lawhern et al., 2018) and TOTEM (Talukder et al., 2024).","EEGNet is a widely used convolutional neural network, while TOTEM is a discrete time series tokenizer and transformer model.","We find that TOTEM outperforms or matches EEGNet across all generalizability cases.","Finally through analysis of TOTEM's latent codebook we observe that tokenization enables generalization."],"url":"http://arxiv.org/abs/2402.18546v1"}
{"created":"2024-02-28 18:24:05","title":"Dynamic Deterministic Constant-Approximate Distance Oracles with $n^\u03b5$ Worst-Case Update Time","abstract":"We present a new distance oracle in the fully dynamic setting: given a weighted undirected graph $G=(V,E)$ with $n$ vertices undergoing both edge insertions and deletions, and an arbitrary parameter $\\epsilon$ where $1/\\log^{c} n<\\epsilon<1$ and $c>0$ is a small constant, we can deterministically maintain a data structure with $n^{\\epsilon}$ worst-case update time that, given any pair of vertices $(u,v)$, returns a $2^{{\\rm poly}(1/\\epsilon)}$-approximate distance between $u$ and $v$ in ${\\rm poly}(1/\\epsilon)\\log\\log n$ query time.   Our algorithm significantly advances the state-of-the-art in two aspects, both for fully dynamic algorithms and even decremental algorithms. First, no existing algorithm with worst-case update time guarantees a $o(n)$-approximation while also achieving an $n^{2-\\Omega(1)}$ update and $n^{o(1)}$ query time, while our algorithm offers a constant $O_{\\epsilon}(1)$-approximation with $n^{\\epsilon}$ update time and $O_{\\epsilon}(\\log \\log n)$ query time. Second, even if amortized update time is allowed, it is the first deterministic constant-approximation algorithm with $n^{1-\\Omega(1)}$ update and query time. The best result in this direction is the recent deterministic distance oracle by Chuzhoy and Zhang [STOC 2023] which achieves an approximation of $(\\log\\log n)^{2^{O(1/\\epsilon^{3})}}$ with amortized update time of $n^{\\epsilon}$ and query time of $2^{{\\rm poly}(1/\\epsilon)}\\log n\\log\\log n$.   We obtain the result by dynamizing tools related to length-constrained expanders [Haeupler-R\\\"acke-Ghaffari, STOC 2022; Haeupler-Hershkowitz-Tan, 2023; Haeupler-Huebotter-Ghaffari, 2022]. Our technique completely bypasses the 40-year-old Even-Shiloach tree, which has remained the most pervasive tool in the area but is inherently amortized.","sentences":["We present a new distance oracle in the fully dynamic setting: given a weighted undirected graph $G=(V,E)$ with $n$ vertices undergoing both edge insertions and deletions, and an arbitrary parameter $\\epsilon$ where $1/\\log^{c} n<\\epsilon<1$ and $c>0$ is a small constant, we can deterministically maintain a data structure with $n^{\\epsilon}$ worst-case update time that, given any pair of vertices $(u,v)$, returns a $2^{{\\rm poly}(1/\\epsilon)}$-approximate distance between $u$ and $v$ in ${\\rm poly}(1/\\epsilon)\\log\\log n$ query time.   ","Our algorithm significantly advances the state-of-the-art in two aspects, both for fully dynamic algorithms and even decremental algorithms.","First, no existing algorithm with worst-case update time guarantees a $o(n)$-approximation while also achieving an $n^{2-\\Omega(1)}$ update and $n^{o(1)}$ query time, while our algorithm offers a constant $O_{\\epsilon}(1)$-approximation with $n^{\\epsilon}$ update time and $O_{\\epsilon}(\\log \\log n)$ query time.","Second, even if amortized update time is allowed, it is the first deterministic constant-approximation algorithm with $n^{1-\\Omega(1)}$ update and query time.","The best result in this direction is the recent deterministic distance oracle by Chuzhoy and Zhang","[STOC 2023] which achieves an approximation of $(\\log\\log n)^{2^{O(1/\\epsilon^{3})}}$ with amortized update time of $n^{\\epsilon}$ and query time of $2^{{\\rm poly}(1/\\epsilon)}\\log n\\log\\log n$.   We obtain the result by dynamizing tools related to length-constrained expanders","[Haeupler-R\\\"acke-Ghaffari, STOC 2022; Haeupler-Hershkowitz-Tan, 2023; Haeupler-Huebotter-Ghaffari, 2022].","Our technique completely bypasses the 40-year-old Even-Shiloach tree, which has remained the most pervasive tool in the area but is inherently amortized."],"url":"http://arxiv.org/abs/2402.18541v1"}
{"created":"2024-02-28 18:22:03","title":"On the enumeration of signatures of XOR-CNF's","abstract":"Given a CNF formula $\\varphi$ with clauses $C_1, \\dots, C_m$ over a set of variables $V$, a truth assignment $\\mathbf{a} : V \\to \\{0, 1\\}$ generates a binary sequence $\\sigma_\\varphi(\\mathbf{a})=(C_1(\\mathbf{a}), \\ldots, C_m(\\mathbf{a}))$, called a signature of $\\varphi$, where $C_i(\\mathbf{a})=1$ if clause $C_i$ evaluates to 1 under assignment $\\mathbf{a}$, and $C_i(\\mathbf{a})=0$ otherwise. Signatures and their associated generation problems have given rise to new yet promising research questions in algorithmic enumeration. In a recent paper, B\\'erczi et al. interestingly proved that generating signatures of a CNF is tractable despite the fact that verifying a solution is hard. They also showed the hardness of finding maximal signatures of an arbitrary CNF due to the intractability of satisfiability in general. Their contribution leaves open the problem of efficiently generating maximal signatures for tractable classes of CNFs, i.e., those for which satisfiability can be solved in polynomial time. Stepping into that direction, we completely characterize the complexity of generating all, minimal, and maximal signatures for XOR-CNFs.","sentences":["Given a CNF formula $\\varphi$ with clauses $C_1, \\dots, C_m$ over a set of variables $V$, a truth assignment $\\mathbf{a} : V \\to \\{0, 1\\}$ generates a binary sequence $\\sigma_\\varphi(\\mathbf{a})=(C_1(\\mathbf{a}), \\ldots, C_m(\\mathbf{a}))$, called a signature of $\\varphi$, where $C_i(\\mathbf{a})=1$ if clause $C_i$ evaluates to 1 under assignment $\\mathbf{a}$, and $C_i(\\mathbf{a})=0$ otherwise.","Signatures and their associated generation problems have given rise to new yet promising research questions in algorithmic enumeration.","In a recent paper, B\\'erczi et al. interestingly proved that generating signatures of a CNF is tractable despite the fact that verifying a solution is hard.","They also showed the hardness of finding maximal signatures of an arbitrary CNF due to the intractability of satisfiability in general.","Their contribution leaves open the problem of efficiently generating maximal signatures for tractable classes of CNFs, i.e., those for which satisfiability can be solved in polynomial time.","Stepping into that direction, we completely characterize the complexity of generating all, minimal, and maximal signatures for XOR-CNFs."],"url":"http://arxiv.org/abs/2402.18537v1"}
{"created":"2024-02-28 18:08:03","title":"Gradient Reweighting: Towards Imbalanced Class-Incremental Learning","abstract":"Class-Incremental Learning (CIL) trains a model to continually recognize new classes from non-stationary data while retaining learned knowledge. A major challenge of CIL arises when applying to real-world data characterized by non-uniform distribution, which introduces a dual imbalance problem involving (i) disparities between stored exemplars of old tasks and new class data (inter-phase imbalance), and (ii) severe class imbalances within each individual task (intra-phase imbalance). We show that this dual imbalance issue causes skewed gradient updates with biased weights in FC layers, thus inducing over/under-fitting and catastrophic forgetting in CIL. Our method addresses it by reweighting the gradients towards balanced optimization and unbiased classifier learning. Additionally, we observe imbalanced forgetting where paradoxically the instance-rich classes suffer higher performance degradation during CIL due to a larger amount of training data becoming unavailable in subsequent learning phases. To tackle this, we further introduce a distribution-aware knowledge distillation loss to mitigate forgetting by aligning output logits proportionally with the distribution of lost training data. We validate our method on CIFAR-100, ImageNetSubset, and Food101 across various evaluation protocols and demonstrate consistent improvements compared to existing works, showing great potential to apply CIL in real-world scenarios with enhanced robustness and effectiveness.","sentences":["Class-Incremental Learning (CIL) trains a model to continually recognize new classes from non-stationary data while retaining learned knowledge.","A major challenge of CIL arises when applying to real-world data characterized by non-uniform distribution, which introduces a dual imbalance problem involving (i) disparities between stored exemplars of old tasks and new class data (inter-phase imbalance), and (ii) severe class imbalances within each individual task (intra-phase imbalance).","We show that this dual imbalance issue causes skewed gradient updates with biased weights in FC layers, thus inducing over/under-fitting and catastrophic forgetting in CIL.","Our method addresses it by reweighting the gradients towards balanced optimization and unbiased classifier learning.","Additionally, we observe imbalanced forgetting where paradoxically the instance-rich classes suffer higher performance degradation during CIL due to a larger amount of training data becoming unavailable in subsequent learning phases.","To tackle this, we further introduce a distribution-aware knowledge distillation loss to mitigate forgetting by aligning output logits proportionally with the distribution of lost training data.","We validate our method on CIFAR-100, ImageNetSubset, and Food101 across various evaluation protocols and demonstrate consistent improvements compared to existing works, showing great potential to apply CIL in real-world scenarios with enhanced robustness and effectiveness."],"url":"http://arxiv.org/abs/2402.18528v1"}
{"created":"2024-02-28 17:40:05","title":"Log Neural Controlled Differential Equations: The Lie Brackets Make a Difference","abstract":"The vector field of a controlled differential equation (CDE) describes the relationship between a control path and the evolution of a solution path. Neural CDEs (NCDEs) treat time series data as observations from a control path, parameterise a CDE's vector field using a neural network, and use the solution path as a continuously evolving hidden state. As their formulation makes them robust to irregular sampling rates, NCDEs are a powerful approach for modelling real-world data. Building on neural rough differential equations (NRDEs), we introduce Log-NCDEs, a novel and effective method for training NCDEs. The core component of Log-NCDEs is the Log-ODE method, a tool from the study of rough paths for approximating a CDE's solution. On a range of multivariate time series classification benchmarks, Log-NCDEs are shown to achieve a higher average test set accuracy than NCDEs, NRDEs, and two state-of-the-art models, S5 and the linear recurrent unit.","sentences":["The vector field of a controlled differential equation (CDE) describes the relationship between a control path and the evolution of a solution path.","Neural CDEs (NCDEs) treat time series data as observations from a control path, parameterise a CDE's vector field using a neural network, and use the solution path as a continuously evolving hidden state.","As their formulation makes them robust to irregular sampling rates, NCDEs are a powerful approach for modelling real-world data.","Building on neural rough differential equations (NRDEs), we introduce Log-NCDEs, a novel and effective method for training NCDEs.","The core component of Log-NCDEs is the Log-ODE method, a tool from the study of rough paths for approximating a CDE's solution.","On a range of multivariate time series classification benchmarks, Log-NCDEs are shown to achieve a higher average test set accuracy than NCDEs, NRDEs, and two state-of-the-art models, S5 and the linear recurrent unit."],"url":"http://arxiv.org/abs/2402.18512v1"}
{"created":"2024-02-28 17:40:01","title":"Leveraging Compliant Tactile Perception for Haptic Blind Surface Reconstruction","abstract":"Non-flat surfaces pose difficulties for robots operating in unstructured environments. Reconstructions of uneven surfaces may only be partially possible due to non-compliant end-effectors and limitations on vision systems such as transparency, reflections, and occlusions. This study achieves blind surface reconstruction by harnessing the robotic manipulator's kinematic data and a compliant tactile sensing module, which incorporates inertial, magnetic, and pressure sensors. The module's flexibility enables us to estimate contact positions and surface normals by analyzing its deformation during interactions with unknown objects. While previous works collect only positional information, we include the local normals in a geometrical approach to estimate curvatures between adjacent contact points. These parameters then guide a spline-based patch generation, which allows us to recreate larger surfaces without an increase in complexity while reducing the time-consuming step of probing the surface. Experimental validation demonstrates that this approach outperforms an off-the-shelf vision system in estimation accuracy. Moreover, this compliant haptic method works effectively even when the manipulator's approach angle is not aligned with the surface normals, which is ideal for unknown non-flat surfaces.","sentences":["Non-flat surfaces pose difficulties for robots operating in unstructured environments.","Reconstructions of uneven surfaces may only be partially possible due to non-compliant end-effectors and limitations on vision systems such as transparency, reflections, and occlusions.","This study achieves blind surface reconstruction by harnessing the robotic manipulator's kinematic data and a compliant tactile sensing module, which incorporates inertial, magnetic, and pressure sensors.","The module's flexibility enables us to estimate contact positions and surface normals by analyzing its deformation during interactions with unknown objects.","While previous works collect only positional information, we include the local normals in a geometrical approach to estimate curvatures between adjacent contact points.","These parameters then guide a spline-based patch generation, which allows us to recreate larger surfaces without an increase in complexity while reducing the time-consuming step of probing the surface.","Experimental validation demonstrates that this approach outperforms an off-the-shelf vision system in estimation accuracy.","Moreover, this compliant haptic method works effectively even when the manipulator's approach angle is not aligned with the surface normals, which is ideal for unknown non-flat surfaces."],"url":"http://arxiv.org/abs/2402.18511v1"}
{"created":"2024-02-28 17:36:45","title":"Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling","abstract":"In the rapidly evolving landscape of deep learning, the quest for models that balance expressivity with computational efficiency has never been more critical. This paper introduces Orchid, a novel architecture that reimagines sequence modeling by incorporating a new data-dependent convolution mechanism. Orchid is designed to address the inherent limitations of traditional attention mechanisms, particularly their quadratic complexity, without compromising the ability to capture long-range dependencies and in-context learning. At the core of Orchid lies the data-dependent convolution layer, which dynamically adjusts its kernel conditioned on input data using a dedicated conditioning neural network. We design two simple conditioning networks that maintain shift equivariance in the adaptive convolution operation. The dynamic nature of data-dependent convolution kernel, coupled with gating operations, grants Orchid high expressivity while maintaining efficiency and quasilinear scalability for long sequences. We rigorously evaluate Orchid across multiple domains, including language modeling and image classification, to showcase its performance and generality. Our experiments demonstrate that Orchid architecture not only outperforms traditional attention-based architectures such as BERT and Vision Transformers with smaller model sizes, but also extends the feasible sequence length beyond the limitations of the dense attention layers. This achievement represents a significant step towards more efficient and scalable deep learning models for sequence modeling.","sentences":["In the rapidly evolving landscape of deep learning, the quest for models that balance expressivity with computational efficiency has never been more critical.","This paper introduces Orchid, a novel architecture that reimagines sequence modeling by incorporating a new data-dependent convolution mechanism.","Orchid is designed to address the inherent limitations of traditional attention mechanisms, particularly their quadratic complexity, without compromising the ability to capture long-range dependencies and in-context learning.","At the core of Orchid lies the data-dependent convolution layer, which dynamically adjusts its kernel conditioned on input data using a dedicated conditioning neural network.","We design two simple conditioning networks that maintain shift equivariance in the adaptive convolution operation.","The dynamic nature of data-dependent convolution kernel, coupled with gating operations, grants Orchid high expressivity while maintaining efficiency and quasilinear scalability for long sequences.","We rigorously evaluate Orchid across multiple domains, including language modeling and image classification, to showcase its performance and generality.","Our experiments demonstrate that Orchid architecture not only outperforms traditional attention-based architectures such as BERT and Vision Transformers with smaller model sizes, but also extends the feasible sequence length beyond the limitations of the dense attention layers.","This achievement represents a significant step towards more efficient and scalable deep learning models for sequence modeling."],"url":"http://arxiv.org/abs/2402.18508v1"}
{"created":"2024-02-28 17:25:06","title":"ROG$_{PL}$: Robust Open-Set Graph Learning via Region-Based Prototype Learning","abstract":"Open-set graph learning is a practical task that aims to classify the known class nodes and to identify unknown class samples as unknowns. Conventional node classification methods usually perform unsatisfactorily in open-set scenarios due to the complex data they encounter, such as out-of-distribution (OOD) data and in-distribution (IND) noise. OOD data are samples that do not belong to any known classes. They are outliers if they occur in training (OOD noise), and open-set samples if they occur in testing. IND noise are training samples which are assigned incorrect labels. The existence of IND noise and OOD noise is prevalent, which usually cause the ambiguity problem, including the intra-class variety problem and the inter-class confusion problem. Thus, to explore robust open-set learning methods is necessary and difficult, and it becomes even more difficult for non-IID graph data.To this end, we propose a unified framework named ROG$_{PL}$ to achieve robust open-set learning on complex noisy graph data, by introducing prototype learning. In specific, ROG$_{PL}$ consists of two modules, i.e., denoising via label propagation and open-set prototype learning via regions. The first module corrects noisy labels through similarity-based label propagation and removes low-confidence samples, to solve the intra-class variety problem caused by noise. The second module learns open-set prototypes for each known class via non-overlapped regions and remains both interior and border prototypes to remedy the inter-class confusion problem.The two modules are iteratively updated under the constraints of classification loss and prototype diversity loss. To the best of our knowledge, the proposed ROG$_{PL}$ is the first robust open-set node classification method for graph data with complex noise.","sentences":["Open-set graph learning is a practical task that aims to classify the known class nodes and to identify unknown class samples as unknowns.","Conventional node classification methods usually perform unsatisfactorily in open-set scenarios due to the complex data they encounter, such as out-of-distribution (OOD) data and in-distribution (IND) noise.","OOD data are samples that do not belong to any known classes.","They are outliers if they occur in training (OOD noise), and open-set samples if they occur in testing.","IND noise are training samples which are assigned incorrect labels.","The existence of IND noise and OOD noise is prevalent, which usually cause the ambiguity problem, including the intra-class variety problem and the inter-class confusion problem.","Thus, to explore robust open-set learning methods is necessary and difficult, and it becomes even more difficult for non-IID graph data.","To this end, we propose a unified framework named ROG$_{PL}$ to achieve robust open-set learning on complex noisy graph data, by introducing prototype learning.","In specific, ROG$_{PL}$ consists of two modules, i.e., denoising via label propagation and open-set prototype learning via regions.","The first module corrects noisy labels through similarity-based label propagation and removes low-confidence samples, to solve the intra-class variety problem caused by noise.","The second module learns open-set prototypes for each known class via non-overlapped regions and remains both interior and border prototypes to remedy the inter-class confusion problem.","The two modules are iteratively updated under the constraints of classification loss and prototype diversity loss.","To the best of our knowledge, the proposed ROG$_{PL}$ is the first robust open-set node classification method for graph data with complex noise."],"url":"http://arxiv.org/abs/2402.18495v1"}
{"created":"2024-02-28 17:21:02","title":"Sunshine to Rainstorm: Cross-Weather Knowledge Distillation for Robust 3D Object Detection","abstract":"LiDAR-based 3D object detection models have traditionally struggled under rainy conditions due to the degraded and noisy scanning signals. Previous research has attempted to address this by simulating the noise from rain to improve the robustness of detection models. However, significant disparities exist between simulated and actual rain-impacted data points. In this work, we propose a novel rain simulation method, termed DRET, that unifies Dynamics and Rainy Environment Theory to provide a cost-effective means of expanding the available realistic rain data for 3D detection training. Furthermore, we present a Sunny-to-Rainy Knowledge Distillation (SRKD) approach to enhance 3D detection under rainy conditions. Extensive experiments on the WaymoOpenDataset large-scale dataset show that, when combined with the state-of-the-art DSVT model and other classical 3D detectors, our proposed framework demonstrates significant detection accuracy improvements, without losing efficiency. Remarkably, our framework also improves detection capabilities under sunny conditions, therefore offering a robust solution for 3D detection regardless of whether the weather is rainy or sunny","sentences":["LiDAR-based 3D object detection models have traditionally struggled under rainy conditions due to the degraded and noisy scanning signals.","Previous research has attempted to address this by simulating the noise from rain to improve the robustness of detection models.","However, significant disparities exist between simulated and actual rain-impacted data points.","In this work, we propose a novel rain simulation method, termed DRET, that unifies Dynamics and Rainy Environment Theory to provide a cost-effective means of expanding the available realistic rain data for 3D detection training.","Furthermore, we present a Sunny-to-Rainy Knowledge Distillation (SRKD) approach to enhance 3D detection under rainy conditions.","Extensive experiments on the WaymoOpenDataset large-scale dataset show that, when combined with the state-of-the-art DSVT model and other classical 3D detectors, our proposed framework demonstrates significant detection accuracy improvements, without losing efficiency.","Remarkably, our framework also improves detection capabilities under sunny conditions, therefore offering a robust solution for 3D detection regardless of whether the weather is rainy or sunny"],"url":"http://arxiv.org/abs/2402.18493v1"}
{"created":"2024-02-28 17:19:26","title":"Dynamical Regimes of Diffusion Models","abstract":"Using statistical physics methods, we study generative diffusion models in the regime where the dimension of space and the number of data are large, and the score function has been trained optimally. Our analysis reveals three distinct dynamical regimes during the backward generative diffusion process. The generative dynamics, starting from pure noise, encounters first a 'speciation' transition where the gross structure of data is unraveled, through a mechanism similar to symmetry breaking in phase transitions. It is followed at later time by a 'collapse' transition where the trajectories of the dynamics become attracted to one of the memorized data points, through a mechanism which is similar to the condensation in a glass phase. For any dataset, the speciation time can be found from a spectral analysis of the correlation matrix, and the collapse time can be found from the estimation of an 'excess entropy' in the data. The dependence of the collapse time on the dimension and number of data provides a thorough characterization of the curse of dimensionality for diffusion models. Analytical solutions for simple models like high-dimensional Gaussian mixtures substantiate these findings and provide a theoretical framework, while extensions to more complex scenarios and numerical validations with real datasets confirm the theoretical predictions.","sentences":["Using statistical physics methods, we study generative diffusion models in the regime where the dimension of space and the number of data are large, and the score function has been trained optimally.","Our analysis reveals three distinct dynamical regimes during the backward generative diffusion process.","The generative dynamics, starting from pure noise, encounters first a 'speciation' transition where the gross structure of data is unraveled, through a mechanism similar to symmetry breaking in phase transitions.","It is followed at later time by a 'collapse' transition where the trajectories of the dynamics become attracted to one of the memorized data points, through a mechanism which is similar to the condensation in a glass phase.","For any dataset, the speciation time can be found from a spectral analysis of the correlation matrix, and the collapse time can be found from the estimation of an 'excess entropy' in the data.","The dependence of the collapse time on the dimension and number of data provides a thorough characterization of the curse of dimensionality for diffusion models.","Analytical solutions for simple models like high-dimensional Gaussian mixtures substantiate these findings and provide a theoretical framework, while extensions to more complex scenarios and numerical validations with real datasets confirm the theoretical predictions."],"url":"http://arxiv.org/abs/2402.18491v1"}
{"created":"2024-02-28 17:18:38","title":"TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding","abstract":"The limited scale of current 3D shape datasets hinders the advancements in 3D shape understanding, and motivates multi-modal learning approaches which transfer learned knowledge from data-abundant 2D image and language modalities to 3D shapes. However, even though the image and language representations have been aligned by cross-modal models like CLIP, we find that the image modality fails to contribute as much as the language in existing multi-modal 3D representation learning methods. This is attributed to the domain shift in the 2D images and the distinct focus of each modality. To more effectively leverage both modalities in the pre-training, we introduce TriAdapter Multi-Modal Learning (TAMM) -- a novel two-stage learning approach based on three synergetic adapters. First, our CLIP Image Adapter mitigates the domain gap between 3D-rendered images and natural images, by adapting the visual representations of CLIP for synthetic image-text pairs. Subsequently, our Dual Adapters decouple the 3D shape representation space into two complementary sub-spaces: one focusing on visual attributes and the other for semantic understanding, which ensure a more comprehensive and effective multi-modal pre-training. Extensive experiments demonstrate that TAMM consistently enhances 3D representations for a wide range of 3D encoder architectures, pre-training datasets, and downstream tasks. Notably, we boost the zero-shot classification accuracy on Objaverse-LVIS from 46.8 to 50.7, and improve the 5-way 10-shot linear probing classification accuracy on ModelNet40 from 96.1 to 99.0. Project page: \\url{https://alanzhangcs.github.io/tamm-page}.","sentences":["The limited scale of current 3D shape datasets hinders the advancements in 3D shape understanding, and motivates multi-modal learning approaches which transfer learned knowledge from data-abundant 2D image and language modalities to 3D shapes.","However, even though the image and language representations have been aligned by cross-modal models like CLIP, we find that the image modality fails to contribute as much as the language in existing multi-modal 3D representation learning methods.","This is attributed to the domain shift in the 2D images and the distinct focus of each modality.","To more effectively leverage both modalities in the pre-training, we introduce TriAdapter Multi-Modal Learning (TAMM) -- a novel two-stage learning approach based on three synergetic adapters.","First, our CLIP Image Adapter mitigates the domain gap between 3D-rendered images and natural images, by adapting the visual representations of CLIP for synthetic image-text pairs.","Subsequently, our Dual Adapters decouple the 3D shape representation space into two complementary sub-spaces: one focusing on visual attributes and the other for semantic understanding, which ensure a more comprehensive and effective multi-modal pre-training.","Extensive experiments demonstrate that TAMM consistently enhances 3D representations for a wide range of 3D encoder architectures, pre-training datasets, and downstream tasks.","Notably, we boost the zero-shot classification accuracy on Objaverse-LVIS from 46.8 to 50.7, and improve the 5-way 10-shot linear probing classification accuracy on ModelNet40 from 96.1 to 99.0.","Project page: \\url{https://alanzhangcs.github.io/tamm-page}."],"url":"http://arxiv.org/abs/2402.18490v1"}
{"created":"2024-02-28 16:59:35","title":"NewsQs: Multi-Source Question Generation for the Inquiring Mind","abstract":"We present NewsQs (news-cues), a dataset that provides question-answer pairs for multiple news documents. To create NewsQs, we augment a traditional multi-document summarization dataset with questions automatically generated by a T5-Large model fine-tuned on FAQ-style news articles from the News On the Web corpus. We show that fine-tuning a model with control codes produces questions that are judged acceptable more often than the same model without them as measured through human evaluation. We use a QNLI model with high correlation with human annotations to filter our data. We release our final dataset of high-quality questions, answers, and document clusters as a resource for future work in query-based multi-document summarization.","sentences":["We present NewsQs","(news-cues), a dataset that provides question-answer pairs for multiple news documents.","To create NewsQs, we augment a traditional multi-document summarization dataset with questions automatically generated by a T5-Large model fine-tuned on FAQ-style news articles from the News On the Web corpus.","We show that fine-tuning a model with control codes produces questions that are judged acceptable more often than the same model without them as measured through human evaluation.","We use a QNLI model with high correlation with human annotations to filter our data.","We release our final dataset of high-quality questions, answers, and document clusters as a resource for future work in query-based multi-document summarization."],"url":"http://arxiv.org/abs/2402.18479v1"}
{"created":"2024-02-28 16:58:31","title":"Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes","abstract":"Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via \"which variables enter the differential of which other variables\". In this paper, we develop a kernel-based test of conditional independence (CI) on \"path-space\" -- solutions to SDEs -- by leveraging recent advances in signature kernels. We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space. Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph. Assuming faithfulness and a CI oracle, our algorithm is sound and complete. We empirically verify that our developed CI test in conjunction with the causal discovery algorithm reliably outperforms baselines across a range of settings.","sentences":["Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance.","Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via \"which variables enter the differential of which other variables\".","In this paper, we develop a kernel-based test of conditional independence (CI) on \"path-space\" -- solutions to SDEs -- by leveraging recent advances in signature kernels.","We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space.","Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph.","Assuming faithfulness and a CI oracle, our algorithm is sound and complete.","We empirically verify that our developed CI test in conjunction with the causal discovery algorithm reliably outperforms baselines across a range of settings."],"url":"http://arxiv.org/abs/2402.18477v1"}
{"created":"2024-02-28 16:57:22","title":"IBD: Alleviating Hallucinations in Large Vision-Language Models via Image-Biased Decoding","abstract":"Despite achieving rapid developments and with widespread applications, Large Vision-Language Models (LVLMs) confront a serious challenge of being prone to generating hallucinations. An over-reliance on linguistic priors has been identified as a key factor leading to these hallucinations. In this paper, we propose to alleviate this problem by introducing a novel image-biased decoding (IBD) technique. Our method derives the next-token probability distribution by contrasting predictions from a conventional LVLM with those of an image-biased LVLM, thereby amplifying the correct information highly correlated with image content while mitigating the hallucinatory errors caused by excessive dependence on text. We further conduct a comprehensive statistical analysis to validate the reliability of our method, and design an adaptive adjustment strategy to achieve robust and flexible handling under varying conditions. Experimental results across multiple evaluation metrics verify that our method, despite not requiring additional training data and only with a minimal increase in model parameters, can significantly reduce hallucinations in LVLMs and enhance the truthfulness of the generated response.","sentences":["Despite achieving rapid developments and with widespread applications, Large Vision-Language Models (LVLMs) confront a serious challenge of being prone to generating hallucinations.","An over-reliance on linguistic priors has been identified as a key factor leading to these hallucinations.","In this paper, we propose to alleviate this problem by introducing a novel image-biased decoding (IBD) technique.","Our method derives the next-token probability distribution by contrasting predictions from a conventional LVLM with those of an image-biased LVLM, thereby amplifying the correct information highly correlated with image content while mitigating the hallucinatory errors caused by excessive dependence on text.","We further conduct a comprehensive statistical analysis to validate the reliability of our method, and design an adaptive adjustment strategy to achieve robust and flexible handling under varying conditions.","Experimental results across multiple evaluation metrics verify that our method, despite not requiring additional training data and only with a minimal increase in model parameters, can significantly reduce hallucinations in LVLMs and enhance the truthfulness of the generated response."],"url":"http://arxiv.org/abs/2402.18476v1"}
{"created":"2024-02-28 16:44:26","title":"A Higher-Order Lens for Social Systems","abstract":"Despite the widespread adoption of higher-order mathematical structures such as hypergraphs, methodological tools for their analysis lag behind those for traditional graphs. This work addresses a critical gap in this context by proposing two micro-canonical random null models for directed hypergraphs: the Directed Hypergraph Configuration Model (DHCM) and the Directed Hypergraph JOINT Model (DHJM). These models preserve essential structural properties of directed hypergraphs such as node in- and out-degree sequences and hyperedge head and tail size sequences, or their joint tensor. We also describe two efficient MCMC algorithms, NuDHy-Degs and NuDHy-JOINT, to sample random hypergraphs from these ensembles.   To showcase the interdisciplinary applicability of the proposed null models, we present three distinct use cases in sociology, epidemiology, and economics. First, we reveal the oscillatory behavior of increased homophily in opposition parties in the US Congress over a 40-year span, emphasizing the role of higher-order structures in quantifying political group homophily. Second, we investigate non-linear contagion in contact hyper-networks, demonstrating that disparities between simulations and theoretical predictions can be explained by considering higher-order joint degree distributions. Last, we examine the economic complexity of countries in the global trade network, showing that local network properties preserved by NuDHy explain the main structural economic complexity indexes.   This work pioneers the development of null models for directed hypergraphs, addressing the intricate challenges posed by their complex entity relations, and providing a versatile suite of tools for researchers across various domains.","sentences":["Despite the widespread adoption of higher-order mathematical structures such as hypergraphs, methodological tools for their analysis lag behind those for traditional graphs.","This work addresses a critical gap in this context by proposing two micro-canonical random null models for directed hypergraphs: the Directed Hypergraph Configuration Model (DHCM) and the Directed Hypergraph JOINT Model (DHJM).","These models preserve essential structural properties of directed hypergraphs such as node in- and out-degree sequences and hyperedge head and tail size sequences, or their joint tensor.","We also describe two efficient MCMC algorithms, NuDHy-Degs and NuDHy-JOINT, to sample random hypergraphs from these ensembles.   ","To showcase the interdisciplinary applicability of the proposed null models, we present three distinct use cases in sociology, epidemiology, and economics.","First, we reveal the oscillatory behavior of increased homophily in opposition parties in the US Congress over a 40-year span, emphasizing the role of higher-order structures in quantifying political group homophily.","Second, we investigate non-linear contagion in contact hyper-networks, demonstrating that disparities between simulations and theoretical predictions can be explained by considering higher-order joint degree distributions.","Last, we examine the economic complexity of countries in the global trade network, showing that local network properties preserved by NuDHy explain the main structural economic complexity indexes.   ","This work pioneers the development of null models for directed hypergraphs, addressing the intricate challenges posed by their complex entity relations, and providing a versatile suite of tools for researchers across various domains."],"url":"http://arxiv.org/abs/2402.18470v1"}
{"created":"2024-02-28 16:44:10","title":"Interval-Constrained Bipartite Matching over Time","abstract":"Interval-constrained online bipartite matching problem frequently occurs in medical appointment scheduling: unit-time jobs representing patients arrive online and are assigned to a time slot within their given time interval. We consider a variant of this problem where reassignments are allowed and extend it by a notion of current time, which is decoupled from the job arrival events. As jobs appear, the current point in time gradually advances. Jobs that are assigned to the current time unit become processed, which fixes part of the matching and disables these jobs or slots for reassignments in future steps. We refer to these time-dependent restrictions on reassignments as the over-time property.   We show that FirstFit with reassignments according to the shortest augmenting path rule is $\\frac{2}{3}$-competitive with respect to the matching cardinality, and that the bound is tight. Interestingly, this bound holds even if the number of reassignments per job is bound by a constant. For the number of reassignments performed by the algorithm, we show that it is in $\\Omega(n \\log n)$ in the worst case, where $n$ is the number of patients or jobs on the online side. This result is in line with lower bounds for the number of reassignments in online bipartite matching with reassignments, and, similarly to this previous work, we also conjecture that this bound should be tight. Known upper bounds like the $O(n \\log^2 n)$ for online bipartite matching with reassignments by Bernstein, Holm, and Rotenberg do not transfer directly: while our interval constraints simplify the problem, the over-time property restricts the set of possible reassignments.","sentences":["Interval-constrained online bipartite matching problem frequently occurs in medical appointment scheduling: unit-time jobs representing patients arrive online and are assigned to a time slot within their given time interval.","We consider a variant of this problem where reassignments are allowed and extend it by a notion of current time, which is decoupled from the job arrival events.","As jobs appear, the current point in time gradually advances.","Jobs that are assigned to the current time unit become processed, which fixes part of the matching and disables these jobs or slots for reassignments in future steps.","We refer to these time-dependent restrictions on reassignments as the over-time property.   ","We show that FirstFit with reassignments according to the shortest augmenting path rule is $\\frac{2}{3}$-competitive with respect to the matching cardinality, and that the bound is tight.","Interestingly, this bound holds even if the number of reassignments per job is bound by a constant.","For the number of reassignments performed by the algorithm, we show that it is in $\\Omega(n \\log n)$ in the worst case, where $n$ is the number of patients or jobs on the online side.","This result is in line with lower bounds for the number of reassignments in online bipartite matching with reassignments, and, similarly to this previous work, we also conjecture that this bound should be tight.","Known upper bounds like the $O(n \\log^2 n)$ for online bipartite matching with reassignments by Bernstein, Holm, and Rotenberg do not transfer directly: while our interval constraints simplify the problem, the over-time property restricts the set of possible reassignments."],"url":"http://arxiv.org/abs/2402.18469v1"}
{"created":"2024-02-28 16:16:51","title":"Prompt-Driven Dynamic Object-Centric Learning for Single Domain Generalization","abstract":"Single-domain generalization aims to learn a model from single source domain data to achieve generalized performance on other unseen target domains. Existing works primarily focus on improving the generalization ability of static networks. However, static networks are unable to dynamically adapt to the diverse variations in different image scenes, leading to limited generalization capability. Different scenes exhibit varying levels of complexity, and the complexity of images further varies significantly in cross-domain scenarios. In this paper, we propose a dynamic object-centric perception network based on prompt learning, aiming to adapt to the variations in image complexity. Specifically, we propose an object-centric gating module based on prompt learning to focus attention on the object-centric features guided by the various scene prompts. Then, with the object-centric gating masks, the dynamic selective module dynamically selects highly correlated feature regions in both spatial and channel dimensions enabling the model to adaptively perceive object-centric relevant features, thereby enhancing the generalization capability. Extensive experiments were conducted on single-domain generalization tasks in image classification and object detection. The experimental results demonstrate that our approach outperforms state-of-the-art methods, which validates the effectiveness and generally of our proposed method.","sentences":["Single-domain generalization aims to learn a model from single source domain data to achieve generalized performance on other unseen target domains.","Existing works primarily focus on improving the generalization ability of static networks.","However, static networks are unable to dynamically adapt to the diverse variations in different image scenes, leading to limited generalization capability.","Different scenes exhibit varying levels of complexity, and the complexity of images further varies significantly in cross-domain scenarios.","In this paper, we propose a dynamic object-centric perception network based on prompt learning, aiming to adapt to the variations in image complexity.","Specifically, we propose an object-centric gating module based on prompt learning to focus attention on the object-centric features guided by the various scene prompts.","Then, with the object-centric gating masks, the dynamic selective module dynamically selects highly correlated feature regions in both spatial and channel dimensions enabling the model to adaptively perceive object-centric relevant features, thereby enhancing the generalization capability.","Extensive experiments were conducted on single-domain generalization tasks in image classification and object detection.","The experimental results demonstrate that our approach outperforms state-of-the-art methods, which validates the effectiveness and generally of our proposed method."],"url":"http://arxiv.org/abs/2402.18447v1"}
{"created":"2024-02-28 16:15:57","title":"HyperFedNet: Communication-Efficient Personalized Federated Learning Via Hypernetwork","abstract":"There are still many challenges in Federated Learning (FL). First, during the model update process, the model parameters on the local user need to be sent to the server for aggregation. This involves the consumption of network bandwidth, especially when the number of users participating in FL is large. High communication costs may limit the application of FL in certain scenarios. Secondly, since users participating in FL usually have different data distributions, this heterogeneity of data may lead to poor model performance or even failure to converge. Third, privacy and security issues are also challenges that need to be addressed in FL. There is still a risk of information leakage during model aggregation. Malicious users may obtain sensitive information by analyzing communications during model updates or aggregation processes. To address these challenges, we propose HyperFedNet (HFN), an innovative approach that leverages hypernetwork. HFN introduces a paradigm shift in transmission aggregation within FL. Unlike traditional FL methods that transmit a large number of parameters from the main network, HFN reduces the communication burden and improves security by transmitting a compact set of hypernetwork parameters. After the parameters of the hypernetwork are deployed locally to the user, the local database features quantified by the embedding vector can be used as input, and parameters can be dynamically generated for the FL main network through user forward propagation. HFN efficiently reduces communication costs while improving accuracy. Extensive experimentation demonstrates that HFN outperforms traditional FL methods significantly. By seamlessly integrating this concept into the conventional FL algorithm, we achieve even more impressive results compared to the original approach.","sentences":["There are still many challenges in Federated Learning (FL).","First, during the model update process, the model parameters on the local user need to be sent to the server for aggregation.","This involves the consumption of network bandwidth, especially when the number of users participating in FL is large.","High communication costs may limit the application of FL in certain scenarios.","Secondly, since users participating in FL usually have different data distributions, this heterogeneity of data may lead to poor model performance or even failure to converge.","Third, privacy and security issues are also challenges that need to be addressed in FL.","There is still a risk of information leakage during model aggregation.","Malicious users may obtain sensitive information by analyzing communications during model updates or aggregation processes.","To address these challenges, we propose HyperFedNet (HFN), an innovative approach that leverages hypernetwork.","HFN introduces a paradigm shift in transmission aggregation within FL.","Unlike traditional FL methods that transmit a large number of parameters from the main network, HFN reduces the communication burden and improves security by transmitting a compact set of hypernetwork parameters.","After the parameters of the hypernetwork are deployed locally to the user, the local database features quantified by the embedding vector can be used as input, and parameters can be dynamically generated for the FL main network through user forward propagation.","HFN efficiently reduces communication costs while improving accuracy.","Extensive experimentation demonstrates that HFN outperforms traditional FL methods significantly.","By seamlessly integrating this concept into the conventional FL algorithm, we achieve even more impressive results compared to the original approach."],"url":"http://arxiv.org/abs/2402.18445v1"}
{"created":"2024-02-28 16:00:25","title":"Graph Regularized Encoder Training for Extreme Classification","abstract":"Deep extreme classification (XC) aims to train an encoder architecture and an accompanying classifier architecture to tag a data point with the most relevant subset of labels from a very large universe of labels. XC applications in ranking, recommendation and tagging routinely encounter tail labels for which the amount of training data is exceedingly small. Graph convolutional networks (GCN) present a convenient but computationally expensive way to leverage task metadata and enhance model accuracies in these settings. This paper formally establishes that in several use cases, the steep computational cost of GCNs is entirely avoidable by replacing GCNs with non-GCN architectures. The paper notices that in these settings, it is much more effective to use graph data to regularize encoder training than to implement a GCN. Based on these insights, an alternative paradigm RAMEN is presented to utilize graph metadata in XC settings that offers significant performance boosts with zero increase in inference computational costs. RAMEN scales to datasets with up to 1M labels and offers prediction accuracy up to 15% higher on benchmark datasets than state of the art methods, including those that use graph metadata to train GCNs. RAMEN also offers 10% higher accuracy over the best baseline on a proprietary recommendation dataset sourced from click logs of a popular search engine. Code for RAMEN will be released publicly.","sentences":["Deep extreme classification (XC) aims to train an encoder architecture and an accompanying classifier architecture to tag a data point with the most relevant subset of labels from a very large universe of labels.","XC applications in ranking, recommendation and tagging routinely encounter tail labels for which the amount of training data is exceedingly small.","Graph convolutional networks (GCN) present a convenient but computationally expensive way to leverage task metadata and enhance model accuracies in these settings.","This paper formally establishes that in several use cases, the steep computational cost of GCNs is entirely avoidable by replacing GCNs with non-GCN architectures.","The paper notices that in these settings, it is much more effective to use graph data to regularize encoder training than to implement a GCN.","Based on these insights, an alternative paradigm RAMEN is presented to utilize graph metadata in XC settings that offers significant performance boosts with zero increase in inference computational costs.","RAMEN scales to datasets with up to 1M labels and offers prediction accuracy up to 15% higher on benchmark datasets than state of the art methods, including those that use graph metadata to train GCNs.","RAMEN also offers 10% higher accuracy over the best baseline on a proprietary recommendation dataset sourced from click logs of a popular search engine.","Code for RAMEN will be released publicly."],"url":"http://arxiv.org/abs/2402.18434v1"}
{"created":"2024-02-28 15:56:28","title":"Smishing Dataset I: Phishing SMS Dataset from Smishtank.com","abstract":"While smishing (SMS Phishing) attacks have risen to become one of the most common types of social engineering attacks, there is a lack of relevant smishing datasets. One of the biggest challenges in the domain of smishing prevention is the availability of fresh smishing datasets. Additionally, as time persists, smishing campaigns are shut down and the crucial information related to the attack are lost. With the changing nature of smishing attacks, a consistent flow of new smishing examples is needed by both researchers and engineers to create effective defenses. In this paper, we present the community-sourced smishing datasets from the smishtank.com. It provides a wealth of information relevant to combating smishing attacks through the breakdown and analysis of smishing samples at the point of submission. In the contribution of our work, we provide a corpus of 1090 smishing samples that have been publicly submitted through the site. Each message includes information relating to the sender, message body, and any brands referenced in the message. Additionally, when a URL is found, we provide additional information on the domain, VirusTotal results, and a characterization of the URL. Through the open access of fresh smishing data, we empower academia and industries to create robust defenses against this evolving threat.","sentences":["While smishing (SMS Phishing) attacks have risen to become one of the most common types of social engineering attacks, there is a lack of relevant smishing datasets.","One of the biggest challenges in the domain of smishing prevention is the availability of fresh smishing datasets.","Additionally, as time persists, smishing campaigns are shut down and the crucial information related to the attack are lost.","With the changing nature of smishing attacks, a consistent flow of new smishing examples is needed by both researchers and engineers to create effective defenses.","In this paper, we present the community-sourced smishing datasets from the smishtank.com.","It provides a wealth of information relevant to combating smishing attacks through the breakdown and analysis of smishing samples at the point of submission.","In the contribution of our work, we provide a corpus of 1090 smishing samples that have been publicly submitted through the site.","Each message includes information relating to the sender, message body, and any brands referenced in the message.","Additionally, when a URL is found, we provide additional information on the domain, VirusTotal results, and a characterization of the URL.","Through the open access of fresh smishing data, we empower academia and industries to create robust defenses against this evolving threat."],"url":"http://arxiv.org/abs/2402.18430v1"}
{"created":"2024-02-28 15:55:02","title":"Leveraging Diverse Modeling Contexts with Collaborating Learning for Neural Machine Translation","abstract":"Autoregressive (AR) and Non-autoregressive (NAR) models are two types of generative models for Neural Machine Translation (NMT). AR models predict tokens in a word-by-word manner and can effectively capture the distribution of real translations. NAR models predict tokens by extracting bidirectional contextual information which can improve the inference speed but they suffer from performance degradation. Previous works utilized AR models to enhance NAR models by reducing the training data's complexity or incorporating the global information into AR models by virtue of NAR models. However, those investigated methods only take advantage of the contextual information of a single type of model while neglecting the diversity in the contextual information that can be provided by different types of models. In this paper, we propose a novel generic collaborative learning method, DCMCL, where AR and NAR models are treated as collaborators instead of teachers and students. To hierarchically leverage the bilateral contextual information, token-level mutual learning and sequence-level contrastive learning are adopted between AR and NAR models. Extensive experiments on four widely used benchmarks show that the proposed DCMCL method can simultaneously improve both AR and NAR models with up to 1.38 and 2.98 BLEU scores respectively, and can also outperform the current best-unified model with up to 0.97 BLEU scores for both AR and NAR decoding.","sentences":["Autoregressive (AR) and Non-autoregressive (NAR) models are two types of generative models for Neural Machine Translation (NMT).","AR models predict tokens in a word-by-word manner and can effectively capture the distribution of real translations.","NAR models predict tokens by extracting bidirectional contextual information which can improve the inference speed but they suffer from performance degradation.","Previous works utilized AR models to enhance NAR models by reducing the training data's complexity or incorporating the global information into AR models by virtue of NAR models.","However, those investigated methods only take advantage of the contextual information of a single type of model while neglecting the diversity in the contextual information that can be provided by different types of models.","In this paper, we propose a novel generic collaborative learning method, DCMCL, where AR and NAR models are treated as collaborators instead of teachers and students.","To hierarchically leverage the bilateral contextual information, token-level mutual learning and sequence-level contrastive learning are adopted between AR and NAR models.","Extensive experiments on four widely used benchmarks show that the proposed DCMCL method can simultaneously improve both AR and NAR models with up to 1.38 and 2.98 BLEU scores respectively, and can also outperform the current best-unified model with up to 0.97 BLEU scores for both AR and NAR decoding."],"url":"http://arxiv.org/abs/2402.18428v1"}
{"created":"2024-02-28 15:51:05","title":"A Relational Inductive Bias for Dimensional Abstraction in Neural Networks","abstract":"The human cognitive system exhibits remarkable flexibility and generalization capabilities, partly due to its ability to form low-dimensional, compositional representations of the environment. In contrast, standard neural network architectures often struggle with abstract reasoning tasks, overfitting, and requiring extensive data for training. This paper investigates the impact of the relational bottleneck -- a mechanism that focuses processing on relations among inputs -- on the learning of factorized representations conducive to compositional coding and the attendant flexibility of processing. We demonstrate that such a bottleneck not only improves generalization and learning efficiency, but also aligns network performance with human-like behavioral biases. Networks trained with the relational bottleneck developed orthogonal representations of feature dimensions latent in the dataset, reflecting the factorized structure thought to underlie human cognitive flexibility. Moreover, the relational network mimics human biases towards regularity without pre-specified symbolic primitives, suggesting that the bottleneck fosters the emergence of abstract representations that confer flexibility akin to symbols.","sentences":["The human cognitive system exhibits remarkable flexibility and generalization capabilities, partly due to its ability to form low-dimensional, compositional representations of the environment.","In contrast, standard neural network architectures often struggle with abstract reasoning tasks, overfitting, and requiring extensive data for training.","This paper investigates the impact of the relational bottleneck -- a mechanism that focuses processing on relations among inputs -- on the learning of factorized representations conducive to compositional coding and the attendant flexibility of processing.","We demonstrate that such a bottleneck not only improves generalization and learning efficiency, but also aligns network performance with human-like behavioral biases.","Networks trained with the relational bottleneck developed orthogonal representations of feature dimensions latent in the dataset, reflecting the factorized structure thought to underlie human cognitive flexibility.","Moreover, the relational network mimics human biases towards regularity without pre-specified symbolic primitives, suggesting that the bottleneck fosters the emergence of abstract representations that confer flexibility akin to symbols."],"url":"http://arxiv.org/abs/2402.18426v1"}
{"created":"2024-02-28 15:41:12","title":"CafkNet: GNN-Empowered Forward Kinematic Modeling for Cable-Driven Parallel Robots","abstract":"When deploying Cable-Driven Parallel Robots (CDPRs) in practice, one of the challenges is kinematic modeling. Unlike serial mechanisms, CDPRs have a simple inverse kinematics problem but a complex forward kinematics (FK) issue. Therefore, the development of accurate and efficient FK solvers has been a prominent research focus in CDPR applications. By observing the topology within CDPRs, in this letter, we propose a graph-based representation to model CDPRs and introduce CafkNet, a fast and general FK solver, leveraging Graph Neural Network (GNN). Extensive experiments are conducted on 3D and 2D CDPRs across various configurations, including under-constrained, fully-constrained, and over-constrained cases, in both simulation environments and real-world scenarios. The experimental results showcase that CafkNet can learn the internal topological information of CDPRs and accurately solve the FK problem as an FK solver. Furthermore, training the CafkNet model on partial configurations enables zero-shot generalization to other configurations. Lastly, CafkNet effectively bridges the sim2real gap by using both simulation data and part of real-world data. To the best of our knowledge, it is the first study that employs the GNN to solve the FK problem for CDPRs.","sentences":["When deploying Cable-Driven Parallel Robots (CDPRs) in practice, one of the challenges is kinematic modeling.","Unlike serial mechanisms, CDPRs have a simple inverse kinematics problem but a complex forward kinematics (FK) issue.","Therefore, the development of accurate and efficient FK solvers has been a prominent research focus in CDPR applications.","By observing the topology within CDPRs, in this letter, we propose a graph-based representation to model CDPRs and introduce CafkNet, a fast and general FK solver, leveraging Graph Neural Network (GNN).","Extensive experiments are conducted on 3D and 2D CDPRs across various configurations, including under-constrained, fully-constrained, and over-constrained cases, in both simulation environments and real-world scenarios.","The experimental results showcase that CafkNet can learn the internal topological information of CDPRs and accurately solve the FK problem as an FK solver.","Furthermore, training the CafkNet model on partial configurations enables zero-shot generalization to other configurations.","Lastly, CafkNet effectively bridges the sim2real gap by using both simulation data and part of real-world data.","To the best of our knowledge, it is the first study that employs the GNN to solve the FK problem for CDPRs."],"url":"http://arxiv.org/abs/2402.18420v1"}
{"created":"2024-02-28 15:31:45","title":"Unsupervised Cross-Domain Image Retrieval via Prototypical Optimal Transport","abstract":"Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images sharing the same category across diverse domains without relying on labeled data. Prior approaches have typically decomposed the UCIR problem into two distinct tasks: intra-domain representation learning and cross-domain feature alignment. However, these segregated strategies overlook the potential synergies between these tasks. This paper introduces ProtoOT, a novel Optimal Transport formulation explicitly tailored for UCIR, which integrates intra-domain feature representation learning and cross-domain alignment into a unified framework. ProtoOT leverages the strengths of the K-means clustering method to effectively manage distribution imbalances inherent in UCIR. By utilizing K-means for generating initial prototypes and approximating class marginal distributions, we modify the constraints in Optimal Transport accordingly, significantly enhancing its performance in UCIR scenarios. Furthermore, we incorporate contrastive learning into the ProtoOT framework to further improve representation learning. This encourages local semantic consistency among features with similar semantics, while also explicitly enforcing separation between features and unmatched prototypes, thereby enhancing global discriminativeness. ProtoOT surpasses existing state-of-the-art methods by a notable margin across benchmark datasets. Notably, on DomainNet, ProtoOT achieves an average P@200 enhancement of 24.44%, and on Office-Home, it demonstrates a P@15 improvement of 12.12%. Code is available at https://github.com/HCVLAB/ProtoOT.","sentences":["Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images sharing the same category across diverse domains without relying on labeled data.","Prior approaches have typically decomposed the UCIR problem into two distinct tasks: intra-domain representation learning and cross-domain feature alignment.","However, these segregated strategies overlook the potential synergies between these tasks.","This paper introduces ProtoOT, a novel Optimal Transport formulation explicitly tailored for UCIR, which integrates intra-domain feature representation learning and cross-domain alignment into a unified framework.","ProtoOT leverages the strengths of the K-means clustering method to effectively manage distribution imbalances inherent in UCIR.","By utilizing K-means for generating initial prototypes and approximating class marginal distributions, we modify the constraints in Optimal Transport accordingly, significantly enhancing its performance in UCIR scenarios.","Furthermore, we incorporate contrastive learning into the ProtoOT framework to further improve representation learning.","This encourages local semantic consistency among features with similar semantics, while also explicitly enforcing separation between features and unmatched prototypes, thereby enhancing global discriminativeness.","ProtoOT surpasses existing state-of-the-art methods by a notable margin across benchmark datasets.","Notably, on DomainNet, ProtoOT achieves an average P@200 enhancement of 24.44%, and on Office-Home, it demonstrates a P@15 improvement of 12.12%.","Code is available at https://github.com/HCVLAB/ProtoOT."],"url":"http://arxiv.org/abs/2402.18411v1"}
{"created":"2024-02-28 15:24:58","title":"A Modular System for Enhanced Robustness of Multimedia Understanding Networks via Deep Parametric Estimation","abstract":"In multimedia understanding tasks, corrupted samples pose a critical challenge, because when fed to machine learning models they lead to performance degradation. In the past, three groups of approaches have been proposed to handle noisy data: i) enhancer and denoiser modules to improve the quality of the noisy data, ii) data augmentation approaches, and iii) domain adaptation strategies. All the aforementioned approaches come with drawbacks that limit their applicability; the first has high computational costs and requires pairs of clean-corrupted data for training, while the others only allow deployment of the same task/network they were trained on (\\ie, when upstream and downstream task/network are the same). In this paper, we propose SyMPIE to solve these shortcomings. To this end, we design a small, modular, and efficient (just 2GFLOPs to process a Full HD image) system to enhance input data for robust downstream multimedia understanding with minimal computational cost. Our SyMPIE is pre-trained on an upstream task/network that should not match the downstream ones and does not need paired clean-corrupted samples. Our key insight is that most input corruptions found in real-world tasks can be modeled through global operations on color channels of images or spatial filters with small kernels. We validate our approach on multiple datasets and tasks, such as image classification (on ImageNetC, ImageNetC-Bar, VizWiz, and a newly proposed mixed corruption benchmark named ImageNetC-mixed) and semantic segmentation (on Cityscapes, ACDC, and DarkZurich) with consistent improvements of about 5\\% relative accuracy gain across the board. The code of our approach and the new ImageNetC-mixed benchmark will be made available upon publication.","sentences":["In multimedia understanding tasks, corrupted samples pose a critical challenge, because when fed to machine learning models they lead to performance degradation.","In the past, three groups of approaches have been proposed to handle noisy data: i) enhancer and denoiser modules to improve the quality of the noisy data, ii) data augmentation approaches, and iii) domain adaptation strategies.","All the aforementioned approaches come with drawbacks that limit their applicability; the first has high computational costs and requires pairs of clean-corrupted data for training, while the others only allow deployment of the same task/network they were trained on (\\ie, when upstream and downstream task/network are the same).","In this paper, we propose SyMPIE to solve these shortcomings.","To this end, we design a small, modular, and efficient (just 2GFLOPs to process a Full HD image) system to enhance input data for robust downstream multimedia understanding with minimal computational cost.","Our SyMPIE is pre-trained on an upstream task/network that should not match the downstream ones and does not need paired clean-corrupted samples.","Our key insight is that most input corruptions found in real-world tasks can be modeled through global operations on color channels of images or spatial filters with small kernels.","We validate our approach on multiple datasets and tasks, such as image classification (on ImageNetC, ImageNetC-Bar, VizWiz, and a newly proposed mixed corruption benchmark named ImageNetC-mixed) and semantic segmentation (on Cityscapes, ACDC, and DarkZurich) with consistent improvements of about 5\\% relative accuracy gain across the board.","The code of our approach and the new ImageNetC-mixed benchmark will be made available upon publication."],"url":"http://arxiv.org/abs/2402.18402v1"}
{"created":"2024-02-28 15:15:39","title":"Decomposed Prompting: Unveiling Multilingual Linguistic Structure Knowledge in English-Centric Large Language Models","abstract":"Despite the predominance of English in their training data, English-centric Large Language Models (LLMs) like GPT-3 and LLaMA display a remarkable ability to perform multilingual tasks, raising questions about the depth and nature of their cross-lingual capabilities. This paper introduces the decomposed prompting approach to probe the linguistic structure understanding of these LLMs in sequence labeling tasks. Diverging from the single text-to-text prompt, our method generates for each token of the input sentence an individual prompt which asks for its linguistic label. We assess our method on the Universal Dependencies part-of-speech tagging dataset for 38 languages, utilizing both English-centric and multilingual LLMs. Our findings show that decomposed prompting surpasses the iterative prompting baseline in efficacy and efficiency under zero- and few-shot settings. Further analysis reveals the influence of evaluation methods and the use of instructions in prompts. Our multilingual investigation shows that English-centric language models perform better on average than multilingual models. Our study offers insights into the multilingual transferability of English-centric LLMs, contributing to the understanding of their multilingual linguistic knowledge.","sentences":["Despite the predominance of English in their training data, English-centric Large Language Models (LLMs) like GPT-3 and LLaMA display a remarkable ability to perform multilingual tasks, raising questions about the depth and nature of their cross-lingual capabilities.","This paper introduces the decomposed prompting approach to probe the linguistic structure understanding of these LLMs in sequence labeling tasks.","Diverging from the single text-to-text prompt, our method generates for each token of the input sentence an individual prompt which asks for its linguistic label.","We assess our method on the Universal Dependencies part-of-speech tagging dataset for 38 languages, utilizing both English-centric and multilingual LLMs.","Our findings show that decomposed prompting surpasses the iterative prompting baseline in efficacy and efficiency under zero- and few-shot settings.","Further analysis reveals the influence of evaluation methods and the use of instructions in prompts.","Our multilingual investigation shows that English-centric language models perform better on average than multilingual models.","Our study offers insights into the multilingual transferability of English-centric LLMs, contributing to the understanding of their multilingual linguistic knowledge."],"url":"http://arxiv.org/abs/2402.18397v1"}
{"created":"2024-02-28 15:11:02","title":"Neuromorphic Event-Driven Semantic Communication in Microgrids","abstract":"Synergies between advanced communications, computing and artificial intelligence are unraveling new directions of coordinated operation and resiliency in microgrids. On one hand, coordination among sources is facilitated by distributed, privacy-minded processing at multiple locations, whereas on the other hand, it also creates exogenous data arrival paths for adversaries that can lead to cyber-physical attacks amongst other reliability issues in the communication layer. This long-standing problem necessitates new intrinsic ways of exchanging information between converters through power lines to optimize the system's control performance. Going beyond the existing power and data co-transfer technologies that are limited by efficiency and scalability concerns, this paper proposes neuromorphic learning to implant communicative features using spiking neural networks (SNNs) at each node, which is trained collaboratively in an online manner simply using the power exchanges between the nodes. As opposed to the conventional neuromorphic sensors that operate with spiking signals, we employ an event-driven selective process to collect sparse data for training of SNNs. Finally, its multi-fold effectiveness and reliable performance is validated under simulation conditions with different microgrid topologies and components to establish a new direction in the sense-actuate-compute cycle for power electronic dominated grids and microgrids.","sentences":["Synergies between advanced communications, computing and artificial intelligence are unraveling new directions of coordinated operation and resiliency in microgrids.","On one hand, coordination among sources is facilitated by distributed, privacy-minded processing at multiple locations, whereas on the other hand, it also creates exogenous data arrival paths for adversaries that can lead to cyber-physical attacks amongst other reliability issues in the communication layer.","This long-standing problem necessitates new intrinsic ways of exchanging information between converters through power lines to optimize the system's control performance.","Going beyond the existing power and data co-transfer technologies that are limited by efficiency and scalability concerns, this paper proposes neuromorphic learning to implant communicative features using spiking neural networks (SNNs) at each node, which is trained collaboratively in an online manner simply using the power exchanges between the nodes.","As opposed to the conventional neuromorphic sensors that operate with spiking signals, we employ an event-driven selective process to collect sparse data for training of SNNs.","Finally, its multi-fold effectiveness and reliable performance is validated under simulation conditions with different microgrid topologies and components to establish a new direction in the sense-actuate-compute cycle for power electronic dominated grids and microgrids."],"url":"http://arxiv.org/abs/2402.18390v1"}
{"created":"2024-02-28 15:07:36","title":"Precoding for Multi-Cell ISAC: from Coordinated Beamforming to Coordinated Multipoint and Bi-Static Sensing","abstract":"This paper proposes a framework for designing robust precoders for a multi-input single-output (MISO) system that performs integrated sensing and communication (ISAC) across multiple cells and users. We use Cramer-Rao-Bound (CRB) to measure the sensing performance and derive its expressions for two multi-cell scenarios, namely coordinated beamforming (CBF) and coordinated multi-point (CoMP). In the CBF scheme, a BS shares channel state information (CSI) and estimates target parameters using monostatic sensing. In contrast, a BS in the CoMP scheme shares the CSI and data, allowing bistatic sensing through inter-cell reflection. We consider both block-level (BL) and symbol-level (SL) precoding schemes for both the multi-cell scenarios that are robust to channel state estimation errors. The formulated optimization problems to minimize the CRB in estimating the parameters of a target and maximize the minimum communication signal-to-interference-plus-noise-ratio (SINR) while satisfying a given total transmit power budget are non-convex. We tackle the non-convexity using a combination of semidefinite relaxation (SDR) and alternating optimization (AO) techniques. Simulations suggest that neglecting the inter-cell reflection and communication links degrades the performance of an ISAC system. The CoMP scenario employing SL precoding performs the best, whereas the BL precoding applied in the CBF scenario produces relatively high estimation error for a given minimum SINR value.","sentences":["This paper proposes a framework for designing robust precoders for a multi-input single-output (MISO) system that performs integrated sensing and communication (ISAC) across multiple cells and users.","We use Cramer-Rao-Bound (CRB) to measure the sensing performance and derive its expressions for two multi-cell scenarios, namely coordinated beamforming (CBF) and coordinated multi-point (CoMP).","In the CBF scheme, a BS shares channel state information (CSI) and estimates target parameters using monostatic sensing.","In contrast, a BS in the CoMP scheme shares the CSI and data, allowing bistatic sensing through inter-cell reflection.","We consider both block-level (BL) and symbol-level (SL) precoding schemes for both the multi-cell scenarios that are robust to channel state estimation errors.","The formulated optimization problems to minimize the CRB in estimating the parameters of a target and maximize the minimum communication signal-to-interference-plus-noise-ratio (SINR) while satisfying a given total transmit power budget are non-convex.","We tackle the non-convexity using a combination of semidefinite relaxation (SDR) and alternating optimization (AO) techniques.","Simulations suggest that neglecting the inter-cell reflection and communication links degrades the performance of an ISAC system.","The CoMP scenario employing SL precoding performs the best, whereas the BL precoding applied in the CBF scenario produces relatively high estimation error for a given minimum SINR value."],"url":"http://arxiv.org/abs/2402.18387v1"}
{"created":"2024-02-28 15:05:43","title":"The First Place Solution of WSDM Cup 2024: Leveraging Large Language Models for Conversational Multi-Doc QA","abstract":"Conversational multi-doc question answering aims to answer specific questions based on the retrieved documents as well as the contextual conversations. In this paper, we introduce our winning approach for the \"Conversational Multi-Doc QA\" challenge in WSDM Cup 2024, which exploits the superior natural language understanding and generation capability of Large Language Models (LLMs). We first adapt LLMs to the task, then devise a hybrid training strategy to make the most of in-domain unlabeled data. Moreover, an advanced text embedding model is adopted to filter out potentially irrelevant documents and several approaches are designed and compared for the model ensemble. Equipped with all these techniques, our solution finally ranked 1st place in WSDM Cup 2024, surpassing its rivals to a large extent. The source codes have been released at https://github.com/zhangzhao219/WSDM-Cup-2024.","sentences":["Conversational multi-doc question answering aims to answer specific questions based on the retrieved documents as well as the contextual conversations.","In this paper, we introduce our winning approach for the \"Conversational Multi-Doc QA\" challenge in WSDM Cup 2024, which exploits the superior natural language understanding and generation capability of Large Language Models (LLMs).","We first adapt LLMs to the task, then devise a hybrid training strategy to make the most of in-domain unlabeled data.","Moreover, an advanced text embedding model is adopted to filter out potentially irrelevant documents and several approaches are designed and compared for the model ensemble.","Equipped with all these techniques, our solution finally ranked 1st place in WSDM Cup 2024, surpassing its rivals to a large extent.","The source codes have been released at https://github.com/zhangzhao219/WSDM-Cup-2024."],"url":"http://arxiv.org/abs/2402.18385v1"}
{"created":"2024-02-28 14:52:58","title":"Out-of-Domain Generalization in Dynamical Systems Reconstruction","abstract":"In science we are interested in finding the governing equations, the dynamical rules, underlying empirical phenomena. While traditionally scientific models are derived through cycles of human insight and experimentation, recently deep learning (DL) techniques have been advanced to reconstruct dynamical systems (DS) directly from time series data. State-of-the-art dynamical systems reconstruction (DSR) methods show promise in capturing invariant and long-term properties of observed DS, but their ability to generalize to unobserved domains remains an open challenge. Yet, this is a crucial property we would expect from any viable scientific theory. In this work, we provide a formal framework that addresses generalization in DSR. We explain why and how out-of-domain (OOD) generalization (OODG) in DSR profoundly differs from OODG considered elsewhere in machine learning. We introduce mathematical notions based on topological concepts and ergodic theory to formalize the idea of learnability of a DSR model. We formally prove that black-box DL techniques, without adequate structural priors, generally will not be able to learn a generalizing DSR model. We also show this empirically, considering major classes of DSR algorithms proposed so far, and illustrate where and why they fail to generalize across the whole phase space. Our study provides the first comprehensive mathematical treatment of OODG in DSR, and gives a deeper conceptual understanding of where the fundamental problems in OODG lie and how they could possibly be addressed in practice.","sentences":["In science we are interested in finding the governing equations, the dynamical rules, underlying empirical phenomena.","While traditionally scientific models are derived through cycles of human insight and experimentation, recently deep learning (DL) techniques have been advanced to reconstruct dynamical systems (DS) directly from time series data.","State-of-the-art dynamical systems reconstruction (DSR) methods show promise in capturing invariant and long-term properties of observed DS, but their ability to generalize to unobserved domains remains an open challenge.","Yet, this is a crucial property we would expect from any viable scientific theory.","In this work, we provide a formal framework that addresses generalization in DSR.","We explain why and how out-of-domain (OOD) generalization (OODG) in DSR profoundly differs from OODG considered elsewhere in machine learning.","We introduce mathematical notions based on topological concepts and ergodic theory to formalize the idea of learnability of a DSR model.","We formally prove that black-box DL techniques, without adequate structural priors, generally will not be able to learn a generalizing DSR model.","We also show this empirically, considering major classes of DSR algorithms proposed so far, and illustrate where and why they fail to generalize across the whole phase space.","Our study provides the first comprehensive mathematical treatment of OODG in DSR, and gives a deeper conceptual understanding of where the fundamental problems in OODG lie and how they could possibly be addressed in practice."],"url":"http://arxiv.org/abs/2402.18377v1"}
{"created":"2024-02-28 14:52:15","title":"Tokenization Is More Than Compression","abstract":"Tokenization is a foundational step in Natural Language Processing (NLP) tasks, bridging raw text and language models. Existing tokenization approaches like Byte-Pair Encoding (BPE) originate from the field of data compression, and it has been suggested that the effectiveness of BPE stems from its ability to condense text into a relatively small number of tokens. We test the hypothesis that fewer tokens lead to better downstream performance by introducing PathPiece, a new tokenizer that segments a document's text into the minimum number of tokens for a given vocabulary. Through extensive experimentation we find this hypothesis not to be the case, casting doubt on the understanding of the reasons for effective tokenization. To examine which other factors play a role, we evaluate design decisions across all three phases of tokenization: pre-tokenization, vocabulary construction, and segmentation, offering new insights into the design of effective tokenizers. Specifically, we illustrate the importance of pre-tokenization and the benefits of using BPE to initialize vocabulary construction. We train 64 language models with varying tokenization, ranging in size from 350M to 2.4B parameters, all of which are made publicly available.","sentences":["Tokenization is a foundational step in Natural Language Processing (NLP) tasks, bridging raw text and language models.","Existing tokenization approaches like Byte-Pair Encoding (BPE) originate from the field of data compression, and it has been suggested that the effectiveness of BPE stems from its ability to condense text into a relatively small number of tokens.","We test the hypothesis that fewer tokens lead to better downstream performance by introducing PathPiece, a new tokenizer that segments a document's text into the minimum number of tokens for a given vocabulary.","Through extensive experimentation we find this hypothesis not to be the case, casting doubt on the understanding of the reasons for effective tokenization.","To examine which other factors play a role, we evaluate design decisions across all three phases of tokenization: pre-tokenization, vocabulary construction, and segmentation, offering new insights into the design of effective tokenizers.","Specifically, we illustrate the importance of pre-tokenization and the benefits of using BPE to initialize vocabulary construction.","We train 64 language models with varying tokenization, ranging in size from 350M to 2.4B parameters, all of which are made publicly available."],"url":"http://arxiv.org/abs/2402.18376v1"}
{"created":"2024-02-28 14:33:14","title":"Objective and Interpretable Breast Cosmesis Evaluation with Attention Guided Denoising Diffusion Anomaly Detection Model","abstract":"As advancements in the field of breast cancer treatment continue to progress, the assessment of post-surgical cosmetic outcomes has gained increasing significance due to its substantial impact on patients' quality of life. However, evaluating breast cosmesis presents challenges due to the inherently subjective nature of expert labeling. In this study, we present a novel automated approach, Attention-Guided Denoising Diffusion Anomaly Detection (AG-DDAD), designed to assess breast cosmesis following surgery, addressing the limitations of conventional supervised learning and existing anomaly detection models. Our approach leverages the attention mechanism of the distillation with no label (DINO) self-supervised Vision Transformer (ViT) in combination with a diffusion model to achieve high-quality image reconstruction and precise transformation of discriminative regions. By training the diffusion model on unlabeled data predominantly with normal cosmesis, we adopt an unsupervised anomaly detection perspective to automatically score the cosmesis. Real-world data experiments demonstrate the effectiveness of our method, providing visually appealing representations and quantifiable scores for cosmesis evaluation. Compared to commonly used rule-based programs, our fully automated approach eliminates the need for manual annotations and offers objective evaluation. Moreover, our anomaly detection model exhibits state-of-the-art performance, surpassing existing models in accuracy. Going beyond the scope of breast cosmesis, our research represents a significant advancement in unsupervised anomaly detection within the medical domain, thereby paving the way for future investigations.","sentences":["As advancements in the field of breast cancer treatment continue to progress, the assessment of post-surgical cosmetic outcomes has gained increasing significance due to its substantial impact on patients' quality of life.","However, evaluating breast cosmesis presents challenges due to the inherently subjective nature of expert labeling.","In this study, we present a novel automated approach, Attention-Guided Denoising Diffusion Anomaly Detection (AG-DDAD), designed to assess breast cosmesis following surgery, addressing the limitations of conventional supervised learning and existing anomaly detection models.","Our approach leverages the attention mechanism of the distillation with no label (DINO) self-supervised Vision Transformer (ViT) in combination with a diffusion model to achieve high-quality image reconstruction and precise transformation of discriminative regions.","By training the diffusion model on unlabeled data predominantly with normal cosmesis, we adopt an unsupervised anomaly detection perspective to automatically score the cosmesis.","Real-world data experiments demonstrate the effectiveness of our method, providing visually appealing representations and quantifiable scores for cosmesis evaluation.","Compared to commonly used rule-based programs, our fully automated approach eliminates the need for manual annotations and offers objective evaluation.","Moreover, our anomaly detection model exhibits state-of-the-art performance, surpassing existing models in accuracy.","Going beyond the scope of breast cosmesis, our research represents a significant advancement in unsupervised anomaly detection within the medical domain, thereby paving the way for future investigations."],"url":"http://arxiv.org/abs/2402.18362v1"}
{"created":"2024-02-28 14:26:52","title":"DynaWarp -- Efficient, large-scale log storage and retrieval","abstract":"Modern, large scale monitoring systems have to process and store vast amounts of log data in near real-time. At query time the systems have to find relevant logs based on the content of the log message using support structures that can scale to these amounts of data while still being efficient to use. We present our novel DynaWarp membership sketch, capable of answering Multi-Set Multi-Membership-Queries, that can be used as an alternative to existing indexing structures for streamed log data. In our experiments, DynaWarp required up to 93% less storage space than the tested state-of-the-art inverted index and had up to four orders of magnitude less false-positives than the tested state-of-the-art membership sketch. Additionally, DynaWarp achieved up to 250 times higher query throughput than the tested inverted index and up to 240 times higher query throughput than the tested membership sketch.","sentences":["Modern, large scale monitoring systems have to process and store vast amounts of log data in near real-time.","At query time the systems have to find relevant logs based on the content of the log message using support structures that can scale to these amounts of data while still being efficient to use.","We present our novel DynaWarp membership sketch, capable of answering Multi-Set Multi-Membership-Queries, that can be used as an alternative to existing indexing structures for streamed log data.","In our experiments, DynaWarp required up to 93% less storage space than the tested state-of-the-art inverted index and had up to four orders of magnitude less false-positives than the tested state-of-the-art membership sketch.","Additionally, DynaWarp achieved up to 250 times higher query throughput than the tested inverted index and up to 240 times higher query throughput than the tested membership sketch."],"url":"http://arxiv.org/abs/2402.18355v1"}
{"created":"2024-02-28 14:20:29","title":"Polynomial-time approximation schemes for induced subgraph problems on fractionally tree-independence-number-fragile graphs","abstract":"We investigate a relaxation of the notion of fractional treewidth-fragility, namely fractional tree-independence-number-fragility. In particular, we obtain polynomial-time approximation schemes for meta-problems such as finding a maximum-weight sparse induced subgraph satisfying a given $\\mathsf{CMSO}_2$ formula on fractionally tree-independence-number-fragile graph classes. Our approach unifies and extends several known polynomial-time approximation schemes on seemingly unrelated graph classes, such as classes of intersection graphs of fat objects in a fixed dimension or proper minor-closed classes. We also study the related notion of layered tree-independence number, a relaxation of layered treewidth, and its applications to exact subexponential-time algorithms.","sentences":["We investigate a relaxation of the notion of fractional treewidth-fragility, namely fractional tree-independence-number-fragility.","In particular, we obtain polynomial-time approximation schemes for meta-problems such as finding a maximum-weight sparse induced subgraph satisfying a given $\\mathsf{CMSO}_2$ formula on fractionally tree-independence-number-fragile graph classes.","Our approach unifies and extends several known polynomial-time approximation schemes on seemingly unrelated graph classes, such as classes of intersection graphs of fat objects in a fixed dimension or proper minor-closed classes.","We also study the related notion of layered tree-independence number, a relaxation of layered treewidth, and its applications to exact subexponential-time algorithms."],"url":"http://arxiv.org/abs/2402.18352v1"}
{"created":"2024-02-28 14:10:35","title":"Solving Multi-Entity Robotic Problems Using Permutation Invariant Neural Networks","abstract":"Challenges in real-world robotic applications often stem from managing multiple, dynamically varying entities such as neighboring robots, manipulable objects, and navigation goals. Existing multi-agent control strategies face scalability limitations, struggling to handle arbitrary numbers of entities. Additionally, they often rely on engineered heuristics for assigning entities among agents. We propose a data driven approach to address these limitations by introducing a decentralized control system using neural network policies trained in simulation. Leveraging permutation invariant neural network architectures and model-free reinforcement learning, our approach allows control agents to autonomously determine the relative importance of different entities without being biased by ordering or limited by a fixed capacity. We validate our approach through both simulations and real-world experiments involving multiple wheeled-legged quadrupedal robots, demonstrating their collaborative control capabilities. We prove the effectiveness of our architectural choice through experiments with three exemplary multi-entity problems. Our analysis underscores the pivotal role of the end-to-end trained permutation invariant encoders in achieving scalability and improving the task performance in multi-object manipulation or multi-goal navigation problems. The adaptability of our policy is further evidenced by its ability to manage varying numbers of entities in a zero-shot manner, showcasing near-optimal autonomous task distribution and collision avoidance behaviors.","sentences":["Challenges in real-world robotic applications often stem from managing multiple, dynamically varying entities such as neighboring robots, manipulable objects, and navigation goals.","Existing multi-agent control strategies face scalability limitations, struggling to handle arbitrary numbers of entities.","Additionally, they often rely on engineered heuristics for assigning entities among agents.","We propose a data driven approach to address these limitations by introducing a decentralized control system using neural network policies trained in simulation.","Leveraging permutation invariant neural network architectures and model-free reinforcement learning, our approach allows control agents to autonomously determine the relative importance of different entities without being biased by ordering or limited by a fixed capacity.","We validate our approach through both simulations and real-world experiments involving multiple wheeled-legged quadrupedal robots, demonstrating their collaborative control capabilities.","We prove the effectiveness of our architectural choice through experiments with three exemplary multi-entity problems.","Our analysis underscores the pivotal role of the end-to-end trained permutation invariant encoders in achieving scalability and improving the task performance in multi-object manipulation or multi-goal navigation problems.","The adaptability of our policy is further evidenced by its ability to manage varying numbers of entities in a zero-shot manner, showcasing near-optimal autonomous task distribution and collision avoidance behaviors."],"url":"http://arxiv.org/abs/2402.18345v1"}
{"created":"2024-02-28 14:03:59","title":"Online Edge Coloring is (Nearly) as Easy as Offline","abstract":"The classic theorem of Vizing (Diskret. Analiz.'64) asserts that any graph of maximum degree $\\Delta$ can be edge colored (offline) using no more than $\\Delta+1$ colors (with $\\Delta$ being a trivial lower bound). In the online setting, Bar-Noy, Motwani and Naor (IPL'92) conjectured that a $(1+o(1))\\Delta$-edge-coloring can be computed online in $n$-vertex graphs of maximum degree $\\Delta=\\omega(\\log n)$. Numerous algorithms made progress on this question, using a higher number of colors or assuming restricted arrival models, such as random-order edge arrivals or vertex arrivals (e.g., AGKM FOCS'03, BMM SODA'10, CPW FOCS'19, BGW SODA'21, KLSST STOC'22). In this work, we resolve this longstanding conjecture in the affirmative in the most general setting of adversarial edge arrivals. We further generalize this result to obtain online counterparts of the list edge coloring result of Kahn (J. Comb. Theory. A'96) and of the recent \"local\" edge coloring result of Christiansen (STOC'23).","sentences":["The classic theorem of Vizing (Diskret.","Analiz.","'64) asserts that any graph of maximum degree $\\Delta$ can be edge colored (offline) using no more than $\\Delta+1$ colors (with $\\Delta$ being a trivial lower bound).","In the online setting, Bar-Noy, Motwani and Naor (IPL'92) conjectured that a $(1+o(1))\\Delta$-edge-coloring can be computed online in $n$-vertex graphs of maximum degree $\\Delta=\\omega(\\log n)$. Numerous algorithms made progress on this question, using a higher number of colors or assuming restricted arrival models, such as random-order edge arrivals or vertex arrivals (e.g., AGKM FOCS'03, BMM SODA'10, CPW FOCS'19, BGW SODA'21, KLSST STOC'22).","In this work, we resolve this longstanding conjecture in the affirmative in the most general setting of adversarial edge arrivals.","We further generalize this result to obtain online counterparts of the list edge coloring result of Kahn (J. Comb.","Theory.","A'96) and of the recent \"local\" edge coloring result of Christiansen (STOC'23)."],"url":"http://arxiv.org/abs/2402.18339v1"}
{"created":"2024-02-28 13:59:20","title":"Probabilistic Bayesian optimal experimental design using conditional normalizing flows","abstract":"Bayesian optimal experimental design (OED) seeks to conduct the most informative experiment under budget constraints to update the prior knowledge of a system to its posterior from the experimental data in a Bayesian framework. Such problems are computationally challenging because of (1) expensive and repeated evaluation of some optimality criterion that typically involves a double integration with respect to both the system parameters and the experimental data, (2) suffering from the curse-of-dimensionality when the system parameters and design variables are high-dimensional, (3) the optimization is combinatorial and highly non-convex if the design variables are binary, often leading to non-robust designs. To make the solution of the Bayesian OED problem efficient, scalable, and robust for practical applications, we propose a novel joint optimization approach. This approach performs simultaneous (1) training of a scalable conditional normalizing flow (CNF) to efficiently maximize the expected information gain (EIG) of a jointly learned experimental design (2) optimization of a probabilistic formulation of the binary experimental design with a Bernoulli distribution. We demonstrate the performance of our proposed method for a practical MRI data acquisition problem, one of the most challenging Bayesian OED problems that has high-dimensional (320 $\\times$ 320) parameters at high image resolution, high-dimensional (640 $\\times$ 386) observations, and binary mask designs to select the most informative observations.","sentences":["Bayesian optimal experimental design (OED) seeks to conduct the most informative experiment under budget constraints to update the prior knowledge of a system to its posterior from the experimental data in a Bayesian framework.","Such problems are computationally challenging because of (1) expensive and repeated evaluation of some optimality criterion that typically involves a double integration with respect to both the system parameters and the experimental data, (2) suffering from the curse-of-dimensionality when the system parameters and design variables are high-dimensional, (3) the optimization is combinatorial and highly non-convex if the design variables are binary, often leading to non-robust designs.","To make the solution of the Bayesian OED problem efficient, scalable, and robust for practical applications, we propose a novel joint optimization approach.","This approach performs simultaneous (1) training of a scalable conditional normalizing flow (CNF) to efficiently maximize the expected information gain (EIG) of a jointly learned experimental design (2) optimization of a probabilistic formulation of the binary experimental design with a Bernoulli distribution.","We demonstrate the performance of our proposed method for a practical MRI data acquisition problem, one of the most challenging Bayesian OED problems that has high-dimensional (320 $\\times$ 320) parameters at high image resolution, high-dimensional (640 $\\times$ 386) observations, and binary mask designs to select the most informative observations."],"url":"http://arxiv.org/abs/2402.18337v1"}
{"created":"2024-02-28 13:54:57","title":"Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation","abstract":"We introduce Bonito, an open-source model for conditional task generation: the task of converting unannotated text into task-specific training datasets for instruction tuning. Our goal is to enable zero-shot task adaptation of large language models on users' specialized, private data. We train Bonito on a new large-scale dataset with 1.65M examples created by remixing existing instruction tuning datasets into meta-templates. The meta-templates for a dataset produce training examples where the input is the unannotated text and the task attribute and the output consists of the instruction and the response. We use Bonito to generate synthetic tasks for seven datasets from specialized domains across three task types -- yes-no question answering, extractive question answering, and natural language inference -- and adapt language models. We show that Bonito significantly improves the average performance of pretrained and instruction tuned models over the de facto self supervised baseline. For example, adapting Mistral-Instruct-v2 and instruction tuned variants of Mistral and Llama2 with Bonito improves the strong zero-shot performance by 22.1 F1 points whereas the next word prediction objective undoes some of the benefits of instruction tuning and reduces the average performance by 0.8 F1 points. We conduct additional experiments with Bonito to understand the effects of the domain, the size of the training set, and the choice of alternative synthetic task generators. Overall, we show that learning with synthetic instruction tuning datasets is an effective way to adapt language models to new domains. The model, dataset, and code are available at https://github.com/BatsResearch/bonito.","sentences":["We introduce Bonito, an open-source model for conditional task generation: the task of converting unannotated text into task-specific training datasets for instruction tuning.","Our goal is to enable zero-shot task adaptation of large language models on users' specialized, private data.","We train Bonito on a new large-scale dataset with 1.65M examples created by remixing existing instruction tuning datasets into meta-templates.","The meta-templates for a dataset produce training examples where the input is the unannotated text and the task attribute and the output consists of the instruction and the response.","We use Bonito to generate synthetic tasks for seven datasets from specialized domains across three task types -- yes-no question answering, extractive question answering, and natural language inference -- and adapt language models.","We show that Bonito significantly improves the average performance of pretrained and instruction tuned models over the de facto self supervised baseline.","For example, adapting Mistral-Instruct-v2 and instruction tuned variants of Mistral and Llama2 with Bonito improves the strong zero-shot performance by 22.1 F1 points whereas the next word prediction objective undoes some of the benefits of instruction tuning and reduces the average performance by 0.8 F1 points.","We conduct additional experiments with Bonito to understand the effects of the domain, the size of the training set, and the choice of alternative synthetic task generators.","Overall, we show that learning with synthetic instruction tuning datasets is an effective way to adapt language models to new domains.","The model, dataset, and code are available at https://github.com/BatsResearch/bonito."],"url":"http://arxiv.org/abs/2402.18334v1"}
{"created":"2024-02-28 13:49:23","title":"Living-off-The-Land Reverse-Shell Detection by Informed Data Augmentation","abstract":"The living-off-the-land (LOTL) offensive methodologies rely on the perpetration of malicious actions through chains of commands executed by legitimate applications, identifiable exclusively by analysis of system logs. LOTL techniques are well hidden inside the stream of events generated by common legitimate activities, moreover threat actors often camouflage activity through obfuscation, making them particularly difficult to detect without incurring in plenty of false alarms, even using machine learning. To improve the performance of models in such an harsh environment, we propose an augmentation framework to enhance and diversify the presence of LOTL malicious activity inside legitimate logs. Guided by threat intelligence, we generate a dataset by injecting attack templates known to be employed in the wild, further enriched by malleable patterns of legitimate activities to replicate the behavior of evasive threat actors. We conduct an extensive ablation study to understand which models better handle our augmented dataset, also manipulated to mimic the presence of model-agnostic evasion and poisoning attacks. Our results suggest that augmentation is needed to maintain high-predictive capabilities, robustness to attack is achieved through specific hardening techniques like adversarial training, and it is possible to deploy near-real-time models with almost-zero false alarms.","sentences":["The living-off-the-land (LOTL) offensive methodologies rely on the perpetration of malicious actions through chains of commands executed by legitimate applications, identifiable exclusively by analysis of system logs.","LOTL techniques are well hidden inside the stream of events generated by common legitimate activities, moreover threat actors often camouflage activity through obfuscation, making them particularly difficult to detect without incurring in plenty of false alarms, even using machine learning.","To improve the performance of models in such an harsh environment, we propose an augmentation framework to enhance and diversify the presence of LOTL malicious activity inside legitimate logs.","Guided by threat intelligence, we generate a dataset by injecting attack templates known to be employed in the wild, further enriched by malleable patterns of legitimate activities to replicate the behavior of evasive threat actors.","We conduct an extensive ablation study to understand which models better handle our augmented dataset, also manipulated to mimic the presence of model-agnostic evasion and poisoning attacks.","Our results suggest that augmentation is needed to maintain high-predictive capabilities, robustness to attack is achieved through specific hardening techniques like adversarial training, and it is possible to deploy near-real-time models with almost-zero false alarms."],"url":"http://arxiv.org/abs/2402.18329v1"}
{"created":"2024-02-28 13:38:27","title":"Equivalent Environments and Covering Spaces for Robots","abstract":"This paper formally defines a robot system, including its sensing and actuation components, as a general, topological dynamical system. The focus is on determining general conditions under which various environments in which the robot can be placed are indistinguishable. A key result is that, under very general conditions, covering maps witness such indistinguishability. This formalizes the intuition behind the well studied loop closure problem in robotics. An important special case is where the sensor mapping reports an invariant of the local topological (metric) structure of an environment because such structure is preserved by (metric) covering maps. Whereas coverings provide a sufficient condition for the equivalence of environments, we also give a necessary condition using bisimulation. The overall framework is applied to unify previously identified phenomena in robotics and related fields, in which moving agents with sensors must make inferences about their environments based on limited data. Many open problems are identified.","sentences":["This paper formally defines a robot system, including its sensing and actuation components, as a general, topological dynamical system.","The focus is on determining general conditions under which various environments in which the robot can be placed are indistinguishable.","A key result is that, under very general conditions, covering maps witness such indistinguishability.","This formalizes the intuition behind the well studied loop closure problem in robotics.","An important special case is where the sensor mapping reports an invariant of the local topological (metric) structure of an environment because such structure is preserved by (metric) covering maps.","Whereas coverings provide a sufficient condition for the equivalence of environments, we also give a necessary condition using bisimulation.","The overall framework is applied to unify previously identified phenomena in robotics and related fields, in which moving agents with sensors must make inferences about their environments based on limited data.","Many open problems are identified."],"url":"http://arxiv.org/abs/2402.18323v1"}
{"created":"2024-02-28 13:36:27","title":"Privacy Policies and Consent Management Platforms: Growth and Users' Interactions over Time","abstract":"In response to growing concerns about user privacy, legislators have introduced new regulations and laws such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) that force websites to obtain user consent before activating personal data collection, fundamental to providing targeted advertising. The cornerstone of this consent-seeking process involves the use of Privacy Banners, the technical mechanism to collect users' approval for data collection practices. Consent management platforms (CMPs) have emerged as practical solutions to make it easier for website administrators to properly manage consent, allowing them to outsource the complexities of managing user consent and activating advertising features.   This paper presents a detailed and longitudinal analysis of the evolution of CMPs spanning nine years. We take a twofold perspective: Firstly, thanks to the HTTP Archive dataset, we provide insights into the growth, market share, and geographical spread of CMPs. Noteworthy observations include the substantial impact of GDPR on the proliferation of CMPs in Europe. Secondly, we analyse millions of user interactions with a medium-sized CMP present in thousands of websites worldwide. We observe how even small changes in the design of Privacy Banners have a critical impact on the user's giving or denying their consent to data collection. For instance, over 60% of users do not consent when offered a simple \"one-click reject-all\" option. Conversely, when opting out requires more than one click, about 90% of users prefer to simply give their consent. The main objective is in fact to eliminate the annoying privacy banner rather the make an informed decision. Curiously, we observe iOS users exhibit a higher tendency to accept cookies compared to Android users, possibly indicating greater confidence in the privacy offered by Apple devices.","sentences":["In response to growing concerns about user privacy, legislators have introduced new regulations and laws such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) that force websites to obtain user consent before activating personal data collection, fundamental to providing targeted advertising.","The cornerstone of this consent-seeking process involves the use of Privacy Banners, the technical mechanism to collect users' approval for data collection practices.","Consent management platforms (CMPs) have emerged as practical solutions to make it easier for website administrators to properly manage consent, allowing them to outsource the complexities of managing user consent and activating advertising features.   ","This paper presents a detailed and longitudinal analysis of the evolution of CMPs spanning nine years.","We take a twofold perspective: Firstly, thanks to the HTTP Archive dataset, we provide insights into the growth, market share, and geographical spread of CMPs.","Noteworthy observations include the substantial impact of GDPR on the proliferation of CMPs in Europe.","Secondly, we analyse millions of user interactions with a medium-sized CMP present in thousands of websites worldwide.","We observe how even small changes in the design of Privacy Banners have a critical impact on the user's giving or denying their consent to data collection.","For instance, over 60% of users do not consent when offered a simple \"one-click reject-all\" option.","Conversely, when opting out requires more than one click, about 90% of users prefer to simply give their consent.","The main objective is in fact to eliminate the annoying privacy banner rather the make an informed decision.","Curiously, we observe iOS users exhibit a higher tendency to accept cookies compared to Android users, possibly indicating greater confidence in the privacy offered by Apple devices."],"url":"http://arxiv.org/abs/2402.18321v1"}
{"created":"2024-02-28 13:29:28","title":"A Multimodal Handover Failure Detection Dataset and Baselines","abstract":"An object handover between a robot and a human is a coordinated action which is prone to failure for reasons such as miscommunication, incorrect actions and unexpected object properties. Existing works on handover failure detection and prevention focus on preventing failures due to object slip or external disturbances. However, there is a lack of datasets and evaluation methods that consider unpreventable failures caused by the human participant. To address this deficit, we present the multimodal Handover Failure Detection dataset, which consists of failures induced by the human participant, such as ignoring the robot or not releasing the object. We also present two baseline methods for handover failure detection: (i) a video classification method using 3D CNNs and (ii) a temporal action segmentation approach which jointly classifies the human action, robot action and overall outcome of the action. The results show that video is an important modality, but using force-torque data and gripper position help improve failure detection and action segmentation accuracy.","sentences":["An object handover between a robot and a human is a coordinated action which is prone to failure for reasons such as miscommunication, incorrect actions and unexpected object properties.","Existing works on handover failure detection and prevention focus on preventing failures due to object slip or external disturbances.","However, there is a lack of datasets and evaluation methods that consider unpreventable failures caused by the human participant.","To address this deficit, we present the multimodal Handover Failure Detection dataset, which consists of failures induced by the human participant, such as ignoring the robot or not releasing the object.","We also present two baseline methods for handover failure detection: (i) a video classification method using 3D CNNs and (ii) a temporal action segmentation approach which jointly classifies the human action, robot action and overall outcome of the action.","The results show that video is an important modality, but using force-torque data and gripper position help improve failure detection and action segmentation accuracy."],"url":"http://arxiv.org/abs/2402.18319v1"}
{"created":"2024-02-28 13:28:54","title":"SD-SLAM: A Semantic SLAM Approach for Dynamic Scenes Based on LiDAR Point Clouds","abstract":"Point cloud maps generated via LiDAR sensors using extensive remotely sensed data are commonly used by autonomous vehicles and robots for localization and navigation. However, dynamic objects contained in point cloud maps not only downgrade localization accuracy and navigation performance but also jeopardize the map quality. In response to this challenge, we propose in this paper a novel semantic SLAM approach for dynamic scenes based on LiDAR point clouds, referred to as SD-SLAM hereafter. The main contributions of this work are in three aspects: 1) introducing a semantic SLAM framework dedicatedly for dynamic scenes based on LiDAR point clouds, 2) Employing semantics and Kalman filtering to effectively differentiate between dynamic and semi-static landmarks, and 3) Making full use of semi-static and pure static landmarks with semantic information in the SD-SLAM process to improve localization and mapping performance. To evaluate the proposed SD-SLAM, tests were conducted using the widely adopted KITTI odometry dataset. Results demonstrate that the proposed SD-SLAM effectively mitigates the adverse effects of dynamic objects on SLAM, improving vehicle localization and mapping performance in dynamic scenes, and simultaneously constructing a static semantic map with multiple semantic classes for enhanced environment understanding.","sentences":["Point cloud maps generated via LiDAR sensors using extensive remotely sensed data are commonly used by autonomous vehicles and robots for localization and navigation.","However, dynamic objects contained in point cloud maps not only downgrade localization accuracy and navigation performance but also jeopardize the map quality.","In response to this challenge, we propose in this paper a novel semantic SLAM approach for dynamic scenes based on LiDAR point clouds, referred to as SD-SLAM hereafter.","The main contributions of this work are in three aspects: 1) introducing a semantic SLAM framework dedicatedly for dynamic scenes based on LiDAR point clouds, 2) Employing semantics and Kalman filtering to effectively differentiate between dynamic and semi-static landmarks, and 3) Making full use of semi-static and pure static landmarks with semantic information in the SD-SLAM process to improve localization and mapping performance.","To evaluate the proposed SD-SLAM, tests were conducted using the widely adopted KITTI odometry dataset.","Results demonstrate that the proposed SD-SLAM effectively mitigates the adverse effects of dynamic objects on SLAM, improving vehicle localization and mapping performance in dynamic scenes, and simultaneously constructing a static semantic map with multiple semantic classes for enhanced environment understanding."],"url":"http://arxiv.org/abs/2402.18318v1"}
{"created":"2024-02-28 12:57:22","title":"Play like a Vertex: A Stackelberg Game Approach for Streaming Graph Partitioning","abstract":"In the realm of distributed systems tasked with managing and processing large-scale graph-structured data, optimizing graph partitioning stands as a pivotal challenge. The primary goal is to minimize communication overhead and runtime cost. However, alongside the computational complexity associated with optimal graph partitioning, a critical factor to consider is memory overhead. Real-world graphs often reach colossal sizes, making it impractical and economically unviable to load the entire graph into memory for partitioning. This is also a fundamental premise in distributed graph processing, where accommodating a graph with non-distributed systems is unattainable. Currently, existing streaming partitioning algorithms exhibit a skew-oblivious nature, yielding satisfactory partitioning results exclusively for specific graph types. In this paper, we propose a novel streaming partitioning algorithm, the Skewness-aware Vertex-cut Partitioner S5P, designed to leverage the skewness characteristics of real graphs for achieving high-quality partitioning. S5P offers high partitioning quality by segregating the graph's edge set into two subsets, head and tail sets. Following processing by a skewness-aware clustering algorithm, these two subsets subsequently undergo a Stackelberg graph game. Our extensive evaluations conducted on substantial real-world and synthetic graphs demonstrate that, in all instances, the partitioning quality of S5P surpasses that of existing streaming partitioning algorithms, operating within the same load balance constraints. For example, S5P can bring up to a 51% improvement in partitioning quality compared to the top partitioner among the baselines. Lastly, we showcase that the implementation of S5P results in up to an 81% reduction in communication cost and a 130% increase in runtime efficiency for distributed graph processing tasks on PowerGraph.","sentences":["In the realm of distributed systems tasked with managing and processing large-scale graph-structured data, optimizing graph partitioning stands as a pivotal challenge.","The primary goal is to minimize communication overhead and runtime cost.","However, alongside the computational complexity associated with optimal graph partitioning, a critical factor to consider is memory overhead.","Real-world graphs often reach colossal sizes, making it impractical and economically unviable to load the entire graph into memory for partitioning.","This is also a fundamental premise in distributed graph processing, where accommodating a graph with non-distributed systems is unattainable.","Currently, existing streaming partitioning algorithms exhibit a skew-oblivious nature, yielding satisfactory partitioning results exclusively for specific graph types.","In this paper, we propose a novel streaming partitioning algorithm, the Skewness-aware Vertex-cut Partitioner S5P, designed to leverage the skewness characteristics of real graphs for achieving high-quality partitioning.","S5P offers high partitioning quality by segregating the graph's edge set into two subsets, head and tail sets.","Following processing by a skewness-aware clustering algorithm, these two subsets subsequently undergo a Stackelberg graph game.","Our extensive evaluations conducted on substantial real-world and synthetic graphs demonstrate that, in all instances, the partitioning quality of S5P surpasses that of existing streaming partitioning algorithms, operating within the same load balance constraints.","For example, S5P can bring up to a 51% improvement in partitioning quality compared to the top partitioner among the baselines.","Lastly, we showcase that the implementation of S5P results in up to an 81% reduction in communication cost and a 130% increase in runtime efficiency for distributed graph processing tasks on PowerGraph."],"url":"http://arxiv.org/abs/2402.18304v1"}
{"created":"2024-02-28 12:41:06","title":"Comparative Analysis of XGBoost and Minirocket Algortihms for Human Activity Recognition","abstract":"Human Activity Recognition (HAR) has been extensively studied, with recent emphasis on the implementation of advanced Machine Learning (ML) and Deep Learning (DL) algorithms for accurate classification. This study investigates the efficacy of two ML algorithms, eXtreme Gradient Boosting (XGBoost) and MiniRocket, in the realm of HAR using data collected from smartphone sensors. The experiments are conducted on a dataset obtained from the UCI repository, comprising accelerometer and gyroscope signals captured from 30 volunteers performing various activities while wearing a smartphone. The dataset undergoes preprocessing, including noise filtering and feature extraction, before being utilized for training and testing the classifiers. Monte Carlo cross-validation is employed to evaluate the models' robustness. The findings reveal that both XGBoost and MiniRocket attain accuracy, F1 score, and AUC values as high as 0.99 in activity classification. XGBoost exhibits a slightly superior performance compared to MiniRocket. Notably, both algorithms surpass the performance of other ML and DL algorithms reported in the literature for HAR tasks. Additionally, the study compares the computational efficiency of the two algorithms, revealing XGBoost's advantage in terms of training time. Furthermore, the performance of MiniRocket, which achieves accuracy and F1 values of 0.94, and an AUC value of 0.96 using raw data and utilizing only one channel from the sensors, highlights the potential of directly leveraging unprocessed signals. It also suggests potential advantages that could be gained by utilizing sensor fusion or channel fusion techniques. Overall, this research sheds light on the effectiveness and computational characteristics of XGBoost and MiniRocket in HAR tasks, providing insights for future studies in activity recognition using smartphone sensor data.","sentences":["Human Activity Recognition (HAR) has been extensively studied, with recent emphasis on the implementation of advanced Machine Learning (ML) and Deep Learning (DL) algorithms for accurate classification.","This study investigates the efficacy of two ML algorithms, eXtreme Gradient Boosting (XGBoost) and MiniRocket, in the realm of HAR using data collected from smartphone sensors.","The experiments are conducted on a dataset obtained from the UCI repository, comprising accelerometer and gyroscope signals captured from 30 volunteers performing various activities while wearing a smartphone.","The dataset undergoes preprocessing, including noise filtering and feature extraction, before being utilized for training and testing the classifiers.","Monte Carlo cross-validation is employed to evaluate the models' robustness.","The findings reveal that both XGBoost and MiniRocket attain accuracy, F1 score, and AUC values as high as 0.99 in activity classification.","XGBoost exhibits a slightly superior performance compared to MiniRocket.","Notably, both algorithms surpass the performance of other ML and DL algorithms reported in the literature for HAR tasks.","Additionally, the study compares the computational efficiency of the two algorithms, revealing XGBoost's advantage in terms of training time.","Furthermore, the performance of MiniRocket, which achieves accuracy and F1 values of 0.94, and an AUC value of 0.96 using raw data and utilizing only one channel from the sensors, highlights the potential of directly leveraging unprocessed signals.","It also suggests potential advantages that could be gained by utilizing sensor fusion or channel fusion techniques.","Overall, this research sheds light on the effectiveness and computational characteristics of XGBoost and MiniRocket in HAR tasks, providing insights for future studies in activity recognition using smartphone sensor data."],"url":"http://arxiv.org/abs/2402.18296v1"}
{"created":"2024-02-28 12:38:49","title":"Whole-body Humanoid Robot Locomotion with Human Reference","abstract":"Recently, humanoid robots have made significant advances in their ability to perform complex tasks due to the deployment of Reinforcement Learning (RL), however, the inherent complexity of humanoid robots, including the difficulty of planning complex reward functions and training entire complex systems, still poses a notable challenge. To conquer these challenges, after many iterations and in-depth investigations, we have meticulously developed a full-size humanoid robot, ''Adam'', whose innovative structural design greatly improves the efficiency and effectiveness of the imitation learning process. In addition, we have developed a novel imitation learning framework based on an adversarial motion prior, which applies not only to Adam but also to humanoid robots in general. Using the framework, Adam can exhibit unprecedented human-like characteristics in locomotion tasks. Our experimental results demonstrate that the proposed framework enables Adam to achieve human-comparable performance in complex locomotion tasks, marking the first time that human locomotion data has been used for imitation learning in a full-size humanoid robot.","sentences":["Recently, humanoid robots have made significant advances in their ability to perform complex tasks due to the deployment of Reinforcement Learning (RL), however, the inherent complexity of humanoid robots, including the difficulty of planning complex reward functions and training entire complex systems, still poses a notable challenge.","To conquer these challenges, after many iterations and in-depth investigations, we have meticulously developed a full-size humanoid robot, ''Adam'', whose innovative structural design greatly improves the efficiency and effectiveness of the imitation learning process.","In addition, we have developed a novel imitation learning framework based on an adversarial motion prior, which applies not only to Adam but also to humanoid robots in general.","Using the framework, Adam can exhibit unprecedented human-like characteristics in locomotion tasks.","Our experimental results demonstrate that the proposed framework enables Adam to achieve human-comparable performance in complex locomotion tasks, marking the first time that human locomotion data has been used for imitation learning in a full-size humanoid robot."],"url":"http://arxiv.org/abs/2402.18294v1"}
{"created":"2024-02-28 12:25:01","title":"Self-Supervised Learning in Electron Microscopy: Towards a Foundation Model for Advanced Image Analysis","abstract":"In this work, we explore the potential of self-supervised learning from unlabeled electron microscopy datasets, taking a step toward building a foundation model in this field. We show how self-supervised pretraining facilitates efficient fine-tuning for a spectrum of downstream tasks, including semantic segmentation, denoising, noise & background removal, and super-resolution. Experimentation with varying model complexities and receptive field sizes reveals the remarkable phenomenon that fine-tuned models of lower complexity consistently outperform more complex models with random weight initialization. We demonstrate the versatility of self-supervised pretraining across various downstream tasks in the context of electron microscopy, allowing faster convergence and better performance. We conclude that self-supervised pretraining serves as a powerful catalyst, being especially advantageous when limited annotated data are available and efficient scaling of computational cost are important.","sentences":["In this work, we explore the potential of self-supervised learning from unlabeled electron microscopy datasets, taking a step toward building a foundation model in this field.","We show how self-supervised pretraining facilitates efficient fine-tuning for a spectrum of downstream tasks, including semantic segmentation, denoising, noise & background removal, and super-resolution.","Experimentation with varying model complexities and receptive field sizes reveals the remarkable phenomenon that fine-tuned models of lower complexity consistently outperform more complex models with random weight initialization.","We demonstrate the versatility of self-supervised pretraining across various downstream tasks in the context of electron microscopy, allowing faster convergence and better performance.","We conclude that self-supervised pretraining serves as a powerful catalyst, being especially advantageous when limited annotated data are available and efficient scaling of computational cost are important."],"url":"http://arxiv.org/abs/2402.18286v1"}
{"created":"2024-02-28 12:24:27","title":"PiShield: A NeSy Framework for Learning with Requirements","abstract":"Deep learning models have shown their strengths in various application domains, however, they often struggle to meet safety requirements for their outputs. In this paper, we introduce PiShield, the first framework ever allowing for the integration of the requirements into the neural networks' topology. PiShield guarantees compliance with these requirements, regardless of input. Additionally, it allows for integrating requirements both at inference and/or training time, depending on the practitioners' needs. Given the widespread application of deep learning, there is a growing need for frameworks allowing for the integration of the requirements across various domains. Here, we explore three application scenarios: functional genomics, autonomous driving, and tabular data generation.","sentences":["Deep learning models have shown their strengths in various application domains, however, they often struggle to meet safety requirements for their outputs.","In this paper, we introduce PiShield, the first framework ever allowing for the integration of the requirements into the neural networks' topology.","PiShield guarantees compliance with these requirements, regardless of input.","Additionally, it allows for integrating requirements both at inference and/or training time, depending on the practitioners' needs.","Given the widespread application of deep learning, there is a growing need for frameworks allowing for the integration of the requirements across various domains.","Here, we explore three application scenarios: functional genomics, autonomous driving, and tabular data generation."],"url":"http://arxiv.org/abs/2402.18285v1"}
{"created":"2024-02-28 12:12:37","title":"Fractional Linear Matroid Matching is in quasi-NC","abstract":"The matching and linear matroid intersection problems are solvable in quasi-NC, meaning that there exist deterministic algorithms that run in polylogarithmic time and use quasi-polynomially many parallel processors. However, such a parallel algorithm is unknown for linear matroid matching, which generalizes both of these problems. In this work, we propose a quasi-NC algorithm for fractional linear matroid matching, which is a relaxation of linear matroid matching and commonly generalizes fractional matching and linear matroid intersection. Our algorithm builds upon the connection of fractional matroid matching to non-commutative Edmonds' problem recently revealed by Oki and Soma~(2023). As a corollary, we also solve black-box non-commutative Edmonds' problem with rank-two skew-symmetric coefficients.","sentences":["The matching and linear matroid intersection problems are solvable in quasi-NC, meaning that there exist deterministic algorithms that run in polylogarithmic time and use quasi-polynomially many parallel processors.","However, such a parallel algorithm is unknown for linear matroid matching, which generalizes both of these problems.","In this work, we propose a quasi-NC algorithm for fractional linear matroid matching, which is a relaxation of linear matroid matching and commonly generalizes fractional matching and linear matroid intersection.","Our algorithm builds upon the connection of fractional matroid matching to non-commutative Edmonds' problem recently revealed by Oki and Soma~(2023).","As a corollary, we also solve black-box non-commutative Edmonds' problem with rank-two skew-symmetric coefficients."],"url":"http://arxiv.org/abs/2402.18276v1"}
{"created":"2024-02-28 12:06:08","title":"Exploration of Adapter for Noise Robust Automatic Speech Recognition","abstract":"Adapting a robust automatic speech recognition (ASR) system to tackle unseen noise scenarios is crucial. Integrating adapters into neural networks has emerged as a potent technique for transfer learning. This paper thoroughly investigates adapter-based noise-robust ASR adaptation. We conducted the experiments using the CHiME--4 dataset. The results show that inserting the adapter in the shallow layer yields superior effectiveness, and there is no significant difference between adapting solely within the shallow layer and adapting across all layers. Besides, the simulated data helps the system to improve its performance under real noise conditions. Nonetheless, when the amount of data is the same, the real data is more effective than the simulated data. Multi-condition training remains valid for adapter training. Furthermore, integrating adapters into speech enhancement-based ASR systems yields substantial improvements.","sentences":["Adapting a robust automatic speech recognition (ASR) system to tackle unseen noise scenarios is crucial.","Integrating adapters into neural networks has emerged as a potent technique for transfer learning.","This paper thoroughly investigates adapter-based noise-robust ASR adaptation.","We conducted the experiments using the CHiME--4 dataset.","The results show that inserting the adapter in the shallow layer yields superior effectiveness, and there is no significant difference between adapting solely within the shallow layer and adapting across all layers.","Besides, the simulated data helps the system to improve its performance under real noise conditions.","Nonetheless, when the amount of data is the same, the real data is more effective than the simulated data.","Multi-condition training remains valid for adapter training.","Furthermore, integrating adapters into speech enhancement-based ASR systems yields substantial improvements."],"url":"http://arxiv.org/abs/2402.18275v1"}
{"created":"2024-02-28 11:57:12","title":"A Survey on Neural Question Generation: Methods, Applications, and Prospects","abstract":"In this survey, we present a detailed examination of the advancements in Neural Question Generation (NQG), a field leveraging neural network techniques to generate relevant questions from diverse inputs like knowledge bases, texts, and images. The survey begins with an overview of NQG's background, encompassing the task's problem formulation, prevalent benchmark datasets, established evaluation metrics, and notable applications. It then methodically classifies NQG approaches into three predominant categories: structured NQG, which utilizes organized data sources, unstructured NQG, focusing on more loosely structured inputs like texts or visual content, and hybrid NQG, drawing on diverse input modalities. This classification is followed by an in-depth analysis of the distinct neural network models tailored for each category, discussing their inherent strengths and potential limitations. The survey culminates with a forward-looking perspective on the trajectory of NQG, identifying emergent research trends and prospective developmental paths. Accompanying this survey is a curated collection of related research papers, datasets and codes, systematically organized on Github, providing an extensive reference for those delving into NQG.","sentences":["In this survey, we present a detailed examination of the advancements in Neural Question Generation (NQG), a field leveraging neural network techniques to generate relevant questions from diverse inputs like knowledge bases, texts, and images.","The survey begins with an overview of NQG's background, encompassing the task's problem formulation, prevalent benchmark datasets, established evaluation metrics, and notable applications.","It then methodically classifies NQG approaches into three predominant categories: structured NQG, which utilizes organized data sources, unstructured NQG, focusing on more loosely structured inputs like texts or visual content, and hybrid NQG, drawing on diverse input modalities.","This classification is followed by an in-depth analysis of the distinct neural network models tailored for each category, discussing their inherent strengths and potential limitations.","The survey culminates with a forward-looking perspective on the trajectory of NQG, identifying emergent research trends and prospective developmental paths.","Accompanying this survey is a curated collection of related research papers, datasets and codes, systematically organized on Github, providing an extensive reference for those delving into NQG."],"url":"http://arxiv.org/abs/2402.18267v1"}
{"created":"2024-02-28 11:53:26","title":"Output-Sensitive Enumeration of Potential Maximal Cliques in Polynomial Space","abstract":"A set of vertices in a graph forms a potential maximal clique if there exists a minimal chordal completion in which it is a maximal clique. Potential maximal cliques were first introduced as a key tool to obtain an efficient, though exponential-time algorithm to compute the treewidth of a graph. As a byproduct, this allowed to compute the treewidth of various graph classes in polynomial time.   In recent years, the concept of potential maximal cliques regained interest as it proved to be useful for a handful of graph algorithmic problems. In particular, it turned out to be a key tool to obtain a polynomial time algorithm for computing maximum weight independent sets in $P_5$-free and $P_6$-free graphs (Lokshtanov et al., SODA `14 and Grzeskik et al., SODA `19. In most of their applications, obtaining all the potential maximal cliques constitutes an algorithmic bottleneck, thus motivating the question of how to efficiently enumerate all the potential maximal cliques in a graph $G$.   The state-of-the-art algorithm by Bouchitt\\'e \\& Todinca can enumerate potential maximal cliques in output-polynomial time by using exponential space, a significant limitation for the size of feasible instances. In this paper, we revisit this algorithm and design an enumeration algorithm that preserves an output-polynomial time complexity while only requiring polynomial space.","sentences":["A set of vertices in a graph forms a potential maximal clique if there exists a minimal chordal completion in which it is a maximal clique.","Potential maximal cliques were first introduced as a key tool to obtain an efficient, though exponential-time algorithm to compute the treewidth of a graph.","As a byproduct, this allowed to compute the treewidth of various graph classes in polynomial time.   ","In recent years, the concept of potential maximal cliques regained interest as it proved to be useful for a handful of graph algorithmic problems.","In particular, it turned out to be a key tool to obtain a polynomial time algorithm for computing maximum weight independent sets in $P_5$-free and $P_6$-free graphs (Lokshtanov et al., SODA `14 and Grzeskik et al., SODA `19.","In most of their applications, obtaining all the potential maximal cliques constitutes an algorithmic bottleneck, thus motivating the question of how to efficiently enumerate all the potential maximal cliques in a graph $G$.   The state-of-the-art algorithm by Bouchitt\\'e \\& Todinca can enumerate potential maximal cliques in output-polynomial time by using exponential space, a significant limitation for the size of feasible instances.","In this paper, we revisit this algorithm and design an enumeration algorithm that preserves an output-polynomial time complexity while only requiring polynomial space."],"url":"http://arxiv.org/abs/2402.18265v1"}
{"created":"2024-02-28 11:51:56","title":"Retrieval-based Full-length Wikipedia Generation for Emergent Events","abstract":"In today's fast-paced world, the growing demand to quickly generate comprehensive and accurate Wikipedia documents for emerging events is both crucial and challenging. However, previous efforts in Wikipedia generation have often fallen short of meeting real-world requirements. Some approaches focus solely on generating segments of a complete Wikipedia document, while others overlook the importance of faithfulness in generation or fail to consider the influence of the pre-training corpus. In this paper, we simulate a real-world scenario where structured full-length Wikipedia documents are generated for emergent events using input retrieved from web sources. To ensure that Large Language Models (LLMs) are not trained on corpora related to recently occurred events, we select events that have taken place recently and introduce a new benchmark Wiki-GenBen, which consists of 309 events paired with their corresponding retrieved web pages for generating evidence. Additionally, we design a comprehensive set of systematic evaluation metrics and baseline methods, to evaluate the capability of LLMs in generating factual full-length Wikipedia documents. The data and code are open-sourced at WikiGenBench.","sentences":["In today's fast-paced world, the growing demand to quickly generate comprehensive and accurate Wikipedia documents for emerging events is both crucial and challenging.","However, previous efforts in Wikipedia generation have often fallen short of meeting real-world requirements.","Some approaches focus solely on generating segments of a complete Wikipedia document, while others overlook the importance of faithfulness in generation or fail to consider the influence of the pre-training corpus.","In this paper, we simulate a real-world scenario where structured full-length Wikipedia documents are generated for emergent events using input retrieved from web sources.","To ensure that Large Language Models (LLMs) are not trained on corpora related to recently occurred events, we select events that have taken place recently and introduce a new benchmark Wiki-GenBen, which consists of 309 events paired with their corresponding retrieved web pages for generating evidence.","Additionally, we design a comprehensive set of systematic evaluation metrics and baseline methods, to evaluate the capability of LLMs in generating factual full-length Wikipedia documents.","The data and code are open-sourced at WikiGenBench."],"url":"http://arxiv.org/abs/2402.18264v1"}
{"created":"2024-02-28 11:51:28","title":"Max-Cut with $\u03b5$-Accurate Predictions","abstract":"We study the approximability of the MaxCut problem in the presence of predictions. Specifically, we consider two models: in the noisy predictions model, for each vertex we are given its correct label in $\\{-1,+1\\}$ with some unknown probability $1/2 + \\epsilon$, and the other (incorrect) label otherwise. In the more-informative partial predictions model, for each vertex we are given its correct label with probability $\\epsilon$ and no label otherwise. We assume only pairwise independence between vertices in both models.   We show how these predictions can be used to improve on the worst-case approximation ratios for this problem. Specifically, we give an algorithm that achieves an $\\alpha + \\widetilde{\\Omega}(\\epsilon^4)$-approximation for the noisy predictions model, where $\\alpha \\approx 0.878$ is the MaxCut threshold. While this result also holds for the partial predictions model, we can also give a $\\beta + \\Omega(\\epsilon)$-approximation, where $\\beta \\approx 0.858$ is the approximation ratio for MaxBisection given by Raghavendra and Tan. This answers a question posed by Ola Svensson in his plenary session talk at SODA'23.","sentences":["We study the approximability of the MaxCut problem in the presence of predictions.","Specifically, we consider two models: in the noisy predictions model, for each vertex we are given its correct label in $\\{-1,+1\\}$ with some unknown probability $1/2 + \\epsilon$, and the other (incorrect) label otherwise.","In the more-informative partial predictions model, for each vertex we are given its correct label with probability $\\epsilon$ and no label otherwise.","We assume only pairwise independence between vertices in both models.   ","We show how these predictions can be used to improve on the worst-case approximation ratios for this problem.","Specifically, we give an algorithm that achieves an $\\alpha + \\widetilde{\\Omega}(\\epsilon^4)$-approximation for the noisy predictions model, where $\\alpha \\approx 0.878$ is the MaxCut threshold.","While this result also holds for the partial predictions model, we can also give a $\\beta + \\Omega(\\epsilon)$-approximation, where $\\beta \\approx 0.858$ is the approximation ratio for MaxBisection given by Raghavendra and Tan.","This answers a question posed by Ola Svensson in his plenary session talk at SODA'23."],"url":"http://arxiv.org/abs/2402.18263v1"}
{"created":"2024-02-28 11:35:34","title":"How open are hybrid journals included in transformative agreements?","abstract":"The ongoing controversy surrounding transformative agreements, which aim to transition journal publishing to full open access, highlight the need for large-scale studies assessing the uptake of open access in hybrid journals. This includes evaluating the extent to which transformative agreements enabled open access. By combining publicly available data from various sources, including cOAlition S Journal Checker, Crossref, and OpenAlex, this study presents a novel approach that analyses over 700 agreements and nine million journal articles published in more than 11.000 hybrid journals. Estimates suggest a strong growth in open access between 2018 and 2022 from 4.3% to 15%. In 2022, 58% of hybrid open access was enabled by transformative agreements. This trend was largely driven by the three commercial publishers Elsevier, Springer Nature, and Wiley, but the open access uptake varied substantially across journals, publishers, disciplines, and country affiliations. In particular, comparing the developments in the OECD and BRICS areas revealed different publication trends relative to hybrid open access. In conclusion, estimates suggest that current levels of implementation of transformative agreements is insufficient to bring about a large-scale transition to full open access.","sentences":["The ongoing controversy surrounding transformative agreements, which aim to transition journal publishing to full open access, highlight the need for large-scale studies assessing the uptake of open access in hybrid journals.","This includes evaluating the extent to which transformative agreements enabled open access.","By combining publicly available data from various sources, including cOAlition S Journal Checker, Crossref, and OpenAlex, this study presents a novel approach that analyses over 700 agreements and nine million journal articles published in more than 11.000 hybrid journals.","Estimates suggest a strong growth in open access between 2018 and 2022 from 4.3% to 15%.","In 2022, 58% of hybrid open access was enabled by transformative agreements.","This trend was largely driven by the three commercial publishers Elsevier, Springer Nature, and Wiley, but the open access uptake varied substantially across journals, publishers, disciplines, and country affiliations.","In particular, comparing the developments in the OECD and BRICS areas revealed different publication trends relative to hybrid open access.","In conclusion, estimates suggest that current levels of implementation of transformative agreements is insufficient to bring about a large-scale transition to full open access."],"url":"http://arxiv.org/abs/2402.18255v1"}
{"created":"2024-02-28 11:18:16","title":"Lower Bounds for Leaf Rank of Leaf Powers","abstract":"Leaf powers and $k$-leaf powers have been studied for over 20 years, but there are still several aspects of this graph class that are poorly understood. One such aspect is the leaf rank of leaf powers, i.e. the smallest number $k$ such that a graph $G$ is a $k$-leaf power. Computing the leaf rank of leaf powers has proved a hard task, and furthermore, results about the asymptotic growth of the leaf rank as a function of the number of vertices in the graph have been few and far between. We present an infinite family of rooted directed path graphs that are leaf powers, and prove that they have leaf rank exponential in the number of vertices (utilizing a type of subtree model first presented by Rautenbach [Some remarks about leaf roots. Discrete mathematics, 2006]). This answers an open question by Brandst\\\"adt et al. [Rooted directed path graphs are leaf powers. Discrete mathematics, 2010].","sentences":["Leaf powers and $k$-leaf powers have been studied for over 20 years, but there are still several aspects of this graph class that are poorly understood.","One such aspect is the leaf rank of leaf powers, i.e. the smallest number $k$ such that a graph $G$ is a $k$-leaf power.","Computing the leaf rank of leaf powers has proved a hard task, and furthermore, results about the asymptotic growth of the leaf rank as a function of the number of vertices in the graph have been few and far between.","We present an infinite family of rooted directed path graphs that are leaf powers, and prove that they have leaf rank exponential in the number of vertices (utilizing a type of subtree model first presented by Rautenbach","[Some remarks about leaf roots.","Discrete mathematics, 2006]).","This answers an open question by Brandst\\\"adt et al.","[Rooted directed path graphs are leaf powers.","Discrete mathematics, 2010]."],"url":"http://arxiv.org/abs/2402.18245v1"}
{"created":"2024-02-28 11:12:47","title":"Affective State Detection using fNIRs and Machine Learning","abstract":"Affective states regulate our day to day to function and has a tremendous effect on mental and physical health. Detection of affective states is of utmost importance for mental health monitoring, smart entertainment selection and dynamic workload management. In this paper, we discussed relevant literature on affective state detection using physiology data, the benefits and limitations of different sensors and methods used for collecting physiology data, and our rationale for selecting functional near-infrared spectroscopy. We present the design of an experiment involving nine subjects to evoke the affective states of meditation, amusement and cognitive load and the results of the attempt to classify using machine learning. A mean accuracy of 83.04% was achieved in three class classification with an individual model; 84.39% accuracy was achieved for a group model and 60.57% accuracy was achieved for subject independent model using leave one out cross validation. It was found that prediction accuracy for cognitive load was higher (evoked using a pen and paper task) than the other two classes (evoked using computer bases tasks). To verify that this discrepancy was not due to motor skills involved in the pen and paper task, a second experiment was conducted using four participants and the results of that experiment has also been presented in the paper.","sentences":["Affective states regulate our day to day to function and has a tremendous effect on mental and physical health.","Detection of affective states is of utmost importance for mental health monitoring, smart entertainment selection and dynamic workload management.","In this paper, we discussed relevant literature on affective state detection using physiology data, the benefits and limitations of different sensors and methods used for collecting physiology data, and our rationale for selecting functional near-infrared spectroscopy.","We present the design of an experiment involving nine subjects to evoke the affective states of meditation, amusement and cognitive load and the results of the attempt to classify using machine learning.","A mean accuracy of 83.04% was achieved in three class classification with an individual model; 84.39% accuracy was achieved for a group model and 60.57% accuracy was achieved for subject independent model using leave one out cross validation.","It was found that prediction accuracy for cognitive load was higher (evoked using a pen and paper task) than the other two classes (evoked using computer bases tasks).","To verify that this discrepancy was not due to motor skills involved in the pen and paper task, a second experiment was conducted using four participants and the results of that experiment has also been presented in the paper."],"url":"http://arxiv.org/abs/2402.18241v1"}
{"created":"2024-02-28 11:01:14","title":"Image2Flow: A hybrid image and graph convolutional neural network for rapid patient-specific pulmonary artery segmentation and CFD flow field calculation from 3D cardiac MRI data","abstract":"Computational fluid dynamics (CFD) can be used for evaluation of hemodynamics. However, its routine use is limited by labor-intensive manual segmentation, CFD mesh creation, and time-consuming simulation. This study aims to train a deep learning model to both generate patient-specific volume-meshes of the pulmonary artery from 3D cardiac MRI data and directly estimate CFD flow fields.   This study used 135 3D cardiac MRIs from both a public and private dataset. The pulmonary arteries in the MRIs were manually segmented and converted into volume-meshes. CFD simulations were performed on ground truth meshes and interpolated onto point-point correspondent meshes to create the ground truth dataset. The dataset was split 85/10/15 for training, validation and testing. Image2Flow, a hybrid image and graph convolutional neural network, was trained to transform a pulmonary artery template to patient-specific anatomy and CFD values. Image2Flow was evaluated in terms of segmentation and accuracy of CFD predicted was assessed using node-wise comparisons. Centerline comparisons of Image2Flow and CFD simulations performed using machine learning segmentation were also performed.   Image2Flow achieved excellent segmentation accuracy with a median Dice score of 0.9 (IQR: 0.86-0.92). The median node-wise normalized absolute error for pressure and velocity magnitude was 11.98% (IQR: 9.44-17.90%) and 8.06% (IQR: 7.54-10.41), respectively. Centerline analysis showed no significant difference between the Image2Flow and conventional CFD simulated on machine learning-generated volume-meshes.   This proof-of-concept study has shown it is possible to simultaneously perform patient specific volume-mesh based segmentation and pressure and flow field estimation. Image2Flow completes segmentation and CFD in ~205ms, which ~7000 times faster than manual methods, making it more feasible in a clinical environment.","sentences":["Computational fluid dynamics (CFD) can be used for evaluation of hemodynamics.","However, its routine use is limited by labor-intensive manual segmentation, CFD mesh creation, and time-consuming simulation.","This study aims to train a deep learning model to both generate patient-specific volume-meshes of the pulmonary artery from 3D cardiac MRI data and directly estimate CFD flow fields.   ","This study used 135 3D cardiac MRIs from both a public and private dataset.","The pulmonary arteries in the MRIs were manually segmented and converted into volume-meshes.","CFD simulations were performed on ground truth meshes and interpolated onto point-point correspondent meshes to create the ground truth dataset.","The dataset was split 85/10/15 for training, validation and testing.","Image2Flow, a hybrid image and graph convolutional neural network, was trained to transform a pulmonary artery template to patient-specific anatomy and CFD values.","Image2Flow was evaluated in terms of segmentation and accuracy of CFD predicted was assessed using node-wise comparisons.","Centerline comparisons of Image2Flow and CFD simulations performed using machine learning segmentation were also performed.   ","Image2Flow achieved excellent segmentation accuracy with a median Dice score of 0.9 (IQR: 0.86-0.92).","The median node-wise normalized absolute error for pressure and velocity magnitude was 11.98% (IQR: 9.44-17.90%) and 8.06% (IQR: 7.54-10.41), respectively.","Centerline analysis showed no significant difference between the Image2Flow and conventional CFD simulated on machine learning-generated volume-meshes.   ","This proof-of-concept study has shown it is possible to simultaneously perform patient specific volume-mesh based segmentation and pressure and flow field estimation.","Image2Flow completes segmentation and CFD in ~205ms, which ~7000 times faster than manual methods, making it more feasible in a clinical environment."],"url":"http://arxiv.org/abs/2402.18236v1"}
{"created":"2024-02-28 11:00:38","title":"On the Joint Effect of Culture and Discussion Topics on X (Twitter) Signed Ego Networks","abstract":"Humans are known to structure social relationships according to certain patterns, such as the Ego Network Model (ENM). These patterns result from our innate cognitive limits and can therefore be observed in the vast majority of large human social groups. Until recently, the main focus of research was the structural characteristics of this model. The main aim of this paper is to complement previous findings with systematic and data-driven analyses on the positive and negative sentiments of social relationships, across different cultures, communities and topics of discussion. A total of 26 datasets were collected for this work. It was found that contrary to previous findings, the influence of culture is not easily ``overwhelmed'' by that of the topic of discussion. However, more specific and polarising topics do lead to noticeable increases in negativity across all cultures. These negativities also appear to be stable across the different levels of the ENM, which contradicts previous hypotheses. Finally, the number of generic topics being discussed between users seems to be a good predictor of the overall positivity of their relationships.","sentences":["Humans are known to structure social relationships according to certain patterns, such as the Ego Network Model (ENM).","These patterns result from our innate cognitive limits and can therefore be observed in the vast majority of large human social groups.","Until recently, the main focus of research was the structural characteristics of this model.","The main aim of this paper is to complement previous findings with systematic and data-driven analyses on the positive and negative sentiments of social relationships, across different cultures, communities and topics of discussion.","A total of 26 datasets were collected for this work.","It was found that contrary to previous findings, the influence of culture is not easily ``overwhelmed'' by that of the topic of discussion.","However, more specific and polarising topics do lead to noticeable increases in negativity across all cultures.","These negativities also appear to be stable across the different levels of the ENM, which contradicts previous hypotheses.","Finally, the number of generic topics being discussed between users seems to be a good predictor of the overall positivity of their relationships."],"url":"http://arxiv.org/abs/2402.18235v1"}
{"created":"2024-02-28 10:58:01","title":"Zero-Shot Aerial Object Detection with Visual Description Regularization","abstract":"Existing object detection models are mainly trained on large-scale labeled datasets. However, annotating data for novel aerial object classes is expensive since it is time-consuming and may require expert knowledge. Thus, it is desirable to study label-efficient object detection methods on aerial images. In this work, we propose a zero-shot method for aerial object detection named visual Description Regularization, or DescReg. Concretely, we identify the weak semantic-visual correlation of the aerial objects and aim to address the challenge with prior descriptions of their visual appearance. Instead of directly encoding the descriptions into class embedding space which suffers from the representation gap problem, we propose to infuse the prior inter-class visual similarity conveyed in the descriptions into the embedding learning. The infusion process is accomplished with a newly designed similarity-aware triplet loss which incorporates structured regularization on the representation space. We conduct extensive experiments with three challenging aerial object detection datasets, including DIOR, xView, and DOTA. The results demonstrate that DescReg significantly outperforms the state-of-the-art ZSD methods with complex projection designs and generative frameworks, e.g., DescReg outperforms best reported ZSD method on DIOR by 4.5 mAP on unseen classes and 8.1 in HM. We further show the generalizability of DescReg by integrating it into generative ZSD methods as well as varying the detection architecture.","sentences":["Existing object detection models are mainly trained on large-scale labeled datasets.","However, annotating data for novel aerial object classes is expensive since it is time-consuming and may require expert knowledge.","Thus, it is desirable to study label-efficient object detection methods on aerial images.","In this work, we propose a zero-shot method for aerial object detection named visual Description Regularization, or DescReg.","Concretely, we identify the weak semantic-visual correlation of the aerial objects and aim to address the challenge with prior descriptions of their visual appearance.","Instead of directly encoding the descriptions into class embedding space which suffers from the representation gap problem, we propose to infuse the prior inter-class visual similarity conveyed in the descriptions into the embedding learning.","The infusion process is accomplished with a newly designed similarity-aware triplet loss which incorporates structured regularization on the representation space.","We conduct extensive experiments with three challenging aerial object detection datasets, including DIOR, xView, and DOTA.","The results demonstrate that DescReg significantly outperforms the state-of-the-art ZSD methods with complex projection designs and generative frameworks, e.g., DescReg outperforms best reported ZSD method on DIOR by 4.5 mAP on unseen classes and 8.1 in HM.","We further show the generalizability of DescReg by integrating it into generative ZSD methods as well as varying the detection architecture."],"url":"http://arxiv.org/abs/2402.18233v1"}
{"created":"2024-02-28 10:43:54","title":"CogBench: a large language model walks into a psychology lab","abstract":"Large language models (LLMs) have significantly advanced the field of artificial intelligence. Yet, evaluating them comprehensively remains challenging. We argue that this is partly due to the predominant focus on performance metrics in most benchmarks. This paper introduces CogBench, a benchmark that includes ten behavioral metrics derived from seven cognitive psychology experiments. This novel approach offers a toolkit for phenotyping LLMs' behavior. We apply CogBench to 35 LLMs, yielding a rich and diverse dataset. We analyze this data using statistical multilevel modeling techniques, accounting for the nested dependencies among fine-tuned versions of specific LLMs. Our study highlights the crucial role of model size and reinforcement learning from human feedback (RLHF) in improving performance and aligning with human behavior. Interestingly, we find that open-source models are less risk-prone than proprietary models and that fine-tuning on code does not necessarily enhance LLMs' behavior. Finally, we explore the effects of prompt-engineering techniques. We discover that chain-of-thought prompting improves probabilistic reasoning, while take-a-step-back prompting fosters model-based behaviors.","sentences":["Large language models (LLMs) have significantly advanced the field of artificial intelligence.","Yet, evaluating them comprehensively remains challenging.","We argue that this is partly due to the predominant focus on performance metrics in most benchmarks.","This paper introduces CogBench, a benchmark that includes ten behavioral metrics derived from seven cognitive psychology experiments.","This novel approach offers a toolkit for phenotyping LLMs' behavior.","We apply CogBench to 35 LLMs, yielding a rich and diverse dataset.","We analyze this data using statistical multilevel modeling techniques, accounting for the nested dependencies among fine-tuned versions of specific LLMs.","Our study highlights the crucial role of model size and reinforcement learning from human feedback (RLHF) in improving performance and aligning with human behavior.","Interestingly, we find that open-source models are less risk-prone than proprietary models and that fine-tuning on code does not necessarily enhance LLMs' behavior.","Finally, we explore the effects of prompt-engineering techniques.","We discover that chain-of-thought prompting improves probabilistic reasoning, while take-a-step-back prompting fosters model-based behaviors."],"url":"http://arxiv.org/abs/2402.18225v1"}
{"created":"2024-02-28 10:01:44","title":"Catastrophic Overfitting: A Potential Blessing in Disguise","abstract":"Fast Adversarial Training (FAT) has gained increasing attention within the research community owing to its efficacy in improving adversarial robustness. Particularly noteworthy is the challenge posed by catastrophic overfitting (CO) in this field. Although existing FAT approaches have made strides in mitigating CO, the ascent of adversarial robustness occurs with a non-negligible decline in classification accuracy on clean samples. To tackle this issue, we initially employ the feature activation differences between clean and adversarial examples to analyze the underlying causes of CO. Intriguingly, our findings reveal that CO can be attributed to the feature coverage induced by a few specific pathways. By intentionally manipulating feature activation differences in these pathways with well-designed regularization terms, we can effectively mitigate and induce CO, providing further evidence for this observation. Notably, models trained stably with these terms exhibit superior performance compared to prior FAT work. On this basis, we harness CO to achieve `attack obfuscation', aiming to bolster model performance. Consequently, the models suffering from CO can attain optimal classification accuracy on both clean and adversarial data when adding random noise to inputs during evaluation. We also validate their robustness against transferred adversarial examples and the necessity of inducing CO to improve robustness. Hence, CO may not be a problem that has to be solved.","sentences":["Fast Adversarial Training (FAT) has gained increasing attention within the research community owing to its efficacy in improving adversarial robustness.","Particularly noteworthy is the challenge posed by catastrophic overfitting (CO) in this field.","Although existing FAT approaches have made strides in mitigating CO, the ascent of adversarial robustness occurs with a non-negligible decline in classification accuracy on clean samples.","To tackle this issue, we initially employ the feature activation differences between clean and adversarial examples to analyze the underlying causes of CO.","Intriguingly, our findings reveal that CO can be attributed to the feature coverage induced by a few specific pathways.","By intentionally manipulating feature activation differences in these pathways with well-designed regularization terms, we can effectively mitigate and induce CO, providing further evidence for this observation.","Notably, models trained stably with these terms exhibit superior performance compared to prior FAT work.","On this basis, we harness CO to achieve `attack obfuscation', aiming to bolster model performance.","Consequently, the models suffering from CO can attain optimal classification accuracy on both clean and adversarial data when adding random noise to inputs during evaluation.","We also validate their robustness against transferred adversarial examples and the necessity of inducing CO to improve robustness.","Hence, CO may not be a problem that has to be solved."],"url":"http://arxiv.org/abs/2402.18211v1"}
{"created":"2024-02-28 09:53:17","title":"Balancing Act: Distribution-Guided Debiasing in Diffusion Models","abstract":"Diffusion Models (DMs) have emerged as powerful generative models with unprecedented image generation capability. These models are widely used for data augmentation and creative applications. However, DMs reflect the biases present in the training datasets. This is especially concerning in the context of faces, where the DM prefers one demographic subgroup vs others (eg. female vs male). In this work, we present a method for debiasing DMs without relying on additional data or model retraining. Specifically, we propose Distribution Guidance, which enforces the generated images to follow the prescribed attribute distribution. To realize this, we build on the key insight that the latent features of denoising UNet hold rich demographic semantics, and the same can be leveraged to guide debiased generation. We train Attribute Distribution Predictor (ADP) - a small mlp that maps the latent features to the distribution of attributes. ADP is trained with pseudo labels generated from existing attribute classifiers. The proposed Distribution Guidance with ADP enables us to do fair generation. Our method reduces bias across single/multiple attributes and outperforms the baseline by a significant margin for unconditional and text-conditional diffusion models. Further, we present a downstream task of training a fair attribute classifier by rebalancing the training set with our generated data.","sentences":["Diffusion Models (DMs) have emerged as powerful generative models with unprecedented image generation capability.","These models are widely used for data augmentation and creative applications.","However, DMs reflect the biases present in the training datasets.","This is especially concerning in the context of faces, where the DM prefers one demographic subgroup vs others (eg. female vs male).","In this work, we present a method for debiasing DMs without relying on additional data or model retraining.","Specifically, we propose Distribution Guidance, which enforces the generated images to follow the prescribed attribute distribution.","To realize this, we build on the key insight that the latent features of denoising UNet hold rich demographic semantics, and the same can be leveraged to guide debiased generation.","We train Attribute Distribution Predictor (ADP) - a small mlp that maps the latent features to the distribution of attributes.","ADP is trained with pseudo labels generated from existing attribute classifiers.","The proposed Distribution Guidance with ADP enables us to do fair generation.","Our method reduces bias across single/multiple attributes and outperforms the baseline by a significant margin for unconditional and text-conditional diffusion models.","Further, we present a downstream task of training a fair attribute classifier by rebalancing the training set with our generated data."],"url":"http://arxiv.org/abs/2402.18206v1"}
{"created":"2024-02-28 09:46:56","title":"Learning Invariant Inter-pixel Correlations for Superpixel Generation","abstract":"Deep superpixel algorithms have made remarkable strides by substituting hand-crafted features with learnable ones. Nevertheless, we observe that existing deep superpixel methods, serving as mid-level representation operations, remain sensitive to the statistical properties (e.g., color distribution, high-level semantics) embedded within the training dataset. Consequently, learnable features exhibit constrained discriminative capability, resulting in unsatisfactory pixel grouping performance, particularly in untrainable application scenarios. To address this issue, we propose the Content Disentangle Superpixel (CDS) algorithm to selectively separate the invariant inter-pixel correlations and statistical properties, i.e., style noise. Specifically, We first construct auxiliary modalities that are homologous to the original RGB image but have substantial stylistic variations. Then, driven by mutual information, we propose the local-grid correlation alignment across modalities to reduce the distribution discrepancy of adaptively selected features and learn invariant inter-pixel correlations. Afterwards, we perform global-style mutual information minimization to enforce the separation of invariant content and train data styles. The experimental results on four benchmark datasets demonstrate the superiority of our approach to existing state-of-the-art methods, regarding boundary adherence, generalization, and efficiency. Code and pre-trained model are available at https://github.com/rookiie/CDSpixel.","sentences":["Deep superpixel algorithms have made remarkable strides by substituting hand-crafted features with learnable ones.","Nevertheless, we observe that existing deep superpixel methods, serving as mid-level representation operations, remain sensitive to the statistical properties (e.g., color distribution, high-level semantics) embedded within the training dataset.","Consequently, learnable features exhibit constrained discriminative capability, resulting in unsatisfactory pixel grouping performance, particularly in untrainable application scenarios.","To address this issue, we propose the Content Disentangle Superpixel (CDS) algorithm to selectively separate the invariant inter-pixel correlations and statistical properties, i.e., style noise.","Specifically, We first construct auxiliary modalities that are homologous to the original RGB image but have substantial stylistic variations.","Then, driven by mutual information, we propose the local-grid correlation alignment across modalities to reduce the distribution discrepancy of adaptively selected features and learn invariant inter-pixel correlations.","Afterwards, we perform global-style mutual information minimization to enforce the separation of invariant content and train data styles.","The experimental results on four benchmark datasets demonstrate the superiority of our approach to existing state-of-the-art methods, regarding boundary adherence, generalization, and efficiency.","Code and pre-trained model are available at https://github.com/rookiie/CDSpixel."],"url":"http://arxiv.org/abs/2402.18201v1"}
{"created":"2024-02-28 09:40:36","title":"Automated Machine Learning for Multi-Label Classification","abstract":"Automated machine learning (AutoML) aims to select and configure machine learning algorithms and combine them into machine learning pipelines tailored to a dataset at hand. For supervised learning tasks, most notably binary and multinomial classification, aka single-label classification (SLC), such AutoML approaches have shown promising results. However, the task of multi-label classification (MLC), where data points are associated with a set of class labels instead of a single class label, has received much less attention so far. In the context of multi-label classification, the data-specific selection and configuration of multi-label classifiers are challenging even for experts in the field, as it is a high-dimensional optimization problem with multi-level hierarchical dependencies. While for SLC, the space of machine learning pipelines is already huge, the size of the MLC search space outnumbers the one of SLC by several orders.   In the first part of this thesis, we devise a novel AutoML approach for single-label classification tasks optimizing pipelines of machine learning algorithms, consisting of two algorithms at most. This approach is then extended first to optimize pipelines of unlimited length and eventually configure the complex hierarchical structures of multi-label classification methods. Furthermore, we investigate how well AutoML approaches that form the state of the art for single-label classification tasks scale with the increased problem complexity of AutoML for multi-label classification.   In the second part, we explore how methods for SLC and MLC could be configured more flexibly to achieve better generalization performance and how to increase the efficiency of execution-based AutoML systems.","sentences":["Automated machine learning (AutoML) aims to select and configure machine learning algorithms and combine them into machine learning pipelines tailored to a dataset at hand.","For supervised learning tasks, most notably binary and multinomial classification, aka single-label classification (SLC), such AutoML approaches have shown promising results.","However, the task of multi-label classification (MLC), where data points are associated with a set of class labels instead of a single class label, has received much less attention so far.","In the context of multi-label classification, the data-specific selection and configuration of multi-label classifiers are challenging even for experts in the field, as it is a high-dimensional optimization problem with multi-level hierarchical dependencies.","While for SLC, the space of machine learning pipelines is already huge, the size of the MLC search space outnumbers the one of SLC by several orders.   ","In the first part of this thesis, we devise a novel AutoML approach for single-label classification tasks optimizing pipelines of machine learning algorithms, consisting of two algorithms at most.","This approach is then extended first to optimize pipelines of unlimited length and eventually configure the complex hierarchical structures of multi-label classification methods.","Furthermore, we investigate how well AutoML approaches that form the state of the art for single-label classification tasks scale with the increased problem complexity of AutoML for multi-label classification.   ","In the second part, we explore how methods for SLC and MLC could be configured more flexibly to achieve better generalization performance and how to increase the efficiency of execution-based AutoML systems."],"url":"http://arxiv.org/abs/2402.18198v1"}
{"created":"2024-02-28 09:28:36","title":"Formalized Identification Of Key Factors In Safety-Relevant Failure Scenarios","abstract":"This research article presents a methodical data-based approach to systematically identify key factors in safety-related failure scenarios, with a focus on complex product-environmental systems in the era of Industry 4.0. The study addresses the uncertainty arising from the growing complexity of modern products. The method uses scenario analysis and focuses on failure analysis within technical product development. The approach involves a derivation of influencing factors based on information from failure databases. The failures described here are documented individually in failure sequence diagrams and then related to each other in a relationship matrix. This creates a network of possible failure scenarios from individual failure cases that can be used in product development. To illustrate the application of the methodology, a case study of 41 Rapex safety alerts for a hair dryer is presented. The failure sequence diagrams and influencing factor relationship matrices show 46 influencing factors that lead to safety-related failures. The predominant harm is burns and electric shocks, which are highlighted by the active and passive sum diagrams. The research demonstrates a robust method for identifying key factors in safety-related failure scenarios using information from failure databases. The methodology provides valuable insights into product development and emphasizes the frequency of influencing factors and their interconnectedness.","sentences":["This research article presents a methodical data-based approach to systematically identify key factors in safety-related failure scenarios, with a focus on complex product-environmental systems in the era of Industry 4.0.","The study addresses the uncertainty arising from the growing complexity of modern products.","The method uses scenario analysis and focuses on failure analysis within technical product development.","The approach involves a derivation of influencing factors based on information from failure databases.","The failures described here are documented individually in failure sequence diagrams and then related to each other in a relationship matrix.","This creates a network of possible failure scenarios from individual failure cases that can be used in product development.","To illustrate the application of the methodology, a case study of 41 Rapex safety alerts for a hair dryer is presented.","The failure sequence diagrams and influencing factor relationship matrices show 46 influencing factors that lead to safety-related failures.","The predominant harm is burns and electric shocks, which are highlighted by the active and passive sum diagrams.","The research demonstrates a robust method for identifying key factors in safety-related failure scenarios using information from failure databases.","The methodology provides valuable insights into product development and emphasizes the frequency of influencing factors and their interconnectedness."],"url":"http://arxiv.org/abs/2402.18194v1"}
{"created":"2024-02-28 09:27:41","title":"Misalignment-Robust Frequency Distribution Loss for Image Transformation","abstract":"This paper aims to address a common challenge in deep learning-based image transformation methods, such as image enhancement and super-resolution, which heavily rely on precisely aligned paired datasets with pixel-level alignments. However, creating precisely aligned paired images presents significant challenges and hinders the advancement of methods trained on such data. To overcome this challenge, this paper introduces a novel and simple Frequency Distribution Loss (FDL) for computing distribution distance within the frequency domain. Specifically, we transform image features into the frequency domain using Discrete Fourier Transformation (DFT). Subsequently, frequency components (amplitude and phase) are processed separately to form the FDL loss function. Our method is empirically proven effective as a training constraint due to the thoughtful utilization of global information in the frequency domain. Extensive experimental evaluations, focusing on image enhancement and super-resolution tasks, demonstrate that FDL outperforms existing misalignment-robust loss functions. Furthermore, we explore the potential of our FDL for image style transfer that relies solely on completely misaligned data. Our code is available at: https://github.com/eezkni/FDL","sentences":["This paper aims to address a common challenge in deep learning-based image transformation methods, such as image enhancement and super-resolution, which heavily rely on precisely aligned paired datasets with pixel-level alignments.","However, creating precisely aligned paired images presents significant challenges and hinders the advancement of methods trained on such data.","To overcome this challenge, this paper introduces a novel and simple Frequency Distribution Loss (FDL) for computing distribution distance within the frequency domain.","Specifically, we transform image features into the frequency domain using Discrete Fourier Transformation (DFT).","Subsequently, frequency components (amplitude and phase) are processed separately to form the FDL loss function.","Our method is empirically proven effective as a training constraint due to the thoughtful utilization of global information in the frequency domain.","Extensive experimental evaluations, focusing on image enhancement and super-resolution tasks, demonstrate that FDL outperforms existing misalignment-robust loss functions.","Furthermore, we explore the potential of our FDL for image style transfer that relies solely on completely misaligned data.","Our code is available at: https://github.com/eezkni/FDL"],"url":"http://arxiv.org/abs/2402.18192v1"}
{"created":"2024-02-28 09:27:29","title":"Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation","abstract":"With contributions from the open-source community, a vast amount of instruction tuning (IT) data has emerged. Given the significant resource allocation required by training and evaluating models, it is advantageous to have an efficient method for selecting high-quality IT data. However, existing methods for instruction data selection have limitations such as relying on fragile external APIs, being affected by biases in GPT models, or reducing the diversity of the selected instruction dataset. In this paper, we propose an industrial-friendly, expert-aligned and diversity-preserved instruction data selection method: Clustering and Ranking (CaR). CaR consists of two steps. The first step involves ranking instruction pairs using a scoring model that is well aligned with expert preferences (achieving an accuracy of 84.25%). The second step involves preserving dataset diversity through a clustering process.In our experiment, CaR selected a subset containing only 1.96% of Alpaca's IT data, yet the underlying AlpaCaR model trained on this subset outperforms Alpaca by an average of 32.1% in GPT-4 evaluations. Furthermore, our method utilizes small models (355M parameters) and requires only 11.2% of the monetary cost compared to existing methods, making it easily deployable in industrial scenarios.","sentences":["With contributions from the open-source community, a vast amount of instruction tuning (IT) data has emerged.","Given the significant resource allocation required by training and evaluating models, it is advantageous to have an efficient method for selecting high-quality IT data.","However, existing methods for instruction data selection have limitations such as relying on fragile external APIs, being affected by biases in GPT models, or reducing the diversity of the selected instruction dataset.","In this paper, we propose an industrial-friendly, expert-aligned and diversity-preserved instruction data selection method: Clustering and Ranking (CaR).","CaR consists of two steps.","The first step involves ranking instruction pairs using a scoring model that is well aligned with expert preferences (achieving an accuracy of 84.25%).","The second step involves preserving dataset diversity through a clustering process.","In our experiment, CaR selected a subset containing only 1.96% of Alpaca's IT data, yet the underlying AlpaCaR model trained on this subset outperforms Alpaca by an average of 32.1% in GPT-4 evaluations.","Furthermore, our method utilizes small models (355M parameters) and requires only 11.2% of the monetary cost compared to existing methods, making it easily deployable in industrial scenarios."],"url":"http://arxiv.org/abs/2402.18191v1"}
{"created":"2024-02-28 09:15:01","title":"Handling Open Research Data within the Max Planck Society -- Looking Closer at the Year 2020","abstract":"This paper analyses the practice of publishing research data within the Max Planck Society in the year 2020. The central finding of the study is that up to 40\\% of the empirical text publications had research data available. The aggregation of the available data is predominantly analysed. There are differences between the sections of the Max Planck Society but they are not as great as one might expect. In the case of the journals, it is also apparent that a data policy can increase the availability of data related to textual publications. Finally, we found that the statement on data availability \"upon (reasonable) request\" does not work.","sentences":["This paper analyses the practice of publishing research data within the Max Planck Society in the year 2020.","The central finding of the study is that up to 40\\% of the empirical text publications had research data available.","The aggregation of the available data is predominantly analysed.","There are differences between the sections of the Max Planck Society but they are not as great as one might expect.","In the case of the journals, it is also apparent that a data policy can increase the availability of data related to textual publications.","Finally, we found that the statement on data availability \"upon (reasonable) request\" does not work."],"url":"http://arxiv.org/abs/2402.18182v1"}
{"created":"2024-02-28 09:07:26","title":"Self-Supervised Spatially Variant PSF Estimation for Aberration-Aware Depth-from-Defocus","abstract":"In this paper, we address the task of aberration-aware depth-from-defocus (DfD), which takes account of spatially variant point spread functions (PSFs) of a real camera. To effectively obtain the spatially variant PSFs of a real camera without requiring any ground-truth PSFs, we propose a novel self-supervised learning method that leverages the pair of real sharp and blurred images, which can be easily captured by changing the aperture setting of the camera. In our PSF estimation, we assume rotationally symmetric PSFs and introduce the polar coordinate system to more accurately learn the PSF estimation network. We also handle the focus breathing phenomenon that occurs in real DfD situations. Experimental results on synthetic and real data demonstrate the effectiveness of our method regarding both the PSF estimation and the depth estimation.","sentences":["In this paper, we address the task of aberration-aware depth-from-defocus (DfD), which takes account of spatially variant point spread functions (PSFs) of a real camera.","To effectively obtain the spatially variant PSFs of a real camera without requiring any ground-truth PSFs, we propose a novel self-supervised learning method that leverages the pair of real sharp and blurred images, which can be easily captured by changing the aperture setting of the camera.","In our PSF estimation, we assume rotationally symmetric PSFs and introduce the polar coordinate system to more accurately learn the PSF estimation network.","We also handle the focus breathing phenomenon that occurs in real DfD situations.","Experimental results on synthetic and real data demonstrate the effectiveness of our method regarding both the PSF estimation and the depth estimation."],"url":"http://arxiv.org/abs/2402.18175v1"}
{"created":"2024-02-28 09:04:10","title":"Generation of skill-specific maps from graph world models for robotic systems","abstract":"With the increase in the availability of Building Information Models (BIM) and (semi-) automatic tools to generate BIM from point clouds, we propose a world model architecture and algorithms to allow the use of the semantic and geometric knowledge encoded within these models to generate maps for robot localization and navigation. When heterogeneous robots are deployed within an environment, maps obtained from classical SLAM approaches might not be shared between all agents within a team of robots, e.g. due to a mismatch in sensor type, or a difference in physical robot dimensions. Our approach extracts the 3D geometry and semantic description of building elements (e.g. material, element type, color) from BIM, and represents this knowledge in a graph. Based on queries on the graph and knowledge of the skills of the robot, we can generate skill-specific maps that can be used during the execution of localization or navigation tasks. The approach is validated with data from complex build environments and integrated into existing navigation frameworks.","sentences":["With the increase in the availability of Building Information Models (BIM) and (semi-) automatic tools to generate BIM from point clouds, we propose a world model architecture and algorithms to allow the use of the semantic and geometric knowledge encoded within these models to generate maps for robot localization and navigation.","When heterogeneous robots are deployed within an environment, maps obtained from classical SLAM approaches might not be shared between all agents within a team of robots, e.g. due to a mismatch in sensor type, or a difference in physical robot dimensions.","Our approach extracts the 3D geometry and semantic description of building elements (e.g. material, element type, color) from BIM, and represents this knowledge in a graph.","Based on queries on the graph and knowledge of the skills of the robot, we can generate skill-specific maps that can be used during the execution of localization or navigation tasks.","The approach is validated with data from complex build environments and integrated into existing navigation frameworks."],"url":"http://arxiv.org/abs/2402.18174v1"}
{"created":"2024-02-28 09:02:33","title":"NiteDR: Nighttime Image De-Raining with Cross-View Sensor Cooperative Learning for Dynamic Driving Scenes","abstract":"In real-world environments, outdoor imaging systems are often affected by disturbances such as rain degradation. Especially, in nighttime driving scenes, insufficient and uneven lighting shrouds the scenes in darkness, resulting degradation of both the image quality and visibility. Particularly, in the field of autonomous driving, the visual perception ability of RGB sensors experiences a sharp decline in such harsh scenarios. Additionally, driving assistance systems suffer from reduced capabilities in capturing and discerning the surrounding environment, posing a threat to driving safety. Single-view information captured by single-modal sensors cannot comprehensively depict the entire scene. To address these challenges, we developed an image de-raining framework tailored for rainy nighttime driving scenes. It aims to remove rain artifacts, enrich scene representation, and restore useful information. Specifically, we introduce cooperative learning between visible and infrared images captured by different sensors. By cross-view fusion of these multi-source data, the scene within the images gains richer texture details and enhanced contrast. We constructed an information cleaning module called CleanNet as the first stage of our framework. Moreover, we designed an information fusion module called FusionNet as the second stage to fuse the clean visible images with infrared images. Using this stage-by-stage learning strategy, we obtain de-rained fusion images with higher quality and better visual perception. Extensive experiments demonstrate the effectiveness of our proposed Cross-View Cooperative Learning (CVCL) in adverse driving scenarios in low-light rainy environments. The proposed approach addresses the gap in the utilization of existing rain removal algorithms in specific low-light conditions.","sentences":["In real-world environments, outdoor imaging systems are often affected by disturbances such as rain degradation.","Especially, in nighttime driving scenes, insufficient and uneven lighting shrouds the scenes in darkness, resulting degradation of both the image quality and visibility.","Particularly, in the field of autonomous driving, the visual perception ability of RGB sensors experiences a sharp decline in such harsh scenarios.","Additionally, driving assistance systems suffer from reduced capabilities in capturing and discerning the surrounding environment, posing a threat to driving safety.","Single-view information captured by single-modal sensors cannot comprehensively depict the entire scene.","To address these challenges, we developed an image de-raining framework tailored for rainy nighttime driving scenes.","It aims to remove rain artifacts, enrich scene representation, and restore useful information.","Specifically, we introduce cooperative learning between visible and infrared images captured by different sensors.","By cross-view fusion of these multi-source data, the scene within the images gains richer texture details and enhanced contrast.","We constructed an information cleaning module called CleanNet as the first stage of our framework.","Moreover, we designed an information fusion module called FusionNet as the second stage to fuse the clean visible images with infrared images.","Using this stage-by-stage learning strategy, we obtain de-rained fusion images with higher quality and better visual perception.","Extensive experiments demonstrate the effectiveness of our proposed Cross-View Cooperative Learning (CVCL) in adverse driving scenarios in low-light rainy environments.","The proposed approach addresses the gap in the utilization of existing rain removal algorithms in specific low-light conditions."],"url":"http://arxiv.org/abs/2402.18172v1"}
{"created":"2024-02-28 08:56:00","title":"Decentralised Traffic Incident Detection via Network Lasso","abstract":"Traffic incident detection plays a key role in intelligent transportation systems, which has gained great attention in transport engineering. In the past, traditional machine learning (ML) based detection methods achieved good performance under a centralised computing paradigm, where all data are transmitted to a central server for building ML models therein. Nowadays, deep neural networks based federated learning (FL) has become a mainstream detection approach to enable the model training in a decentralised manner while warranting local data governance. Such neural networks-centred techniques, however, have overshadowed the utility of well-established ML-based detection methods. In this work, we aim to explore the potential of potent conventional ML-based detection models in modern traffic scenarios featured by distributed data. We leverage an elegant but less explored distributed optimisation framework named Network Lasso, with guaranteed global convergence for convex problem formulations, integrate the potent convex ML model with it, and compare it with centralised learning, local learning, and federated learning methods atop a well-known traffic incident detection dataset. Experimental results show that the proposed network lasso-based approach provides a promising alternative to the FL-based approach in data-decentralised traffic scenarios, with a strong convergence guarantee while rekindling the significance of conventional ML-based detection methods.","sentences":["Traffic incident detection plays a key role in intelligent transportation systems, which has gained great attention in transport engineering.","In the past, traditional machine learning (ML) based detection methods achieved good performance under a centralised computing paradigm, where all data are transmitted to a central server for building ML models therein.","Nowadays, deep neural networks based federated learning (FL) has become a mainstream detection approach to enable the model training in a decentralised manner while warranting local data governance.","Such neural networks-centred techniques, however, have overshadowed the utility of well-established ML-based detection methods.","In this work, we aim to explore the potential of potent conventional ML-based detection models in modern traffic scenarios featured by distributed data.","We leverage an elegant but less explored distributed optimisation framework named Network Lasso, with guaranteed global convergence for convex problem formulations, integrate the potent convex ML model with it, and compare it with centralised learning, local learning, and federated learning methods atop a well-known traffic incident detection dataset.","Experimental results show that the proposed network lasso-based approach provides a promising alternative to the FL-based approach in data-decentralised traffic scenarios, with a strong convergence guarantee while rekindling the significance of conventional ML-based detection methods."],"url":"http://arxiv.org/abs/2402.18167v1"}
{"created":"2024-02-28 08:55:20","title":"Sequence-level Semantic Representation Fusion for Recommender Systems","abstract":"With the rapid development of recommender systems, there is increasing side information that can be employed to improve the recommendation performance. Specially, we focus on the utilization of the associated \\emph{textual data} of items (eg product title) and study how text features can be effectively fused with ID features in sequential recommendation. However, there exists distinct data characteristics for the two kinds of item features, making a direct fusion method (eg adding text and ID embeddings as item representation) become less effective. To address this issue, we propose a novel {\\ul \\emph{Te}}xt-I{\\ul \\emph{D}} semantic fusion approach for sequential {\\ul \\emph{Rec}}ommendation, namely \\textbf{\\our}. The core idea of our approach is to conduct a sequence-level semantic fusion approach by better integrating global contexts. The key strategy lies in that we transform the text embeddings and ID embeddings by Fourier Transform from \\emph{time domain} to \\emph{frequency domain}. In the frequency domain, the global sequential characteristics of the original sequences are inherently aggregated into the transformed representations, so that we can employ simple multiplicative operations to effectively fuse the two kinds of item features. Our fusion approach can be proved to have the same effects of contextual convolution, so as to achieving sequence-level semantic fusion. In order to further improve the fusion performance, we propose to enhance the discriminability of the text embeddings from the text encoder, by adaptively injecting positional information via a mixture-of-experts~(MoE) modulation method. Our implementation is available at this repository: \\textcolor{magenta}{\\url{https://github.com/RUCAIBox/TedRec}}.","sentences":["With the rapid development of recommender systems, there is increasing side information that can be employed to improve the recommendation performance.","Specially, we focus on the utilization of the associated \\emph{textual data} of items (eg product title) and study how text features can be effectively fused with ID features in sequential recommendation.","However, there exists distinct data characteristics for the two kinds of item features, making a direct fusion method (eg adding text and ID embeddings as item representation) become less effective.","To address this issue, we propose a novel {\\ul \\emph{Te}}xt-I{\\ul \\emph{D}} semantic fusion approach for sequential {\\ul \\emph{Rec}}ommendation, namely \\textbf{\\our}.","The core idea of our approach is to conduct a sequence-level semantic fusion approach by better integrating global contexts.","The key strategy lies in that we transform the text embeddings and ID embeddings by Fourier Transform from \\emph{time domain} to \\emph{frequency domain}.","In the frequency domain, the global sequential characteristics of the original sequences are inherently aggregated into the transformed representations, so that we can employ simple multiplicative operations to effectively fuse the two kinds of item features.","Our fusion approach can be proved to have the same effects of contextual convolution, so as to achieving sequence-level semantic fusion.","In order to further improve the fusion performance, we propose to enhance the discriminability of the text embeddings from the text encoder, by adaptively injecting positional information via a mixture-of-experts~(MoE) modulation method.","Our implementation is available at this repository: \\textcolor{magenta}{\\url{https://github.com/RUCAIBox/TedRec}}."],"url":"http://arxiv.org/abs/2402.18166v1"}
{"created":"2024-02-28 08:53:20","title":"Autoencoder-based General Purpose Representation Learning for Customer Embedding","abstract":"In recent years, exploiting the domain-specific underlying structure of data and its generative factors for representation learning has shown success in various use-case agnostic applications. However, the diversity and complexity of tabular data have made it challenging to represent these structures in a latent space through multi-dimensional vectors. We design an autoencoder-based framework for building general purpose embeddings, we assess the performance of different autoencoder architectures, and show simpler models outperform complex ones in embedding highly complex tabular data. We apply our framework to produce plug-and-play, rich, and anonymized embeddings representing AWS customers for usage in any model, saving up to 45% of development time, and observe significant improvements in downstream models. Moreover, we propose a significant improvement to the calculation of reconstruction loss for multi-layer contractive autoencoders (CAE) by calculating the Jacobian of the entire encoder leading to a 15% improvement in reconstruction quality when compared to a stacked CAE.","sentences":["In recent years, exploiting the domain-specific underlying structure of data and its generative factors for representation learning has shown success in various use-case agnostic applications.","However, the diversity and complexity of tabular data have made it challenging to represent these structures in a latent space through multi-dimensional vectors.","We design an autoencoder-based framework for building general purpose embeddings, we assess the performance of different autoencoder architectures, and show simpler models outperform complex ones in embedding highly complex tabular data.","We apply our framework to produce plug-and-play, rich, and anonymized embeddings representing AWS customers for usage in any model, saving up to 45% of development time, and observe significant improvements in downstream models.","Moreover, we propose a significant improvement to the calculation of reconstruction loss for multi-layer contractive autoencoders (CAE) by calculating the Jacobian of the entire encoder leading to a 15% improvement in reconstruction quality when compared to a stacked CAE."],"url":"http://arxiv.org/abs/2402.18164v1"}
{"created":"2024-02-28 08:53:01","title":"Ef-QuantFace: Streamlined Face Recognition with Small Data and Low-Bit Precision","abstract":"In recent years, model quantization for face recognition has gained prominence. Traditionally, compressing models involved vast datasets like the 5.8 million-image MS1M dataset as well as extensive training times, raising the question of whether such data enormity is essential. This paper addresses this by introducing an efficiency-driven approach, fine-tuning the model with just up to 14,000 images, 440 times smaller than MS1M. We demonstrate that effective quantization is achievable with a smaller dataset, presenting a new paradigm. Moreover, we incorporate an evaluation-based metric loss and achieve an outstanding 96.15% accuracy on the IJB-C dataset, establishing a new state-of-the-art compressed model training for face recognition. The subsequent analysis delves into potential applications, emphasizing the transformative power of this approach. This paper advances model quantization by highlighting the efficiency and optimal results with small data and training time.","sentences":["In recent years, model quantization for face recognition has gained prominence.","Traditionally, compressing models involved vast datasets like the 5.8 million-image MS1M dataset as well as extensive training times, raising the question of whether such data enormity is essential.","This paper addresses this by introducing an efficiency-driven approach, fine-tuning the model with just up to 14,000 images, 440 times smaller than MS1M. We demonstrate that effective quantization is achievable with a smaller dataset, presenting a new paradigm.","Moreover, we incorporate an evaluation-based metric loss and achieve an outstanding 96.15% accuracy on the IJB-C dataset, establishing a new state-of-the-art compressed model training for face recognition.","The subsequent analysis delves into potential applications, emphasizing the transformative power of this approach.","This paper advances model quantization by highlighting the efficiency and optimal results with small data and training time."],"url":"http://arxiv.org/abs/2402.18163v1"}
{"created":"2024-02-28 08:45:07","title":"Out-of-Distribution Detection using Neural Activation Prior","abstract":"Out-of-distribution detection is a crucial technique for deploying machine learning models in the real world to handle the unseen scenarios.In this paper, we propose a simple but effective Neural Activation Prior (NAP) for out-of-distribution detection (OOD). Our neural activation prior is based on a key observation that, for a channel before the global pooling layer of a fully trained neural network, the probability of a few of its neurons being activated with a larger response by an in-distribution (ID) sample is significantly higher than that by an OOD sample. An intuitive explanation is each channel in a model fully trained on ID dataset would play a role in detecting a certain pattern in the samples within the ID dataset, and a few neurons can be activated with a large response when the pattern is detected in an input sample. Thus, a new scoring function based on this prior is proposed to highlight the role of these strongly activated neurons in OOD detection. This approach is plug-and-play and does not lead to any performance degradation on in-distribution data classification and requires no extra training or statistics from training or external datasets. Notice that previous methods primarily rely on post-global-pooling features of the neural networks, while the within-channel distribution information we leverage would be discarded by the global pooling operator. Consequently, our method is orthogonal to existing approaches and can be effectively combined with them in various applications. Experimental results show that our method achieves the state-of-the-art performance on CIFAR-10, CIFAR-100 and ImageNet datasets, which demonstrates the power of the proposed prior.","sentences":["Out-of-distribution detection is a crucial technique for deploying machine learning models in the real world to handle the unseen scenarios.","In this paper, we propose a simple but effective Neural Activation Prior (NAP) for out-of-distribution detection (OOD).","Our neural activation prior is based on a key observation that, for a channel before the global pooling layer of a fully trained neural network, the probability of a few of its neurons being activated with a larger response by an in-distribution (ID) sample is significantly higher than that by an OOD sample.","An intuitive explanation is each channel in a model fully trained on ID dataset would play a role in detecting a certain pattern in the samples within the ID dataset, and a few neurons can be activated with a large response when the pattern is detected in an input sample.","Thus, a new scoring function based on this prior is proposed to highlight the role of these strongly activated neurons in OOD detection.","This approach is plug-and-play and does not lead to any performance degradation on in-distribution data classification and requires no extra training or statistics from training or external datasets.","Notice that previous methods primarily rely on post-global-pooling features of the neural networks, while the within-channel distribution information we leverage would be discarded by the global pooling operator.","Consequently, our method is orthogonal to existing approaches and can be effectively combined with them in various applications.","Experimental results show that our method achieves the state-of-the-art performance on CIFAR-10, CIFAR-100 and ImageNet datasets, which demonstrates the power of the proposed prior."],"url":"http://arxiv.org/abs/2402.18162v1"}
{"created":"2024-02-28 08:34:23","title":"Diffusion-based Neural Network Weights Generation","abstract":"Transfer learning is a topic of significant interest in recent deep learning research because it enables faster convergence and improved performance on new tasks. While the performance of transfer learning depends on the similarity of the source data to the target data, it is costly to train a model on a large number of datasets. Therefore, pretrained models are generally blindly selected with the hope that they will achieve good performance on the given task. To tackle such suboptimality of the pretrained models, we propose an efficient and adaptive transfer learning scheme through dataset-conditioned pretrained weights sampling. Specifically, we use a latent diffusion model with a variational autoencoder that can reconstruct the neural network weights, to learn the distribution of a set of pretrained weights conditioned on each dataset for transfer learning on unseen datasets. By learning the distribution of a neural network on a variety pretrained models, our approach enables adaptive sampling weights for unseen datasets achieving faster convergence and reaching competitive performance.","sentences":["Transfer learning is a topic of significant interest in recent deep learning research because it enables faster convergence and improved performance on new tasks.","While the performance of transfer learning depends on the similarity of the source data to the target data, it is costly to train a model on a large number of datasets.","Therefore, pretrained models are generally blindly selected with the hope that they will achieve good performance on the given task.","To tackle such suboptimality of the pretrained models, we propose an efficient and adaptive transfer learning scheme through dataset-conditioned pretrained weights sampling.","Specifically, we use a latent diffusion model with a variational autoencoder that can reconstruct the neural network weights, to learn the distribution of a set of pretrained weights conditioned on each dataset for transfer learning on unseen datasets.","By learning the distribution of a neural network on a variety pretrained models, our approach enables adaptive sampling weights for unseen datasets achieving faster convergence and reaching competitive performance."],"url":"http://arxiv.org/abs/2402.18153v1"}
{"created":"2024-02-28 08:12:31","title":"3DSFLabelling: Boosting 3D Scene Flow Estimation by Pseudo Auto-labelling","abstract":"Learning 3D scene flow from LiDAR point clouds presents significant difficulties, including poor generalization from synthetic datasets to real scenes, scarcity of real-world 3D labels, and poor performance on real sparse LiDAR point clouds. We present a novel approach from the perspective of auto-labelling, aiming to generate a large number of 3D scene flow pseudo labels for real-world LiDAR point clouds. Specifically, we employ the assumption of rigid body motion to simulate potential object-level rigid movements in autonomous driving scenarios. By updating different motion attributes for multiple anchor boxes, the rigid motion decomposition is obtained for the whole scene. Furthermore, we developed a novel 3D scene flow data augmentation method for global and local motion. By perfectly synthesizing target point clouds based on augmented motion parameters, we easily obtain lots of 3D scene flow labels in point clouds highly consistent with real scenarios. On multiple real-world datasets including LiDAR KITTI, nuScenes, and Argoverse, our method outperforms all previous supervised and unsupervised methods without requiring manual labelling. Impressively, our method achieves a tenfold reduction in EPE3D metric on the LiDAR KITTI dataset, reducing it from $0.190m$ to a mere $0.008m$ error.","sentences":["Learning 3D scene flow from LiDAR point clouds presents significant difficulties, including poor generalization from synthetic datasets to real scenes, scarcity of real-world 3D labels, and poor performance on real sparse LiDAR point clouds.","We present a novel approach from the perspective of auto-labelling, aiming to generate a large number of 3D scene flow pseudo labels for real-world LiDAR point clouds.","Specifically, we employ the assumption of rigid body motion to simulate potential object-level rigid movements in autonomous driving scenarios.","By updating different motion attributes for multiple anchor boxes, the rigid motion decomposition is obtained for the whole scene.","Furthermore, we developed a novel 3D scene flow data augmentation method for global and local motion.","By perfectly synthesizing target point clouds based on augmented motion parameters, we easily obtain lots of 3D scene flow labels in point clouds highly consistent with real scenarios.","On multiple real-world datasets including LiDAR KITTI, nuScenes, and Argoverse, our method outperforms all previous supervised and unsupervised methods without requiring manual labelling.","Impressively, our method achieves a tenfold reduction in EPE3D metric on the LiDAR KITTI dataset, reducing it from $0.190m$ to a mere $0.008m$ error."],"url":"http://arxiv.org/abs/2402.18146v1"}
{"created":"2024-02-28 08:09:14","title":"Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information","abstract":"Large language models exhibit societal biases associated with demographic information, including race, gender, and others. Endowing such language models with personalities based on demographic data can enable generating opinions that align with those of humans. Building on this idea, we propose \"random silicon sampling,\" a method to emulate the opinions of the human population sub-group. Our study analyzed 1) a language model that generates the survey responses that correspond with a human group based solely on its demographic distribution and 2) the applicability of our methodology across various demographic subgroups and thematic questions. Through random silicon sampling and using only group-level demographic information, we discovered that language models can generate response distributions that are remarkably similar to the actual U.S. public opinion polls. Moreover, we found that the replicability of language models varies depending on the demographic group and topic of the question, and this can be attributed to inherent societal biases in the models. Our findings demonstrate the feasibility of mirroring a group's opinion using only demographic distribution and elucidate the effect of social biases in language models on such simulations.","sentences":["Large language models exhibit societal biases associated with demographic information, including race, gender, and others.","Endowing such language models with personalities based on demographic data can enable generating opinions that align with those of humans.","Building on this idea, we propose \"random silicon sampling,\" a method to emulate the opinions of the human population sub-group.","Our study analyzed 1) a language model that generates the survey responses that correspond with a human group based solely on its demographic distribution and 2) the applicability of our methodology across various demographic subgroups and thematic questions.","Through random silicon sampling and using only group-level demographic information, we discovered that language models can generate response distributions that are remarkably similar to the actual U.S. public opinion polls.","Moreover, we found that the replicability of language models varies depending on the demographic group and topic of the question, and this can be attributed to inherent societal biases in the models.","Our findings demonstrate the feasibility of mirroring a group's opinion using only demographic distribution and elucidate the effect of social biases in language models on such simulations."],"url":"http://arxiv.org/abs/2402.18144v1"}
{"created":"2024-02-28 08:03:34","title":"OccTransformer: Improving BEVFormer for 3D camera-only occupancy prediction","abstract":"This technical report presents our solution, \"occTransformer\" for the 3D occupancy prediction track in the autonomous driving challenge at CVPR 2023. Our method builds upon the strong baseline BEVFormer and improves its performance through several simple yet effective techniques. Firstly, we employed data augmentation to increase the diversity of the training data and improve the model's generalization ability. Secondly, we used a strong image backbone to extract more informative features from the input data. Thirdly, we incorporated a 3D unet head to better capture the spatial information of the scene. Fourthly, we added more loss functions to better optimize the model. Additionally, we used an ensemble approach with the occ model BevDet and SurroundOcc to further improve the performance. Most importantly, we integrated 3D detection model StreamPETR to enhance the model's ability to detect objects in the scene. Using these methods, our solution achieved 49.23 miou on the 3D occupancy prediction track in the autonomous driving challenge.","sentences":["This technical report presents our solution, \"occTransformer\" for the 3D occupancy prediction track in the autonomous driving challenge at CVPR 2023.","Our method builds upon the strong baseline BEVFormer and improves its performance through several simple yet effective techniques.","Firstly, we employed data augmentation to increase the diversity of the training data and improve the model's generalization ability.","Secondly, we used a strong image backbone to extract more informative features from the input data.","Thirdly, we incorporated a 3D unet head to better capture the spatial information of the scene.","Fourthly, we added more loss functions to better optimize the model.","Additionally, we used an ensemble approach with the occ model BevDet and SurroundOcc to further improve the performance.","Most importantly, we integrated 3D detection model StreamPETR to enhance the model's ability to detect objects in the scene.","Using these methods, our solution achieved 49.23 miou on the 3D occupancy prediction track in the autonomous driving challenge."],"url":"http://arxiv.org/abs/2402.18140v1"}
{"created":"2024-02-28 07:54:50","title":"Classes Are Not Equal: An Empirical Study on Image Recognition Fairness","abstract":"In this paper, we present an empirical study on image recognition fairness, i.e., extreme class accuracy disparity on balanced data like ImageNet. We experimentally demonstrate that classes are not equal and the fairness issue is prevalent for image classification models across various datasets, network architectures, and model capacities. Moreover, several intriguing properties of fairness are identified. First, the unfairness lies in problematic representation rather than classifier bias. Second, with the proposed concept of Model Prediction Bias, we investigate the origins of problematic representation during optimization. Our findings reveal that models tend to exhibit greater prediction biases for classes that are more challenging to recognize. It means that more other classes will be confused with harder classes. Then the False Positives (FPs) will dominate the learning in optimization, thus leading to their poor accuracy. Further, we conclude that data augmentation and representation learning algorithms improve overall performance by promoting fairness to some degree in image classification.","sentences":["In this paper, we present an empirical study on image recognition fairness, i.e., extreme class accuracy disparity on balanced data like ImageNet.","We experimentally demonstrate that classes are not equal and the fairness issue is prevalent for image classification models across various datasets, network architectures, and model capacities.","Moreover, several intriguing properties of fairness are identified.","First, the unfairness lies in problematic representation rather than classifier bias.","Second, with the proposed concept of Model Prediction Bias, we investigate the origins of problematic representation during optimization.","Our findings reveal that models tend to exhibit greater prediction biases for classes that are more challenging to recognize.","It means that more other classes will be confused with harder classes.","Then the False Positives (FPs) will dominate the learning in optimization, thus leading to their poor accuracy.","Further, we conclude that data augmentation and representation learning algorithms improve overall performance by promoting fairness to some degree in image classification."],"url":"http://arxiv.org/abs/2402.18133v1"}
{"created":"2024-02-28 07:53:19","title":"Understanding the Role of Pathways in a Deep Neural Network","abstract":"Deep neural networks have demonstrated superior performance in artificial intelligence applications, but the opaqueness of their inner working mechanism is one major drawback in their application. The prevailing unit-based interpretation is a statistical observation of stimulus-response data, which fails to show a detailed internal process of inherent mechanisms of neural networks. In this work, we analyze a convolutional neural network (CNN) trained in the classification task and present an algorithm to extract the diffusion pathways of individual pixels to identify the locations of pixels in an input image associated with object classes. The pathways allow us to test the causal components which are important for classification and the pathway-based representations are clearly distinguishable between categories. We find that the few largest pathways of an individual pixel from an image tend to cross the feature maps in each layer that is important for classification. And the large pathways of images of the same category are more consistent in their trends than those of different categories. We also apply the pathways to understanding adversarial attacks, object completion, and movement perception. Further, the total number of pathways on feature maps in all layers can clearly discriminate the original, deformed, and target samples.","sentences":["Deep neural networks have demonstrated superior performance in artificial intelligence applications, but the opaqueness of their inner working mechanism is one major drawback in their application.","The prevailing unit-based interpretation is a statistical observation of stimulus-response data, which fails to show a detailed internal process of inherent mechanisms of neural networks.","In this work, we analyze a convolutional neural network (CNN) trained in the classification task and present an algorithm to extract the diffusion pathways of individual pixels to identify the locations of pixels in an input image associated with object classes.","The pathways allow us to test the causal components which are important for classification and the pathway-based representations are clearly distinguishable between categories.","We find that the few largest pathways of an individual pixel from an image tend to cross the feature maps in each layer that is important for classification.","And the large pathways of images of the same category are more consistent in their trends than those of different categories.","We also apply the pathways to understanding adversarial attacks, object completion, and movement perception.","Further, the total number of pathways on feature maps in all layers can clearly discriminate the original, deformed, and target samples."],"url":"http://arxiv.org/abs/2402.18132v1"}
{"created":"2024-02-28 07:39:58","title":"On the Inductive Biases of Demographic Parity-based Fair Learning Algorithms","abstract":"Fair supervised learning algorithms assigning labels with little dependence on a sensitive attribute have attracted great attention in the machine learning community. While the demographic parity (DP) notion has been frequently used to measure a model's fairness in training fair classifiers, several studies in the literature suggest potential impacts of enforcing DP in fair learning algorithms. In this work, we analytically study the effect of standard DP-based regularization methods on the conditional distribution of the predicted label given the sensitive attribute. Our analysis shows that an imbalanced training dataset with a non-uniform distribution of the sensitive attribute could lead to a classification rule biased toward the sensitive attribute outcome holding the majority of training data. To control such inductive biases in DP-based fair learning, we propose a sensitive attribute-based distributionally robust optimization (SA-DRO) method improving robustness against the marginal distribution of the sensitive attribute. Finally, we present several numerical results on the application of DP-based learning methods to standard centralized and distributed learning problems. The empirical findings support our theoretical results on the inductive biases in DP-based fair learning algorithms and the debiasing effects of the proposed SA-DRO method.","sentences":["Fair supervised learning algorithms assigning labels with little dependence on a sensitive attribute have attracted great attention in the machine learning community.","While the demographic parity (DP) notion has been frequently used to measure a model's fairness in training fair classifiers, several studies in the literature suggest potential impacts of enforcing DP in fair learning algorithms.","In this work, we analytically study the effect of standard DP-based regularization methods on the conditional distribution of the predicted label given the sensitive attribute.","Our analysis shows that an imbalanced training dataset with a non-uniform distribution of the sensitive attribute could lead to a classification rule biased toward the sensitive attribute outcome holding the majority of training data.","To control such inductive biases in DP-based fair learning, we propose a sensitive attribute-based distributionally robust optimization (SA-DRO) method improving robustness against the marginal distribution of the sensitive attribute.","Finally, we present several numerical results on the application of DP-based learning methods to standard centralized and distributed learning problems.","The empirical findings support our theoretical results on the inductive biases in DP-based fair learning algorithms and the debiasing effects of the proposed SA-DRO method."],"url":"http://arxiv.org/abs/2402.18129v1"}
{"created":"2024-02-28 07:36:16","title":"Hierarchical Multi-Relational Graph Representation Learning for Large-Scale Prediction of Drug-Drug Interactions","abstract":"Most existing methods for predicting drug-drug interactions (DDI) predominantly concentrate on capturing the explicit relationships among drugs, overlooking the valuable implicit correlations present between drug pairs (DPs), which leads to weak predictions. To address this issue, this paper introduces a hierarchical multi-relational graph representation learning (HMGRL) approach. Within the framework of HMGRL, we leverage a wealth of drug-related heterogeneous data sources to construct heterogeneous graphs, where nodes represent drugs and edges denote clear and various associations. The relational graph convolutional network (RGCN) is employed to capture diverse explicit relationships between drugs from these heterogeneous graphs. Additionally, a multi-view differentiable spectral clustering (MVDSC) module is developed to capture multiple valuable implicit correlations between DPs. Within the MVDSC, we utilize multiple DP features to construct graphs, where nodes represent DPs and edges denote different implicit correlations. Subsequently, multiple DP representations are generated through graph cutting, each emphasizing distinct implicit correlations. The graph-cutting strategy enables our HMGRL to identify strongly connected communities of graphs, thereby reducing the fusion of irrelevant features. By combining every representation view of a DP, we create high-level DP representations for predicting DDIs. Two genuine datasets spanning three distinct tasks are adopted to gauge the efficacy of our HMGRL. Experimental outcomes unequivocally indicate that HMGRL surpasses several leading-edge methods in performance.","sentences":["Most existing methods for predicting drug-drug interactions (DDI) predominantly concentrate on capturing the explicit relationships among drugs, overlooking the valuable implicit correlations present between drug pairs (DPs), which leads to weak predictions.","To address this issue, this paper introduces a hierarchical multi-relational graph representation learning (HMGRL) approach.","Within the framework of HMGRL, we leverage a wealth of drug-related heterogeneous data sources to construct heterogeneous graphs, where nodes represent drugs and edges denote clear and various associations.","The relational graph convolutional network (RGCN) is employed to capture diverse explicit relationships between drugs from these heterogeneous graphs.","Additionally, a multi-view differentiable spectral clustering (MVDSC) module is developed to capture multiple valuable implicit correlations between DPs.","Within the MVDSC, we utilize multiple DP features to construct graphs, where nodes represent DPs and edges denote different implicit correlations.","Subsequently, multiple DP representations are generated through graph cutting, each emphasizing distinct implicit correlations.","The graph-cutting strategy enables our HMGRL to identify strongly connected communities of graphs, thereby reducing the fusion of irrelevant features.","By combining every representation view of a DP, we create high-level DP representations for predicting DDIs.","Two genuine datasets spanning three distinct tasks are adopted to gauge the efficacy of our HMGRL.","Experimental outcomes unequivocally indicate that HMGRL surpasses several leading-edge methods in performance."],"url":"http://arxiv.org/abs/2402.18127v1"}
{"created":"2024-02-28 07:18:39","title":"Exploring Multilingual Human Value Concepts in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?","abstract":"Prior research in representation engineering has revealed that LLMs encode concepts within their representation spaces, predominantly centered around English. In this study, we extend this philosophy to a multilingual scenario, delving into multilingual human value concepts in LLMs. Through our comprehensive exploration covering 7 types of human values, 16 languages and 3 LLM series with distinct multilinguality, we empirically substantiate the existence of multilingual human values in LLMs. Further cross-lingual analysis on these concepts discloses 3 traits arising from language resource disparities: cross-lingual inconsistency, distorted linguistic relationships, and unidirectional cross-lingual transfer between high- and low-resource languages, all in terms of human value concepts. Additionally, we validate the feasibility of cross-lingual control over value alignment capabilities of LLMs, leveraging the dominant language as a source language. Drawing from our findings on multilingual value alignment, we prudently provide suggestions on the composition of multilingual data for LLMs pre-training: including a limited number of dominant languages for cross-lingual alignment transfer while avoiding their excessive prevalence, and keeping a balanced distribution of non-dominant languages. We aspire that our findings would contribute to enhancing the safety and utility of multilingual AI.","sentences":["Prior research in representation engineering has revealed that LLMs encode concepts within their representation spaces, predominantly centered around English.","In this study, we extend this philosophy to a multilingual scenario, delving into multilingual human value concepts in LLMs.","Through our comprehensive exploration covering 7 types of human values, 16 languages and 3 LLM series with distinct multilinguality, we empirically substantiate the existence of multilingual human values in LLMs.","Further cross-lingual analysis on these concepts discloses 3 traits arising from language resource disparities: cross-lingual inconsistency, distorted linguistic relationships, and unidirectional cross-lingual transfer between high- and low-resource languages, all in terms of human value concepts.","Additionally, we validate the feasibility of cross-lingual control over value alignment capabilities of LLMs, leveraging the dominant language as a source language.","Drawing from our findings on multilingual value alignment, we prudently provide suggestions on the composition of multilingual data for LLMs pre-training: including a limited number of dominant languages for cross-lingual alignment transfer while avoiding their excessive prevalence, and keeping a balanced distribution of non-dominant languages.","We aspire that our findings would contribute to enhancing the safety and utility of multilingual AI."],"url":"http://arxiv.org/abs/2402.18120v1"}
{"created":"2024-02-28 07:02:38","title":"Small But Funny: A Feedback-Driven Approach to Humor Distillation","abstract":"The emergence of Large Language Models (LLMs) has brought to light promising language generation capabilities, particularly in performing tasks like complex reasoning and creative writing. Consequently, distillation through imitation of teacher responses has emerged as a popular technique to transfer knowledge from LLMs to more accessible, Small Language Models (SLMs). While this works well for simpler tasks, there is a substantial performance gap on tasks requiring intricate language comprehension and creativity, such as humor generation. We hypothesize that this gap may stem from the fact that creative tasks might be hard to learn by imitation alone and explore whether an approach, involving supplementary guidance from the teacher, could yield higher performance. To address this, we study the effect of assigning a dual role to the LLM - as a \"teacher\" generating data, as well as a \"critic\" evaluating the student's performance. Our experiments on humor generation reveal that the incorporation of feedback significantly narrows the performance gap between SLMs and their larger counterparts compared to merely relying on imitation. As a result, our research highlights the potential of using feedback as an additional dimension to data when transferring complex language abilities via distillation.","sentences":["The emergence of Large Language Models (LLMs) has brought to light promising language generation capabilities, particularly in performing tasks like complex reasoning and creative writing.","Consequently, distillation through imitation of teacher responses has emerged as a popular technique to transfer knowledge from LLMs to more accessible, Small Language Models (SLMs).","While this works well for simpler tasks, there is a substantial performance gap on tasks requiring intricate language comprehension and creativity, such as humor generation.","We hypothesize that this gap may stem from the fact that creative tasks might be hard to learn by imitation alone and explore whether an approach, involving supplementary guidance from the teacher, could yield higher performance.","To address this, we study the effect of assigning a dual role to the LLM - as a \"teacher\" generating data, as well as a \"critic\" evaluating the student's performance.","Our experiments on humor generation reveal that the incorporation of feedback significantly narrows the performance gap between SLMs and their larger counterparts compared to merely relying on imitation.","As a result, our research highlights the potential of using feedback as an additional dimension to data when transferring complex language abilities via distillation."],"url":"http://arxiv.org/abs/2402.18113v1"}
{"created":"2024-02-28 06:54:35","title":"Multimodal Interaction Modeling via Self-Supervised Multi-Task Learning for Review Helpfulness Prediction","abstract":"In line with the latest research, the task of identifying helpful reviews from a vast pool of user-generated textual and visual data has become a prominent area of study. Effective modal representations are expected to possess two key attributes: consistency and differentiation. Current methods designed for Multimodal Review Helpfulness Prediction (MRHP) face limitations in capturing distinctive information due to their reliance on uniform multimodal annotation. The process of adding varied multimodal annotations is not only time-consuming but also labor-intensive. To tackle these challenges, we propose an auto-generated scheme based on multi-task learning to generate pseudo labels. This approach allows us to simultaneously train for the global multimodal interaction task and the separate cross-modal interaction subtasks, enabling us to learn and leverage both consistency and differentiation effectively. Subsequently, experimental results validate the effectiveness of pseudo labels, and our approach surpasses previous textual and multimodal baseline models on two widely accessible benchmark datasets, providing a solution to the MRHP problem.","sentences":["In line with the latest research, the task of identifying helpful reviews from a vast pool of user-generated textual and visual data has become a prominent area of study.","Effective modal representations are expected to possess two key attributes: consistency and differentiation.","Current methods designed for Multimodal Review Helpfulness Prediction (MRHP) face limitations in capturing distinctive information due to their reliance on uniform multimodal annotation.","The process of adding varied multimodal annotations is not only time-consuming but also labor-intensive.","To tackle these challenges, we propose an auto-generated scheme based on multi-task learning to generate pseudo labels.","This approach allows us to simultaneously train for the global multimodal interaction task and the separate cross-modal interaction subtasks, enabling us to learn and leverage both consistency and differentiation effectively.","Subsequently, experimental results validate the effectiveness of pseudo labels, and our approach surpasses previous textual and multimodal baseline models on two widely accessible benchmark datasets, providing a solution to the MRHP problem."],"url":"http://arxiv.org/abs/2402.18107v1"}
{"created":"2024-02-28 06:28:15","title":"ChatSpamDetector: Leveraging Large Language Models for Effective Phishing Email Detection","abstract":"The proliferation of phishing sites and emails poses significant challenges to existing cybersecurity efforts. Despite advances in spam filters and email security protocols, problems with oversight and false positives persist. Users often struggle to understand why emails are flagged as spam, risking the possibility of missing important communications or mistakenly trusting phishing emails.   This study introduces ChatSpamDetector, a system that uses large language models (LLMs) to detect phishing emails. By converting email data into a prompt suitable for LLM analysis, the system provides a highly accurate determination of whether an email is phishing or not. Importantly, it offers detailed reasoning for its phishing determinations, assisting users in making informed decisions about how to handle suspicious emails. We conducted an evaluation using a comprehensive phishing email dataset and compared our system to several LLMs and baseline systems. We confirmed that our system using GPT-4 has superior detection capabilities with an accuracy of 99.70%. Advanced contextual interpretation by LLMs enables the identification of various phishing tactics and impersonations, making them a potentially powerful tool in the fight against email-based phishing threats.","sentences":["The proliferation of phishing sites and emails poses significant challenges to existing cybersecurity efforts.","Despite advances in spam filters and email security protocols, problems with oversight and false positives persist.","Users often struggle to understand why emails are flagged as spam, risking the possibility of missing important communications or mistakenly trusting phishing emails.   ","This study introduces ChatSpamDetector, a system that uses large language models (LLMs) to detect phishing emails.","By converting email data into a prompt suitable for LLM analysis, the system provides a highly accurate determination of whether an email is phishing or not.","Importantly, it offers detailed reasoning for its phishing determinations, assisting users in making informed decisions about how to handle suspicious emails.","We conducted an evaluation using a comprehensive phishing email dataset and compared our system to several LLMs and baseline systems.","We confirmed that our system using GPT-4 has superior detection capabilities with an accuracy of 99.70%.","Advanced contextual interpretation by LLMs enables the identification of various phishing tactics and impersonations, making them a potentially powerful tool in the fight against email-based phishing threats."],"url":"http://arxiv.org/abs/2402.18093v1"}
{"created":"2024-02-28 06:24:39","title":"Polos: Multimodal Metric Learning from Human Feedback for Image Captioning","abstract":"Establishing an automatic evaluation metric that closely aligns with human judgments is essential for effectively developing image captioning models. Recent data-driven metrics have demonstrated a stronger correlation with human judgments than classic metrics such as CIDEr; however they lack sufficient capabilities to handle hallucinations and generalize across diverse images and texts partially because they compute scalar similarities merely using embeddings learned from tasks unrelated to image captioning evaluation. In this study, we propose Polos, a supervised automatic evaluation metric for image captioning models. Polos computes scores from multimodal inputs, using a parallel feature extraction mechanism that leverages embeddings trained through large-scale contrastive learning. To train Polos, we introduce Multimodal Metric Learning from Human Feedback (M$^2$LHF), a framework for developing metrics based on human feedback. We constructed the Polaris dataset, which comprises 131K human judgments from 550 evaluators, which is approximately ten times larger than standard datasets. Our approach achieved state-of-the-art performance on Composite, Flickr8K-Expert, Flickr8K-CF, PASCAL-50S, FOIL, and the Polaris dataset, thereby demonstrating its effectiveness and robustness.","sentences":["Establishing an automatic evaluation metric that closely aligns with human judgments is essential for effectively developing image captioning models.","Recent data-driven metrics have demonstrated a stronger correlation with human judgments than classic metrics such as CIDEr; however they lack sufficient capabilities to handle hallucinations and generalize across diverse images and texts partially because they compute scalar similarities merely using embeddings learned from tasks unrelated to image captioning evaluation.","In this study, we propose Polos, a supervised automatic evaluation metric for image captioning models.","Polos computes scores from multimodal inputs, using a parallel feature extraction mechanism that leverages embeddings trained through large-scale contrastive learning.","To train Polos, we introduce Multimodal Metric Learning from Human Feedback (M$^2$LHF), a framework for developing metrics based on human feedback.","We constructed the Polaris dataset, which comprises 131K human judgments from 550 evaluators, which is approximately ten times larger than standard datasets.","Our approach achieved state-of-the-art performance on Composite, Flickr8K-Expert, Flickr8K-CF, PASCAL-50S, FOIL, and the Polaris dataset, thereby demonstrating its effectiveness and robustness."],"url":"http://arxiv.org/abs/2402.18091v1"}
{"created":"2024-02-28 06:22:24","title":"Computing Minimal Absent Words and Extended Bispecial Factors with CDAWG Space","abstract":"A string $w$ is said to be a minimal absent word (MAW) for a string $S$ if $w$ does not occur in $S$ and any proper substring of $w$ occurs in $S$. We focus on non-trivial MAWs which are of length at least 2. Finding such non-trivial MAWs for a given string is motivated for applications in bioinformatics and data compression. Fujishige et al. [TCS 2023] proposed a data structure of size $\\Theta(n)$ that can output the set $\\mathsf{MAW}(S)$ of all MAWs for a given string $S$ of length $n$ in $O(n + |\\mathsf{MAW}(S)|)$ time, based on the directed acyclic word graph (DAWG). In this paper, we present a more space efficient data structure based on the compact DAWG (CDAWG), which can output $\\mathsf{MAW}(S)$ in $O(|\\mathsf{MAW}(S)|)$ time with $O(e)$ space, where $e$ denotes the minimum of the sizes of the CDAWGs for $S$ and for its reversal $S^R$. For any strings of length $n$, it holds that $e < 2n$, and for highly repetitive strings $e$ can be sublinear (up to logarithmic) in $n$. We also show that MAWs and their generalization minimal rare words have close relationships with extended bispecial factors, via the CDAWG.","sentences":["A string $w$ is said to be a minimal absent word (MAW) for a string $S$ if $w$ does not occur in $S$ and any proper substring of $w$ occurs in $S$. We focus on non-trivial MAWs which are of length at least 2.","Finding such non-trivial MAWs for a given string is motivated for applications in bioinformatics and data compression.","Fujishige et al.","[TCS 2023] proposed a data structure of size $\\Theta(n)$ that can output the set $\\mathsf{MAW}(S)$ of all MAWs for a given string $S$ of length $n$ in $O(n + |\\mathsf{MAW}(S)|)$ time, based on the directed acyclic word graph (DAWG).","In this paper, we present a more space efficient data structure based on the compact DAWG (CDAWG), which can output $\\mathsf{MAW}(S)$ in $O(|\\mathsf{MAW}(S)|)$ time with $O(e)$ space, where $e$ denotes the minimum of the sizes of the CDAWGs for $S$ and for its reversal $S^R$. For any strings of length $n$, it holds that $e < 2n$, and for highly repetitive strings $e$ can be sublinear (up to logarithmic) in $n$. We also show that MAWs and their generalization minimal rare words have close relationships with extended bispecial factors, via the CDAWG."],"url":"http://arxiv.org/abs/2402.18090v1"}
{"created":"2024-02-28 06:01:44","title":"A Hierarchical Dataflow-Driven Heterogeneous Architecture for Wireless Baseband Processing","abstract":"Wireless baseband processing (WBP) is a key element of wireless communications, with a series of signal processing modules to improve data throughput and counter channel fading. Conventional hardware solutions, such as digital signal processors (DSPs) and more recently, graphic processing units (GPUs), provide various degrees of parallelism, yet they both fail to take into account the cyclical and consecutive character of WBP. Furthermore, the large amount of data in WBPs cannot be processed quickly in symmetric multiprocessors (SMPs) due to the unpredictability of memory latency. To address this issue, we propose a hierarchical dataflow-driven architecture to accelerate WBP. A pack-and-ship approach is presented under a non-uniform memory access (NUMA) architecture to allow the subordinate tiles to operate in a bundled access and execute manner. We also propose a multi-level dataflow model and the related scheduling scheme to manage and allocate the heterogeneous hardware resources. Experiment results demonstrate that our prototype achieves $2\\times$ and $2.3\\times$ speedup in terms of normalized throughput and single-tile clock cycles compared with GPU and DSP counterparts in several critical WBP benchmarks. Additionally, a link-level throughput of $288$ Mbps can be achieved with a $45$-core configuration.","sentences":["Wireless baseband processing (WBP) is a key element of wireless communications, with a series of signal processing modules to improve data throughput and counter channel fading.","Conventional hardware solutions, such as digital signal processors (DSPs) and more recently, graphic processing units (GPUs), provide various degrees of parallelism, yet they both fail to take into account the cyclical and consecutive character of WBP.","Furthermore, the large amount of data in WBPs cannot be processed quickly in symmetric multiprocessors (SMPs) due to the unpredictability of memory latency.","To address this issue, we propose a hierarchical dataflow-driven architecture to accelerate WBP.","A pack-and-ship approach is presented under a non-uniform memory access (NUMA) architecture to allow the subordinate tiles to operate in a bundled access and execute manner.","We also propose a multi-level dataflow model and the related scheduling scheme to manage and allocate the heterogeneous hardware resources.","Experiment results demonstrate that our prototype achieves $2\\times$ and $2.3\\times$ speedup in terms of normalized throughput and single-tile clock cycles compared with GPU and DSP counterparts in several critical WBP benchmarks.","Additionally, a link-level throughput of $288$ Mbps can be achieved with a $45$-core configuration."],"url":"http://arxiv.org/abs/2402.18070v1"}
{"created":"2024-02-28 05:50:18","title":"A Probabilistic Motion Model for Skid-Steer Wheeled Mobile Robot Navigation on Off-Road Terrains","abstract":"Skid-Steer Wheeled Mobile Robots (SSWMRs) are increasingly being used for off-road autonomy applications. When turning at high speeds, these robots tend to undergo significant skidding and slipping. In this work, using Gaussian Process Regression (GPR) and Sigma-Point Transforms, we estimate the non-linear effects of tire-terrain interaction on robot velocities in a probabilistic fashion. Using the mean estimates from GPR, we propose a data-driven dynamic motion model that is more accurate at predicting future robot poses than conventional kinematic motion models. By efficiently solving a convex optimization problem based on the history of past robot motion, the GPR augmented motion model generalizes to previously unseen terrain conditions. The output distribution from the proposed motion model can be used for local motion planning approaches, such as stochastic model predictive control, leveraging model uncertainty to make safe decisions. We validate our work on a benchmark real-world multi-terrain SSWMR dataset. Our results show that the model generalizes to three different terrains while significantly reducing errors in linear and angular motion predictions. As shown in the attached video, we perform a separate set of experiments on a physical robot to demonstrate the robustness of the proposed algorithm.","sentences":["Skid-Steer Wheeled Mobile Robots (SSWMRs) are increasingly being used for off-road autonomy applications.","When turning at high speeds, these robots tend to undergo significant skidding and slipping.","In this work, using Gaussian Process Regression (GPR) and Sigma-Point Transforms, we estimate the non-linear effects of tire-terrain interaction on robot velocities in a probabilistic fashion.","Using the mean estimates from GPR, we propose a data-driven dynamic motion model that is more accurate at predicting future robot poses than conventional kinematic motion models.","By efficiently solving a convex optimization problem based on the history of past robot motion, the GPR augmented motion model generalizes to previously unseen terrain conditions.","The output distribution from the proposed motion model can be used for local motion planning approaches, such as stochastic model predictive control, leveraging model uncertainty to make safe decisions.","We validate our work on a benchmark real-world multi-terrain SSWMR dataset.","Our results show that the model generalizes to three different terrains while significantly reducing errors in linear and angular motion predictions.","As shown in the attached video, we perform a separate set of experiments on a physical robot to demonstrate the robustness of the proposed algorithm."],"url":"http://arxiv.org/abs/2402.18065v1"}
{"created":"2024-02-28 05:49:08","title":"Automated Testing of Spatially-Dependent Environmental Hypotheses through Active Transfer Learning","abstract":"The efficient collection of samples is an important factor in outdoor information gathering applications on account of high sampling costs such as time, energy, and potential destruction to the environment. Utilization of available a-priori data can be a powerful tool for increasing efficiency. However, the relationships of this data with the quantity of interest are often not known ahead of time, limiting the ability to leverage this knowledge for improved planning efficiency. To this end, this work combines transfer learning and active learning through a Multi-Task Gaussian Process and an information-based objective function. Through this combination it can explore the space of hypothetical inter-quantity relationships and evaluate these hypotheses in real-time, allowing this new knowledge to be immediately exploited for future plans. The performance of the proposed method is evaluated against synthetic data and is shown to evaluate multiple hypotheses correctly. Its effectiveness is also demonstrated on real datasets. The technique is able to identify and leverage hypotheses which show a medium or strong correlation to reduce prediction error by a factor of 1.5--6 within the first 5 samples, and poor hypotheses are quickly identified and rejected, having no adverse effect on planning after around 3 samples.","sentences":["The efficient collection of samples is an important factor in outdoor information gathering applications on account of high sampling costs such as time, energy, and potential destruction to the environment.","Utilization of available a-priori data can be a powerful tool for increasing efficiency.","However, the relationships of this data with the quantity of interest are often not known ahead of time, limiting the ability to leverage this knowledge for improved planning efficiency.","To this end, this work combines transfer learning and active learning through a Multi-Task Gaussian Process and an information-based objective function.","Through this combination it can explore the space of hypothetical inter-quantity relationships and evaluate these hypotheses in real-time, allowing this new knowledge to be immediately exploited for future plans.","The performance of the proposed method is evaluated against synthetic data and is shown to evaluate multiple hypotheses correctly.","Its effectiveness is also demonstrated on real datasets.","The technique is able to identify and leverage hypotheses which show a medium or strong correlation to reduce prediction error by a factor of 1.5--6 within the first 5 samples, and poor hypotheses are quickly identified and rejected, having no adverse effect on planning after around 3 samples."],"url":"http://arxiv.org/abs/2402.18064v1"}
{"created":"2024-02-28 05:46:23","title":"Generative AI for Unmanned Vehicle Swarms: Challenges, Applications and Opportunities","abstract":"With recent advances in artificial intelligence (AI) and robotics, unmanned vehicle swarms have received great attention from both academia and industry due to their potential to provide services that are difficult and dangerous to perform by humans. However, learning and coordinating movements and actions for a large number of unmanned vehicles in complex and dynamic environments introduce significant challenges to conventional AI methods. Generative AI (GAI), with its capabilities in complex data feature extraction, transformation, and enhancement, offers great potential in solving these challenges of unmanned vehicle swarms. For that, this paper aims to provide a comprehensive survey on applications, challenges, and opportunities of GAI in unmanned vehicle swarms. Specifically, we first present an overview of unmanned vehicles and unmanned vehicle swarms as well as their use cases and existing issues. Then, an in-depth background of various GAI techniques together with their capabilities in enhancing unmanned vehicle swarms are provided. After that, we present a comprehensive review on the applications and challenges of GAI in unmanned vehicle swarms with various insights and discussions. Finally, we highlight open issues of GAI in unmanned vehicle swarms and discuss potential research directions.","sentences":["With recent advances in artificial intelligence (AI) and robotics, unmanned vehicle swarms have received great attention from both academia and industry due to their potential to provide services that are difficult and dangerous to perform by humans.","However, learning and coordinating movements and actions for a large number of unmanned vehicles in complex and dynamic environments introduce significant challenges to conventional AI methods.","Generative AI (GAI), with its capabilities in complex data feature extraction, transformation, and enhancement, offers great potential in solving these challenges of unmanned vehicle swarms.","For that, this paper aims to provide a comprehensive survey on applications, challenges, and opportunities of GAI in unmanned vehicle swarms.","Specifically, we first present an overview of unmanned vehicles and unmanned vehicle swarms as well as their use cases and existing issues.","Then, an in-depth background of various GAI techniques together with their capabilities in enhancing unmanned vehicle swarms are provided.","After that, we present a comprehensive review on the applications and challenges of GAI in unmanned vehicle swarms with various insights and discussions.","Finally, we highlight open issues of GAI in unmanned vehicle swarms and discuss potential research directions."],"url":"http://arxiv.org/abs/2402.18062v1"}
{"created":"2024-02-28 05:45:37","title":"On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction","abstract":"The superior performance of supervised classification methods in the information extraction (IE) area heavily relies on a large amount of gold standard data. Recent zero-shot classification methods converted the task to other NLP tasks (e.g., textual entailment) and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of IE annotation data. A potentially valuable by-product of these methods is the large-scale silver standard data, i.e., pseudo-labeled data by the off-the-shelf models of other NLP tasks. However, there is no further investigation into the use of these data. In this paper, we propose a new framework, Clean-LaVe, which aims to utilize silver standard data to enhance the zero-shot performance. Clean-LaVe includes four phases: (1) Obtaining silver data; (2) Identifying relatively clean data from silver data; (3) Finetuning the off-the-shelf model using clean data; (4) Inference on the test data. The experimental results show that Clean-LaVe can outperform the baseline by 5% and 6% on TACRED and Wiki80 dataset in the zero-shot relation classification task, and by 3%-7% on Smile (Korean and Polish) in the zero-shot cross-lingual relation classification task, and by 8% on ACE05-E+ in the zero-shot event argument classification task. The code is share in https://github.com/wjw136/Clean_LaVe.git.","sentences":["The superior performance of supervised classification methods in the information extraction (IE) area heavily relies on a large amount of gold standard data.","Recent zero-shot classification methods converted the task to other NLP tasks (e.g., textual entailment) and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of IE annotation data.","A potentially valuable by-product of these methods is the large-scale silver standard data, i.e., pseudo-labeled data by the off-the-shelf models of other NLP tasks.","However, there is no further investigation into the use of these data.","In this paper, we propose a new framework, Clean-LaVe, which aims to utilize silver standard data to enhance the zero-shot performance.","Clean-LaVe includes four phases: (1) Obtaining silver data; (2) Identifying relatively clean data from silver data; (3) Finetuning the off-the-shelf model using clean data; (4) Inference on the test data.","The experimental results show that Clean-LaVe can outperform the baseline by 5% and 6% on TACRED and Wiki80 dataset in the zero-shot relation classification task, and by 3%-7% on Smile (Korean and Polish) in the zero-shot cross-lingual relation classification task, and by 8% on ACE05-E+ in the zero-shot event argument classification task.","The code is share in https://github.com/wjw136/Clean_LaVe.git."],"url":"http://arxiv.org/abs/2402.18061v1"}
{"created":"2024-02-28 04:58:07","title":"MEGAnno+: A Human-LLM Collaborative Annotation System","abstract":"Large language models (LLMs) can label data faster and cheaper than humans for various NLP tasks. Despite their prowess, LLMs may fall short in understanding of complex, sociocultural, or domain-specific context, potentially leading to incorrect annotations. Therefore, we advocate a collaborative approach where humans and LLMs work together to produce reliable and high-quality labels. We present MEGAnno+, a human-LLM collaborative annotation system that offers effective LLM agent and annotation management, convenient and robust LLM annotation, and exploratory verification of LLM labels by humans.","sentences":["Large language models (LLMs) can label data faster and cheaper than humans for various NLP tasks.","Despite their prowess, LLMs may fall short in understanding of complex, sociocultural, or domain-specific context, potentially leading to incorrect annotations.","Therefore, we advocate a collaborative approach where humans and LLMs work together to produce reliable and high-quality labels.","We present MEGAnno+, a human-LLM collaborative annotation system that offers effective LLM agent and annotation management, convenient and robust LLM annotation, and exploratory verification of LLM labels by humans."],"url":"http://arxiv.org/abs/2402.18050v1"}
{"created":"2024-02-28 04:47:32","title":"Data augmentation method for modeling health records with applications to clopidogrel treatment failure detection","abstract":"We present a novel data augmentation method to address the challenge of data scarcity in modeling longitudinal patterns in Electronic Health Records (EHR) of patients using natural language processing (NLP) algorithms. The proposed method generates augmented data by rearranging the orders of medical records within a visit where the order of elements are not obvious, if any. Applying the proposed method to the clopidogrel treatment failure detection task enabled up to 5.3% absolute improvement in terms of ROC-AUC (from 0.908 without augmentation to 0.961 with augmentation) when it was used during the pre-training procedure. It was also shown that the augmentation helped to improve performance during fine-tuning procedures, especially when the amount of labeled training data is limited.","sentences":["We present a novel data augmentation method to address the challenge of data scarcity in modeling longitudinal patterns in Electronic Health Records (EHR) of patients using natural language processing (NLP) algorithms.","The proposed method generates augmented data by rearranging the orders of medical records within a visit where the order of elements are not obvious, if any.","Applying the proposed method to the clopidogrel treatment failure detection task enabled up to 5.3% absolute improvement in terms of ROC-AUC (from 0.908 without augmentation to 0.961 with augmentation) when it was used during the pre-training procedure.","It was also shown that the augmentation helped to improve performance during fine-tuning procedures, especially when the amount of labeled training data is limited."],"url":"http://arxiv.org/abs/2402.18046v1"}
{"created":"2024-02-28 04:42:59","title":"Crisis talk: analysis of the public debate around the energy crisis and cost of living","abstract":"A prominent media topic in the UK in the early 2020s is the energy crisis affecting the UK and most of Europe. It brings into a single public debate issues of energy dependency and sustainability, fair distribution of economic burdens and cost of living, as well as climate change, risk, and sustainability. In this paper, we investigate the public discourse around the energy crisis and cost of living to identify how these pivotal and contradictory issues are reconciled in this debate and to identify which social actors are involved and the role they play. We analyse a document corpus retrieved from UK newspapers from January 2014 to March 2023. We apply a variety of natural language processing and data visualisation techniques to identify key topics, novel trends, critical social actors, and the role they play in the debate, along with the sentiment associated with those actors and topics. We combine automated techniques with manual discourse analysis to explore and validate the insights revealed in this study. The findings verify the utility of these techniques by providing a flexible and scalable pipeline for discourse analysis and providing critical insights for cost of living - energy crisis nexus research.","sentences":["A prominent media topic in the UK in the early 2020s is the energy crisis affecting the UK and most of Europe.","It brings into a single public debate issues of energy dependency and sustainability, fair distribution of economic burdens and cost of living, as well as climate change, risk, and sustainability.","In this paper, we investigate the public discourse around the energy crisis and cost of living to identify how these pivotal and contradictory issues are reconciled in this debate and to identify which social actors are involved and the role they play.","We analyse a document corpus retrieved from UK newspapers from January 2014 to March 2023.","We apply a variety of natural language processing and data visualisation techniques to identify key topics, novel trends, critical social actors, and the role they play in the debate, along with the sentiment associated with those actors and topics.","We combine automated techniques with manual discourse analysis to explore and validate the insights revealed in this study.","The findings verify the utility of these techniques by providing a flexible and scalable pipeline for discourse analysis and providing critical insights for cost of living - energy crisis nexus research."],"url":"http://arxiv.org/abs/2402.18043v1"}
{"created":"2024-02-28 04:35:51","title":"Datasets for Large Language Models: A Comprehensive Survey","abstract":"This paper embarks on an exploration into the Large Language Model (LLM) datasets, which play a crucial role in the remarkable advancements of LLMs. The datasets serve as the foundational infrastructure analogous to a root system that sustains and nurtures the development of LLMs. Consequently, examination of these datasets emerges as a critical topic in research. In order to address the current lack of a comprehensive overview and thorough analysis of LLM datasets, and to gain insights into their current status and future trends, this survey consolidates and categorizes the fundamental aspects of LLM datasets from five perspectives: (1) Pre-training Corpora; (2) Instruction Fine-tuning Datasets; (3) Preference Datasets; (4) Evaluation Datasets; (5) Traditional Natural Language Processing (NLP) Datasets. The survey sheds light on the prevailing challenges and points out potential avenues for future investigation. Additionally, a comprehensive review of the existing available dataset resources is also provided, including statistics from 444 datasets, covering 8 language categories and spanning 32 domains. Information from 20 dimensions is incorporated into the dataset statistics. The total data size surveyed surpasses 774.5 TB for pre-training corpora and 700M instances for other datasets. We aim to present the entire landscape of LLM text datasets, serving as a comprehensive reference for researchers in this field and contributing to future studies. Related resources are available at: https://github.com/lmmlzn/Awesome-LLMs-Datasets.","sentences":["This paper embarks on an exploration into the Large Language Model (LLM) datasets, which play a crucial role in the remarkable advancements of LLMs.","The datasets serve as the foundational infrastructure analogous to a root system that sustains and nurtures the development of LLMs.","Consequently, examination of these datasets emerges as a critical topic in research.","In order to address the current lack of a comprehensive overview and thorough analysis of LLM datasets, and to gain insights into their current status and future trends, this survey consolidates and categorizes the fundamental aspects of LLM datasets from five perspectives: (1) Pre-training Corpora; (2) Instruction Fine-tuning Datasets; (3) Preference Datasets; (4) Evaluation Datasets; (5) Traditional Natural Language Processing (NLP) Datasets.","The survey sheds light on the prevailing challenges and points out potential avenues for future investigation.","Additionally, a comprehensive review of the existing available dataset resources is also provided, including statistics from 444 datasets, covering 8 language categories and spanning 32 domains.","Information from 20 dimensions is incorporated into the dataset statistics.","The total data size surveyed surpasses 774.5 TB for pre-training corpora and 700M instances for other datasets.","We aim to present the entire landscape of LLM text datasets, serving as a comprehensive reference for researchers in this field and contributing to future studies.","Related resources are available at: https://github.com/lmmlzn/Awesome-LLMs-Datasets."],"url":"http://arxiv.org/abs/2402.18041v1"}
{"created":"2024-02-28 04:34:15","title":"Automated Discovery of Integral with Deep Learning","abstract":"Recent advancements in the realm of deep learning, particularly in the development of large language models (LLMs), have demonstrated AI's ability to tackle complex mathematical problems or solving programming challenges. However, the capability to solve well-defined problems based on extensive training data differs significantly from the nuanced process of making scientific discoveries. Trained on almost all human knowledge available, today's sophisticated LLMs basically learn to predict sequences of tokens. They generate mathematical derivations and write code in a similar way as writing an essay, and do not have the ability to pioneer scientific discoveries in the manner a human scientist would do.   In this study we delve into the potential of using deep learning to rediscover a fundamental mathematical concept: integrals. By defining integrals as area under the curve, we illustrate how AI can deduce the integral of a given function, exemplified by inferring $\\int_{0}^{x} t^2 dt = \\frac{x^3}{3}$ and $\\int_{0}^{x} ae^{bt} dt = \\frac{a}{b} e^{bx} - \\frac{a}{b}$. Our experiments show that deep learning models can approach the task of inferring integrals either through a sequence-to-sequence model, akin to language translation, or by uncovering the rudimentary principles of integration, such as $\\int_{0}^{x} t^n dt = \\frac{x^{n+1}}{n+1}$.","sentences":["Recent advancements in the realm of deep learning, particularly in the development of large language models (LLMs), have demonstrated AI's ability to tackle complex mathematical problems or solving programming challenges.","However, the capability to solve well-defined problems based on extensive training data differs significantly from the nuanced process of making scientific discoveries.","Trained on almost all human knowledge available, today's sophisticated LLMs basically learn to predict sequences of tokens.","They generate mathematical derivations and write code in a similar way as writing an essay, and do not have the ability to pioneer scientific discoveries in the manner a human scientist would do.   ","In this study we delve into the potential of using deep learning to rediscover a fundamental mathematical concept: integrals.","By defining integrals as area under the curve, we illustrate how AI can deduce the integral of a given function, exemplified by inferring $\\int_{0}^{x} t^2 dt = \\frac{x^3}{3}$ and $\\int_{0}^{x} ae^{bt} dt = \\frac{a}{b} e^{bx} - \\frac{a}{b}$.","Our experiments show that deep learning models can approach the task of inferring integrals either through a sequence-to-sequence model, akin to language translation, or by uncovering the rudimentary principles of integration, such as $\\int_{0}^{x} t^n dt = \\frac{x^{n+1}}{n+1}$."],"url":"http://arxiv.org/abs/2402.18040v1"}
{"created":"2024-02-28 03:51:02","title":"OpenMEDLab: An Open-source Platform for Multi-modality Foundation Models in Medicine","abstract":"The emerging trend of advancing generalist artificial intelligence, such as GPTv4 and Gemini, has reshaped the landscape of research (academia and industry) in machine learning and many other research areas. However, domain-specific applications of such foundation models (e.g., in medicine) remain untouched or often at their very early stages. It will require an individual set of transfer learning and model adaptation techniques by further expanding and injecting these models with domain knowledge and data. The development of such technologies could be largely accelerated if the bundle of data, algorithms, and pre-trained foundation models were gathered together and open-sourced in an organized manner. In this work, we present OpenMEDLab, an open-source platform for multi-modality foundation models. It encapsulates not only solutions of pioneering attempts in prompting and fine-tuning large language and vision models for frontline clinical and bioinformatic applications but also building domain-specific foundation models with large-scale multi-modal medical data. Importantly, it opens access to a group of pre-trained foundation models for various medical image modalities, clinical text, protein engineering, etc. Inspiring and competitive results are also demonstrated for each collected approach and model in a variety of benchmarks for downstream tasks. We welcome researchers in the field of medical artificial intelligence to continuously contribute cutting-edge methods and models to OpenMEDLab, which can be accessed via https://github.com/openmedlab.","sentences":["The emerging trend of advancing generalist artificial intelligence, such as GPTv4 and Gemini, has reshaped the landscape of research (academia and industry) in machine learning and many other research areas.","However, domain-specific applications of such foundation models (e.g., in medicine) remain untouched or often at their very early stages.","It will require an individual set of transfer learning and model adaptation techniques by further expanding and injecting these models with domain knowledge and data.","The development of such technologies could be largely accelerated if the bundle of data, algorithms, and pre-trained foundation models were gathered together and open-sourced in an organized manner.","In this work, we present OpenMEDLab, an open-source platform for multi-modality foundation models.","It encapsulates not only solutions of pioneering attempts in prompting and fine-tuning large language and vision models for frontline clinical and bioinformatic applications but also building domain-specific foundation models with large-scale multi-modal medical data.","Importantly, it opens access to a group of pre-trained foundation models for various medical image modalities, clinical text, protein engineering, etc. Inspiring and competitive results are also demonstrated for each collected approach and model in a variety of benchmarks for downstream tasks.","We welcome researchers in the field of medical artificial intelligence to continuously contribute cutting-edge methods and models to OpenMEDLab, which can be accessed via https://github.com/openmedlab."],"url":"http://arxiv.org/abs/2402.18028v1"}
{"created":"2024-02-28 03:47:17","title":"Breaking the Black-Box: Confidence-Guided Model Inversion Attack for Distribution Shift","abstract":"Model inversion attacks (MIAs) seek to infer the private training data of a target classifier by generating synthetic images that reflect the characteristics of the target class through querying the model. However, prior studies have relied on full access to the target model, which is not practical in real-world scenarios. Additionally, existing black-box MIAs assume that the image prior and target model follow the same distribution. However, when confronted with diverse data distribution settings, these methods may result in suboptimal performance in conducting attacks. To address these limitations, this paper proposes a \\textbf{C}onfidence-\\textbf{G}uided \\textbf{M}odel \\textbf{I}nversion attack method called CG-MI, which utilizes the latent space of a pre-trained publicly available generative adversarial network (GAN) as prior information and gradient-free optimizer, enabling high-resolution MIAs across different data distributions in a black-box setting. Our experiments demonstrate that our method significantly \\textbf{outperforms the SOTA black-box MIA by more than 49\\% for Celeba and 58\\% for Facescrub in different distribution settings}. Furthermore, our method exhibits the ability to generate high-quality images \\textbf{comparable to those produced by white-box attacks}. Our method provides a practical and effective solution for black-box model inversion attacks.","sentences":["Model inversion attacks (MIAs) seek to infer the private training data of a target classifier by generating synthetic images that reflect the characteristics of the target class through querying the model.","However, prior studies have relied on full access to the target model, which is not practical in real-world scenarios.","Additionally, existing black-box MIAs assume that the image prior and target model follow the same distribution.","However, when confronted with diverse data distribution settings, these methods may result in suboptimal performance in conducting attacks.","To address these limitations, this paper proposes a \\textbf{C}onfidence-\\textbf{G}uided \\textbf{M}odel \\textbf{I}nversion attack method called CG-MI, which utilizes the latent space of a pre-trained publicly available generative adversarial network (GAN) as prior information and gradient-free optimizer, enabling high-resolution MIAs across different data distributions in a black-box setting.","Our experiments demonstrate that our method significantly \\textbf{outperforms the SOTA black-box MIA by more than 49\\% for Celeba and 58\\% for Facescrub in different distribution settings}.","Furthermore, our method exhibits the ability to generate high-quality images \\textbf{comparable to those produced by white-box attacks}.","Our method provides a practical and effective solution for black-box model inversion attacks."],"url":"http://arxiv.org/abs/2402.18027v1"}
{"created":"2024-02-28 03:44:01","title":"Hire a Linguist!: Learning Endangered Languages with In-Context Linguistic Descriptions","abstract":"How can large language models (LLMs) process and translate endangered languages? Many languages lack a large corpus to train a decent LLM; therefore existing LLMs rarely perform well in unseen, endangered languages. On the contrary, we observe that 2000 endangered languages, though without a large corpus, have a grammar book or a dictionary. We propose LINGOLLM, a training-free approach to enable an LLM to process unseen languages that hardly occur in its pre-training. Our key insight is to demonstrate linguistic knowledge of an unseen language in an LLM's prompt, including a dictionary, a grammar book, and morphologically analyzed input text. We implement LINGOLLM on top of two models, GPT-4 and Mixtral, and evaluate their performance on 5 tasks across 8 endangered or low-resource languages. Our results show that LINGOLLM elevates translation capability from GPT-4's 0 to 10.5 BLEU for 10 language directions. Our findings demonstrate the tremendous value of linguistic knowledge in the age of LLMs for endangered languages. Our data, code, and model generations can be found at https://github.com/LLiLab/llm4endangeredlang.","sentences":["How can large language models (LLMs) process and translate endangered languages?","Many languages lack a large corpus to train a decent LLM; therefore existing LLMs rarely perform well in unseen, endangered languages.","On the contrary, we observe that 2000 endangered languages, though without a large corpus, have a grammar book or a dictionary.","We propose LINGOLLM, a training-free approach to enable an LLM to process unseen languages that hardly occur in its pre-training.","Our key insight is to demonstrate linguistic knowledge of an unseen language in an LLM's prompt, including a dictionary, a grammar book, and morphologically analyzed input text.","We implement LINGOLLM on top of two models, GPT-4 and Mixtral, and evaluate their performance on 5 tasks across 8 endangered or low-resource languages.","Our results show that LINGOLLM elevates translation capability from GPT-4's 0 to 10.5 BLEU for 10 language directions.","Our findings demonstrate the tremendous value of linguistic knowledge in the age of LLMs for endangered languages.","Our data, code, and model generations can be found at https://github.com/LLiLab/llm4endangeredlang."],"url":"http://arxiv.org/abs/2402.18025v1"}
{"created":"2024-02-28 03:30:31","title":"Tighter Bounds for Local Differentially Private Core Decomposition and Densest Subgraph","abstract":"Computing the core decomposition of a graph is a fundamental problem that has recently been studied in the differentially private setting, motivated by practical applications in data mining. In particular, Dhulipala et al. [FOCS 2022] gave the first mechanism for approximate core decomposition in the challenging and practically relevant setting of local differential privacy. One of the main open problems left by their work is whether the accuracy, i.e., the approximation ratio and additive error, of their mechanism can be improved. We show the first lower bounds on the additive error of approximate and exact core decomposition mechanisms in the centralized and local model of differential privacy, respectively. We also give mechanisms for exact and approximate core decomposition in the local model, with almost matching additive error bounds. Our mechanisms are based on a black-box application of continual counting. They also yield improved mechanisms for the approximate densest subgraph problem in the local model.","sentences":["Computing the core decomposition of a graph is a fundamental problem that has recently been studied in the differentially private setting, motivated by practical applications in data mining.","In particular, Dhulipala et al.","[FOCS 2022] gave the first mechanism for approximate core decomposition in the challenging and practically relevant setting of local differential privacy.","One of the main open problems left by their work is whether the accuracy, i.e., the approximation ratio and additive error, of their mechanism can be improved.","We show the first lower bounds on the additive error of approximate and exact core decomposition mechanisms in the centralized and local model of differential privacy, respectively.","We also give mechanisms for exact and approximate core decomposition in the local model, with almost matching additive error bounds.","Our mechanisms are based on a black-box application of continual counting.","They also yield improved mechanisms for the approximate densest subgraph problem in the local model."],"url":"http://arxiv.org/abs/2402.18020v1"}
{"created":"2024-02-28 03:27:10","title":"Communication Efficient ConFederated Learning: An Event-Triggered SAGA Approach","abstract":"Federated learning (FL) is a machine learning paradigm that targets model training without gathering the local data dispersed over various data sources. Standard FL, which employs a single server, can only support a limited number of users, leading to degraded learning capability. In this work, we consider a multi-server FL framework, referred to as \\emph{Confederated Learning} (CFL), in order to accommodate a larger number of users. A CFL system is composed of multiple networked edge servers, with each server connected to an individual set of users. Decentralized collaboration among servers is leveraged to harness all users' data for model training. Due to the potentially massive number of users involved, it is crucial to reduce the communication overhead of the CFL system. We propose a stochastic gradient method for distributed learning in the CFL framework. The proposed method incorporates a conditionally-triggered user selection (CTUS) mechanism as the central component to effectively reduce communication overhead. Relying on a delicately designed triggering condition, the CTUS mechanism allows each server to select only a small number of users to upload their gradients, without significantly jeopardizing the convergence performance of the algorithm. Our theoretical analysis reveals that the proposed algorithm enjoys a linear convergence rate. Simulation results show that it achieves substantial improvement over state-of-the-art algorithms in terms of communication efficiency.","sentences":["Federated learning (FL) is a machine learning paradigm that targets model training without gathering the local data dispersed over various data sources.","Standard FL, which employs a single server, can only support a limited number of users, leading to degraded learning capability.","In this work, we consider a multi-server FL framework, referred to as \\emph{Confederated Learning} (CFL), in order to accommodate a larger number of users.","A CFL system is composed of multiple networked edge servers, with each server connected to an individual set of users.","Decentralized collaboration among servers is leveraged to harness all users' data for model training.","Due to the potentially massive number of users involved, it is crucial to reduce the communication overhead of the CFL system.","We propose a stochastic gradient method for distributed learning in the CFL framework.","The proposed method incorporates a conditionally-triggered user selection (CTUS) mechanism as the central component to effectively reduce communication overhead.","Relying on a delicately designed triggering condition, the CTUS mechanism allows each server to select only a small number of users to upload their gradients, without significantly jeopardizing the convergence performance of the algorithm.","Our theoretical analysis reveals that the proposed algorithm enjoys a linear convergence rate.","Simulation results show that it achieves substantial improvement over state-of-the-art algorithms in terms of communication efficiency."],"url":"http://arxiv.org/abs/2402.18018v1"}
{"created":"2024-02-28 03:09:12","title":"Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints","abstract":"Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. To enhance sampling efficiency, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dynamics stage for further correction. Theoretical analysis shows that the initial stage results in a distribution focused on feasible solutions, thereby providing a better initialization for the later stage. Comprehensive experiments on a synthetic dataset, six real-world black-box optimization datasets, and a multi-objective optimization dataset show that our method achieves better or comparable performance with previous state-of-the-art baselines.","sentences":["Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable.","While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly.","Overlooking these constraints can lead to spurious solutions that are unrealistic in practice.","To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models.","To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model.","To enhance sampling efficiency, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dynamics stage for further correction.","Theoretical analysis shows that the initial stage results in a distribution focused on feasible solutions, thereby providing a better initialization for the later stage.","Comprehensive experiments on a synthetic dataset, six real-world black-box optimization datasets, and a multi-objective optimization dataset show that our method achieves better or comparable performance with previous state-of-the-art baselines."],"url":"http://arxiv.org/abs/2402.18012v1"}
{"created":"2024-02-28 02:45:58","title":"Mixer is more than just a model","abstract":"Recently, MLP structures have regained popularity, with MLP-Mixer standing out as a prominent example. In the field of computer vision, MLP-Mixer is noted for its ability to extract data information from both channel and token perspectives, effectively acting as a fusion of channel and token information. Indeed, Mixer represents a paradigm for information extraction that amalgamates channel and token information. The essence of Mixer lies in its ability to blend information from diverse perspectives, epitomizing the true concept of \"mixing\" in the realm of neural network architectures. Beyond channel and token considerations, it is possible to create more tailored mixers from various perspectives to better suit specific task requirements. This study focuses on the domain of audio recognition, introducing a novel model named Audio Spectrogram Mixer with Roll-Time and Hermit FFT (ASM-RH) that incorporates insights from both time and frequency domains. Experimental results demonstrate that ASM-RH is particularly well-suited for audio data and yields promising outcomes across multiple classification tasks.","sentences":["Recently, MLP structures have regained popularity, with MLP-Mixer standing out as a prominent example.","In the field of computer vision, MLP-Mixer is noted for its ability to extract data information from both channel and token perspectives, effectively acting as a fusion of channel and token information.","Indeed, Mixer represents a paradigm for information extraction that amalgamates channel and token information.","The essence of Mixer lies in its ability to blend information from diverse perspectives, epitomizing the true concept of \"mixing\" in the realm of neural network architectures.","Beyond channel and token considerations, it is possible to create more tailored mixers from various perspectives to better suit specific task requirements.","This study focuses on the domain of audio recognition, introducing a novel model named Audio Spectrogram Mixer with Roll-Time and Hermit FFT (ASM-RH) that incorporates insights from both time and frequency domains.","Experimental results demonstrate that ASM-RH is particularly well-suited for audio data and yields promising outcomes across multiple classification tasks."],"url":"http://arxiv.org/abs/2402.18007v1"}
{"created":"2024-02-28 02:30:59","title":"Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial Observability with a Soft Wrist","abstract":"This study tackles the representative yet challenging contact-rich peg-in-hole task of robotic assembly, using a soft wrist that can operate more safely and tolerate lower-frequency control signals than a rigid one. Previous studies often use a fully observable formulation, requiring external setups or estimators for the peg-to-hole pose. In contrast, we use a partially observable formulation and deep reinforcement learning from demonstrations to learn a memory-based agent that acts purely on haptic and proprioceptive signals. Moreover, previous works do not incorporate potential domain symmetry and thus must search for solutions in a bigger space. Instead, we propose to leverage the symmetry for sample efficiency by augmenting the training data and constructing auxiliary losses to force the agent to adhere to the symmetry. Results in simulation with five different symmetric peg shapes show that our proposed agent can be comparable to or even outperform a state-based agent. In particular, the sample efficiency also allows us to learn directly on the real robot within 3 hours.","sentences":["This study tackles the representative yet challenging contact-rich peg-in-hole task of robotic assembly, using a soft wrist that can operate more safely and tolerate lower-frequency control signals than a rigid one.","Previous studies often use a fully observable formulation, requiring external setups or estimators for the peg-to-hole pose.","In contrast, we use a partially observable formulation and deep reinforcement learning from demonstrations to learn a memory-based agent that acts purely on haptic and proprioceptive signals.","Moreover, previous works do not incorporate potential domain symmetry and thus must search for solutions in a bigger space.","Instead, we propose to leverage the symmetry for sample efficiency by augmenting the training data and constructing auxiliary losses to force the agent to adhere to the symmetry.","Results in simulation with five different symmetric peg shapes show that our proposed agent can be comparable to or even outperform a state-based agent.","In particular, the sample efficiency also allows us to learn directly on the real robot within 3 hours."],"url":"http://arxiv.org/abs/2402.18002v1"}
{"created":"2024-02-28 02:00:34","title":"FlattenQuant: Breaking Through the Inference Compute-bound for Large Language Models with Per-tensor Quantization","abstract":"Large language models (LLMs) have demonstrated state-of-the-art performance across various tasks. However, the latency of inference and the large GPU memory consumption of LLMs restrict their deployment performance. Recently, there have been some efficient attempts to quantize LLMs, yet inference with large batch size or long sequence still has the issue of being compute-bound. Fine-grained quantization methods have showcased their proficiency in achieving low-bit quantization for LLMs, while requiring FP16 data type for linear layer computations, which is time-consuming when dealing with large batch size or long sequence. In this paper, we introduce a method called FlattenQuant, which significantly reduces the maximum value of the tensor by flattening the large channels in the tensor, to achieve low bit per-tensor quantization with minimal accuracy loss. Our experiments show that FlattenQuant can directly use 4 bits to achieve 48.29% of the linear layer calculation in LLMs, with the remaining layers using 8 bits. The 4-bit matrix multiplication introduced in the FlattenQuant method can effectively address the compute-bound caused by large matrix calculation. Our work achieves up to 2$\\times$ speedup and 2.3$\\times$ memory reduction for LLMs with negligible loss in accuracy.","sentences":["Large language models (LLMs) have demonstrated state-of-the-art performance across various tasks.","However, the latency of inference and the large GPU memory consumption of LLMs restrict their deployment performance.","Recently, there have been some efficient attempts to quantize LLMs, yet inference with large batch size or long sequence still has the issue of being compute-bound.","Fine-grained quantization methods have showcased their proficiency in achieving low-bit quantization for LLMs, while requiring FP16 data type for linear layer computations, which is time-consuming when dealing with large batch size or long sequence.","In this paper, we introduce a method called FlattenQuant, which significantly reduces the maximum value of the tensor by flattening the large channels in the tensor, to achieve low bit per-tensor quantization with minimal accuracy loss.","Our experiments show that FlattenQuant can directly use 4 bits to achieve 48.29% of the linear layer calculation in LLMs, with the remaining layers using 8 bits.","The 4-bit matrix multiplication introduced in the FlattenQuant method can effectively address the compute-bound caused by large matrix calculation.","Our work achieves up to 2$\\times$ speedup and 2.3$\\times$ memory reduction for LLMs with negligible loss in accuracy."],"url":"http://arxiv.org/abs/2402.17985v1"}
{"created":"2024-02-28 01:33:49","title":"From Generalization to Precision: Exploring SAM for Tool Segmentation in Surgical Environments","abstract":"Purpose: Accurate tool segmentation is essential in computer-aided procedures. However, this task conveys challenges due to artifacts' presence and the limited training data in medical scenarios. Methods that generalize to unseen data represent an interesting venue, where zero-shot segmentation presents an option to account for data limitation. Initial exploratory works with the Segment Anything Model (SAM) show that bounding-box-based prompting presents notable zero-short generalization. However, point-based prompting leads to a degraded performance that further deteriorates under image corruption. We argue that SAM drastically over-segment images with high corruption levels, resulting in degraded performance when only a single segmentation mask is considered, while the combination of the masks overlapping the object of interest generates an accurate prediction. Method: We use SAM to generate the over-segmented prediction of endoscopic frames. Then, we employ the ground-truth tool mask to analyze the results of SAM when the best single mask is selected as prediction and when all the individual masks overlapping the object of interest are combined to obtain the final predicted mask. We analyze the Endovis18 and Endovis17 instrument segmentation datasets using synthetic corruptions of various strengths and an In-House dataset featuring counterfactually created real-world corruptions. Results: Combining the over-segmented masks contributes to improvements in the IoU. Furthermore, selecting the best single segmentation presents a competitive IoU score for clean images. Conclusions: Combined SAM predictions present improved results and robustness up to a certain corruption level. However, appropriate prompting strategies are fundamental for implementing these models in the medical domain.","sentences":["Purpose:","Accurate tool segmentation is essential in computer-aided procedures.","However, this task conveys challenges due to artifacts' presence and the limited training data in medical scenarios.","Methods that generalize to unseen data represent an interesting venue, where zero-shot segmentation presents an option to account for data limitation.","Initial exploratory works with the Segment Anything Model (SAM) show that bounding-box-based prompting presents notable zero-short generalization.","However, point-based prompting leads to a degraded performance that further deteriorates under image corruption.","We argue that SAM drastically over-segment images with high corruption levels, resulting in degraded performance when only a single segmentation mask is considered, while the combination of the masks overlapping the object of interest generates an accurate prediction.","Method: We use SAM to generate the over-segmented prediction of endoscopic frames.","Then, we employ the ground-truth tool mask to analyze the results of SAM when the best single mask is selected as prediction and when all the individual masks overlapping the object of interest are combined to obtain the final predicted mask.","We analyze the Endovis18 and Endovis17 instrument segmentation datasets using synthetic corruptions of various strengths and an In-House dataset featuring counterfactually created real-world corruptions.","Results: Combining the over-segmented masks contributes to improvements in the IoU.","Furthermore, selecting the best single segmentation presents a competitive IoU score for clean images.","Conclusions: Combined SAM predictions present improved results and robustness up to a certain corruption level.","However, appropriate prompting strategies are fundamental for implementing these models in the medical domain."],"url":"http://arxiv.org/abs/2402.17972v1"}
{"created":"2024-02-28 01:32:59","title":"All in a Single Image: Large Multimodal Models are In-Image Learners","abstract":"This paper introduces a new in-context learning (ICL) mechanism called In-Image Learning (I$^2$L) that combines demonstration examples, visual cues, and instructions into a single image to enhance the capabilities of GPT-4V. Unlike previous approaches that rely on converting images to text or incorporating visual input into language models, I$^2$L consolidates all information into one image and primarily leverages image processing, understanding, and reasoning abilities. This has several advantages: it avoids inaccurate textual descriptions of complex images, provides flexibility in positioning demonstration examples, reduces the input burden, and avoids exceeding input limits by eliminating the need for multiple images and lengthy text. To further combine the strengths of different ICL methods, we introduce an automatic strategy to select the appropriate ICL method for a data example in a given task. We conducted experiments on MathVista and Hallusionbench to test the effectiveness of I$^2$L in complex multimodal reasoning tasks and mitigating language hallucination and visual illusion. Additionally, we explored the impact of image resolution, the number of demonstration examples, and their positions on the effectiveness of I$^2$L. Our code is publicly available at https://github.com/AGI-Edgerunners/IIL.","sentences":["This paper introduces a new in-context learning (ICL) mechanism called In-Image Learning (I$^2$L) that combines demonstration examples, visual cues, and instructions into a single image to enhance the capabilities of GPT-4V. Unlike previous approaches that rely on converting images to text or incorporating visual input into language models, I$^2$L consolidates all information into one image and primarily leverages image processing, understanding, and reasoning abilities.","This has several advantages: it avoids inaccurate textual descriptions of complex images, provides flexibility in positioning demonstration examples, reduces the input burden, and avoids exceeding input limits by eliminating the need for multiple images and lengthy text.","To further combine the strengths of different ICL methods, we introduce an automatic strategy to select the appropriate ICL method for a data example in a given task.","We conducted experiments on MathVista and Hallusionbench to test the effectiveness of I$^2$L in complex multimodal reasoning tasks and mitigating language hallucination and visual illusion.","Additionally, we explored the impact of image resolution, the number of demonstration examples, and their positions on the effectiveness of I$^2$L. Our code is publicly available at https://github.com/AGI-Edgerunners/IIL."],"url":"http://arxiv.org/abs/2402.17971v1"}
{"created":"2024-02-28 01:19:42","title":"Imitation-regularized Optimal Transport on Networks: Provable Robustness and Application to Logistics Planning","abstract":"Network systems form the foundation of modern society, playing a critical role in various applications. However, these systems are at significant risk of being adversely affected by unforeseen circumstances, such as disasters. Considering this, there is a pressing need for research to enhance the robustness of network systems. Recently, in reinforcement learning, the relationship between acquiring robustness and regularizing entropy has been identified. Additionally, imitation learning is used within this framework to reflect experts' behavior. However, there are no comprehensive studies on the use of a similar imitation framework for optimal transport on networks. Therefore, in this study, imitation-regularized optimal transport (I-OT) on networks was investigated. It encodes prior knowledge on the network by imitating a given prior distribution. The I-OT solution demonstrated robustness in terms of the cost defined on the network. Moreover, we applied the I-OT to a logistics planning problem using real data. We also examined the imitation and apriori risk information scenarios to demonstrate the usefulness and implications of the proposed method.","sentences":["Network systems form the foundation of modern society, playing a critical role in various applications.","However, these systems are at significant risk of being adversely affected by unforeseen circumstances, such as disasters.","Considering this, there is a pressing need for research to enhance the robustness of network systems.","Recently, in reinforcement learning, the relationship between acquiring robustness and regularizing entropy has been identified.","Additionally, imitation learning is used within this framework to reflect experts' behavior.","However, there are no comprehensive studies on the use of a similar imitation framework for optimal transport on networks.","Therefore, in this study, imitation-regularized optimal transport (I-OT) on networks was investigated.","It encodes prior knowledge on the network by imitating a given prior distribution.","The I-OT solution demonstrated robustness in terms of the cost defined on the network.","Moreover, we applied the I-OT to a logistics planning problem using real data.","We also examined the imitation and apriori risk information scenarios to demonstrate the usefulness and implications of the proposed method."],"url":"http://arxiv.org/abs/2402.17967v1"}
{"created":"2024-02-28 01:15:30","title":"Conformer: Embedding Continuous Attention in Vision Transformer for Weather Forecasting","abstract":"Operational weather forecasting system relies on computationally expensive physics-based models. Although Transformers-based models have shown remarkable potential in weather forecasting, Transformers are discrete models which limit their ability to learn the continuous spatio-temporal features of the dynamical weather system. We address this issue with Conformer, a spatio-temporal Continuous Vision Transformer for weather forecasting. Conformer is designed to learn the continuous weather evolution over time by implementing continuity in the multi-head attention mechanism. The attention mechanism is encoded as a differentiable function in the transformer architecture to model the complex weather dynamics. We evaluate Conformer against a state-of-the-art Numerical Weather Prediction (NWP) model and several deep learning based weather forecasting models. Conformer outperforms some of the existing data-driven models at all lead times while only being trained at lower resolution data.","sentences":["Operational weather forecasting system relies on computationally expensive physics-based models.","Although Transformers-based models have shown remarkable potential in weather forecasting, Transformers are discrete models which limit their ability to learn the continuous spatio-temporal features of the dynamical weather system.","We address this issue with Conformer, a spatio-temporal Continuous Vision Transformer for weather forecasting.","Conformer is designed to learn the continuous weather evolution over time by implementing continuity in the multi-head attention mechanism.","The attention mechanism is encoded as a differentiable function in the transformer architecture to model the complex weather dynamics.","We evaluate Conformer against a state-of-the-art Numerical Weather Prediction (NWP) model and several deep learning based weather forecasting models.","Conformer outperforms some of the existing data-driven models at all lead times while only being trained at lower resolution data."],"url":"http://arxiv.org/abs/2402.17966v1"}
{"created":"2024-02-28 01:08:07","title":"The Design and Implementation of a High-Performance Log-Structured RAID System for ZNS SSDs","abstract":"Zoned Namespace (ZNS) defines a new abstraction for host software to flexibly manage storage in flash-based SSDs as append-only zones. It also provides a Zone Append primitive to further boost the write performance of ZNS SSDs by exploiting intra-zone parallelism. However, making Zone Append effective for reliable and scalable storage, in the form of a RAID array of multiple ZNS SSDs, is non-trivial since Zone Append offloads address management to ZNS SSDs and requires hosts to dedicatedly manage RAID stripes across multiple drives. We propose ZapRAID, a high-performance log-structured RAID system for ZNS SSDs by carefully exploiting Zone Append to achieve high write parallelism and lightweight stripe management. ZapRAID adopts a group-based data layout with a coarse-grained ordering across multiple groups of stripes, such that it can use small-size metadata for stripe management on a per-group basis under Zone Append. It further adopts hybrid data management to simultaneously achieve intra-zone and inter-zone parallelism through a careful combination of both Zone Append and Zone Write primitives. We evaluate ZapRAID using microbenchmarks, trace-driven experiments, and real-application experiments. Our evaluation results show that ZapRAID achieves high write throughput and maintains high performance in normal reads, degraded reads, crash recovery, and full-drive recovery.","sentences":["Zoned Namespace (ZNS) defines a new abstraction for host software to flexibly manage storage in flash-based SSDs as append-only zones.","It also provides a Zone Append primitive to further boost the write performance of ZNS SSDs by exploiting intra-zone parallelism.","However, making Zone Append effective for reliable and scalable storage, in the form of a RAID array of multiple ZNS SSDs, is non-trivial since Zone Append offloads address management to ZNS SSDs and requires hosts to dedicatedly manage RAID stripes across multiple drives.","We propose ZapRAID, a high-performance log-structured RAID system for ZNS SSDs by carefully exploiting Zone Append to achieve high write parallelism and lightweight stripe management.","ZapRAID adopts a group-based data layout with a coarse-grained ordering across multiple groups of stripes, such that it can use small-size metadata for stripe management on a per-group basis under Zone Append.","It further adopts hybrid data management to simultaneously achieve intra-zone and inter-zone parallelism through a careful combination of both Zone Append and Zone Write primitives.","We evaluate ZapRAID using microbenchmarks, trace-driven experiments, and real-application experiments.","Our evaluation results show that ZapRAID achieves high write throughput and maintains high performance in normal reads, degraded reads, crash recovery, and full-drive recovery."],"url":"http://arxiv.org/abs/2402.17963v1"}
{"created":"2024-02-28 00:57:35","title":"Rapid hyperspectral photothermal mid-infrared spectroscopic imaging from sparse data for gynecologic cancer tissue subtyping","abstract":"Ovarian cancer detection has traditionally relied on a multi-step process that includes biopsy, tissue staining, and morphological analysis by experienced pathologists. While widely practiced, this conventional approach suffers from several drawbacks: it is qualitative, time-intensive, and heavily dependent on the quality of staining. Mid-infrared (MIR) hyperspectral photothermal imaging is a label-free, biochemically quantitative technology that, when combined with machine learning algorithms, can eliminate the need for staining and provide quantitative results comparable to traditional histology. However, this technology is slow. This work presents a novel approach to MIR photothermal imaging that enhances its speed by an order of magnitude. Our method significantly accelerates data collection by capturing a combination of high-resolution and interleaved, lower-resolution infrared band images and applying computational techniques for data interpolation. We effectively minimize data collection requirements by leveraging sparse data acquisition and employing curvelet-based reconstruction algorithms. This method enables the reconstruction of high-quality, high-resolution images from undersampled datasets and achieving a 10X improvement in data acquisition time. We assessed the performance of our sparse imaging methodology using a variety of quantitative metrics, including mean squared error (MSE), structural similarity index (SSIM), and tissue subtype classification accuracies, employing both random forest and convolutional neural network (CNN) models, accompanied by ROC curves. Our statistically robust analysis, based on data from 100 ovarian cancer patient samples and over 65 million data points, demonstrates the method's capability to produce superior image quality and accurately distinguish between different gynecological tissue types with segmentation accuracy exceeding 95%.","sentences":["Ovarian cancer detection has traditionally relied on a multi-step process that includes biopsy, tissue staining, and morphological analysis by experienced pathologists.","While widely practiced, this conventional approach suffers from several drawbacks: it is qualitative, time-intensive, and heavily dependent on the quality of staining.","Mid-infrared (MIR) hyperspectral photothermal imaging is a label-free, biochemically quantitative technology that, when combined with machine learning algorithms, can eliminate the need for staining and provide quantitative results comparable to traditional histology.","However, this technology is slow.","This work presents a novel approach to MIR photothermal imaging that enhances its speed by an order of magnitude.","Our method significantly accelerates data collection by capturing a combination of high-resolution and interleaved, lower-resolution infrared band images and applying computational techniques for data interpolation.","We effectively minimize data collection requirements by leveraging sparse data acquisition and employing curvelet-based reconstruction algorithms.","This method enables the reconstruction of high-quality, high-resolution images from undersampled datasets and achieving a 10X improvement in data acquisition time.","We assessed the performance of our sparse imaging methodology using a variety of quantitative metrics, including mean squared error (MSE), structural similarity index (SSIM), and tissue subtype classification accuracies, employing both random forest and convolutional neural network (CNN) models, accompanied by ROC curves.","Our statistically robust analysis, based on data from 100 ovarian cancer patient samples and over 65 million data points, demonstrates the method's capability to produce superior image quality and accurately distinguish between different gynecological tissue types with segmentation accuracy exceeding 95%."],"url":"http://arxiv.org/abs/2402.17960v1"}
{"created":"2024-02-27 23:59:01","title":"Large Language Models on Tabular Data -- A Survey","abstract":"Recent breakthroughs in large language modeling have facilitated rigorous exploration of their application in diverse tasks related to tabular data modeling, such as prediction, tabular data synthesis, question answering, and table understanding. Each task presents unique challenges and opportunities. However, there is currently a lack of comprehensive review that summarizes and compares the key techniques, metrics, datasets, models, and optimization approaches in this research domain. This survey aims to address this gap by consolidating recent progress in these areas, offering a thorough survey and taxonomy of the datasets, metrics, and methodologies utilized. It identifies strengths, limitations, unexplored territories, and gaps in the existing literature, while providing some insights for future research directions in this vital and rapidly evolving field. It also provides relevant code and datasets references. Through this comprehensive review, we hope to provide interested readers with pertinent references and insightful perspectives, empowering them with the necessary tools and knowledge to effectively navigate and address the prevailing challenges in the field.","sentences":["Recent breakthroughs in large language modeling have facilitated rigorous exploration of their application in diverse tasks related to tabular data modeling, such as prediction, tabular data synthesis, question answering, and table understanding.","Each task presents unique challenges and opportunities.","However, there is currently a lack of comprehensive review that summarizes and compares the key techniques, metrics, datasets, models, and optimization approaches in this research domain.","This survey aims to address this gap by consolidating recent progress in these areas, offering a thorough survey and taxonomy of the datasets, metrics, and methodologies utilized.","It identifies strengths, limitations, unexplored territories, and gaps in the existing literature, while providing some insights for future research directions in this vital and rapidly evolving field.","It also provides relevant code and datasets references.","Through this comprehensive review, we hope to provide interested readers with pertinent references and insightful perspectives, empowering them with the necessary tools and knowledge to effectively navigate and address the prevailing challenges in the field."],"url":"http://arxiv.org/abs/2402.17944v1"}
{"created":"2024-02-27 23:29:10","title":"Acquiring Linguistic Knowledge from Multimodal Input","abstract":"In contrast to children, language models (LMs) exhibit considerably inferior data efficiency when acquiring language. In this submission to the BabyLM Challenge (Warstadt et al., 2023), we test the hypothesis that this data efficiency gap is partly caused by a lack of multimodal input and grounding in the learning environment of typical language models. Although previous work looking into this question found that multimodal training can even harm language-only performance, we speculate that these findings can be attributed to catastrophic forgetting of complex language due to fine-tuning on captions data. To test our hypothesis, we perform an ablation study on FLAVA (Singh et al., 2022), a multimodal vision-and-language model, independently varying the volume of text and vision input to quantify how much text data (if any) can be offset by vision at different data scales. We aim to limit catastrophic forgetting through a multitask pretraining regime that includes unimodal text-only tasks and data sampled from WiT, the relatively diverse Wikipedia-based dataset (Srinivasan et al., 2021). Our results are largely negative: Multimodal pretraining does not harm our models' language performance but does not consistently help either. That said, our conclusions are limited by our having been able to conduct only a small number of runs. While we must leave open the possibility that multimodal input explains some of the gap in data efficiency between LMs and humans, positive evidence for this hypothesis will require better architectures and techniques for multimodal training.","sentences":["In contrast to children, language models (LMs) exhibit considerably inferior data efficiency when acquiring language.","In this submission to the BabyLM Challenge (Warstadt et al., 2023), we test the hypothesis that this data efficiency gap is partly caused by a lack of multimodal input and grounding in the learning environment of typical language models.","Although previous work looking into this question found that multimodal training can even harm language-only performance, we speculate that these findings can be attributed to catastrophic forgetting of complex language due to fine-tuning on captions data.","To test our hypothesis, we perform an ablation study on FLAVA (Singh et al., 2022), a multimodal vision-and-language model, independently varying the volume of text and vision input to quantify how much text data (if any) can be offset by vision at different data scales.","We aim to limit catastrophic forgetting through a multitask pretraining regime that includes unimodal text-only tasks and data sampled from WiT, the relatively diverse Wikipedia-based dataset (Srinivasan et al., 2021).","Our results are largely negative: Multimodal pretraining does not harm our models' language performance but does not consistently help either.","That said, our conclusions are limited by our having been able to conduct only a small number of runs.","While we must leave open the possibility that multimodal input explains some of the gap in data efficiency between LMs and humans, positive evidence for this hypothesis will require better architectures and techniques for multimodal training."],"url":"http://arxiv.org/abs/2402.17936v1"}
{"created":"2024-02-27 23:12:45","title":"Multitask Multilingual Model Adaptation with Featurized Low-Rank Mixtures","abstract":"Adapting pretrained large language models (LLMs) to various downstream tasks in tens or hundreds of human languages is computationally expensive. Parameter-efficient fine-tuning (PEFT) significantly reduces the adaptation cost, by tuning only a small amount of parameters. However, directly applying PEFT methods such as LoRA (Hu et al., 2022) on diverse dataset mixtures could lead to suboptimal performance due to limited parameter capacity and negative interference among different datasets. In this work, we propose Featurized Low-rank Mixtures (FLix), a novel PEFT method designed for effective multitask multilingual tuning. FLix associates each unique dataset feature, such as the dataset's language or task, with its own low-rank weight update parameters. By composing feature-specific parameters for each dataset, FLix can accommodate diverse dataset mixtures and generalize better to unseen datasets. Our experiments show that FLix leads to significant improvements over a variety of tasks for both supervised learning and zero-shot settings using different training data mixtures.","sentences":["Adapting pretrained large language models (LLMs) to various downstream tasks in tens or hundreds of human languages is computationally expensive.","Parameter-efficient fine-tuning (PEFT) significantly reduces the adaptation cost, by tuning only a small amount of parameters.","However, directly applying PEFT methods such as LoRA (Hu et al., 2022) on diverse dataset mixtures could lead to suboptimal performance due to limited parameter capacity and negative interference among different datasets.","In this work, we propose Featurized Low-rank Mixtures (FLix), a novel PEFT method designed for effective multitask multilingual tuning.","FLix associates each unique dataset feature, such as the dataset's language or task, with its own low-rank weight update parameters.","By composing feature-specific parameters for each dataset, FLix can accommodate diverse dataset mixtures and generalize better to unseen datasets.","Our experiments show that FLix leads to significant improvements over a variety of tasks for both supervised learning and zero-shot settings using different training data mixtures."],"url":"http://arxiv.org/abs/2402.17934v1"}
{"created":"2024-02-27 23:04:28","title":"Decremental $(1+\u03b5)$-Approximate Maximum Eigenvector: Dynamic Power Method","abstract":"We present a dynamic algorithm for maintaining $(1+\\epsilon)$-approximate maximum eigenvector and eigenvalue of a positive semi-definite matrix $A$ undergoing \\emph{decreasing} updates, i.e., updates which may only decrease eigenvalues. Given a vector $v$ updating $A\\gets A-vv^{\\top}$, our algorithm takes $\\tilde{O}(\\mathrm{nnz}(v))$ amortized update time, i.e., polylogarithmic per non-zeros in the update vector.   Our technique is based on a novel analysis of the influential power method in the dynamic setting. The two previous sets of techniques have the following drawbacks (1) algebraic techniques can maintain exact solutions but their update time is at least polynomial per non-zeros, and (2) sketching techniques admit polylogarithmic update time but suffer from a crude additive approximation.   Our algorithm exploits an oblivious adversary. Interestingly, we show that any algorithm with polylogarithmic update time per non-zeros that works against an adaptive adversary and satisfies an additional natural property would imply a breakthrough for checking psd-ness of matrices in $\\tilde{O}(n^{2})$ time, instead of $O(n^{\\omega})$ time.","sentences":["We present a dynamic algorithm for maintaining $(1+\\epsilon)$-approximate maximum eigenvector and eigenvalue of a positive semi-definite matrix $A$ undergoing \\emph{decreasing} updates, i.e., updates which may only decrease eigenvalues.","Given a vector $v$ updating $A\\gets A-vv^{\\top}$, our algorithm takes $\\tilde{O}(\\mathrm{nnz}(v))$ amortized update time, i.e., polylogarithmic per non-zeros in the update vector.   ","Our technique is based on a novel analysis of the influential power method in the dynamic setting.","The two previous sets of techniques have the following drawbacks (1) algebraic techniques can maintain exact solutions but their update time is at least polynomial per non-zeros, and (2) sketching techniques admit polylogarithmic update time but suffer from a crude additive approximation.   ","Our algorithm exploits an oblivious adversary.","Interestingly, we show that any algorithm with polylogarithmic update time per non-zeros that works against an adaptive adversary and satisfies an additional natural property would imply a breakthrough for checking psd-ness of matrices in $\\tilde{O}(n^{2})$ time, instead of $O(n^{\\omega})$ time."],"url":"http://arxiv.org/abs/2402.17929v1"}
{"created":"2024-02-27 22:10:51","title":"Collaborative learning of common latent representations in routinely collected multivariate ICU physiological signals","abstract":"In Intensive Care Units (ICU), the abundance of multivariate time series presents an opportunity for machine learning (ML) to enhance patient phenotyping. In contrast to previous research focused on electronic health records (EHR), here we propose an ML approach for phenotyping using routinely collected physiological time series data. Our new algorithm integrates Long Short-Term Memory (LSTM) networks with collaborative filtering concepts to identify common physiological states across patients. Tested on real-world ICU clinical data for intracranial hypertension (IH) detection in patients with brain injury, our method achieved an area under the curve (AUC) of 0.889 and average precision (AP) of 0.725. Moreover, our algorithm outperforms autoencoders in learning more structured latent representations of the physiological signals. These findings highlight the promise of our methodology for patient phenotyping, leveraging routinely collected multivariate time series to improve clinical care practices.","sentences":["In Intensive Care Units (ICU), the abundance of multivariate time series presents an opportunity for machine learning (ML) to enhance patient phenotyping.","In contrast to previous research focused on electronic health records (EHR), here we propose an ML approach for phenotyping using routinely collected physiological time series data.","Our new algorithm integrates Long Short-Term Memory (LSTM) networks with collaborative filtering concepts to identify common physiological states across patients.","Tested on real-world ICU clinical data for intracranial hypertension (IH) detection in patients with brain injury, our method achieved an area under the curve (AUC) of 0.889 and average precision (AP) of 0.725.","Moreover, our algorithm outperforms autoencoders in learning more structured latent representations of the physiological signals.","These findings highlight the promise of our methodology for patient phenotyping, leveraging routinely collected multivariate time series to improve clinical care practices."],"url":"http://arxiv.org/abs/2402.17917v1"}
{"created":"2024-02-27 21:47:06","title":"Representation learning in multiplex graphs: Where and how to fuse information?","abstract":"In recent years, unsupervised and self-supervised graph representation learning has gained popularity in the research community. However, most proposed methods are focused on homogeneous networks, whereas real-world graphs often contain multiple node and edge types. Multiplex graphs, a special type of heterogeneous graphs, possess richer information, provide better modeling capabilities and integrate more detailed data from potentially different sources. The diverse edge types in multiplex graphs provide more context and insights into the underlying processes of representation learning. In this paper, we tackle the problem of learning representations for nodes in multiplex networks in an unsupervised or self-supervised manner. To that end, we explore diverse information fusion schemes performed at different levels of the graph processing pipeline. The detailed analysis and experimental evaluation of various scenarios inspired us to propose improvements in how to construct GNN architectures that deal with multiplex graphs.","sentences":["In recent years, unsupervised and self-supervised graph representation learning has gained popularity in the research community.","However, most proposed methods are focused on homogeneous networks, whereas real-world graphs often contain multiple node and edge types.","Multiplex graphs, a special type of heterogeneous graphs, possess richer information, provide better modeling capabilities and integrate more detailed data from potentially different sources.","The diverse edge types in multiplex graphs provide more context and insights into the underlying processes of representation learning.","In this paper, we tackle the problem of learning representations for nodes in multiplex networks in an unsupervised or self-supervised manner.","To that end, we explore diverse information fusion schemes performed at different levels of the graph processing pipeline.","The detailed analysis and experimental evaluation of various scenarios inspired us to propose improvements in how to construct GNN architectures that deal with multiplex graphs."],"url":"http://arxiv.org/abs/2402.17906v1"}
{"created":"2024-02-27 21:43:14","title":"Using Graph Neural Networks to Predict Local Culture","abstract":"Urban research has long recognized that neighbourhoods are dynamic and relational. However, lack of data, methodologies, and computer processing power have hampered a formal quantitative examination of neighbourhood relational dynamics. To make progress on this issue, this study proposes a graph neural network (GNN) approach that permits combining and evaluating multiple sources of information about internal characteristics of neighbourhoods, their past characteristics, and flows of groups among them, potentially providing greater expressive power in predictive models. By exploring a public large-scale dataset from Yelp, we show the potential of our approach for considering structural connectedness in predicting neighbourhood attributes, specifically to predict local culture. Results are promising from a substantive and methodologically point of view. Substantively, we find that either local area information (e.g. area demographics) or group profiles (tastes of Yelp reviewers) give the best results in predicting local culture, and they are nearly equivalent in all studied cases. Methodologically, exploring group profiles could be a helpful alternative where finding local information for specific areas is challenging, since they can be extracted automatically from many forms of online data. Thus, our approach could empower researchers and policy-makers to use a range of data sources when other local area information is lacking.","sentences":["Urban research has long recognized that neighbourhoods are dynamic and relational.","However, lack of data, methodologies, and computer processing power have hampered a formal quantitative examination of neighbourhood relational dynamics.","To make progress on this issue, this study proposes a graph neural network (GNN) approach that permits combining and evaluating multiple sources of information about internal characteristics of neighbourhoods, their past characteristics, and flows of groups among them, potentially providing greater expressive power in predictive models.","By exploring a public large-scale dataset from Yelp, we show the potential of our approach for considering structural connectedness in predicting neighbourhood attributes, specifically to predict local culture.","Results are promising from a substantive and methodologically point of view.","Substantively, we find that either local area information (e.g. area demographics) or group profiles (tastes of Yelp reviewers) give the best results in predicting local culture, and they are nearly equivalent in all studied cases.","Methodologically, exploring group profiles could be a helpful alternative where finding local information for specific areas is challenging, since they can be extracted automatically from many forms of online data.","Thus, our approach could empower researchers and policy-makers to use a range of data sources when other local area information is lacking."],"url":"http://arxiv.org/abs/2402.17905v1"}
{"created":"2024-02-27 21:12:31","title":"SWTrack: Multiple Hypothesis Sliding Window 3D Multi-Object Tracking","abstract":"Modern robotic systems are required to operate in dense dynamic environments, requiring highly accurate real-time track identification and estimation. For 3D multi-object tracking, recent approaches process a single measurement frame recursively with greedy association and are prone to errors in ambiguous association decisions. Our method, Sliding Window Tracker (SWTrack), yields more accurate association and state estimation by batch processing many frames of sensor data while being capable of running online in real-time. The most probable track associations are identified by evaluating all possible track hypotheses across the temporal sliding window. A novel graph optimization approach is formulated to solve the multidimensional assignment problem with lifted graph edges introduced to account for missed detections and graph sparsity enforced to retain real-time efficiency. We evaluate our SWTrack implementation$^{2}$ on the NuScenes autonomous driving dataset to demonstrate improved tracking performance.","sentences":["Modern robotic systems are required to operate in dense dynamic environments, requiring highly accurate real-time track identification and estimation.","For 3D multi-object tracking, recent approaches process a single measurement frame recursively with greedy association and are prone to errors in ambiguous association decisions.","Our method, Sliding Window Tracker (SWTrack), yields more accurate association and state estimation by batch processing many frames of sensor data while being capable of running online in real-time.","The most probable track associations are identified by evaluating all possible track hypotheses across the temporal sliding window.","A novel graph optimization approach is formulated to solve the multidimensional assignment problem with lifted graph edges introduced to account for missed detections and graph sparsity enforced to retain real-time efficiency.","We evaluate our SWTrack implementation$^{2}$ on the NuScenes autonomous driving dataset to demonstrate improved tracking performance."],"url":"http://arxiv.org/abs/2402.17892v1"}
