{"created":"2024-09-30 17:59:34","title":"MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning","abstract":"We present MM1.5, a new family of multimodal large language models (MLLMs) designed to enhance capabilities in text-rich image understanding, visual referring and grounding, and multi-image reasoning. Building upon the MM1 architecture, MM1.5 adopts a data-centric approach to model training, systematically exploring the impact of diverse data mixtures across the entire model training lifecycle. This includes high-quality OCR data and synthetic captions for continual pre-training, as well as an optimized visual instruction-tuning data mixture for supervised fine-tuning. Our models range from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE) variants, and demonstrate that careful data curation and training strategies can yield strong performance even at small scales (1B and 3B). Additionally, we introduce two specialized variants: MM1.5-Video, designed for video understanding, and MM1.5-UI, tailored for mobile UI understanding. Through extensive empirical studies and ablations, we provide detailed insights into the training processes and decisions that inform our final designs, offering valuable guidance for future research in MLLM development.","sentences":["We present MM1.5, a new family of multimodal large language models (MLLMs) designed to enhance capabilities in text-rich image understanding, visual referring and grounding, and multi-image reasoning.","Building upon the MM1 architecture, MM1.5 adopts a data-centric approach to model training, systematically exploring the impact of diverse data mixtures across the entire model training lifecycle.","This includes high-quality OCR data and synthetic captions for continual pre-training, as well as an optimized visual instruction-tuning data mixture for supervised fine-tuning.","Our models range from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE) variants, and demonstrate that careful data curation and training strategies can yield strong performance even at small scales (1B and 3B).","Additionally, we introduce two specialized variants: MM1.5-Video, designed for video understanding, and MM1.5-UI, tailored for mobile UI understanding.","Through extensive empirical studies and ablations, we provide detailed insights into the training processes and decisions that inform our final designs, offering valuable guidance for future research in MLLM development."],"url":"http://arxiv.org/abs/2409.20566v1"}
{"created":"2024-09-30 17:59:15","title":"DressRecon: Freeform 4D Human Reconstruction from Monocular Video","abstract":"We present a method to reconstruct time-consistent human body models from monocular videos, focusing on extremely loose clothing or handheld object interactions. Prior work in human reconstruction is either limited to tight clothing with no object interactions, or requires calibrated multi-view captures or personalized template scans which are costly to collect at scale. Our key insight for high-quality yet flexible reconstruction is the careful combination of generic human priors about articulated body shape (learned from large-scale training data) with video-specific articulated \"bag-of-bones\" deformation (fit to a single video via test-time optimization). We accomplish this by learning a neural implicit model that disentangles body versus clothing deformations as separate motion model layers. To capture subtle geometry of clothing, we leverage image-based priors such as human body pose, surface normals, and optical flow during optimization. The resulting neural fields can be extracted into time-consistent meshes, or further optimized as explicit 3D Gaussians for high-fidelity interactive rendering. On datasets with highly challenging clothing deformations and object interactions, DressRecon yields higher-fidelity 3D reconstructions than prior art. Project page: https://jefftan969.github.io/dressrecon/","sentences":["We present a method to reconstruct time-consistent human body models from monocular videos, focusing on extremely loose clothing or handheld object interactions.","Prior work in human reconstruction is either limited to tight clothing with no object interactions, or requires calibrated multi-view captures or personalized template scans which are costly to collect at scale.","Our key insight for high-quality yet flexible reconstruction is the careful combination of generic human priors about articulated body shape (learned from large-scale training data) with video-specific articulated \"bag-of-bones\" deformation (fit to a single video via test-time optimization).","We accomplish this by learning a neural implicit model that disentangles body versus clothing deformations as separate motion model layers.","To capture subtle geometry of clothing, we leverage image-based priors such as human body pose, surface normals, and optical flow during optimization.","The resulting neural fields can be extracted into time-consistent meshes, or further optimized as explicit 3D Gaussians for high-fidelity interactive rendering.","On datasets with highly challenging clothing deformations and object interactions, DressRecon yields higher-fidelity 3D reconstructions than prior art.","Project page: https://jefftan969.github.io/dressrecon/"],"url":"http://arxiv.org/abs/2409.20563v1"}
{"created":"2024-09-30 17:58:03","title":"Supervised Multi-Modal Fission Learning","abstract":"Learning from multimodal datasets can leverage complementary information and improve performance in prediction tasks. A commonly used strategy to account for feature correlations in high-dimensional datasets is the latent variable approach. Several latent variable methods have been proposed for multimodal datasets. However, these methods either focus on extracting the shared component across all modalities or on extracting both a shared component and individual components specific to each modality. To address this gap, we propose a Multi-Modal Fission Learning (MMFL) model that simultaneously identifies globally joint, partially joint, and individual components underlying the features of multimodal datasets. Unlike existing latent variable methods, MMFL uses supervision from the response variable to identify predictive latent components and has a natural extension for incorporating incomplete multimodal data. Through simulation studies, we demonstrate that MMFL outperforms various existing multimodal algorithms in both complete and incomplete modality settings. We applied MMFL to a real-world case study for early prediction of Alzheimers Disease using multimodal neuroimaging and genomics data from the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset. MMFL provided more accurate predictions and better insights into within- and across-modality correlations compared to existing methods.","sentences":["Learning from multimodal datasets can leverage complementary information and improve performance in prediction tasks.","A commonly used strategy to account for feature correlations in high-dimensional datasets is the latent variable approach.","Several latent variable methods have been proposed for multimodal datasets.","However, these methods either focus on extracting the shared component across all modalities or on extracting both a shared component and individual components specific to each modality.","To address this gap, we propose a Multi-Modal Fission Learning (MMFL) model that simultaneously identifies globally joint, partially joint, and individual components underlying the features of multimodal datasets.","Unlike existing latent variable methods, MMFL uses supervision from the response variable to identify predictive latent components and has a natural extension for incorporating incomplete multimodal data.","Through simulation studies, we demonstrate that MMFL outperforms various existing multimodal algorithms in both complete and incomplete modality settings.","We applied MMFL to a real-world case study for early prediction of Alzheimers Disease using multimodal neuroimaging and genomics data from the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset.","MMFL provided more accurate predictions and better insights into within- and across-modality correlations compared to existing methods."],"url":"http://arxiv.org/abs/2409.20559v1"}
{"created":"2024-09-30 17:57:50","title":"Uni$^2$Det: Unified and Universal Framework for Prompt-Guided Multi-dataset 3D Detection","abstract":"We present Uni$^2$Det, a brand new framework for unified and universal multi-dataset training on 3D detection, enabling robust performance across diverse domains and generalization to unseen domains. Due to substantial disparities in data distribution and variations in taxonomy across diverse domains, training such a detector by simply merging datasets poses a significant challenge. Motivated by this observation, we introduce multi-stage prompting modules for multi-dataset 3D detection, which leverages prompts based on the characteristics of corresponding datasets to mitigate existing differences. This elegant design facilitates seamless plug-and-play integration within various advanced 3D detection frameworks in a unified manner, while also allowing straightforward adaptation for universal applicability across datasets. Experiments are conducted across multiple dataset consolidation scenarios involving KITTI, Waymo, and nuScenes, demonstrating that our Uni$^2$Det outperforms existing methods by a large margin in multi-dataset training. Notably, results on zero-shot cross-dataset transfer validate the generalization capability of our proposed method.","sentences":["We present Uni$^2$Det, a brand new framework for unified and universal multi-dataset training on 3D detection, enabling robust performance across diverse domains and generalization to unseen domains.","Due to substantial disparities in data distribution and variations in taxonomy across diverse domains, training such a detector by simply merging datasets poses a significant challenge.","Motivated by this observation, we introduce multi-stage prompting modules for multi-dataset 3D detection, which leverages prompts based on the characteristics of corresponding datasets to mitigate existing differences.","This elegant design facilitates seamless plug-and-play integration within various advanced 3D detection frameworks in a unified manner, while also allowing straightforward adaptation for universal applicability across datasets.","Experiments are conducted across multiple dataset consolidation scenarios involving KITTI, Waymo, and nuScenes, demonstrating that our Uni$^2$Det outperforms existing methods by a large margin in multi-dataset training.","Notably, results on zero-shot cross-dataset transfer validate the generalization capability of our proposed method."],"url":"http://arxiv.org/abs/2409.20558v1"}
{"created":"2024-09-30 17:51:15","title":"LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation","abstract":"Code generation aims to automatically generate code from input requirements, significantly enhancing development efficiency. Recent large language models (LLMs) based approaches have shown promising results and revolutionized code generation task. Despite the promising performance, LLMs often generate contents with hallucinations, especially for the code generation scenario requiring the handling of complex contextual dependencies in practical development process. Although previous study has analyzed hallucinations in LLM-powered code generation, the study is limited to standalone function generation. In this paper, we conduct an empirical study to study the phenomena, mechanism, and mitigation of LLM hallucinations within more practical and complex development contexts in repository-level generation scenario. First, we manually examine the code generation results from six mainstream LLMs to establish a hallucination taxonomy of LLM-generated code. Next, we elaborate on the phenomenon of hallucinations, analyze their distribution across different models. We then analyze causes of hallucinations and identify four potential factors contributing to hallucinations. Finally, we propose an RAG-based mitigation method, which demonstrates consistent effectiveness in all studied LLMs. The replication package including code, data, and experimental results is available at https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination","sentences":["Code generation aims to automatically generate code from input requirements, significantly enhancing development efficiency.","Recent large language models (LLMs) based approaches have shown promising results and revolutionized code generation task.","Despite the promising performance, LLMs often generate contents with hallucinations, especially for the code generation scenario requiring the handling of complex contextual dependencies in practical development process.","Although previous study has analyzed hallucinations in LLM-powered code generation, the study is limited to standalone function generation.","In this paper, we conduct an empirical study to study the phenomena, mechanism, and mitigation of LLM hallucinations within more practical and complex development contexts in repository-level generation scenario.","First, we manually examine the code generation results from six mainstream LLMs to establish a hallucination taxonomy of LLM-generated code.","Next, we elaborate on the phenomenon of hallucinations, analyze their distribution across different models.","We then analyze causes of hallucinations and identify four potential factors contributing to hallucinations.","Finally, we propose an RAG-based mitigation method, which demonstrates consistent effectiveness in all studied LLMs.","The replication package including code, data, and experimental results is available at https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination"],"url":"http://arxiv.org/abs/2409.20550v1"}
{"created":"2024-09-30 17:39:41","title":"Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers","abstract":"One of the roadblocks for training generalist robotic models today is heterogeneity. Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting. This work studies the problem of learning policy representations through heterogeneous pre-training on robot data across different embodiments and tasks at scale. We propose Heterogeneous Pre-trained Transformers (HPT), which pre-train a large, shareable trunk of a policy neural network to learn a task and embodiment agnostic shared representation. This general architecture aligns the specific proprioception and vision inputs from distinct embodiments to a short sequence of tokens and then processes such tokens to map to control robots for different tasks. Leveraging the recent large-scale multi-embodiment real-world robotic datasets as well as simulation, deployed robots, and human video datasets, we investigate pre-training policies across heterogeneity. We conduct experiments to investigate the scaling behaviors of training objectives, to the extent of 52 datasets. HPTs outperform several baselines and enhance the fine-tuned policy performance by over 20% on unseen tasks in multiple simulator benchmarks and real-world settings. See the project website (https://liruiw.github.io/hpt/) for code and videos.","sentences":["One of the roadblocks for training generalist robotic models today is heterogeneity.","Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting.","This work studies the problem of learning policy representations through heterogeneous pre-training on robot data across different embodiments and tasks at scale.","We propose Heterogeneous Pre-trained Transformers (HPT), which pre-train a large, shareable trunk of a policy neural network to learn a task and embodiment agnostic shared representation.","This general architecture aligns the specific proprioception and vision inputs from distinct embodiments to a short sequence of tokens and then processes such tokens to map to control robots for different tasks.","Leveraging the recent large-scale multi-embodiment real-world robotic datasets as well as simulation, deployed robots, and human video datasets, we investigate pre-training policies across heterogeneity.","We conduct experiments to investigate the scaling behaviors of training objectives, to the extent of 52 datasets.","HPTs outperform several baselines and enhance the fine-tuned policy performance by over 20% on unseen tasks in multiple simulator benchmarks and real-world settings.","See the project website (https://liruiw.github.io/hpt/) for code and videos."],"url":"http://arxiv.org/abs/2409.20537v1"}
{"created":"2024-09-30 17:39:38","title":"Best Practices for Responsible Machine Learning in Credit Scoring","abstract":"The widespread use of machine learning in credit scoring has brought significant advancements in risk assessment and decision-making. However, it has also raised concerns about potential biases, discrimination, and lack of transparency in these automated systems. This tutorial paper performed a non-systematic literature review to guide best practices for developing responsible machine learning models in credit scoring, focusing on fairness, reject inference, and explainability. We discuss definitions, metrics, and techniques for mitigating biases and ensuring equitable outcomes across different groups. Additionally, we address the issue of limited data representativeness by exploring reject inference methods that incorporate information from rejected loan applications. Finally, we emphasize the importance of transparency and explainability in credit models, discussing techniques that provide insights into the decision-making process and enable individuals to understand and potentially improve their creditworthiness. By adopting these best practices, financial institutions can harness the power of machine learning while upholding ethical and responsible lending practices.","sentences":["The widespread use of machine learning in credit scoring has brought significant advancements in risk assessment and decision-making.","However, it has also raised concerns about potential biases, discrimination, and lack of transparency in these automated systems.","This tutorial paper performed a non-systematic literature review to guide best practices for developing responsible machine learning models in credit scoring, focusing on fairness, reject inference, and explainability.","We discuss definitions, metrics, and techniques for mitigating biases and ensuring equitable outcomes across different groups.","Additionally, we address the issue of limited data representativeness by exploring reject inference methods that incorporate information from rejected loan applications.","Finally, we emphasize the importance of transparency and explainability in credit models, discussing techniques that provide insights into the decision-making process and enable individuals to understand and potentially improve their creditworthiness.","By adopting these best practices, financial institutions can harness the power of machine learning while upholding ethical and responsible lending practices."],"url":"http://arxiv.org/abs/2409.20536v1"}
{"created":"2024-09-30 17:19:57","title":"SMLE: Safe Machine Learning via Embedded Overapproximation","abstract":"Despite the extent of recent advances in Machine Learning (ML) and Neural Networks, providing formal guarantees on the behavior of these systems is still an open problem, and a crucial requirement for their adoption in regulated or safety-critical scenarios. We consider the task of training differentiable ML models guaranteed to satisfy designer-chosen properties, stated as input-output implications. This is very challenging, due to the computational complexity of rigorously verifying and enforcing compliance in modern neural models. We provide an innovative approach based on three components: 1) a general, simple architecture enabling efficient verification with a conservative semantic; 2) a rigorous training algorithm based on the Projected Gradient Method; 3) a formulation of the problem of searching for strong counterexamples. The proposed framework, being only marginally affected by model complexity, scales well to practical applications, and produces models that provide full property satisfaction guarantees. We evaluate our approach on properties defined by linear inequalities in regression, and on mutually exclusive classes in multilabel classification. Our approach is competitive with a baseline that includes property enforcement during preprocessing, i.e. on the training data, as well as during postprocessing, i.e. on the model predictions. Finally, our contributions establish a framework that opens up multiple research directions and potential improvements.","sentences":["Despite the extent of recent advances in Machine Learning (ML) and Neural Networks, providing formal guarantees on the behavior of these systems is still an open problem, and a crucial requirement for their adoption in regulated or safety-critical scenarios.","We consider the task of training differentiable ML models guaranteed to satisfy designer-chosen properties, stated as input-output implications.","This is very challenging, due to the computational complexity of rigorously verifying and enforcing compliance in modern neural models.","We provide an innovative approach based on three components: 1) a general, simple architecture enabling efficient verification with a conservative semantic; 2) a rigorous training algorithm based on the Projected Gradient Method; 3) a formulation of the problem of searching for strong counterexamples.","The proposed framework, being only marginally affected by model complexity, scales well to practical applications, and produces models that provide full property satisfaction guarantees.","We evaluate our approach on properties defined by linear inequalities in regression, and on mutually exclusive classes in multilabel classification.","Our approach is competitive with a baseline that includes property enforcement during preprocessing, i.e. on the training data, as well as during postprocessing, i.e. on the model predictions.","Finally, our contributions establish a framework that opens up multiple research directions and potential improvements."],"url":"http://arxiv.org/abs/2409.20517v1"}
{"created":"2024-09-30 17:10:25","title":"NUTRIVISION: A System for Automatic Diet Management in Smart Healthcare","abstract":"Maintaining health and fitness through a balanced diet is essential for preventing non communicable diseases such as heart disease, diabetes, and cancer. NutriVision combines smart healthcare with computer vision and machine learning to address the challenges of nutrition and dietary management. This paper introduces a novel system that can identify food items, estimate quantities, and provide comprehensive nutritional information. NutriVision employs the Faster Region based Convolutional Neural Network, a deep learning algorithm that improves object detection by generating region proposals and then classifying those regions, making it highly effective for accurate and fast food identification even in complex and disorganized meal settings. Through smartphone based image capture, NutriVision delivers instant nutritional data, including macronutrient breakdown, calorie count, and micronutrient details. One of the standout features of NutriVision is its personalized nutritional analysis and diet recommendations, which are tailored to each user's dietary preferences, nutritional needs, and health history. By providing customized advice, NutriVision helps users achieve specific health and fitness goals, such as managing dietary restrictions or controlling weight. In addition to offering precise food detection and nutritional assessment, NutriVision supports smarter dietary decisions by integrating user data with recommendations that promote a balanced, healthful diet. This system presents a practical and advanced solution for nutrition management and has the potential to significantly influence how people approach their dietary choices, promoting healthier eating habits and overall well being. This paper discusses the design, performance evaluation, and prospective applications of the NutriVision system.","sentences":["Maintaining health and fitness through a balanced diet is essential for preventing non communicable diseases such as heart disease, diabetes, and cancer.","NutriVision combines smart healthcare with computer vision and machine learning to address the challenges of nutrition and dietary management.","This paper introduces a novel system that can identify food items, estimate quantities, and provide comprehensive nutritional information.","NutriVision employs the Faster Region based Convolutional Neural Network, a deep learning algorithm that improves object detection by generating region proposals and then classifying those regions, making it highly effective for accurate and fast food identification even in complex and disorganized meal settings.","Through smartphone based image capture, NutriVision delivers instant nutritional data, including macronutrient breakdown, calorie count, and micronutrient details.","One of the standout features of NutriVision is its personalized nutritional analysis and diet recommendations, which are tailored to each user's dietary preferences, nutritional needs, and health history.","By providing customized advice, NutriVision helps users achieve specific health and fitness goals, such as managing dietary restrictions or controlling weight.","In addition to offering precise food detection and nutritional assessment, NutriVision supports smarter dietary decisions by integrating user data with recommendations that promote a balanced, healthful diet.","This system presents a practical and advanced solution for nutrition management and has the potential to significantly influence how people approach their dietary choices, promoting healthier eating habits and overall well being.","This paper discusses the design, performance evaluation, and prospective applications of the NutriVision system."],"url":"http://arxiv.org/abs/2409.20508v1"}
{"created":"2024-09-30 17:03:13","title":"What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach","abstract":"Log data are generated from logging statements in the source code, providing insights into the execution processes of software applications and systems. State-of-the-art log-based anomaly detection approaches typically leverage deep learning models to capture the semantic or sequential information in the log data and detect anomalous runtime behaviors. However, the impacts of these different types of information are not clear. In addition, existing approaches have not captured the timestamps in the log data, which can potentially provide more fine-grained temporal information than sequential information. In this work, we propose a configurable transformer-based anomaly detection model that can capture the semantic, sequential, and temporal information in the log data and allows us to configure the different types of information as the model's features. Additionally, we train and evaluate the proposed model using log sequences of different lengths, thus overcoming the constraint of existing methods that rely on fixed-length or time-windowed log sequences as inputs. With the proposed model, we conduct a series of experiments with different combinations of input features to evaluate the roles of different types of information in anomaly detection. When presented with log sequences of varying lengths, the model can attain competitive and consistently stable performance compared to the baselines. The results indicate that the event occurrence information plays a key role in identifying anomalies, while the impact of the sequential and temporal information is not significant for anomaly detection in the studied public datasets. On the other hand, the findings also reveal the simplicity of the studied public datasets and highlight the importance of constructing new datasets that contain different types of anomalies to better evaluate the performance of anomaly detection models.","sentences":["Log data are generated from logging statements in the source code, providing insights into the execution processes of software applications and systems.","State-of-the-art log-based anomaly detection approaches typically leverage deep learning models to capture the semantic or sequential information in the log data and detect anomalous runtime behaviors.","However, the impacts of these different types of information are not clear.","In addition, existing approaches have not captured the timestamps in the log data, which can potentially provide more fine-grained temporal information than sequential information.","In this work, we propose a configurable transformer-based anomaly detection model that can capture the semantic, sequential, and temporal information in the log data and allows us to configure the different types of information as the model's features.","Additionally, we train and evaluate the proposed model using log sequences of different lengths, thus overcoming the constraint of existing methods that rely on fixed-length or time-windowed log sequences as inputs.","With the proposed model, we conduct a series of experiments with different combinations of input features to evaluate the roles of different types of information in anomaly detection.","When presented with log sequences of varying lengths, the model can attain competitive and consistently stable performance compared to the baselines.","The results indicate that the event occurrence information plays a key role in identifying anomalies, while the impact of the sequential and temporal information is not significant for anomaly detection in the studied public datasets.","On the other hand, the findings also reveal the simplicity of the studied public datasets and highlight the importance of constructing new datasets that contain different types of anomalies to better evaluate the performance of anomaly detection models."],"url":"http://arxiv.org/abs/2409.20503v1"}
{"created":"2024-09-30 17:01:32","title":"Packet Aggregation May Harm Batched Network Coding","abstract":"Batched network coding (BNC) is a solution to multi-hop transmission on networks with packet loss. To be compatible with the existing infrastructure, BNC is usually implemented over UDP. A single error bit will probably result in discarding the packet. UDP-Lite is a variant of UDP that supports partial checksums. As long as the data covered by the checksum is correct, damaged payload will be delivered. With UDP-Lite, we can cope with other techniques such as payload aggregation of BNC packets to reduce the protocol overhead, and forward error correction to combat against bit errors. Unlike traditional transmissions, BNC has a loss resilience feature and there are dependencies between BNC packets. In this paper, we conduct a preliminary investigation on BNC over UDP-Lite. We show that aggregating as much as we can is not always the best strategy, and a hop-by-hop distributed efficiency optimization approach may lead to a worse throughput compared with the scheme without aggregation in a long network. These unnatural results caution that a casual integration of techniques with BNC can be harmful, and give us hints on future research directions.","sentences":["Batched network coding (BNC) is a solution to multi-hop transmission on networks with packet loss.","To be compatible with the existing infrastructure, BNC is usually implemented over UDP.","A single error bit will probably result in discarding the packet.","UDP-Lite is a variant of UDP that supports partial checksums.","As long as the data covered by the checksum is correct, damaged payload will be delivered.","With UDP-Lite, we can cope with other techniques such as payload aggregation of BNC packets to reduce the protocol overhead, and forward error correction to combat against bit errors.","Unlike traditional transmissions, BNC has a loss resilience feature and there are dependencies between BNC packets.","In this paper, we conduct a preliminary investigation on BNC over UDP-Lite.","We show that aggregating as much as we can is not always the best strategy, and a hop-by-hop distributed efficiency optimization approach may lead to a worse throughput compared with the scheme without aggregation in a long network.","These unnatural results caution that a casual integration of techniques with BNC can be harmful, and give us hints on future research directions."],"url":"http://arxiv.org/abs/2409.20501v1"}
{"created":"2024-09-30 16:59:48","title":"Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation","abstract":"This paper highlights the significance of natural language processing (NLP) within artificial intelligence, underscoring its pivotal role in comprehending and modeling human language. Recent advancements in NLP, particularly in conversational bots, have garnered substantial attention and adoption among developers. This paper explores advanced methodologies for attaining smaller and more efficient NLP models. Specifically, we employ three key approaches: (1) training a Transformer-based neural network to detect offensive language, (2) employing data augmentation and knowledge distillation techniques to increase performance, and (3) incorporating multi-task learning with knowledge distillation and teacher annealing using diverse datasets to enhance efficiency. The culmination of these methods has yielded demonstrably improved outcomes.","sentences":["This paper highlights the significance of natural language processing (NLP) within artificial intelligence, underscoring its pivotal role in comprehending and modeling human language.","Recent advancements in NLP, particularly in conversational bots, have garnered substantial attention and adoption among developers.","This paper explores advanced methodologies for attaining smaller and more efficient NLP models.","Specifically, we employ three key approaches: (1) training a Transformer-based neural network to detect offensive language, (2) employing data augmentation and knowledge distillation techniques to increase performance, and (3) incorporating multi-task learning with knowledge distillation and teacher annealing using diverse datasets to enhance efficiency.","The culmination of these methods has yielded demonstrably improved outcomes."],"url":"http://arxiv.org/abs/2409.20498v1"}
{"created":"2024-09-30 16:51:30","title":"Propelling Innovation to Defeat Data-Leakage Hardware Trojans: From Theory to Practice","abstract":"Many design companies have gone fabless and rely on external fabrication facilities to produce chips due to increasing cost of semiconductor manufacturing. However, not all of these facilities can be considered trustworthy; some may inject hardware Trojans and jeopardize the security of the system. One common objective of hardware Trojans is to establish a side channel for data leakage. While extensive literature exists on various defensive measures, almost all of them focus on preventing the establishment of side channels, and can be compromised if attackers gain access to the physical chip and can perform reverse engineering between multiple fabrication runs. In this paper, we advance (from theory to practice) RECORD: Randomized Encoding of COmbinational Logic for Resistance to Data Leakage. RECORD is a novel scheme of temporarily randomized encoding for combinational logic that, with the aid of Quilt Packaging, prevents attackers from interpreting the data.","sentences":["Many design companies have gone fabless and rely on external fabrication facilities to produce chips due to increasing cost of semiconductor manufacturing.","However, not all of these facilities can be considered trustworthy; some may inject hardware Trojans and jeopardize the security of the system.","One common objective of hardware Trojans is to establish a side channel for data leakage.","While extensive literature exists on various defensive measures, almost all of them focus on preventing the establishment of side channels, and can be compromised if attackers gain access to the physical chip and can perform reverse engineering between multiple fabrication runs.","In this paper, we advance (from theory to practice) RECORD:","Randomized Encoding of COmbinational Logic for Resistance to Data Leakage.","RECORD is a novel scheme of temporarily randomized encoding for combinational logic that, with the aid of Quilt Packaging, prevents attackers from interpreting the data."],"url":"http://arxiv.org/abs/2409.20486v1"}
{"created":"2024-09-30 16:35:16","title":"IRFusionFormer: Enhancing Pavement Crack Segmentation with RGB-T Fusion and Topological-Based Loss","abstract":"Crack segmentation is crucial in civil engineering, particularly for assessing pavement integrity and ensuring the durability of infrastructure. While deep learning has advanced RGB-based segmentation, performance degrades under adverse conditions like low illumination or motion blur. Thermal imaging offers complementary information by capturing emitted radiation, improving crack detection in challenging environments. Combining RGB and thermal images (RGB-T) for crack segmentation shows promise in complex real-world conditions, such as adverse weather, yet research in this area remains limited. Current RGB-T segmentation methods often fail to fully exploit the complementary relationships between modalities at various levels of interaction. To address this, we propose IRFusionFormer, a novel model for crack segmentation that effectively integrates RGB and thermal data. Our Efficient RGB-T Cross Fusion Module captures multi-scale relationships and long-range dependencies between modalities without significant computational overhead. Additionally, we introduce the Interaction-Hybrid-Branch-Supervision framework, which enhances interaction between modalities by distributing fused features across branches with joint supervision. To maintain the topological structure of cracks, we introduce a novel topology-based loss function that preserves connectivity during training. Our method achieves state-of-the-art performance, with a Dice score of 90.01% and an IoU of 81.83%, significantly improving robustness and accuracy in varying environmental conditions. These advancements address key challenges in pavement crack segmentation, offering a more reliable and efficient solution. For access to the codes, data, and models from this study, visit https://github.com/sheauhuu/IRFusionFormer","sentences":["Crack segmentation is crucial in civil engineering, particularly for assessing pavement integrity and ensuring the durability of infrastructure.","While deep learning has advanced RGB-based segmentation, performance degrades under adverse conditions like low illumination or motion blur.","Thermal imaging offers complementary information by capturing emitted radiation, improving crack detection in challenging environments.","Combining RGB and thermal images (RGB-T) for crack segmentation shows promise in complex real-world conditions, such as adverse weather, yet research in this area remains limited.","Current RGB-T segmentation methods often fail to fully exploit the complementary relationships between modalities at various levels of interaction.","To address this, we propose IRFusionFormer, a novel model for crack segmentation that effectively integrates RGB and thermal data.","Our Efficient RGB-T Cross Fusion Module captures multi-scale relationships and long-range dependencies between modalities without significant computational overhead.","Additionally, we introduce the Interaction-Hybrid-Branch-Supervision framework, which enhances interaction between modalities by distributing fused features across branches with joint supervision.","To maintain the topological structure of cracks, we introduce a novel topology-based loss function that preserves connectivity during training.","Our method achieves state-of-the-art performance, with a Dice score of 90.01% and an IoU of 81.83%, significantly improving robustness and accuracy in varying environmental conditions.","These advancements address key challenges in pavement crack segmentation, offering a more reliable and efficient solution.","For access to the codes, data, and models from this study, visit https://github.com/sheauhuu/IRFusionFormer"],"url":"http://arxiv.org/abs/2409.20474v1"}
{"created":"2024-09-30 16:29:30","title":"Continual Human Pose Estimation for Incremental Integration of Keypoints and Pose Variations","abstract":"This paper reformulates cross-dataset human pose estimation as a continual learning task, aiming to integrate new keypoints and pose variations into existing models without losing accuracy on previously learned datasets. We benchmark this formulation against established regularization-based methods for mitigating catastrophic forgetting, including EWC, LFL, and LwF. Moreover, we propose a novel regularization method called Importance-Weighted Distillation (IWD), which enhances conventional LwF by introducing a layer-wise distillation penalty and dynamic temperature adjustment based on layer importance for previously learned knowledge. This allows for a controlled adaptation to new tasks that respects the stability-plasticity balance critical in continual learning. Through extensive experiments across three datasets, we demonstrate that our approach outperforms existing regularization-based continual learning strategies. IWD shows an average improvement of 3.60\\% over the state-of-the-art LwF method. The results highlight the potential of our method to serve as a robust framework for real-world applications where models must evolve with new data without forgetting past knowledge.","sentences":["This paper reformulates cross-dataset human pose estimation as a continual learning task, aiming to integrate new keypoints and pose variations into existing models without losing accuracy on previously learned datasets.","We benchmark this formulation against established regularization-based methods for mitigating catastrophic forgetting, including EWC, LFL, and LwF.","Moreover, we propose a novel regularization method called Importance-Weighted Distillation (IWD), which enhances conventional LwF by introducing a layer-wise distillation penalty and dynamic temperature adjustment based on layer importance for previously learned knowledge.","This allows for a controlled adaptation to new tasks that respects the stability-plasticity balance critical in continual learning.","Through extensive experiments across three datasets, we demonstrate that our approach outperforms existing regularization-based continual learning strategies.","IWD shows an average improvement of 3.60\\% over the state-of-the-art LwF method.","The results highlight the potential of our method to serve as a robust framework for real-world applications where models must evolve with new data without forgetting past knowledge."],"url":"http://arxiv.org/abs/2409.20469v1"}
{"created":"2024-09-30 16:26:40","title":"A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media","abstract":"This study introduces an innovative automatic labeling framework to address the challenges of lexical normalization in social media texts for low-resource languages like Vietnamese. Social media data is rich and diverse, but the evolving and varied language used in these contexts makes manual labeling labor-intensive and expensive. To tackle these issues, we propose a framework that integrates semi-supervised learning with weak supervision techniques. This approach enhances the quality of training dataset and expands its size while minimizing manual labeling efforts. Our framework automatically labels raw data, converting non-standard vocabulary into standardized forms, thereby improving the accuracy and consistency of the training data. Experimental results demonstrate the effectiveness of our weak supervision framework in normalizing Vietnamese text, especially when utilizing Pre-trained Language Models. The proposed framework achieves an impressive F1-score of 82.72% and maintains vocabulary integrity with an accuracy of up to 99.22%. Additionally, it effectively handles undiacritized text under various conditions. This framework significantly enhances natural language normalization quality and improves the accuracy of various NLP tasks, leading to an average accuracy increase of 1-3%.","sentences":["This study introduces an innovative automatic labeling framework to address the challenges of lexical normalization in social media texts for low-resource languages like Vietnamese.","Social media data is rich and diverse, but the evolving and varied language used in these contexts makes manual labeling labor-intensive and expensive.","To tackle these issues, we propose a framework that integrates semi-supervised learning with weak supervision techniques.","This approach enhances the quality of training dataset and expands its size while minimizing manual labeling efforts.","Our framework automatically labels raw data, converting non-standard vocabulary into standardized forms, thereby improving the accuracy and consistency of the training data.","Experimental results demonstrate the effectiveness of our weak supervision framework in normalizing Vietnamese text, especially when utilizing Pre-trained Language Models.","The proposed framework achieves an impressive F1-score of 82.72% and maintains vocabulary integrity with an accuracy of up to 99.22%.","Additionally, it effectively handles undiacritized text under various conditions.","This framework significantly enhances natural language normalization quality and improves the accuracy of various NLP tasks, leading to an average accuracy increase of 1-3%."],"url":"http://arxiv.org/abs/2409.20467v1"}
{"created":"2024-09-30 16:20:58","title":"Time Efficiency of BATS Coding on Wireless Relay Network With Overhearing","abstract":"Wireless relay network is a solution to extend the reach of a wireless connection by installing a relay node between the source node and the sink node. Due to the broadcast nature of wireless transmission, the sink node has a chance to receive part of the data sent by the source node. In this paper, we apply a network coding scheme called BATS codes on a wireless relay network where the relay node has a stable power supply, so that we can aim for the best decoding time instead of minimizing the number of transmissions for saving energy. We optimize the time efficiency that maximize the average decoding rate per unit time by some heuristics, and bring out a message that it is not optimal to set an average number of recoded packets per batch at the relay node equals the number of packets per batch sent by the source node.","sentences":["Wireless relay network is a solution to extend the reach of a wireless connection by installing a relay node between the source node and the sink node.","Due to the broadcast nature of wireless transmission, the sink node has a chance to receive part of the data sent by the source node.","In this paper, we apply a network coding scheme called BATS codes on a wireless relay network where the relay node has a stable power supply, so that we can aim for the best decoding time instead of minimizing the number of transmissions for saving energy.","We optimize the time efficiency that maximize the average decoding rate per unit time by some heuristics, and bring out a message that it is not optimal to set an average number of recoded packets per batch at the relay node equals the number of packets per batch sent by the source node."],"url":"http://arxiv.org/abs/2409.20463v1"}
{"created":"2024-09-30 16:17:16","title":"The Secretary Problem with Predicted Additive Gap","abstract":"The secretary problem is one of the fundamental problems in online decision making; a tight competitive ratio for this problem of $1/\\mathrm{e} \\approx 0.368$ has been known since the 1960s. Much more recently, the study of algorithms with predictions was introduced: The algorithm is equipped with a (possibly erroneous) additional piece of information upfront which can be used to improve the algorithm's performance. Complementing previous work on secretary problems with prior knowledge, we tackle the following question:   What is the weakest piece of information that allows us to break the $1/\\mathrm{e}$ barrier?   To this end, we introduce the secretary problem with predicted additive gap. As in the classical problem, weights are fixed by an adversary and elements appear in random order. In contrast to previous variants of predictions, our algorithm only has access to a much weaker piece of information: an \\emph{additive gap} $c$. This gap is the difference between the highest and $k$-th highest weight in the sequence. Unlike previous pieces of advice, knowing an exact additive gap does not make the problem trivial. Our contribution is twofold. First, we show that for any index $k$ and any gap $c$, we can obtain a competitive ratio of $0.4$ when knowing the exact gap (even if we do not know $k$), hence beating the prevalent bound for the classical problem by a constant. Second, a slightly modified version of our algorithm allows to prove standard robustness-consistency properties as well as improved guarantees when knowing a range for the error of the prediction.","sentences":["The secretary problem is one of the fundamental problems in online decision making; a tight competitive ratio for this problem of $1/\\mathrm{e} \\approx 0.368$ has been known since the 1960s.","Much more recently, the study of algorithms with predictions was introduced: The algorithm is equipped with a (possibly erroneous) additional piece of information upfront which can be used to improve the algorithm's performance.","Complementing previous work on secretary problems with prior knowledge, we tackle the following question:   What is the weakest piece of information that allows us to break the $1/\\mathrm{e}$ barrier?   ","To this end, we introduce the secretary problem with predicted additive gap.","As in the classical problem, weights are fixed by an adversary and elements appear in random order.","In contrast to previous variants of predictions, our algorithm only has access to a much weaker piece of information: an \\emph{additive gap} $c$. This gap is the difference between the highest and $k$-th highest weight in the sequence.","Unlike previous pieces of advice, knowing an exact additive gap does not make the problem trivial.","Our contribution is twofold.","First, we show that for any index $k$ and any gap $c$, we can obtain a competitive ratio of $0.4$ when knowing the exact gap (even if we do not know $k$), hence beating the prevalent bound for the classical problem by a constant.","Second, a slightly modified version of our algorithm allows to prove standard robustness-consistency properties as well as improved guarantees when knowing a range for the error of the prediction."],"url":"http://arxiv.org/abs/2409.20460v1"}
{"created":"2024-09-30 16:07:34","title":"Linear Projections of Teacher Embeddings for Few-Class Distillation","abstract":"Knowledge Distillation (KD) has emerged as a promising approach for transferring knowledge from a larger, more complex teacher model to a smaller student model. Traditionally, KD involves training the student to mimic the teacher's output probabilities, while more advanced techniques have explored guiding the student to adopt the teacher's internal representations. Despite its widespread success, the performance of KD in binary classification and few-class problems has been less satisfactory. This is because the information about the teacher model's generalization patterns scales directly with the number of classes. Moreover, several sophisticated distillation methods may not be universally applicable or effective for data types beyond Computer Vision. Consequently, effective distillation techniques remain elusive for a range of key real-world applications, such as sentiment analysis, search query understanding, and advertisement-query relevance assessment. Taking these observations into account, we introduce a novel method for distilling knowledge from the teacher's model representations, which we term Learning Embedding Linear Projections (LELP). Inspired by recent findings about the structure of final-layer representations, LELP works by identifying informative linear subspaces in the teacher's embedding space, and splitting them into pseudo-subclasses. The student model is then trained to replicate these pseudo-classes. Our experimental evaluation on large-scale NLP benchmarks like Amazon Reviews and Sentiment140 demonstrate the LELP is consistently competitive with, and typically superior to, existing state-of-the-art distillation algorithms for binary and few-class problems, where most KD methods suffer.","sentences":["Knowledge Distillation (KD) has emerged as a promising approach for transferring knowledge from a larger, more complex teacher model to a smaller student model.","Traditionally, KD involves training the student to mimic the teacher's output probabilities, while more advanced techniques have explored guiding the student to adopt the teacher's internal representations.","Despite its widespread success, the performance of KD in binary classification and few-class problems has been less satisfactory.","This is because the information about the teacher model's generalization patterns scales directly with the number of classes.","Moreover, several sophisticated distillation methods may not be universally applicable or effective for data types beyond Computer Vision.","Consequently, effective distillation techniques remain elusive for a range of key real-world applications, such as sentiment analysis, search query understanding, and advertisement-query relevance assessment.","Taking these observations into account, we introduce a novel method for distilling knowledge from the teacher's model representations, which we term Learning Embedding Linear Projections (LELP).","Inspired by recent findings about the structure of final-layer representations, LELP works by identifying informative linear subspaces in the teacher's embedding space, and splitting them into pseudo-subclasses.","The student model is then trained to replicate these pseudo-classes.","Our experimental evaluation on large-scale NLP benchmarks like Amazon Reviews and Sentiment140 demonstrate the LELP is consistently competitive with, and typically superior to, existing state-of-the-art distillation algorithms for binary and few-class problems, where most KD methods suffer."],"url":"http://arxiv.org/abs/2409.20449v1"}
{"created":"2024-09-30 16:03:44","title":"Robot Navigation Using Physically Grounded Vision-Language Models in Outdoor Environments","abstract":"We present a novel autonomous robot navigation algorithm for outdoor environments that is capable of handling diverse terrain traversability conditions. Our approach, VLM-GroNav, uses vision-language models (VLMs) and integrates them with physical grounding that is used to assess intrinsic terrain properties such as deformability and slipperiness. We use proprioceptive-based sensing, which provides direct measurements of these physical properties, and enhances the overall semantic understanding of the terrains. Our formulation uses in-context learning to ground the VLM's semantic understanding with proprioceptive data to allow dynamic updates of traversability estimates based on the robot's real-time physical interactions with the environment. We use the updated traversability estimations to inform both the local and global planners for real-time trajectory replanning. We validate our method on a legged robot (Ghost Vision 60) and a wheeled robot (Clearpath Husky), in diverse real-world outdoor environments with different deformable and slippery terrains. In practice, we observe significant improvements over state-of-the-art methods by up to 50% increase in navigation success rate.","sentences":["We present a novel autonomous robot navigation algorithm for outdoor environments that is capable of handling diverse terrain traversability conditions.","Our approach, VLM-GroNav, uses vision-language models (VLMs) and integrates them with physical grounding that is used to assess intrinsic terrain properties such as deformability and slipperiness.","We use proprioceptive-based sensing, which provides direct measurements of these physical properties, and enhances the overall semantic understanding of the terrains.","Our formulation uses in-context learning to ground the VLM's semantic understanding with proprioceptive data to allow dynamic updates of traversability estimates based on the robot's real-time physical interactions with the environment.","We use the updated traversability estimations to inform both the local and global planners for real-time trajectory replanning.","We validate our method on a legged robot (Ghost Vision 60) and a wheeled robot (Clearpath Husky), in diverse real-world outdoor environments with different deformable and slippery terrains.","In practice, we observe significant improvements over state-of-the-art methods by up to 50% increase in navigation success rate."],"url":"http://arxiv.org/abs/2409.20445v1"}
{"created":"2024-09-30 15:53:46","title":"ALLO: A Photorealistic Dataset and Data Generation Pipeline for Anomaly Detection During Robotic Proximity Operations in Lunar Orbit","abstract":"NASA's forthcoming Lunar Gateway space station, which will be uncrewed most of the time, will need to operate with an unprecedented level of autonomy. Enhancing autonomy on the Gateway presents several unique challenges, one of which is to equip the Canadarm3, the Gateway's external robotic system, with the capability to perform worksite monitoring. Monitoring will involve using the arm's inspection cameras to detect any anomalies within the operating environment, a task complicated by the widely-varying lighting conditions in space. In this paper, we introduce the visual anomaly detection and localization task for space applications and establish a benchmark with our novel synthetic dataset called ALLO (for Anomaly Localization in Lunar Orbit). We develop a complete data generation pipeline to create ALLO, which we use to evaluate the performance of state-of-the-art visual anomaly detection algorithms. Given the low tolerance for risk during space operations and the lack of relevant data, we emphasize the need for novel, robust, and accurate anomaly detection methods to handle the challenging visual conditions found in lunar orbit and beyond.","sentences":["NASA's forthcoming Lunar Gateway space station, which will be uncrewed most of the time, will need to operate with an unprecedented level of autonomy.","Enhancing autonomy on the Gateway presents several unique challenges, one of which is to equip the Canadarm3, the Gateway's external robotic system, with the capability to perform worksite monitoring.","Monitoring will involve using the arm's inspection cameras to detect any anomalies within the operating environment, a task complicated by the widely-varying lighting conditions in space.","In this paper, we introduce the visual anomaly detection and localization task for space applications and establish a benchmark with our novel synthetic dataset called ALLO (for Anomaly Localization in Lunar Orbit).","We develop a complete data generation pipeline to create ALLO, which we use to evaluate the performance of state-of-the-art visual anomaly detection algorithms.","Given the low tolerance for risk during space operations and the lack of relevant data, we emphasize the need for novel, robust, and accurate anomaly detection methods to handle the challenging visual conditions found in lunar orbit and beyond."],"url":"http://arxiv.org/abs/2409.20435v1"}
{"created":"2024-09-30 15:50:36","title":"Navigating Threats: A Survey of Physical Adversarial Attacks on LiDAR Perception Systems in Autonomous Vehicles","abstract":"Autonomous vehicles (AVs) rely heavily on LiDAR (Light Detection and Ranging) systems for accurate perception and navigation, providing high-resolution 3D environmental data that is crucial for object detection and classification. However, LiDAR systems are vulnerable to adversarial attacks, which pose significant challenges to the safety and robustness of AVs. This survey presents a thorough review of the current research landscape on physical adversarial attacks targeting LiDAR-based perception systems, covering both single-modality and multi-modality contexts. We categorize and analyze various attack types, including spoofing and physical adversarial object attacks, detailing their methodologies, impacts, and potential real-world implications. Through detailed case studies and analyses, we identify critical challenges and highlight gaps in existing attacks for LiDAR-based systems. Additionally, we propose future research directions to enhance the security and resilience of these systems, ultimately contributing to the safer deployment of autonomous vehicles.","sentences":["Autonomous vehicles (AVs) rely heavily on LiDAR (Light Detection and Ranging) systems for accurate perception and navigation, providing high-resolution 3D environmental data that is crucial for object detection and classification.","However, LiDAR systems are vulnerable to adversarial attacks, which pose significant challenges to the safety and robustness of AVs.","This survey presents a thorough review of the current research landscape on physical adversarial attacks targeting LiDAR-based perception systems, covering both single-modality and multi-modality contexts.","We categorize and analyze various attack types, including spoofing and physical adversarial object attacks, detailing their methodologies, impacts, and potential real-world implications.","Through detailed case studies and analyses, we identify critical challenges and highlight gaps in existing attacks for LiDAR-based systems.","Additionally, we propose future research directions to enhance the security and resilience of these systems, ultimately contributing to the safer deployment of autonomous vehicles."],"url":"http://arxiv.org/abs/2409.20426v1"}
{"created":"2024-09-30 15:49:54","title":"World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering","abstract":"Recent advances in Vision-Language Models (VLMs) and the scarcity of high-quality multi-modal alignment data have inspired numerous researches on synthetic VLM data generation. The conventional norm in VLM data construction uses a mixture of specialists in caption and OCR, or stronger VLM APIs and expensive human annotation. In this paper, we present World to Code (W2C), a meticulously curated multi-modal data construction pipeline that organizes the final generation output into a Python code format. The pipeline leverages the VLM itself to extract cross-modal information via different prompts and filter the generated outputs again via a consistency filtering strategy. Experiments have demonstrated the high quality of W2C by improving various existing visual question answering and visual grounding benchmarks across different VLMs. Further analysis also demonstrates that the new code parsing ability of VLMs presents better cross-modal equivalence than the commonly used detail caption ability. Our code is available at https://github.com/foundation-multimodal-models/World2Code.","sentences":["Recent advances in Vision-Language Models (VLMs) and the scarcity of high-quality multi-modal alignment data have inspired numerous researches on synthetic VLM data generation.","The conventional norm in VLM data construction uses a mixture of specialists in caption and OCR, or stronger VLM APIs and expensive human annotation.","In this paper, we present World to Code (W2C), a meticulously curated multi-modal data construction pipeline that organizes the final generation output into a Python code format.","The pipeline leverages the VLM itself to extract cross-modal information via different prompts and filter the generated outputs again via a consistency filtering strategy.","Experiments have demonstrated the high quality of W2C by improving various existing visual question answering and visual grounding benchmarks across different VLMs.","Further analysis also demonstrates that the new code parsing ability of VLMs presents better cross-modal equivalence than the commonly used detail caption ability.","Our code is available at https://github.com/foundation-multimodal-models/World2Code."],"url":"http://arxiv.org/abs/2409.20424v1"}
{"created":"2024-09-30 15:43:06","title":"AI-Based Fully Automatic Analysis of Retinal Vascular Morphology in Pediatric High Myopia","abstract":"Purpose: To investigate the changes in retinal vascular structures associated various stages of myopia by designing automated software based on an artif intelligencemodel. Methods: The study involved 1324 pediatric participants from the National Childr Medical Center in China, and 2366 high-quality retinal images and correspon refractive parameters were obtained and analyzed. Spherical equivalent refrac(SER) degree was calculated. We proposed a data analysis model based c combination of the Convolutional Neural Networks (CNN) model and the atter module to classify images, segment vascular structures, and measure vasc parameters, such as main angle (MA), branching angle (BA), bifurcation edge al(BEA) and bifurcation edge coefficient (BEC). One-way ANOVA compared param measurements betweenthenormalfundus,lowmyopia,moderate myopia,and high myopia group. Results: There were 279 (12.38%) images in normal group and 384 (16.23%) images in the high myopia group. Compared normal fundus, the MA of fundus vessels in different myopic refractive groups significantly reduced (P = 0.006, P = 0.004, P = 0.019, respectively), and performance of the venous system was particularly obvious (P<0.001). At the sa time, the BEC decreased disproportionately (P<0.001). Further analysis of fundus vascular parameters at different degrees of myopia showed that there were also significant differences in BA and branching coefficient (BC). The arterial BA value of the fundus vessel in the high myopia group was lower than that of other groups (P : 0.032, 95% confidence interval [Ci], 0.22-4.86), while the venous BA values increased(P = 0.026). The BEC values of high myopia were higher than those of low and moderate myopia groups. When the loss function of our data classification model converged to 0.09,the model accuracy reached 94.19%","sentences":["Purpose: To investigate the changes in retinal vascular structures associated various stages of myopia by designing automated software based on an artif intelligencemodel.","Methods: The study involved 1324 pediatric participants from the National Childr Medical Center in China, and 2366 high-quality retinal images and correspon refractive parameters were obtained and analyzed.","Spherical equivalent refrac(SER) degree was calculated.","We proposed a data analysis model based c combination of the Convolutional Neural Networks (CNN) model and the atter module to classify images, segment vascular structures, and measure vasc parameters, such as main angle (MA), branching angle (BA), bifurcation edge al(BEA) and bifurcation edge coefficient (BEC).","One-way ANOVA compared param measurements betweenthenormalfundus,lowmyopia,moderate myopia,and high myopia group.","Results:","There were 279 (12.38%) images in normal group and 384 (16.23%) images in the high myopia group.","Compared normal fundus, the MA of fundus vessels in different myopic refractive groups significantly reduced (P = 0.006, P = 0.004, P = 0.019, respectively), and performance of the venous system was particularly obvious (P<0.001).","At the sa time, the BEC decreased disproportionately (P<0.001).","Further analysis of fundus vascular parameters at different degrees of myopia showed that there were also significant differences in BA and branching coefficient (BC).","The arterial BA value of the fundus vessel in the high myopia group was lower than that of other groups (P : 0.032, 95% confidence interval","[Ci], 0.22-4.86), while the venous BA values increased(P = 0.026).","The BEC values of high myopia were higher than those of low and moderate myopia groups.","When the loss function of our data classification model converged to 0.09,the model accuracy reached 94.19%"],"url":"http://arxiv.org/abs/2409.20419v1"}
{"created":"2024-09-30 15:36:14","title":"Physics-Regularized Multi-Modal Image Assimilation for Brain Tumor Localization","abstract":"Physical models in the form of partial differential equations represent an important prior for many under-constrained problems. One example is tumor treatment planning, which heavily depends on accurate estimates of the spatial distribution of tumor cells in a patient's anatomy. Medical imaging scans can identify the bulk of the tumor, but they cannot reveal its full spatial distribution. Tumor cells at low concentrations remain undetectable, for example, in the most frequent type of primary brain tumors, glioblastoma. Deep-learning-based approaches fail to estimate the complete tumor cell distribution due to a lack of reliable training data. Most existing works therefore rely on physics-based simulations to match observed tumors, providing anatomically and physiologically plausible estimations. However, these approaches struggle with complex and unknown initial conditions and are limited by overly rigid physical models. In this work, we present a novel method that balances data-driven and physics-based cost functions. In particular, we propose a unique discretization scheme that quantifies the adherence of our learned spatiotemporal tumor and brain tissue distributions to their corresponding growth and elasticity equations. This quantification, serving as a regularization term rather than a hard constraint, enables greater flexibility and proficiency in assimilating patient data than existing models. We demonstrate improved coverage of tumor recurrence areas compared to existing techniques on real-world data from a cohort of patients. The method holds the potential to enhance clinical adoption of model-driven treatment planning for glioblastoma.","sentences":["Physical models in the form of partial differential equations represent an important prior for many under-constrained problems.","One example is tumor treatment planning, which heavily depends on accurate estimates of the spatial distribution of tumor cells in a patient's anatomy.","Medical imaging scans can identify the bulk of the tumor, but they cannot reveal its full spatial distribution.","Tumor cells at low concentrations remain undetectable, for example, in the most frequent type of primary brain tumors, glioblastoma.","Deep-learning-based approaches fail to estimate the complete tumor cell distribution due to a lack of reliable training data.","Most existing works therefore rely on physics-based simulations to match observed tumors, providing anatomically and physiologically plausible estimations.","However, these approaches struggle with complex and unknown initial conditions and are limited by overly rigid physical models.","In this work, we present a novel method that balances data-driven and physics-based cost functions.","In particular, we propose a unique discretization scheme that quantifies the adherence of our learned spatiotemporal tumor and brain tissue distributions to their corresponding growth and elasticity equations.","This quantification, serving as a regularization term rather than a hard constraint, enables greater flexibility and proficiency in assimilating patient data than existing models.","We demonstrate improved coverage of tumor recurrence areas compared to existing techniques on real-world data from a cohort of patients.","The method holds the potential to enhance clinical adoption of model-driven treatment planning for glioblastoma."],"url":"http://arxiv.org/abs/2409.20409v1"}
{"created":"2024-09-30 15:36:04","title":"Beacon based uplink transmission for lorawan direct to satellite internet of things","abstract":"Direct-to-satellite IoT DtS IoT communication structure is a promising solution to provide connectivity and extend the coverage of traditional low-power and long-range technologies, especially for isolated and remote areas where deploying traditional infrastructure is impracticable. Despite their bounded visibility, the Low Earth Orbit LEO satellites complement the terrestrial networks, offering broader gateway coverage and terrestrial network traffic offloading. However, the dynamics of LEO and the nature of such integration come with several challenges affecting the efficacy of the network. Therefore, this paper proposes Beacon based Uplink LoRaWAN BU LoRaWAN to enhance satellite-terrestrial communication efficiency. The proposed scheme exploits the LoRaWAN class B synchronization mechanism to provide efficient uplink transmission from LoRaWAN devices placed on the ground to satellite gateways. BU LoRaWAN proposes an uplink transmission slot approach to synchronize ground devices uplink traffic with LEO based orbiting gateways. It also uses a queue data structure to buffer end devices ready to send packets until the appropriate moment. BU LoRaWAN avoids possible transmission collision by optimizing a random transmission slot for an end device within the beacon window. The proposed system is implemented and evaluated using OMNeT network simulator and FLoRaSat framework. The result demonstrates the feasibility of the proposed system. BU-LoRaWAN achieves better performance compared to the standard LoRaWAN, which manages to deliver almost double the traffic delivered by the standard one.","sentences":["Direct-to-satellite IoT DtS IoT communication structure is a promising solution to provide connectivity and extend the coverage of traditional low-power and long-range technologies, especially for isolated and remote areas where deploying traditional infrastructure is impracticable.","Despite their bounded visibility, the Low Earth Orbit LEO satellites complement the terrestrial networks, offering broader gateway coverage and terrestrial network traffic offloading.","However, the dynamics of LEO and the nature of such integration come with several challenges affecting the efficacy of the network.","Therefore, this paper proposes Beacon based Uplink LoRaWAN BU LoRaWAN to enhance satellite-terrestrial communication efficiency.","The proposed scheme exploits the LoRaWAN class B synchronization mechanism to provide efficient uplink transmission from LoRaWAN devices placed on the ground to satellite gateways.","BU LoRaWAN proposes an uplink transmission slot approach to synchronize ground devices uplink traffic with LEO based orbiting gateways.","It also uses a queue data structure to buffer end devices ready to send packets until the appropriate moment.","BU LoRaWAN avoids possible transmission collision by optimizing a random transmission slot for an end device within the beacon window.","The proposed system is implemented and evaluated using OMNeT network simulator and FLoRaSat framework.","The result demonstrates the feasibility of the proposed system.","BU-LoRaWAN achieves better performance compared to the standard LoRaWAN, which manages to deliver almost double the traffic delivered by the standard one."],"url":"http://arxiv.org/abs/2409.20408v1"}
{"created":"2024-09-30 15:35:27","title":"Open-Source Periorbital Segmentation Dataset for Ophthalmic Applications","abstract":"Periorbital segmentation and distance prediction using deep learning allows for the objective quantification of disease state, treatment monitoring, and remote medicine. However, there are currently no reports of segmentation datasets for the purposes of training deep learning models with sub mm accuracy on the regions around the eyes. All images (n=2842) had the iris, sclera, lid, caruncle, and brow segmented by five trained annotators. Here, we validate this dataset through intra and intergrader reliability tests and show the utility of the data in training periorbital segmentation networks. All the annotations are publicly available for free download. Having access to segmentation datasets designed specifically for oculoplastic surgery will permit more rapid development of clinically useful segmentation networks which can be leveraged for periorbital distance prediction and disease classification. In addition to the annotations, we also provide an open-source toolkit for periorbital distance prediction from segmentation masks. The weights of all models have also been open-sourced and are publicly available for use by the community.","sentences":["Periorbital segmentation and distance prediction using deep learning allows for the objective quantification of disease state, treatment monitoring, and remote medicine.","However, there are currently no reports of segmentation datasets for the purposes of training deep learning models with sub mm accuracy on the regions around the eyes.","All images (n=2842) had the iris, sclera, lid, caruncle, and brow segmented by five trained annotators.","Here, we validate this dataset through intra and intergrader reliability tests and show the utility of the data in training periorbital segmentation networks.","All the annotations are publicly available for free download.","Having access to segmentation datasets designed specifically for oculoplastic surgery will permit more rapid development of clinically useful segmentation networks which can be leveraged for periorbital distance prediction and disease classification.","In addition to the annotations, we also provide an open-source toolkit for periorbital distance prediction from segmentation masks.","The weights of all models have also been open-sourced and are publicly available for use by the community."],"url":"http://arxiv.org/abs/2409.20407v1"}
{"created":"2024-09-30 15:33:47","title":"Accelerating PoT Quantization on Edge Devices","abstract":"Non-uniform quantization, such as power-of-two (PoT) quantization, matches data distributions better than uniform quantization, which reduces the quantization error of Deep Neural Networks (DNNs). PoT quantization also allows bit-shift operations to replace multiplications, but there are limited studies on the efficiency of shift-based accelerators for PoT quantization. Furthermore, existing pipelines for accelerating PoT-quantized DNNs on edge devices are not open-source. In this paper, we first design shift-based processing elements (shift-PE) for different PoT quantization methods and evaluate their efficiency using synthetic benchmarks. Then we design a shift-based accelerator using our most efficient shift-PE and propose PoTAcc, an open-source pipeline for end-to-end acceleration of PoT-quantized DNNs on resource-constrained edge devices. Using PoTAcc, we evaluate the performance of our shift-based accelerator across three DNNs. On average, it achieves a 1.23x speedup and 1.24x energy reduction compared to a multiplier-based accelerator, and a 2.46x speedup and 1.83x energy reduction compared to CPU-only execution. Our code is available at https://github.com/gicLAB/PoTAcc","sentences":["Non-uniform quantization, such as power-of-two (PoT) quantization, matches data distributions better than uniform quantization, which reduces the quantization error of Deep Neural Networks (DNNs).","PoT quantization also allows bit-shift operations to replace multiplications, but there are limited studies on the efficiency of shift-based accelerators for PoT quantization.","Furthermore, existing pipelines for accelerating PoT-quantized DNNs on edge devices are not open-source.","In this paper, we first design shift-based processing elements (shift-PE) for different PoT quantization methods and evaluate their efficiency using synthetic benchmarks.","Then we design a shift-based accelerator using our most efficient shift-PE and propose PoTAcc, an open-source pipeline for end-to-end acceleration of PoT-quantized DNNs on resource-constrained edge devices.","Using PoTAcc, we evaluate the performance of our shift-based accelerator across three DNNs.","On average, it achieves a 1.23x speedup and 1.24x energy reduction compared to a multiplier-based accelerator, and a 2.46x speedup and 1.83x energy reduction compared to CPU-only execution.","Our code is available at https://github.com/gicLAB/PoTAcc"],"url":"http://arxiv.org/abs/2409.20403v1"}
{"created":"2024-09-30 15:32:17","title":"Multi-Robot Target Monitoring and Encirclement via Triggered Distributed Feedback Optimization","abstract":"We design a distributed feedback optimization strategy, embedded into a modular ROS 2 control architecture, which allows a team of heterogeneous robots to cooperatively monitor and encircle a target while patrolling points of interest. Relying on the aggregative feedback optimization framework, we handle multi-robot dynamics while minimizing a global performance index depending on both microscopic (e.g., the location of single robots) and macroscopic variables (e.g., the spatial distribution of the team). The proposed distributed policy allows the robots to cooperatively address the global problem by employing only local measurements and neighboring data exchanges. These exchanges are performed through an asynchronous communication protocol ruled by locally-verifiable triggering conditions. We formally prove that our strategy steers the robots to a set of configurations representing stationary points of the considered optimization problem. The effectiveness and scalability of the overall strategy are tested via Monte Carlo campaigns of realistic Webots ROS 2 virtual experiments. Finally, the applicability of our solution is shown with real experiments on ground and aerial robots.","sentences":["We design a distributed feedback optimization strategy, embedded into a modular ROS 2 control architecture, which allows a team of heterogeneous robots to cooperatively monitor and encircle a target while patrolling points of interest.","Relying on the aggregative feedback optimization framework, we handle multi-robot dynamics while minimizing a global performance index depending on both microscopic (e.g., the location of single robots) and macroscopic variables (e.g., the spatial distribution of the team).","The proposed distributed policy allows the robots to cooperatively address the global problem by employing only local measurements and neighboring data exchanges.","These exchanges are performed through an asynchronous communication protocol ruled by locally-verifiable triggering conditions.","We formally prove that our strategy steers the robots to a set of configurations representing stationary points of the considered optimization problem.","The effectiveness and scalability of the overall strategy are tested via Monte Carlo campaigns of realistic Webots ROS 2 virtual experiments.","Finally, the applicability of our solution is shown with real experiments on ground and aerial robots."],"url":"http://arxiv.org/abs/2409.20399v1"}
{"created":"2024-09-30 15:21:25","title":"Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing","abstract":"AI-based systems such as language models can replicate and amplify social biases reflected in their training data. Among other questionable behavior, this can lead to LM-generated text--and text suggestions--that contain normatively inappropriate stereotypical associations. In this paper, we consider the question of how \"debiasing\" a language model impacts stories that people write using that language model in a predictive text scenario. We find that (n=414), in certain scenarios, language model suggestions that align with common social stereotypes are more likely to be accepted by human authors. Conversely, although anti-stereotypical language model suggestions sometimes lead to an increased rate of anti-stereotypical stories, this influence is far from sufficient to lead to \"fully debiased\" stories.","sentences":["AI-based systems such as language models can replicate and amplify social biases reflected in their training data.","Among other questionable behavior, this can lead to LM-generated text--and text suggestions--that contain normatively inappropriate stereotypical associations.","In this paper, we consider the question of how \"debiasing\" a language model impacts stories that people write using that language model in a predictive text scenario.","We find that (n=414), in certain scenarios, language model suggestions that align with common social stereotypes are more likely to be accepted by human authors.","Conversely, although anti-stereotypical language model suggestions sometimes lead to an increased rate of anti-stereotypical stories, this influence is far from sufficient to lead to \"fully debiased\" stories."],"url":"http://arxiv.org/abs/2409.20390v1"}
{"created":"2024-09-30 15:16:35","title":"Heterogeneous computing in a strongly-connected CPU-GPU environment: fast multiple time-evolution equation-based modeling accelerated using data-driven approach","abstract":"We propose a CPU-GPU heterogeneous computing method for solving time-evolution partial differential equation problems many times with guaranteed accuracy, in short time-to-solution and low energy-to-solution. On a single-GH200 node, the proposed method improved the computation speed by 86.4 and 8.67 times compared to the conventional method run only on CPU and only on GPU, respectively. Furthermore, the energy-to-solution was reduced by 32.2-fold (from 9944 J to 309 J) and 7.01-fold (from 2163 J to 309 J) when compared to using only the CPU and GPU, respectively. Using the proposed method on the Alps supercomputer, a 51.6-fold and 6.98-fold speedup was attained when compared to using only the CPU and GPU, respectively, and a high weak scaling efficiency of 94.3% was obtained up to 1,920 compute nodes. These implementations were realized using directive-based parallel programming models while enabling portability, indicating that directives are highly effective in analyses in heterogeneous computing environments.","sentences":["We propose a CPU-GPU heterogeneous computing method for solving time-evolution partial differential equation problems many times with guaranteed accuracy, in short time-to-solution and low energy-to-solution.","On a single-GH200 node, the proposed method improved the computation speed by 86.4 and 8.67 times compared to the conventional method run only on CPU and only on GPU, respectively.","Furthermore, the energy-to-solution was reduced by 32.2-fold (from 9944 J to 309 J) and 7.01-fold (from 2163 J to 309 J) when compared to using only the CPU and GPU, respectively.","Using the proposed method on the Alps supercomputer, a 51.6-fold and 6.98-fold speedup was attained when compared to using only the CPU and GPU, respectively, and a high weak scaling efficiency of 94.3% was obtained up to 1,920 compute nodes.","These implementations were realized using directive-based parallel programming models while enabling portability, indicating that directives are highly effective in analyses in heterogeneous computing environments."],"url":"http://arxiv.org/abs/2409.20380v1"}
{"created":"2024-09-30 15:09:42","title":"Word-wise intonation model for cross-language TTS systems","abstract":"In this paper we propose a word-wise intonation model for Russian language and show how it can be generalized for other languages. The proposed model is suitable for automatic data markup and its extended application to text-to-speech systems. It can also be implemented for an intonation contour modeling by using rule-based algorithms or by predicting contours with language models. The key idea is a partial elimination of the variability connected with different placements of a stressed syllable in a word. It is achieved with simultaneous applying of pitch simplification with a dynamic time warping clustering. The proposed model could be used as a tool for intonation research or as a backbone for prosody description in text-to-speech systems. As the advantage of the model, we show its relations with the existing intonation systems as well as the possibility of using language models for prosody prediction. Finally, we demonstrate some practical evidence of the system robustness to parameter variations.","sentences":["In this paper we propose a word-wise intonation model for Russian language and show how it can be generalized for other languages.","The proposed model is suitable for automatic data markup and its extended application to text-to-speech systems.","It can also be implemented for an intonation contour modeling by using rule-based algorithms or by predicting contours with language models.","The key idea is a partial elimination of the variability connected with different placements of a stressed syllable in a word.","It is achieved with simultaneous applying of pitch simplification with a dynamic time warping clustering.","The proposed model could be used as a tool for intonation research or as a backbone for prosody description in text-to-speech systems.","As the advantage of the model, we show its relations with the existing intonation systems as well as the possibility of using language models for prosody prediction.","Finally, we demonstrate some practical evidence of the system robustness to parameter variations."],"url":"http://arxiv.org/abs/2409.20374v1"}
{"created":"2024-09-30 15:07:16","title":"Frequency Adaptive Normalization For Non-stationary Time Series Forecasting","abstract":"Time series forecasting typically needs to address non-stationary data with evolving trend and seasonal patterns. To address the non-stationarity, reversible instance normalization has been recently proposed to alleviate impacts from the trend with certain statistical measures, e.g., mean and variance. Although they demonstrate improved predictive accuracy, they are limited to expressing basic trends and are incapable of handling seasonal patterns. To address this limitation, this paper proposes a new instance normalization solution, called frequency adaptive normalization (FAN), which extends instance normalization in handling both dynamic trend and seasonal patterns. Specifically, we employ the Fourier transform to identify instance-wise predominant frequent components that cover most non-stationary factors. Furthermore, the discrepancy of those frequency components between inputs and outputs is explicitly modeled as a prediction task with a simple MLP model. FAN is a model-agnostic method that can be applied to arbitrary predictive backbones. We instantiate FAN on four widely used forecasting models as the backbone and evaluate their prediction performance improvements on eight benchmark datasets. FAN demonstrates significant performance advancement, achieving 7.76% ~ 37.90% average improvements in MSE.","sentences":["Time series forecasting typically needs to address non-stationary data with evolving trend and seasonal patterns.","To address the non-stationarity, reversible instance normalization has been recently proposed to alleviate impacts from the trend with certain statistical measures, e.g., mean and variance.","Although they demonstrate improved predictive accuracy, they are limited to expressing basic trends and are incapable of handling seasonal patterns.","To address this limitation, this paper proposes a new instance normalization solution, called frequency adaptive normalization (FAN), which extends instance normalization in handling both dynamic trend and seasonal patterns.","Specifically, we employ the Fourier transform to identify instance-wise predominant frequent components that cover most non-stationary factors.","Furthermore, the discrepancy of those frequency components between inputs and outputs is explicitly modeled as a prediction task with a simple MLP model.","FAN is a model-agnostic method that can be applied to arbitrary predictive backbones.","We instantiate FAN on four widely used forecasting models as the backbone and evaluate their prediction performance improvements on eight benchmark datasets.","FAN demonstrates significant performance advancement, achieving 7.76% ~ 37.90% average improvements in MSE."],"url":"http://arxiv.org/abs/2409.20371v1"}
{"created":"2024-09-30 15:06:53","title":"The Perfect Blend: Redefining RLHF with Mixture of Judges","abstract":"Reinforcement learning from human feedback (RLHF) has become the leading approach for fine-tuning large language models (LLM). However, RLHF has limitations in multi-task learning (MTL) due to challenges of reward hacking and extreme multi-objective optimization (i.e., trade-off of multiple and/or sometimes conflicting objectives). Applying RLHF for MTL currently requires careful tuning of the weights for reward model and data combinations. This is often done via human intuition and does not generalize. In this work, we introduce a novel post-training paradigm which we called Constrained Generative Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with cost-efficient constrained policy optimization with stratification, which can identify the perfect blend in RLHF in a principled manner. It shows strong empirical results with theoretical guarantees, does not require extensive hyper-parameter tuning, and is plug-and-play in common post-training pipelines. Together, this can detect and mitigate reward hacking behaviors while reaching a pareto-optimal point across an extremely large number of objectives.   Our empirical evaluations demonstrate that CGPO significantly outperforms standard RLHF algorithms like PPO and DPO across various tasks including general chat, STEM questions, instruction following, and coding. Specifically, CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in Arena-Hard (STEM & reasoning), and consistent gains in other domains like math and coding. Notably, PPO, while commonly used, is prone to severe reward hacking in popular coding benchmarks, which CGPO successfully addresses. This breakthrough in RLHF not only tackles reward hacking and extreme multi-objective optimization challenges but also advances the state-of-the-art in aligning general-purpose LLMs for diverse applications.","sentences":["Reinforcement learning from human feedback (RLHF) has become the leading approach for fine-tuning large language models (LLM).","However, RLHF has limitations in multi-task learning (MTL) due to challenges of reward hacking and extreme multi-objective optimization (i.e., trade-off of multiple and/or sometimes conflicting objectives).","Applying RLHF for MTL currently requires careful tuning of the weights for reward model and data combinations.","This is often done via human intuition and does not generalize.","In this work, we introduce a novel post-training paradigm which we called Constrained Generative Policy Optimization (CGPO).","The core of CGPO is Mixture of Judges (MoJ) with cost-efficient constrained policy optimization with stratification, which can identify the perfect blend in RLHF in a principled manner.","It shows strong empirical results with theoretical guarantees, does not require extensive hyper-parameter tuning, and is plug-and-play in common post-training pipelines.","Together, this can detect and mitigate reward hacking behaviors while reaching a pareto-optimal point across an extremely large number of objectives.   ","Our empirical evaluations demonstrate that CGPO significantly outperforms standard RLHF algorithms like PPO and DPO across various tasks including general chat, STEM questions, instruction following, and coding.","Specifically, CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in Arena-Hard (STEM & reasoning), and consistent gains in other domains like math and coding.","Notably, PPO, while commonly used, is prone to severe reward hacking in popular coding benchmarks, which CGPO successfully addresses.","This breakthrough in RLHF not only tackles reward hacking and extreme multi-objective optimization challenges but also advances the state-of-the-art in aligning general-purpose LLMs for diverse applications."],"url":"http://arxiv.org/abs/2409.20370v1"}
{"created":"2024-09-30 15:03:55","title":"Efficient Driving Behavior Narration and Reasoning on Edge Device Using Large Language Models","abstract":"Deep learning architectures with powerful reasoning capabilities have driven significant advancements in autonomous driving technology. Large language models (LLMs) applied in this field can describe driving scenes and behaviors with a level of accuracy similar to human perception, particularly in visual tasks. Meanwhile, the rapid development of edge computing, with its advantage of proximity to data sources, has made edge devices increasingly important in autonomous driving. Edge devices process data locally, reducing transmission delays and bandwidth usage, and achieving faster response times. In this work, we propose a driving behavior narration and reasoning framework that applies LLMs to edge devices. The framework consists of multiple roadside units, with LLMs deployed on each unit. These roadside units collect road data and communicate via 5G NSR/NR networks. Our experiments show that LLMs deployed on edge devices can achieve satisfactory response speeds. Additionally, we propose a prompt strategy to enhance the narration and reasoning performance of the system. This strategy integrates multi-modal information, including environmental, agent, and motion data. Experiments conducted on the OpenDV-Youtube dataset demonstrate that our approach significantly improves performance across both tasks.","sentences":["Deep learning architectures with powerful reasoning capabilities have driven significant advancements in autonomous driving technology.","Large language models (LLMs) applied in this field can describe driving scenes and behaviors with a level of accuracy similar to human perception, particularly in visual tasks.","Meanwhile, the rapid development of edge computing, with its advantage of proximity to data sources, has made edge devices increasingly important in autonomous driving.","Edge devices process data locally, reducing transmission delays and bandwidth usage, and achieving faster response times.","In this work, we propose a driving behavior narration and reasoning framework that applies LLMs to edge devices.","The framework consists of multiple roadside units, with LLMs deployed on each unit.","These roadside units collect road data and communicate via 5G NSR/NR networks.","Our experiments show that LLMs deployed on edge devices can achieve satisfactory response speeds.","Additionally, we propose a prompt strategy to enhance the narration and reasoning performance of the system.","This strategy integrates multi-modal information, including environmental, agent, and motion data.","Experiments conducted on the OpenDV-Youtube dataset demonstrate that our approach significantly improves performance across both tasks."],"url":"http://arxiv.org/abs/2409.20364v1"}
{"created":"2024-09-30 15:01:02","title":"TwinArray Sort: An Ultrarapid Conditional Non-Comparison Based Sorting Algorithm","abstract":"In computer science, sorting algorithms are crucial for data processing and machine learning. Large datasets and high efficiency requirements provide challenges for comparison-based algorithms like Quicksort and Merge sort, which achieve O(n log n) time complexity. Non-comparison-based algorithms like Spreadsort and Counting Sort have memory consumption issues and a relatively high computational demand, even if they can attain linear time complexity under certain circumstances. We present TwinArray Sort, a novel conditional non-comparison-based sorting algorithm that effectively uses array indices. When it comes to worst-case time and space complexities, TwinArray Sort achieves O(n+k). The approach remains efficient under all settings and works well with datasets with randomly sorted, reverse-sorted, or nearly sorted distributions. TwinArray Sort can handle duplicates and optimize memory efficiently since thanks to its two auxiliary arrays for value storage and frequency counting, as well as a conditional distinct array verifier. TwinArray Sort constantly performs better than conventional algorithms, according to experimental assessments and particularly when sorting unique arrays under all data distribution scenarios. The approach is suitable for massive data processing and machine learning dataset management due to its creative use of dual auxiliary arrays and a conditional distinct array verification, which improves memory use and duplication handling. TwinArray Sort overcomes conventional sorting algorithmic constraints by combining cutting-edge methods with non-comparison-based sorting advantages. Its reliable performance in a range of data distributions makes it an adaptable and effective answer for contemporary computing requirements.","sentences":["In computer science, sorting algorithms are crucial for data processing and machine learning.","Large datasets and high efficiency requirements provide challenges for comparison-based algorithms like Quicksort and Merge sort, which achieve O(n log n) time complexity.","Non-comparison-based algorithms like Spreadsort and Counting Sort have memory consumption issues and a relatively high computational demand, even if they can attain linear time complexity under certain circumstances.","We present TwinArray Sort, a novel conditional non-comparison-based sorting algorithm that effectively uses array indices.","When it comes to worst-case time and space complexities, TwinArray Sort achieves O(n+k).","The approach remains efficient under all settings and works well with datasets with randomly sorted, reverse-sorted, or nearly sorted distributions.","TwinArray Sort can handle duplicates and optimize memory efficiently since thanks to its two auxiliary arrays for value storage and frequency counting, as well as a conditional distinct array verifier.","TwinArray Sort constantly performs better than conventional algorithms, according to experimental assessments and particularly when sorting unique arrays under all data distribution scenarios.","The approach is suitable for massive data processing and machine learning dataset management due to its creative use of dual auxiliary arrays and a conditional distinct array verification, which improves memory use and duplication handling.","TwinArray Sort overcomes conventional sorting algorithmic constraints by combining cutting-edge methods with non-comparison-based sorting advantages.","Its reliable performance in a range of data distributions makes it an adaptable and effective answer for contemporary computing requirements."],"url":"http://arxiv.org/abs/2409.20362v1"}
{"created":"2024-09-30 14:50:13","title":"CableInspect-AD: An Expert-Annotated Anomaly Detection Dataset","abstract":"Machine learning models are increasingly being deployed in real-world contexts. However, systematic studies on their transferability to specific and critical applications are underrepresented in the research literature. An important example is visual anomaly detection (VAD) for robotic power line inspection. While existing VAD methods perform well in controlled environments, real-world scenarios present diverse and unexpected anomalies that current datasets fail to capture. To address this gap, we introduce $\\textit{CableInspect-AD}$, a high-quality, publicly available dataset created and annotated by domain experts from Hydro-Qu\\'ebec, a Canadian public utility. This dataset includes high-resolution images with challenging real-world anomalies, covering defects with varying severity levels. To address the challenges of collecting diverse anomalous and nominal examples for setting a detection threshold, we propose an enhancement to the celebrated PatchCore algorithm. This enhancement enables its use in scenarios with limited labeled data. We also present a comprehensive evaluation protocol based on cross-validation to assess models' performances. We evaluate our $\\textit{Enhanced-PatchCore}$ for few-shot and many-shot detection, and Vision-Language Models for zero-shot detection. While promising, these models struggle to detect all anomalies, highlighting the dataset's value as a challenging benchmark for the broader research community. Project page: https://mila-iqia.github.io/cableinspect-ad/.","sentences":["Machine learning models are increasingly being deployed in real-world contexts.","However, systematic studies on their transferability to specific and critical applications are underrepresented in the research literature.","An important example is visual anomaly detection (VAD) for robotic power line inspection.","While existing VAD methods perform well in controlled environments, real-world scenarios present diverse and unexpected anomalies that current datasets fail to capture.","To address this gap, we introduce $\\textit{CableInspect-AD}$, a high-quality, publicly available dataset created and annotated by domain experts from Hydro-Qu\\'ebec, a Canadian public utility.","This dataset includes high-resolution images with challenging real-world anomalies, covering defects with varying severity levels.","To address the challenges of collecting diverse anomalous and nominal examples for setting a detection threshold, we propose an enhancement to the celebrated PatchCore algorithm.","This enhancement enables its use in scenarios with limited labeled data.","We also present a comprehensive evaluation protocol based on cross-validation to assess models' performances.","We evaluate our $\\textit{Enhanced-PatchCore}$ for few-shot and many-shot detection, and Vision-Language Models for zero-shot detection.","While promising, these models struggle to detect all anomalies, highlighting the dataset's value as a challenging benchmark for the broader research community.","Project page: https://mila-iqia.github.io/cableinspect-ad/."],"url":"http://arxiv.org/abs/2409.20353v1"}
{"created":"2024-09-30 14:31:19","title":"Fine-Tuning Personalization in Federated Learning to Mitigate Adversarial Clients","abstract":"Federated learning (FL) is an appealing paradigm that allows a group of machines (a.k.a. clients) to learn collectively while keeping their data local. However, due to the heterogeneity between the clients' data distributions, the model obtained through the use of FL algorithms may perform poorly on some client's data. Personalization addresses this issue by enabling each client to have a different model tailored to their own data while simultaneously benefiting from the other clients' data. We consider an FL setting where some clients can be adversarial, and we derive conditions under which full collaboration fails. Specifically, we analyze the generalization performance of an interpolated personalized FL framework in the presence of adversarial clients, and we precisely characterize situations when full collaboration performs strictly worse than fine-tuned personalization. Our analysis determines how much we should scale down the level of collaboration, according to data heterogeneity and the tolerable fraction of adversarial clients. We support our findings with empirical results on mean estimation and binary classification problems, considering synthetic and benchmark image classification datasets.","sentences":["Federated learning (FL) is an appealing paradigm that allows a group of machines (a.k.a. clients) to learn collectively while keeping their data local.","However, due to the heterogeneity between the clients' data distributions, the model obtained through the use of FL algorithms may perform poorly on some client's data.","Personalization addresses this issue by enabling each client to have a different model tailored to their own data while simultaneously benefiting from the other clients' data.","We consider an FL setting where some clients can be adversarial, and we derive conditions under which full collaboration fails.","Specifically, we analyze the generalization performance of an interpolated personalized FL framework in the presence of adversarial clients, and we precisely characterize situations when full collaboration performs strictly worse than fine-tuned personalization.","Our analysis determines how much we should scale down the level of collaboration, according to data heterogeneity and the tolerable fraction of adversarial clients.","We support our findings with empirical results on mean estimation and binary classification problems, considering synthetic and benchmark image classification datasets."],"url":"http://arxiv.org/abs/2409.20329v1"}
{"created":"2024-09-30 14:15:53","title":"A faster algorithm for the $k$-forest problem: breaking the $O_k(n^{3/2})$ complexity barrier","abstract":"The $k$-forest problem asks to find $k$ forests in a graph $G$ maximizing the number of edges in their union. We show how to solve this problem in $O(k^3 \\min\\{kn, m\\} \\log^2 n + k \\cdot{\\rm MAXFLOW}(m, m) \\log n)$ time, breaking the $O_k(n^{3/2})$ complexity barrier of previously known approaches. Our algorithm relies on three subroutines: the directed $k$-forest problem with bounded indegree condition, the $k$-pseudoforest problem, and the top clump computation.","sentences":["The $k$-forest problem asks to find $k$ forests in a graph $G$ maximizing the number of edges in their union.","We show how to solve this problem in $O(k^3 \\min\\{kn, m\\} \\log^2 n + k \\cdot{\\rm MAXFLOW}(m, m) \\log","n)$ time, breaking the $O_k(n^{3/2})$ complexity barrier of previously known approaches.","Our algorithm relies on three subroutines: the directed $k$-forest problem with bounded indegree condition, the $k$-pseudoforest problem, and the top clump computation."],"url":"http://arxiv.org/abs/2409.20314v1"}
{"created":"2024-09-30 13:55:42","title":"PersonalLLM: Tailoring LLMs to Individual Preferences","abstract":"As LLMs become capable of complex tasks, there is growing potential for personalized interactions tailored to the subtle and idiosyncratic preferences of the user. We present a public benchmark, PersonalLLM, focusing on adapting LLMs to provide maximal benefits for a particular user. Departing from existing alignment benchmarks that implicitly assume uniform preferences, we curate open-ended prompts paired with many high-quality answers over which users would be expected to display heterogeneous latent preferences. Instead of persona-prompting LLMs based on high-level attributes (e.g., user's race or response length), which yields homogeneous preferences relative to humans, we develop a method that can simulate a large user base with diverse preferences from a set of pre-trained reward models. Our dataset and generated personalities offer an innovative testbed for developing personalization algorithms that grapple with continual data sparsity--few relevant feedback from the particular user--by leveraging historical data from other (similar) users. We explore basic in-context learning and meta-learning baselines to illustrate the utility of PersonalLLM and highlight the need for future methodological development. Our dataset is available at https://huggingface.co/datasets/namkoong-lab/PersonalLLM","sentences":["As LLMs become capable of complex tasks, there is growing potential for personalized interactions tailored to the subtle and idiosyncratic preferences of the user.","We present a public benchmark, PersonalLLM, focusing on adapting LLMs to provide maximal benefits for a particular user.","Departing from existing alignment benchmarks that implicitly assume uniform preferences, we curate open-ended prompts paired with many high-quality answers over which users would be expected to display heterogeneous latent preferences.","Instead of persona-prompting LLMs based on high-level attributes (e.g., user's race or response length), which yields homogeneous preferences relative to humans, we develop a method that can simulate a large user base with diverse preferences from a set of pre-trained reward models.","Our dataset and generated personalities offer an innovative testbed for developing personalization algorithms that grapple with continual data sparsity--few relevant feedback from the particular user--by leveraging historical data from other (similar) users.","We explore basic in-context learning and meta-learning baselines to illustrate the utility of PersonalLLM and highlight the need for future methodological development.","Our dataset is available at https://huggingface.co/datasets/namkoong-lab/PersonalLLM"],"url":"http://arxiv.org/abs/2409.20296v1"}
{"created":"2024-09-30 13:53:01","title":"Automating MedSAM by Learning Prompts with Weak Few-Shot Supervision","abstract":"Foundation models such as the recently introduced Segment Anything Model (SAM) have achieved remarkable results in image segmentation tasks. However, these models typically require user interaction through handcrafted prompts such as bounding boxes, which limits their deployment to downstream tasks. Adapting these models to a specific task with fully labeled data also demands expensive prior user interaction to obtain ground-truth annotations. This work proposes to replace conditioning on input prompts with a lightweight module that directly learns a prompt embedding from the image embedding, both of which are subsequently used by the foundation model to output a segmentation mask. Our foundation models with learnable prompts can automatically segment any specific region by 1) modifying the input through a prompt embedding predicted by a simple module, and 2) using weak labels (tight bounding boxes) and few-shot supervision (10 samples). Our approach is validated on MedSAM, a version of SAM fine-tuned for medical images, with results on three medical datasets in MR and ultrasound imaging. Our code is available on https://github.com/Minimel/MedSAMWeakFewShotPromptAutomation.","sentences":["Foundation models such as the recently introduced Segment Anything Model (SAM) have achieved remarkable results in image segmentation tasks.","However, these models typically require user interaction through handcrafted prompts such as bounding boxes, which limits their deployment to downstream tasks.","Adapting these models to a specific task with fully labeled data also demands expensive prior user interaction to obtain ground-truth annotations.","This work proposes to replace conditioning on input prompts with a lightweight module that directly learns a prompt embedding from the image embedding, both of which are subsequently used by the foundation model to output a segmentation mask.","Our foundation models with learnable prompts can automatically segment any specific region by 1) modifying the input through a prompt embedding predicted by a simple module, and 2) using weak labels (tight bounding boxes) and few-shot supervision (10 samples).","Our approach is validated on MedSAM, a version of SAM fine-tuned for medical images, with results on three medical datasets in MR and ultrasound imaging.","Our code is available on https://github.com/Minimel/MedSAMWeakFewShotPromptAutomation."],"url":"http://arxiv.org/abs/2409.20293v1"}
{"created":"2024-09-30 13:52:05","title":"RL-GSBridge: 3D Gaussian Splatting Based Real2Sim2Real Method for Robotic Manipulation Learning","abstract":"Sim-to-Real refers to the process of transferring policies learned in simulation to the real world, which is crucial for achieving practical robotics applications. However, recent Sim2real methods either rely on a large amount of augmented data or large learning models, which is inefficient for specific tasks. In recent years, radiance field-based reconstruction methods, especially the emergence of 3D Gaussian Splatting, making it possible to reproduce realistic real-world scenarios. To this end, we propose a novel real-to-sim-to-real reinforcement learning framework, RL-GSBridge, which introduces a mesh-based 3D Gaussian Splatting method to realize zero-shot sim-to-real transfer for vision-based deep reinforcement learning. We improve the mesh-based 3D GS modeling method by using soft binding constraints, enhancing the rendering quality of mesh models. We then employ a GS editing approach to synchronize rendering with the physics simulator, reflecting the interactions of the physical robot more accurately. Through a series of sim-to-real robotic arm experiments, including grasping and pick-and-place tasks, we demonstrate that RL-GSBridge maintains a satisfactory success rate in real-world task completion during sim-to-real transfer. Furthermore, a series of rendering metrics and visualization results indicate that our proposed mesh-based 3D Gaussian reduces artifacts in unstructured objects, demonstrating more realistic rendering performance.","sentences":["Sim-to-Real refers to the process of transferring policies learned in simulation to the real world, which is crucial for achieving practical robotics applications.","However, recent Sim2real methods either rely on a large amount of augmented data or large learning models, which is inefficient for specific tasks.","In recent years, radiance field-based reconstruction methods, especially the emergence of 3D Gaussian Splatting, making it possible to reproduce realistic real-world scenarios.","To this end, we propose a novel real-to-sim-to-real reinforcement learning framework, RL-GSBridge, which introduces a mesh-based 3D Gaussian Splatting method to realize zero-shot sim-to-real transfer for vision-based deep reinforcement learning.","We improve the mesh-based 3D GS modeling method by using soft binding constraints, enhancing the rendering quality of mesh models.","We then employ a GS editing approach to synchronize rendering with the physics simulator, reflecting the interactions of the physical robot more accurately.","Through a series of sim-to-real robotic arm experiments, including grasping and pick-and-place tasks, we demonstrate that RL-GSBridge maintains a satisfactory success rate in real-world task completion during sim-to-real transfer.","Furthermore, a series of rendering metrics and visualization results indicate that our proposed mesh-based 3D Gaussian reduces artifacts in unstructured objects, demonstrating more realistic rendering performance."],"url":"http://arxiv.org/abs/2409.20291v1"}
{"created":"2024-09-30 13:45:50","title":"Distributed NeRF Learning for Collaborative Multi-Robot Perception","abstract":"Effective environment perception is crucial for enabling downstream robotic applications. Individual robotic agents often face occlusion and limited visibility issues, whereas multi-agent systems can offer a more comprehensive mapping of the environment, quicker coverage, and increased fault tolerance. In this paper, we propose a collaborative multi-agent perception system where agents collectively learn a neural radiance field (NeRF) from posed RGB images to represent a scene. Each agent processes its local sensory data and shares only its learned NeRF model with other agents, reducing communication overhead. Given NeRF's low memory footprint, this approach is well-suited for robotic systems with limited bandwidth, where transmitting all raw data is impractical. Our distributed learning framework ensures consistency across agents' local NeRF models, enabling convergence to a unified scene representation. We show the effectiveness of our method through an extensive set of experiments on datasets containing challenging real-world scenes, achieving performance comparable to centralized mapping of the environment where data is sent to a central server for processing. Additionally, we find that multi-agent learning provides regularization benefits, improving geometric consistency in scenarios with sparse input views. We show that in such scenarios, multi-agent mapping can even outperform centralized training.","sentences":["Effective environment perception is crucial for enabling downstream robotic applications.","Individual robotic agents often face occlusion and limited visibility issues, whereas multi-agent systems can offer a more comprehensive mapping of the environment, quicker coverage, and increased fault tolerance.","In this paper, we propose a collaborative multi-agent perception system where agents collectively learn a neural radiance field (NeRF) from posed RGB images to represent a scene.","Each agent processes its local sensory data and shares only its learned NeRF model with other agents, reducing communication overhead.","Given NeRF's low memory footprint, this approach is well-suited for robotic systems with limited bandwidth, where transmitting all raw data is impractical.","Our distributed learning framework ensures consistency across agents' local NeRF models, enabling convergence to a unified scene representation.","We show the effectiveness of our method through an extensive set of experiments on datasets containing challenging real-world scenes, achieving performance comparable to centralized mapping of the environment where data is sent to a central server for processing.","Additionally, we find that multi-agent learning provides regularization benefits, improving geometric consistency in scenarios with sparse input views.","We show that in such scenarios, multi-agent mapping can even outperform centralized training."],"url":"http://arxiv.org/abs/2409.20289v1"}
{"created":"2024-09-30 13:44:00","title":"LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models","abstract":"Large language models (LLMs) have made significant progress in natural language processing tasks and demonstrate considerable potential in the legal domain. However, legal applications demand high standards of accuracy, reliability, and fairness. Applying existing LLMs to legal systems without careful evaluation of their potential and limitations could pose significant risks in legal practice. To this end, we introduce a standardized comprehensive Chinese legal benchmark LexEval. This benchmark is notable in the following three aspects: (1) Ability Modeling: We propose a new taxonomy of legal cognitive abilities to organize different tasks. (2) Scale: To our knowledge, LexEval is currently the largest Chinese legal evaluation dataset, comprising 23 tasks and 14,150 questions. (3) Data: we utilize formatted existing datasets, exam datasets and newly annotated datasets by legal experts to comprehensively evaluate the various capabilities of LLMs. LexEval not only focuses on the ability of LLMs to apply fundamental legal knowledge but also dedicates efforts to examining the ethical issues involved in their application. We evaluated 38 open-source and commercial LLMs and obtained some interesting findings. The experiments and findings offer valuable insights into the challenges and potential solutions for developing Chinese legal systems and LLM evaluation pipelines. The LexEval dataset and leaderboard are publicly available at \\url{https://github.com/CSHaitao/LexEval} and will be continuously updated.","sentences":["Large language models (LLMs) have made significant progress in natural language processing tasks and demonstrate considerable potential in the legal domain.","However, legal applications demand high standards of accuracy, reliability, and fairness.","Applying existing LLMs to legal systems without careful evaluation of their potential and limitations could pose significant risks in legal practice.","To this end, we introduce a standardized comprehensive Chinese legal benchmark LexEval.","This benchmark is notable in the following three aspects: (1) Ability Modeling: We propose a new taxonomy of legal cognitive abilities to organize different tasks.","(2) Scale: To our knowledge, LexEval is currently the largest Chinese legal evaluation dataset, comprising 23 tasks and 14,150 questions.","(3) Data: we utilize formatted existing datasets, exam datasets and newly annotated datasets by legal experts to comprehensively evaluate the various capabilities of LLMs.","LexEval not only focuses on the ability of LLMs to apply fundamental legal knowledge but also dedicates efforts to examining the ethical issues involved in their application.","We evaluated 38 open-source and commercial LLMs and obtained some interesting findings.","The experiments and findings offer valuable insights into the challenges and potential solutions for developing Chinese legal systems and LLM evaluation pipelines.","The LexEval dataset and leaderboard are publicly available at \\url{https://github.com/CSHaitao/LexEval} and will be continuously updated."],"url":"http://arxiv.org/abs/2409.20288v1"}
{"created":"2024-09-30 13:42:54","title":"Self-Assessment of Evidential Grid Map Fusion for Robust Motion Planning","abstract":"Conflicting sensor measurements pose a huge problem for the environment representation of an autonomous robot. Therefore, in this paper, we address the self-assessment of an evidential grid map in which data from conflicting LiDAR sensor measurements are fused, followed by methods for robust motion planning under these circumstances. First, conflicting measurements aggregated in Subjective-Logic-based evidential grid maps are classified. Then, a self-assessment framework evaluates these conflicts and estimates their severity for the overall system by calculating a degradation score. This enables the detection of calibration errors and insufficient sensor setups. In contrast to other motion planning approaches, the information gained from the evidential grid maps is further used inside our proposed path-planning algorithm. Here, the impact of conflicting measurements on the current motion plan is evaluated, and a robust and curious path-planning strategy is derived to plan paths under the influence of conflicting data. This ensures that the system integrity is maintained in severely degraded environment representations which can prevent the unnecessary abortion of planning tasks.","sentences":["Conflicting sensor measurements pose a huge problem for the environment representation of an autonomous robot.","Therefore, in this paper, we address the self-assessment of an evidential grid map in which data from conflicting LiDAR sensor measurements are fused, followed by methods for robust motion planning under these circumstances.","First, conflicting measurements aggregated in Subjective-Logic-based evidential grid maps are classified.","Then, a self-assessment framework evaluates these conflicts and estimates their severity for the overall system by calculating a degradation score.","This enables the detection of calibration errors and insufficient sensor setups.","In contrast to other motion planning approaches, the information gained from the evidential grid maps is further used inside our proposed path-planning algorithm.","Here, the impact of conflicting measurements on the current motion plan is evaluated, and a robust and curious path-planning strategy is derived to plan paths under the influence of conflicting data.","This ensures that the system integrity is maintained in severely degraded environment representations which can prevent the unnecessary abortion of planning tasks."],"url":"http://arxiv.org/abs/2409.20286v1"}
{"created":"2024-09-30 13:30:42","title":"Parameterised Approximation and Complexity of Minimum Flow Decompositions","abstract":"Minimum flow decomposition (MFD) is the strongly NP-hard problem of finding a smallest set of integer weighted paths in a graph $G$ whose weighted sum is equal to a given flow $f$ on $G$. Despite its many practical applications, we lack an understanding of graph structures that make MFD easy or hard. In particular, it is not known whether a good approximation algorithm exists when the weights are positive.   On the positive side, the main result of this paper is that MFD can be approximated within a factor $O(\\log\\Vert f\\Vert)$ (where $\\Vert f\\Vert$ is the largest flow weight of all edges) times the ratio between the parallel-width of $G$ (introduced by Deligkas and Meir, MFCS 2018) and the width of $G$ (minimum number of paths to cover all edges). In particular, when the MFD size is at least the parallel-width of $G$, this becomes the first parameterised $O(\\log\\Vert f\\Vert)$-factor approximation algorithm for MFD over positive integers. We also show that there exist instances where the ratio between the parallel-width of $G$ and the MFD size is arbitrarily large, thus narrowing down the class of graphs whose approximation is still open. We achieve these results by introducing a new notion of flow-width of $(G,f)$, which unifies both the width and the parallel-width and may be of independent interest.   On the negative side, we show that small-width graphs do not make MFD easy. This question was previously open, because width-1 graphs (i.e. paths) are trivially solvable, and the existing NP-hardness proofs use graphs of unbounded width. We close this problem by showing the tight results that MFD remains strongly NP-hard on graphs of width 3, and NP-hard on graphs of width 2 (and thus also parallel-width 2). Moreover, on width-2 graphs (and more generally, on constant parallel-width graphs), MFD is solvable in quasi-polynomial time on unary-coded flows.","sentences":["Minimum flow decomposition (MFD) is the strongly NP-hard problem of finding a smallest set of integer weighted paths in a graph $G$ whose weighted sum is equal to a given flow $f$ on $G$. Despite its many practical applications, we lack an understanding of graph structures that make MFD easy or hard.","In particular, it is not known whether a good approximation algorithm exists when the weights are positive.   ","On the positive side, the main result of this paper is that MFD can be approximated within a factor $O(\\log\\Vert f\\Vert)$ (where $\\Vert f\\Vert$ is the largest flow weight of all edges) times the ratio between the parallel-width of $G$ (introduced by Deligkas and Meir, MFCS 2018) and the width of $G$ (minimum number of paths to cover all edges).","In particular, when the MFD size is at least the parallel-width of $G$, this becomes the first parameterised $O(\\log\\Vert f\\Vert)$-factor approximation algorithm for MFD over positive integers.","We also show that there exist instances where the ratio between the parallel-width of $G$ and the MFD size is arbitrarily large, thus narrowing down the class of graphs whose approximation is still open.","We achieve these results by introducing a new notion of flow-width of $(G,f)$, which unifies both the width and the parallel-width and may be of independent interest.   ","On the negative side, we show that small-width graphs do not make MFD easy.","This question was previously open, because width-1 graphs (i.e. paths) are trivially solvable, and the existing NP-hardness proofs use graphs of unbounded width.","We close this problem by showing the tight results that MFD remains strongly NP-hard on graphs of width 3, and NP-hard on graphs of width 2 (and thus also parallel-width 2).","Moreover, on width-2 graphs (and more generally, on constant parallel-width graphs), MFD is solvable in quasi-polynomial time on unary-coded flows."],"url":"http://arxiv.org/abs/2409.20278v1"}
{"created":"2024-09-30 12:43:20","title":"Medical Image Segmentation with SAM-generated Annotations","abstract":"The field of medical image segmentation is hindered by the scarcity of large, publicly available annotated datasets. Not all datasets are made public for privacy reasons, and creating annotations for a large dataset is time-consuming and expensive, as it requires specialized expertise to accurately identify regions of interest (ROIs) within the images. To address these challenges, we evaluate the performance of the Segment Anything Model (SAM) as an annotation tool for medical data by using it to produce so-called \"pseudo labels\" on the Medical Segmentation Decathlon (MSD) computed tomography (CT) tasks. The pseudo labels are then used in place of ground truth labels to train a UNet model in a weakly-supervised manner. We experiment with different prompt types on SAM and find that the bounding box prompt is a simple yet effective method for generating pseudo labels. This method allows us to develop a weakly-supervised model that performs comparably to a fully supervised model.","sentences":["The field of medical image segmentation is hindered by the scarcity of large, publicly available annotated datasets.","Not all datasets are made public for privacy reasons, and creating annotations for a large dataset is time-consuming and expensive, as it requires specialized expertise to accurately identify regions of interest (ROIs) within the images.","To address these challenges, we evaluate the performance of the Segment Anything Model (SAM) as an annotation tool for medical data by using it to produce so-called \"pseudo labels\" on the Medical Segmentation Decathlon (MSD) computed tomography (CT) tasks.","The pseudo labels are then used in place of ground truth labels to train a UNet model in a weakly-supervised manner.","We experiment with different prompt types on SAM and find that the bounding box prompt is a simple yet effective method for generating pseudo labels.","This method allows us to develop a weakly-supervised model that performs comparably to a fully supervised model."],"url":"http://arxiv.org/abs/2409.20253v1"}
{"created":"2024-09-30 12:37:07","title":"Feature Extractor or Decision Maker: Rethinking the Role of Visual Encoders in Visuomotor Policies","abstract":"An end-to-end (E2E) visuomotor policy is typically treated as a unified whole, but recent approaches using out-of-domain (OOD) data to pretrain the visual encoder have cleanly separated the visual encoder from the network, with the remainder referred to as the policy. We propose Visual Alignment Testing, an experimental framework designed to evaluate the validity of this functional separation. Our results indicate that in E2E-trained models, visual encoders actively contribute to decision-making resulting from motor data supervision, contradicting the assumed functional separation. In contrast, OOD-pretrained models, where encoders lack this capability, experience an average performance drop of 42% in our benchmark results, compared to the state-of-the-art performance achieved by E2E policies. We believe this initial exploration of visual encoders' role can provide a first step towards guiding future pretraining methods to address their decision-making ability, such as developing task-conditioned or context-aware encoders.","sentences":["An end-to-end (E2E) visuomotor policy is typically treated as a unified whole, but recent approaches using out-of-domain (OOD) data to pretrain the visual encoder have cleanly separated the visual encoder from the network, with the remainder referred to as the policy.","We propose Visual Alignment Testing, an experimental framework designed to evaluate the validity of this functional separation.","Our results indicate that in E2E-trained models, visual encoders actively contribute to decision-making resulting from motor data supervision, contradicting the assumed functional separation.","In contrast, OOD-pretrained models, where encoders lack this capability, experience an average performance drop of 42% in our benchmark results, compared to the state-of-the-art performance achieved by E2E policies.","We believe this initial exploration of visual encoders' role can provide a first step towards guiding future pretraining methods to address their decision-making ability, such as developing task-conditioned or context-aware encoders."],"url":"http://arxiv.org/abs/2409.20248v1"}
{"created":"2024-09-30 12:36:27","title":"Resource Allocation for Stable LLM Training in Mobile Edge Computing","abstract":"As mobile devices increasingly become focal points for advanced applications, edge computing presents a viable solution to their inherent computational limitations, particularly in deploying large language models (LLMs). However, despite the advancements in edge computing, significant challenges remain in efficient training and deploying LLMs due to the computational demands and data privacy concerns associated with these models. This paper explores a collaborative training framework that integrates mobile users with edge servers to optimize resource allocation, thereby enhancing both performance and efficiency. Our approach leverages parameter-efficient fine-tuning (PEFT) methods, allowing mobile users to adjust the initial layers of the LLM while edge servers handle the more demanding latter layers. Specifically, we formulate a multi-objective optimization problem to minimize the total energy consumption and delay during training. We also address the common issue of instability in model performance by incorporating stability enhancements into our objective function. Through novel fractional programming technique, we achieve a stationary point for the formulated problem. Simulations demonstrate that our method reduces the energy consumption as well as the latency, and increases the reliability of LLMs across various mobile settings.","sentences":["As mobile devices increasingly become focal points for advanced applications, edge computing presents a viable solution to their inherent computational limitations, particularly in deploying large language models (LLMs).","However, despite the advancements in edge computing, significant challenges remain in efficient training and deploying LLMs due to the computational demands and data privacy concerns associated with these models.","This paper explores a collaborative training framework that integrates mobile users with edge servers to optimize resource allocation, thereby enhancing both performance and efficiency.","Our approach leverages parameter-efficient fine-tuning (PEFT) methods, allowing mobile users to adjust the initial layers of the LLM while edge servers handle the more demanding latter layers.","Specifically, we formulate a multi-objective optimization problem to minimize the total energy consumption and delay during training.","We also address the common issue of instability in model performance by incorporating stability enhancements into our objective function.","Through novel fractional programming technique, we achieve a stationary point for the formulated problem.","Simulations demonstrate that our method reduces the energy consumption as well as the latency, and increases the reliability of LLMs across various mobile settings."],"url":"http://arxiv.org/abs/2409.20247v1"}
{"created":"2024-09-30 12:36:25","title":"Analysing Zero-Shot Readability-Controlled Sentence Simplification","abstract":"Readability-controlled text simplification (RCTS) rewrites texts to lower readability levels while preserving their meaning. RCTS models often depend on parallel corpora with readability annotations on both source and target sides. Such datasets are scarce and difficult to curate, especially at the sentence level. To reduce reliance on parallel data, we explore using instruction-tuned large language models for zero-shot RCTS. Through automatic and manual evaluations, we examine: (1) how different types of contextual information affect a model's ability to generate sentences with the desired readability, and (2) the trade-off between achieving target readability and preserving meaning. Results show that all tested models struggle to simplify sentences (especially to the lowest levels) due to models' limitations and characteristics of the source sentences that impede adequate rewriting. Our experiments also highlight the need for better automatic evaluation metrics tailored to RCTS, as standard ones often misinterpret common simplification operations, and inaccurately assess readability and meaning preservation.","sentences":["Readability-controlled text simplification (RCTS) rewrites texts to lower readability levels while preserving their meaning.","RCTS models often depend on parallel corpora with readability annotations on both source and target sides.","Such datasets are scarce and difficult to curate, especially at the sentence level.","To reduce reliance on parallel data, we explore using instruction-tuned large language models for zero-shot RCTS.","Through automatic and manual evaluations, we examine: (1) how different types of contextual information affect a model's ability to generate sentences with the desired readability, and (2) the trade-off between achieving target readability and preserving meaning.","Results show that all tested models struggle to simplify sentences (especially to the lowest levels) due to models' limitations and characteristics of the source sentences that impede adequate rewriting.","Our experiments also highlight the need for better automatic evaluation metrics tailored to RCTS, as standard ones often misinterpret common simplification operations, and inaccurately assess readability and meaning preservation."],"url":"http://arxiv.org/abs/2409.20246v1"}
{"created":"2024-09-30 12:28:10","title":"PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling","abstract":"As awareness of mental health issues grows, online counseling support services are becoming increasingly prevalent worldwide. Detecting whether users express suicidal ideation in text-based counseling services is crucial for identifying and prioritizing at-risk individuals. However, the lack of domain-specific systems to facilitate fine-grained suicide detection and corresponding risk assessment in online counseling poses a significant challenge for automated crisis intervention aimed at suicide prevention. In this paper, we propose PsyGUARD, an automated system for detecting suicide ideation and assessing risk in psychological counseling. To achieve this, we first develop a detailed taxonomy for detecting suicide ideation based on foundational theories. We then curate a large-scale, high-quality dataset called PsySUICIDE for suicide detection. To evaluate the capabilities of automated systems in fine-grained suicide detection, we establish a range of baselines. Subsequently, to assist automated services in providing safe, helpful, and tailored responses for further assessment, we propose to build a suite of risk assessment frameworks. Our study not only provides an insightful analysis of the effectiveness of automated risk assessment systems based on fine-grained suicide detection but also highlights their potential to improve mental health services on online counseling platforms. Code, data, and models are available at https://github.com/qiuhuachuan/PsyGUARD.","sentences":["As awareness of mental health issues grows, online counseling support services are becoming increasingly prevalent worldwide.","Detecting whether users express suicidal ideation in text-based counseling services is crucial for identifying and prioritizing at-risk individuals.","However, the lack of domain-specific systems to facilitate fine-grained suicide detection and corresponding risk assessment in online counseling poses a significant challenge for automated crisis intervention aimed at suicide prevention.","In this paper, we propose PsyGUARD, an automated system for detecting suicide ideation and assessing risk in psychological counseling.","To achieve this, we first develop a detailed taxonomy for detecting suicide ideation based on foundational theories.","We then curate a large-scale, high-quality dataset called PsySUICIDE for suicide detection.","To evaluate the capabilities of automated systems in fine-grained suicide detection, we establish a range of baselines.","Subsequently, to assist automated services in providing safe, helpful, and tailored responses for further assessment, we propose to build a suite of risk assessment frameworks.","Our study not only provides an insightful analysis of the effectiveness of automated risk assessment systems based on fine-grained suicide detection but also highlights their potential to improve mental health services on online counseling platforms.","Code, data, and models are available at https://github.com/qiuhuachuan/PsyGUARD."],"url":"http://arxiv.org/abs/2409.20243v1"}
{"created":"2024-09-30 12:20:07","title":"Classroom-Inspired Multi-Mentor Distillation with Adaptive Learning Strategies","abstract":"We propose ClassroomKD, a novel multi-mentor knowledge distillation framework inspired by classroom environments to enhance knowledge transfer between student and multiple mentors. Unlike traditional methods that rely on fixed mentor-student relationships, our framework dynamically selects and adapts the teaching strategies of diverse mentors based on their effectiveness for each data sample. ClassroomKD comprises two main modules: the Knowledge Filtering (KF) Module and the Mentoring Module. The KF Module dynamically ranks mentors based on their performance for each input, activating only high-quality mentors to minimize error accumulation and prevent information loss. The Mentoring Module adjusts the distillation strategy by tuning each mentor's influence according to the performance gap between the student and mentors, effectively modulating the learning pace. Extensive experiments on image classification (CIFAR-100 and ImageNet) and 2D human pose estimation (COCO Keypoints and MPII Human Pose) demonstrate that ClassroomKD significantly outperforms existing knowledge distillation methods. Our results highlight that a dynamic and adaptive approach to mentor selection and guidance leads to more effective knowledge transfer, paving the way for enhanced model performance through distillation.","sentences":["We propose ClassroomKD, a novel multi-mentor knowledge distillation framework inspired by classroom environments to enhance knowledge transfer between student and multiple mentors.","Unlike traditional methods that rely on fixed mentor-student relationships, our framework dynamically selects and adapts the teaching strategies of diverse mentors based on their effectiveness for each data sample.","ClassroomKD comprises two main modules: the Knowledge Filtering (KF) Module and the Mentoring Module.","The KF Module dynamically ranks mentors based on their performance for each input, activating only high-quality mentors to minimize error accumulation and prevent information loss.","The Mentoring Module adjusts the distillation strategy by tuning each mentor's influence according to the performance gap between the student and mentors, effectively modulating the learning pace.","Extensive experiments on image classification (CIFAR-100 and ImageNet) and 2D human pose estimation (COCO Keypoints and MPII Human Pose) demonstrate that ClassroomKD significantly outperforms existing knowledge distillation methods.","Our results highlight that a dynamic and adaptive approach to mentor selection and guidance leads to more effective knowledge transfer, paving the way for enhanced model performance through distillation."],"url":"http://arxiv.org/abs/2409.20237v1"}
{"created":"2024-09-30 12:02:38","title":"Trapped in Transformative Agreements? A Multifaceted Analysis of >1,000 Contracts","abstract":"Transformative agreements between academic publishers and research institutions are ubiquitous. The 'Efficiency and Standards for Article Charges' (ESAC) Initiative lists more than 1,000 contracts in its database. We make use of this unique dataset by web-scraping the details of every contract to substantially expand the overview spreadsheet provided by the ESAC Initiative. Based on that hitherto unused data source, we combine qualitative and quantitative methods to conduct an in-depth analysis of the contract characteristics and the TA landscape. Our analysis demonstrates that research institutions seem to be 'trapped' in transformative agreements. Instead of being a bridge towards a fully Open Access world, academia is stuck in the hybrid system. This endows the legacy (non-Open Access) publishing houses with substantial market power. It raises entry barriers, lowers competition, and increases costs for libraries and universities.","sentences":["Transformative agreements between academic publishers and research institutions are ubiquitous.","The 'Efficiency and Standards for Article Charges' (ESAC) Initiative lists more than 1,000 contracts in its database.","We make use of this unique dataset by web-scraping the details of every contract to substantially expand the overview spreadsheet provided by the ESAC Initiative.","Based on that hitherto unused data source, we combine qualitative and quantitative methods to conduct an in-depth analysis of the contract characteristics and the TA landscape.","Our analysis demonstrates that research institutions seem to be 'trapped' in transformative agreements.","Instead of being a bridge towards a fully Open Access world, academia is stuck in the hybrid system.","This endows the legacy (non-Open Access) publishing houses with substantial market power.","It raises entry barriers, lowers competition, and increases costs for libraries and universities."],"url":"http://arxiv.org/abs/2409.20224v1"}
{"created":"2024-09-30 11:56:22","title":"Co-Movement and Trust Development in Human-Robot Teams","abstract":"For humans and robots to form an effective human-robot team (HRT) there must be sufficient trust between team members throughout a mission. We analyze data from an HRT experiment focused on trust dynamics in teams of one human and two robots, where trust was manipulated by robots becoming temporarily unresponsive. Whole-body movement tracking was achieved using ultrasound beacons, alongside communications and performance logs from a human-robot interface. We find evidence that synchronization between time series of human-robot movement, within a certain spatial proximity, is correlated with changes in self-reported trust. This suggests that the interplay of proxemics and kinesics, i.e. moving together through space, where implicit communication via coordination can occur, could play a role in building and maintaining trust in human-robot teams. Thus, quantitative indicators of coordination dynamics between team members could be used to predict trust over time and also provide early warning signals of the need for timely trust repair if trust is damaged. Hence, we aim to develop the metrology of trust in mobile human-robot teams.","sentences":["For humans and robots to form an effective human-robot team (HRT) there must be sufficient trust between team members throughout a mission.","We analyze data from an HRT experiment focused on trust dynamics in teams of one human and two robots, where trust was manipulated by robots becoming temporarily unresponsive.","Whole-body movement tracking was achieved using ultrasound beacons, alongside communications and performance logs from a human-robot interface.","We find evidence that synchronization between time series of human-robot movement, within a certain spatial proximity, is correlated with changes in self-reported trust.","This suggests that the interplay of proxemics and kinesics, i.e. moving together through space, where implicit communication via coordination can occur, could play a role in building and maintaining trust in human-robot teams.","Thus, quantitative indicators of coordination dynamics between team members could be used to predict trust over time and also provide early warning signals of the need for timely trust repair if trust is damaged.","Hence, we aim to develop the metrology of trust in mobile human-robot teams."],"url":"http://arxiv.org/abs/2409.20218v1"}
{"created":"2024-09-30 11:47:19","title":"Graph matching based on similarities in structure and attributes","abstract":"Finding vertex-to-vertex correspondences in real-world graphs is a challenging task with applications in a wide variety of domains. Structural matching based on graphs connectivities has attracted considerable attention, while the integration of all the other information stemming from vertices and edges attributes has been mostly left aside. Here we present the Graph Attributes and Structure Matching (GASM) algorithm, which provides high-quality solutions by integrating all the available information in a unified framework. Parameters quantifying the reliability of the attributes can tune how much the solutions should rely on the structure or on the attributes. We further show that even without attributes GASM consistently finds as-good-as or better solutions than state-of-the-art algorithms, with similar processing times.","sentences":["Finding vertex-to-vertex correspondences in real-world graphs is a challenging task with applications in a wide variety of domains.","Structural matching based on graphs connectivities has attracted considerable attention, while the integration of all the other information stemming from vertices and edges attributes has been mostly left aside.","Here we present the Graph Attributes and Structure Matching (GASM) algorithm, which provides high-quality solutions by integrating all the available information in a unified framework.","Parameters quantifying the reliability of the attributes can tune how much the solutions should rely on the structure or on the attributes.","We further show that even without attributes GASM consistently finds as-good-as or better solutions than state-of-the-art algorithms, with similar processing times."],"url":"http://arxiv.org/abs/2409.20212v1"}
{"created":"2024-09-30 11:43:26","title":"Constraining Anomaly Detection with Anomaly-Free Regions","abstract":"We propose the novel concept of anomaly-free regions (AFR) to improve anomaly detection. An AFR is a region in the data space for which it is known that there are no anomalies inside it, e.g., via domain knowledge. This region can contain any number of normal data points and can be anywhere in the data space. AFRs have the key advantage that they constrain the estimation of the distribution of non-anomalies: The estimated probability mass inside the AFR must be consistent with the number of normal data points inside the AFR. Based on this insight, we provide a solid theoretical foundation and a reference implementation of anomaly detection using AFRs. Our empirical results confirm that anomaly detection constrained via AFRs improves upon unconstrained anomaly detection. Specifically, we show that, when equipped with an estimated AFR, an efficient algorithm based on random guessing becomes a strong baseline that several widely-used methods struggle to overcome. On a dataset with a ground-truth AFR available, the current state of the art is outperformed.","sentences":["We propose the novel concept of anomaly-free regions (AFR) to improve anomaly detection.","An AFR is a region in the data space for which it is known that there are no anomalies inside it, e.g., via domain knowledge.","This region can contain any number of normal data points and can be anywhere in the data space.","AFRs have the key advantage that they constrain the estimation of the distribution of non-anomalies: The estimated probability mass inside the AFR must be consistent with the number of normal data points inside the AFR.","Based on this insight, we provide a solid theoretical foundation and a reference implementation of anomaly detection using AFRs.","Our empirical results confirm that anomaly detection constrained via AFRs improves upon unconstrained anomaly detection.","Specifically, we show that, when equipped with an estimated AFR, an efficient algorithm based on random guessing becomes a strong baseline that several widely-used methods struggle to overcome.","On a dataset with a ground-truth AFR available, the current state of the art is outperformed."],"url":"http://arxiv.org/abs/2409.20208v1"}
{"created":"2024-09-30 11:28:33","title":"AfriHuBERT: A self-supervised speech representation model for African languages","abstract":"In this work, we present AfriHuBERT, an extension of mHuBERT-147, a state-of-the-art (SOTA) and compact self-supervised learning (SSL) model, originally pretrained on 147 languages. While mHuBERT-147 was pretrained on 16 African languages, we expand this to cover 39 African languages through continued pretraining on 6,500+ hours of speech data aggregated from diverse sources, including 23 newly added languages. We evaluate AfriHuBERT on two key speech tasks: Language Identification (LID) and Automatic Speech Recognition (ASR) using FLEURS dataset. Our results show a +4% F1 score improvement on average for LID and a -1.2% average Word Error Rate (WER) reduction for ASR. Further analysis shows that ASR models trained on AfriHuBERT exhibit improved cross-corpus generalization. Additionally, the analysis indicates that the FLEURS have data quality limitations that may affect their suitability for evaluating low-resource African languages, suggesting the need for better evaluation benchmarks for these languages.","sentences":["In this work, we present AfriHuBERT, an extension of mHuBERT-147, a state-of-the-art (SOTA) and compact self-supervised learning (SSL) model, originally pretrained on 147 languages.","While mHuBERT-147 was pretrained on 16 African languages, we expand this to cover 39 African languages through continued pretraining on 6,500+ hours of speech data aggregated from diverse sources, including 23 newly added languages.","We evaluate AfriHuBERT on two key speech tasks: Language Identification (LID) and Automatic Speech Recognition (ASR) using FLEURS dataset.","Our results show a +4% F1 score improvement on average for LID and a -1.2% average Word Error Rate (WER) reduction for ASR.","Further analysis shows that ASR models trained on AfriHuBERT exhibit improved cross-corpus generalization.","Additionally, the analysis indicates that the FLEURS have data quality limitations that may affect their suitability for evaluating low-resource African languages, suggesting the need for better evaluation benchmarks for these languages."],"url":"http://arxiv.org/abs/2409.20201v1"}
{"created":"2024-09-30 11:13:35","title":"Melody Is All You Need For Music Generation","abstract":"We present the Melody Guided Music Generation (MMGen) model, the first novel approach using melody to guide the music generation that, despite a pretty simple method and extremely limited resources, achieves excellent performance. Specifically, we first align the melody with audio waveforms and their associated descriptions using the multimodal alignment module. Subsequently, we condition the diffusion module on the learned melody representations. This allows MMGen to generate music that matches the style of the provided audio while also producing music that reflects the content of the given text description. To address the scarcity of high-quality data, we construct a multi-modal dataset, MusicSet, which includes melody, text, and audio, and will be made publicly available. We conduct extensive experiments which demonstrate the superiority of the proposed model both in terms of experimental metrics and actual performance quality.","sentences":["We present the Melody Guided Music Generation (MMGen) model, the first novel approach using melody to guide the music generation that, despite a pretty simple method and extremely limited resources, achieves excellent performance.","Specifically, we first align the melody with audio waveforms and their associated descriptions using the multimodal alignment module.","Subsequently, we condition the diffusion module on the learned melody representations.","This allows MMGen to generate music that matches the style of the provided audio while also producing music that reflects the content of the given text description.","To address the scarcity of high-quality data, we construct a multi-modal dataset, MusicSet, which includes melody, text, and audio, and will be made publicly available.","We conduct extensive experiments which demonstrate the superiority of the proposed model both in terms of experimental metrics and actual performance quality."],"url":"http://arxiv.org/abs/2409.20196v1"}
{"created":"2024-09-30 11:11:35","title":"Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT","abstract":"Predicting future disease progression risk from medical images is challenging due to patient heterogeneity, and subtle or unknown imaging biomarkers. Moreover, deep learning (DL) methods for survival analysis are susceptible to image domain shifts across scanners. We tackle these issues in the task of predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal OCT scans. We propose a novel DL method for survival prediction to jointly predict from the current scan a risk score, inversely related to time-to-conversion, and the probability of conversion within a time interval $t$. It uses a family of parallel hyperplanes generated by parameterizing the bias term as a function of $t$. In addition, we develop unsupervised losses based on intra-subject image pairs to ensure that risk scores increase over time and that future conversion predictions are consistent with AMD stage prediction using actual scans of future visits. Such losses enable data-efficient fine-tuning of the trained model on new unlabeled datasets acquired with a different scanner. Extensive evaluation on two large datasets acquired with different scanners resulted in a mean AUROCs of 0.82 for Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24 months.","sentences":["Predicting future disease progression risk from medical images is challenging due to patient heterogeneity, and subtle or unknown imaging biomarkers.","Moreover, deep learning (DL) methods for survival analysis are susceptible to image domain shifts across scanners.","We tackle these issues in the task of predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal OCT scans.","We propose a novel DL method for survival prediction to jointly predict from the current scan a risk score, inversely related to time-to-conversion, and the probability of conversion within a time interval $t$. It uses a family of parallel hyperplanes generated by parameterizing the bias term as a function of $t$. In addition, we develop unsupervised losses based on intra-subject image pairs to ensure that risk scores increase over time and that future conversion predictions are consistent with AMD stage prediction using actual scans of future visits.","Such losses enable data-efficient fine-tuning of the trained model on new unlabeled datasets acquired with a different scanner.","Extensive evaluation on two large datasets acquired with different scanners resulted in a mean AUROCs of 0.82 for Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24 months."],"url":"http://arxiv.org/abs/2409.20195v1"}
{"created":"2024-09-30 11:04:56","title":"TaskComplexity: A Dataset for Task Complexity Classification with In-Context Learning, FLAN-T5 and GPT-4o Benchmarks","abstract":"This paper addresses the challenge of classifying and assigning programming tasks to experts, a process that typically requires significant effort, time, and cost. To tackle this issue, a novel dataset containing a total of 4,112 programming tasks was created by extracting tasks from various websites. Web scraping techniques were employed to collect this dataset of programming problems systematically. Specific HTML tags were tracked to extract key elements of each issue, including the title, problem description, input-output, examples, problem class, and complexity score. Examples from the dataset are provided in the appendix to illustrate the variety and complexity of tasks included. The dataset's effectiveness has been evaluated and benchmarked using two approaches; the first approach involved fine-tuning the FLAN-T5 small model on the dataset, while the second approach used in-context learning (ICL) with the GPT-4o mini. The performance was assessed using standard metrics: accuracy, recall, precision, and F1-score. The results indicated that in-context learning with GPT-4o-mini outperformed the FLAN-T5 model.","sentences":["This paper addresses the challenge of classifying and assigning programming tasks to experts, a process that typically requires significant effort, time, and cost.","To tackle this issue, a novel dataset containing a total of 4,112 programming tasks was created by extracting tasks from various websites.","Web scraping techniques were employed to collect this dataset of programming problems systematically.","Specific HTML tags were tracked to extract key elements of each issue, including the title, problem description, input-output, examples, problem class, and complexity score.","Examples from the dataset are provided in the appendix to illustrate the variety and complexity of tasks included.","The dataset's effectiveness has been evaluated and benchmarked using two approaches; the first approach involved fine-tuning the FLAN-T5 small model on the dataset, while the second approach used in-context learning (ICL) with the GPT-4o mini.","The performance was assessed using standard metrics: accuracy, recall, precision, and F1-score.","The results indicated that in-context learning with GPT-4o-mini outperformed the FLAN-T5 model."],"url":"http://arxiv.org/abs/2409.20189v1"}
{"created":"2024-09-30 11:04:28","title":"Active Listener: Continuous Generation of Listener's Head Motion Response in Dyadic Interactions","abstract":"A key component of dyadic spoken interactions is the contextually relevant non-verbal gestures, such as head movements that reflect a listener's response to the interlocutor's speech. Although significant progress has been made in the context of generating co-speech gestures, generating listener's response has remained a challenge. We introduce the task of generating continuous head motion response of a listener in response to the speaker's speech in real time. To this end, we propose a graph-based end-to-end crossmodal model that takes interlocutor's speech audio as input and directly generates head pose angles (roll, pitch, yaw) of the listener in real time. Different from previous work, our approach is completely data-driven, does not require manual annotations or oversimplify head motion to merely nods and shakes. Extensive evaluation on the dyadic interaction sessions on the IEMOCAP dataset shows that our model produces a low overall error (4.5 degrees) and a high frame rate, thereby indicating its deployability in real-world human-robot interaction systems. Our code is available at - https://github.com/bigzen/Active-Listener","sentences":["A key component of dyadic spoken interactions is the contextually relevant non-verbal gestures, such as head movements that reflect a listener's response to the interlocutor's speech.","Although significant progress has been made in the context of generating co-speech gestures, generating listener's response has remained a challenge.","We introduce the task of generating continuous head motion response of a listener in response to the speaker's speech in real time.","To this end, we propose a graph-based end-to-end crossmodal model that takes interlocutor's speech audio as input and directly generates head pose angles (roll, pitch, yaw) of the listener in real time.","Different from previous work, our approach is completely data-driven, does not require manual annotations or oversimplify head motion to merely nods and shakes.","Extensive evaluation on the dyadic interaction sessions on the IEMOCAP dataset shows that our model produces a low overall error (4.5 degrees) and a high frame rate, thereby indicating its deployability in real-world human-robot interaction systems.","Our code is available at - https://github.com/bigzen/Active-Listener"],"url":"http://arxiv.org/abs/2409.20188v1"}
{"created":"2024-09-30 11:03:44","title":"Choosing DAG Models Using Markov and Minimal Edge Count in the Absence of Ground Truth","abstract":"We give a novel nonparametric pointwise consistent statistical test (the Markov Checker) of the Markov condition for directed acyclic graph (DAG) or completed partially directed acyclic graph (CPDAG) models given a dataset. We also introduce the Cross-Algorithm Frugality Search (CAFS) for rejecting DAG models that either do not pass the Markov Checker test or that are not edge minimal. Edge minimality has been used previously by Raskutti and Uhler as a nonparametric simplicity criterion, though CAFS readily generalizes to other simplicity conditions. Reference to the ground truth is not necessary for CAFS, so it is useful for finding causal structure learning algorithms and tuning parameter settings that output causal models that are approximately true from a given data set. We provide a software tool for this analysis that is suitable for even quite large or dense models, provided a suitably fast pointwise consistent test of conditional independence is available. In addition, we show in simulation that the CAFS procedure can pick approximately correct models without knowing the ground truth.","sentences":["We give a novel nonparametric pointwise consistent statistical test (the Markov Checker) of the Markov condition for directed acyclic graph (DAG) or completed partially directed acyclic graph (CPDAG) models given a dataset.","We also introduce the Cross-Algorithm Frugality Search (CAFS) for rejecting DAG models that either do not pass the Markov Checker test or that are not edge minimal.","Edge minimality has been used previously by Raskutti and Uhler as a nonparametric simplicity criterion, though CAFS readily generalizes to other simplicity conditions.","Reference to the ground truth is not necessary for CAFS, so it is useful for finding causal structure learning algorithms and tuning parameter settings that output causal models that are approximately true from a given data set.","We provide a software tool for this analysis that is suitable for even quite large or dense models, provided a suitably fast pointwise consistent test of conditional independence is available.","In addition, we show in simulation that the CAFS procedure can pick approximately correct models without knowing the ground truth."],"url":"http://arxiv.org/abs/2409.20187v1"}
{"created":"2024-09-30 10:31:27","title":"ILeSiA: Interactive Learning of Situational Awareness from Camera Input","abstract":"Learning from demonstration is a promising way of teaching robots new skills. However, a central problem when executing acquired skills is to recognize risks and failures. This is essential since the demonstrations usually cover only a few mostly successful cases. Inevitable errors during execution require specific reactions that were not apparent in the demonstrations. In this paper, we focus on teaching the robot situational awareness from an initial skill demonstration via kinesthetic teaching and sparse labeling of autonomous skill executions as safe or risky. At runtime, our system, called ILeSiA, detects risks based on the perceived camera images by encoding the images into a low-dimensional latent space representation and training a classifier based on the encoding and the provided labels. In this way, ILeSiA boosts the confidence and safety with which robotic skills can be executed. Our experiments demonstrate that classifiers, trained with only a small amount of user-provided data, can successfully detect numerous risks. The system is flexible because the risk cases are defined by labeling data. This also means that labels can be added as soon as risks are identified by a human supervisor. We provide all code and data required to reproduce our experiments at imitrob.ciirc.cvut.cz/publications/ilesia.","sentences":["Learning from demonstration is a promising way of teaching robots new skills.","However, a central problem when executing acquired skills is to recognize risks and failures.","This is essential since the demonstrations usually cover only a few mostly successful cases.","Inevitable errors during execution require specific reactions that were not apparent in the demonstrations.","In this paper, we focus on teaching the robot situational awareness from an initial skill demonstration via kinesthetic teaching and sparse labeling of autonomous skill executions as safe or risky.","At runtime, our system, called ILeSiA, detects risks based on the perceived camera images by encoding the images into a low-dimensional latent space representation and training a classifier based on the encoding and the provided labels.","In this way, ILeSiA boosts the confidence and safety with which robotic skills can be executed.","Our experiments demonstrate that classifiers, trained with only a small amount of user-provided data, can successfully detect numerous risks.","The system is flexible because the risk cases are defined by labeling data.","This also means that labels can be added as soon as risks are identified by a human supervisor.","We provide all code and data required to reproduce our experiments at imitrob.ciirc.cvut.cz/publications/ilesia."],"url":"http://arxiv.org/abs/2409.20173v1"}
{"created":"2024-09-30 10:29:54","title":"Efficient Approximation of Fractional Hypertree Width","abstract":"We give two new approximation algorithms to compute the fractional hypertree width of an input hypergraph. The first algorithm takes as input $n$-vertex $m$-edge hypergraph $H$ of fractional hypertree width at most $\\omega$, runs in polynomial time and produces a tree decomposition of $H$ of fractional hypertree width $O(\\omega \\log n \\log \\omega)$. As an immediate corollary this yields polynomial time $O(\\log^2 n \\log \\omega)$-approximation algorithms for (generalized) hypertree width as well. To the best of our knowledge our algorithm is the first non-trivial polynomial-time approximation algorithm for fractional hypertree width and (generalized) hypertree width, as opposed to algorithms that run in polynomial time only when $\\omega$ is considered a constant. For hypergraphs with the bounded intersection property we get better bounds, comparable with that recent algorithm of Lanzinger and Razgon [STACS 2024].   The second algorithm runs in time $n^{\\omega}m^{O(1)}$ and produces a tree decomposition of $H$ of fractional hypertree width $O(\\omega \\log^2 \\omega)$. This significantly improves over the $(n+m)^{O(\\omega^3)}$ time algorithm of Marx [ACM TALG 2010], which produces a tree decomposition of fractional hypertree width $O(\\omega^3)$, both in terms of running time and the approximation ratio.   Our main technical contribution, and the key insight behind both algorithms, is a variant of the classic Menger's Theorem for clique separators in graphs: For every graph $G$, vertex sets $A$ and $B$, family ${\\cal F}$ of cliques in $G$, and positive rational $f$, either there exists a sub-family of $O(f \\cdot \\log^2 n)$ cliques in ${\\cal F}$ whose union separates $A$ from $B$, or there exist $f \\cdot \\log |{\\cal F}|$ paths from $A$ to $B$ such that no clique in ${\\cal F}$ intersects more than $\\log |{\\cal F}|$ paths.","sentences":["We give two new approximation algorithms to compute the fractional hypertree width of an input hypergraph.","The first algorithm takes as input $n$-vertex $m$-edge hypergraph $H$ of fractional hypertree width at most $\\omega$, runs in polynomial time and produces a tree decomposition of $H$ of fractional hypertree width $O(\\omega \\log n \\log \\omega)$. As an immediate corollary this yields polynomial time $O(\\log^2 n \\log \\omega)$-approximation algorithms for (generalized) hypertree width as well.","To the best of our knowledge our algorithm is the first non-trivial polynomial-time approximation algorithm for fractional hypertree width and (generalized) hypertree width, as opposed to algorithms that run in polynomial time only when $\\omega$ is considered a constant.","For hypergraphs with the bounded intersection property we get better bounds, comparable with that recent algorithm of Lanzinger and Razgon [STACS 2024].   ","The second algorithm runs in time $n^{\\omega}m^{O(1)}$ and produces a tree decomposition of $H$ of fractional hypertree width $O(\\omega \\log^2 \\omega)$.","This significantly improves over the $(n+m)^{O(\\omega^3)}$ time algorithm of Marx [ACM TALG 2010], which produces a tree decomposition of fractional hypertree width $O(\\omega^3)$, both in terms of running time and the approximation ratio.   ","Our main technical contribution, and the key insight behind both algorithms, is a variant of the classic Menger's Theorem for clique separators in graphs: For every graph $G$, vertex sets $A$ and $B$, family ${\\cal F}$ of cliques in $G$, and positive rational $f$, either there exists a sub-family of $O(f \\cdot \\log^2 n)$ cliques in ${\\cal F}$ whose union separates $A$ from $B$, or there exist $f \\cdot \\log |{\\cal F}|$ paths from $A$ to $B$ such that no clique in ${\\cal F}$ intersects more than $\\log |{\\cal F}|$ paths."],"url":"http://arxiv.org/abs/2409.20172v1"}
{"created":"2024-09-30 10:29:41","title":"Annotation-Free Curb Detection Leveraging Altitude Difference Image","abstract":"Road curbs are considered as one of the crucial and ubiquitous traffic features, which are essential for ensuring the safety of autonomous vehicles. Current methods for detecting curbs primarily rely on camera imagery or LiDAR point clouds. Image-based methods are vulnerable to fluctuations in lighting conditions and exhibit poor robustness, while methods based on point clouds circumvent the issues associated with lighting variations. However, it is the typical case that significant processing delays are encountered due to the voluminous amount of 3D points contained in each frame of the point cloud data. Furthermore, the inherently unstructured characteristics of point clouds poses challenges for integrating the latest deep learning advancements into point cloud data applications. To address these issues, this work proposes an annotation-free curb detection method leveraging Altitude Difference Image (ADI), which effectively mitigates the aforementioned challenges. Given that methods based on deep learning generally demand extensive, manually annotated datasets, which are both expensive and labor-intensive to create, we present an Automatic Curb Annotator (ACA) module. This module utilizes a deterministic curb detection algorithm to automatically generate a vast quantity of training data. Consequently, it facilitates the training of the curb detection model without necessitating any manual annotation of data. Finally, by incorporating a post-processing module, we manage to achieve state-of-the-art results on the KITTI 3D curb dataset with considerably reduced processing delays compared to existing methods, which underscores the effectiveness of our approach in curb detection tasks.","sentences":["Road curbs are considered as one of the crucial and ubiquitous traffic features, which are essential for ensuring the safety of autonomous vehicles.","Current methods for detecting curbs primarily rely on camera imagery or LiDAR point clouds.","Image-based methods are vulnerable to fluctuations in lighting conditions and exhibit poor robustness, while methods based on point clouds circumvent the issues associated with lighting variations.","However, it is the typical case that significant processing delays are encountered due to the voluminous amount of 3D points contained in each frame of the point cloud data.","Furthermore, the inherently unstructured characteristics of point clouds poses challenges for integrating the latest deep learning advancements into point cloud data applications.","To address these issues, this work proposes an annotation-free curb detection method leveraging Altitude Difference Image (ADI), which effectively mitigates the aforementioned challenges.","Given that methods based on deep learning generally demand extensive, manually annotated datasets, which are both expensive and labor-intensive to create, we present an Automatic Curb Annotator (ACA) module.","This module utilizes a deterministic curb detection algorithm to automatically generate a vast quantity of training data.","Consequently, it facilitates the training of the curb detection model without necessitating any manual annotation of data.","Finally, by incorporating a post-processing module, we manage to achieve state-of-the-art results on the KITTI 3D curb dataset with considerably reduced processing delays compared to existing methods, which underscores the effectiveness of our approach in curb detection tasks."],"url":"http://arxiv.org/abs/2409.20171v1"}
{"created":"2024-09-30 10:26:29","title":"Using Large Multimodal Models to Extract Knowledge Components for Knowledge Tracing from Multimedia Question Information","abstract":"Knowledge tracing models have enabled a range of intelligent tutoring systems to provide feedback to students. However, existing methods for knowledge tracing in learning sciences are predominantly reliant on statistical data and instructor-defined knowledge components, making it challenging to integrate AI-generated educational content with traditional established methods. We propose a method for automatically extracting knowledge components from educational content using instruction-tuned large multimodal models. We validate this approach by comprehensively evaluating it against knowledge tracing benchmarks in five domains. Our results indicate that the automatically extracted knowledge components can effectively replace human-tagged labels, offering a promising direction for enhancing intelligent tutoring systems in limited-data scenarios, achieving more explainable assessments in educational settings, and laying the groundwork for automated assessment.","sentences":["Knowledge tracing models have enabled a range of intelligent tutoring systems to provide feedback to students.","However, existing methods for knowledge tracing in learning sciences are predominantly reliant on statistical data and instructor-defined knowledge components, making it challenging to integrate AI-generated educational content with traditional established methods.","We propose a method for automatically extracting knowledge components from educational content using instruction-tuned large multimodal models.","We validate this approach by comprehensively evaluating it against knowledge tracing benchmarks in five domains.","Our results indicate that the automatically extracted knowledge components can effectively replace human-tagged labels, offering a promising direction for enhancing intelligent tutoring systems in limited-data scenarios, achieving more explainable assessments in educational settings, and laying the groundwork for automated assessment."],"url":"http://arxiv.org/abs/2409.20167v1"}
{"created":"2024-09-30 10:25:47","title":"Task-Oriented Pre-Training for Drivable Area Detection","abstract":"Pre-training techniques play a crucial role in deep learning, enhancing models' performance across a variety of tasks. By initially training on large datasets and subsequently fine-tuning on task-specific data, pre-training provides a solid foundation for models, improving generalization abilities and accelerating convergence rates. This approach has seen significant success in the fields of natural language processing and computer vision. However, traditional pre-training methods necessitate large datasets and substantial computational resources, and they can only learn shared features through prolonged training and struggle to capture deeper, task-specific features. In this paper, we propose a task-oriented pre-training method that begins with generating redundant segmentation proposals using the Segment Anything (SAM) model. We then introduce a Specific Category Enhancement Fine-tuning (SCEF) strategy for fine-tuning the Contrastive Language-Image Pre-training (CLIP) model to select proposals most closely related to the drivable area from those generated by SAM. This approach can generate a lot of coarse training data for pre-training models, which are further fine-tuned using manually annotated data, thereby improving model's performance. Comprehensive experiments conducted on the KITTI road dataset demonstrate that our task-oriented pre-training method achieves an all-around performance improvement compared to models without pre-training. Moreover, our pre-training method not only surpasses traditional pre-training approach but also achieves the best performance compared to state-of-the-art self-training methods.","sentences":["Pre-training techniques play a crucial role in deep learning, enhancing models' performance across a variety of tasks.","By initially training on large datasets and subsequently fine-tuning on task-specific data, pre-training provides a solid foundation for models, improving generalization abilities and accelerating convergence rates.","This approach has seen significant success in the fields of natural language processing and computer vision.","However, traditional pre-training methods necessitate large datasets and substantial computational resources, and they can only learn shared features through prolonged training and struggle to capture deeper, task-specific features.","In this paper, we propose a task-oriented pre-training method that begins with generating redundant segmentation proposals using the Segment Anything (SAM) model.","We then introduce a Specific Category Enhancement Fine-tuning (SCEF) strategy for fine-tuning the Contrastive Language-Image Pre-training (CLIP) model to select proposals most closely related to the drivable area from those generated by SAM.","This approach can generate a lot of coarse training data for pre-training models, which are further fine-tuned using manually annotated data, thereby improving model's performance.","Comprehensive experiments conducted on the KITTI road dataset demonstrate that our task-oriented pre-training method achieves an all-around performance improvement compared to models without pre-training.","Moreover, our pre-training method not only surpasses traditional pre-training approach but also achieves the best performance compared to state-of-the-art self-training methods."],"url":"http://arxiv.org/abs/2409.20166v1"}
{"created":"2024-09-30 10:21:54","title":"Erase, then Redraw: A Novel Data Augmentation Approach for Free Space Detection Using Diffusion Model","abstract":"Data augmentation is one of the most common tools in deep learning, underpinning many recent advances including tasks such as classification, detection, and semantic segmentation. The standard approach to data augmentation involves simple transformations like rotation and flipping to generate new images. However, these new images often lack diversity along the main semantic dimensions within the data. Traditional data augmentation methods cannot alter high-level semantic attributes such as the presence of vehicles, trees, and buildings in a scene to enhance data diversity. In recent years, the rapid development of generative models has injected new vitality into the field of data augmentation. In this paper, we address the lack of diversity in data augmentation for road detection task by using a pre-trained text-to-image diffusion model to parameterize image-to-image transformations. Our method involves editing images using these diffusion models to change their semantics. In essence, we achieve this goal by erasing instances of real objects from the original dataset and generating new instances with similar semantics in the erased regions using the diffusion model, thereby expanding the original dataset. We evaluate our approach on the KITTI road dataset and achieve the best results compared to other data augmentation methods, which demonstrates the effectiveness of our proposed development.","sentences":["Data augmentation is one of the most common tools in deep learning, underpinning many recent advances including tasks such as classification, detection, and semantic segmentation.","The standard approach to data augmentation involves simple transformations like rotation and flipping to generate new images.","However, these new images often lack diversity along the main semantic dimensions within the data.","Traditional data augmentation methods cannot alter high-level semantic attributes such as the presence of vehicles, trees, and buildings in a scene to enhance data diversity.","In recent years, the rapid development of generative models has injected new vitality into the field of data augmentation.","In this paper, we address the lack of diversity in data augmentation for road detection task by using a pre-trained text-to-image diffusion model to parameterize image-to-image transformations.","Our method involves editing images using these diffusion models to change their semantics.","In essence, we achieve this goal by erasing instances of real objects from the original dataset and generating new instances with similar semantics in the erased regions using the diffusion model, thereby expanding the original dataset.","We evaluate our approach on the KITTI road dataset and achieve the best results compared to other data augmentation methods, which demonstrates the effectiveness of our proposed development."],"url":"http://arxiv.org/abs/2409.20164v1"}
{"created":"2024-09-30 10:10:52","title":"Professor X: Manipulating EEG BCI with Invisible and Robust Backdoor Attack","abstract":"While electroencephalogram (EEG) based brain-computer interface (BCI) has been widely used for medical diagnosis, health care, and device control, the safety of EEG BCI has long been neglected. In this paper, we propose Professor X, an invisible and robust \"mind-controller\" that can arbitrarily manipulate the outputs of EEG BCI through backdoor attack, to alert the EEG community of the potential hazard. However, existing EEG attacks mainly focus on single-target class attacks, and they either require engaging the training stage of the target BCI, or fail to maintain high stealthiness. Addressing these limitations, Professor X exploits a three-stage clean label poisoning attack: 1) selecting one trigger for each class; 2) learning optimal injecting EEG electrodes and frequencies strategy with reinforcement learning for each trigger; 3) generating poisoned samples by injecting the corresponding trigger's frequencies into poisoned data for each class by linearly interpolating the spectral amplitude of both data according to previously learned strategies. Experiments on datasets of three common EEG tasks demonstrate the effectiveness and robustness of Professor X, which also easily bypasses existing backdoor defenses.","sentences":["While electroencephalogram (EEG) based brain-computer interface (BCI) has been widely used for medical diagnosis, health care, and device control, the safety of EEG BCI has long been neglected.","In this paper, we propose Professor X, an invisible and robust \"mind-controller\" that can arbitrarily manipulate the outputs of EEG BCI through backdoor attack, to alert the EEG community of the potential hazard.","However, existing EEG attacks mainly focus on single-target class attacks, and they either require engaging the training stage of the target BCI, or fail to maintain high stealthiness.","Addressing these limitations, Professor X exploits a three-stage clean label poisoning attack: 1) selecting one trigger for each class; 2) learning optimal injecting EEG electrodes and frequencies strategy with reinforcement learning for each trigger; 3) generating poisoned samples by injecting the corresponding trigger's frequencies into poisoned data for each class by linearly interpolating the spectral amplitude of both data according to previously learned strategies.","Experiments on datasets of three common EEG tasks demonstrate the effectiveness and robustness of Professor X, which also easily bypasses existing backdoor defenses."],"url":"http://arxiv.org/abs/2409.20158v1"}
{"created":"2024-09-30 10:08:10","title":"RSVP: Beyond Weisfeiler Lehman Graph Isomorphism Test","abstract":"Graph isomorphism, a classical algorithmic problem, determines whether two input graphs are structurally identical or not. Interestingly, it is one of the few problems that is not yet known to belong to either the P or NP-complete complexity classes. As such, intelligent search-space pruning based strategies were proposed for developing isomorphism testing solvers like nauty and bliss, which are still, unfortunately, exponential in the worst-case scenario. Thus, the polynomial-time Weisfeiler-Lehman (WL) isomorphism testing heuristic, based on colour refinement, has been widely adopted in the literature. However, WL fails for multiple classes of non-isomorphic graph instances such as strongly regular graphs, block structures, and switched edges, among others. In this paper, we propose a novel polynomial-time graph isomorphism testing heuristic, RSVP, and depict its enhanced discriminative power compared to the Weisfeiler-Lehman approach for several challenging classes of graphs. Bounded by a run-time complexity of O(m^2+mn^2+n^3) (where n and m are the number of vertices and edges respectively), we show that RSVP can identify non-isomorphism in several 'hard' graph instance classes including Miyazaki, Paulus, cubic hypohamiltonian, strongly regular, Latin series and Steiner triple system graphs, where the 3-WL test fails. Similar to the WL test, our proposed algorithm is prone to only one-sided errors, where isomorphic graphs will never be determined to be non-isomorphic, although the reverse can happen.","sentences":["Graph isomorphism, a classical algorithmic problem, determines whether two input graphs are structurally identical or not.","Interestingly, it is one of the few problems that is not yet known to belong to either the P or NP-complete complexity classes.","As such, intelligent search-space pruning based strategies were proposed for developing isomorphism testing solvers like nauty and bliss, which are still, unfortunately, exponential in the worst-case scenario.","Thus, the polynomial-time Weisfeiler-Lehman (WL) isomorphism testing heuristic, based on colour refinement, has been widely adopted in the literature.","However, WL fails for multiple classes of non-isomorphic graph instances such as strongly regular graphs, block structures, and switched edges, among others.","In this paper, we propose a novel polynomial-time graph isomorphism testing heuristic, RSVP, and depict its enhanced discriminative power compared to the Weisfeiler-Lehman approach for several challenging classes of graphs.","Bounded by a run-time complexity of O(m^2+mn^2+n^3) (where n and m are the number of vertices and edges respectively), we show that RSVP can identify non-isomorphism in several 'hard' graph instance classes including Miyazaki, Paulus, cubic hypohamiltonian, strongly regular, Latin series and Steiner triple system graphs, where the 3-WL test fails.","Similar to the WL test, our proposed algorithm is prone to only one-sided errors, where isomorphic graphs will never be determined to be non-isomorphic, although the reverse can happen."],"url":"http://arxiv.org/abs/2409.20157v1"}
{"created":"2024-09-30 10:07:28","title":"ASTRA: Accurate and Scalable ANNS-based Training of Extreme Classifiers","abstract":"`Extreme Classification'' (or XC) is the task of annotating data points (queries) with relevant labels (documents), from an extremely large set of $L$ possible labels, arising in search and recommendations. The most successful deep learning paradigm that has emerged over the last decade or so for XC is to embed the queries (and labels) using a deep encoder (e.g. DistilBERT), and use linear classifiers on top of the query embeddings. This architecture is of appeal because it enables millisecond-time inference using approximate nearest neighbor search (ANNS). The key question is how do we design training algorithms that are accurate as well as scale to $O(100M)$ labels on a limited number of GPUs.   State-of-the-art XC techniques that demonstrate high accuracies (e.g., DEXML, Ren\\'ee, DEXA) on standard datasets have per-epoch training time that scales as $O(L)$ or employ expensive negative sampling strategies, which are prohibitive in XC scenarios. In this work, we develop an accurate and scalable XC algorithm ASTRA with two key observations: (a) building ANNS index on the classifier vectors and retrieving hard negatives using the classifiers aligns the negative sampling strategy to the loss function optimized; (b) keeping the ANNS indices current as the classifiers change through the epochs is prohibitively expensive while using stale negatives (refreshed periodically) results in poor accuracy; to remedy this, we propose a negative sampling strategy that uses a mixture of importance sampling and uniform sampling. By extensive evaluation on standard XC as well as proprietary datasets with 120M labels, we demonstrate that ASTRA achieves SOTA precision, while reducing training time by 4x-15x relative to the second best.","sentences":["`Extreme Classification'' (or XC) is the task of annotating data points (queries) with relevant labels (documents), from an extremely large set of $L$ possible labels, arising in search and recommendations.","The most successful deep learning paradigm that has emerged over the last decade or so for XC is to embed the queries (and labels) using a deep encoder (e.g. DistilBERT), and use linear classifiers on top of the query embeddings.","This architecture is of appeal because it enables millisecond-time inference using approximate nearest neighbor search (ANNS).","The key question is how do we design training algorithms that are accurate as well as scale to $O(100M)$ labels on a limited number of GPUs.   ","State-of-the-art XC techniques that demonstrate high accuracies (e.g., DEXML, Ren\\'ee, DEXA) on standard datasets have per-epoch training time that scales as $O(L)$ or employ expensive negative sampling strategies, which are prohibitive in XC scenarios.","In this work, we develop an accurate and scalable XC algorithm ASTRA with two key observations: (a) building ANNS index on the classifier vectors and retrieving hard negatives using the classifiers aligns the negative sampling strategy to the loss function optimized; (b) keeping the ANNS indices current as the classifiers change through the epochs is prohibitively expensive while using stale negatives (refreshed periodically) results in poor accuracy; to remedy this, we propose a negative sampling strategy that uses a mixture of importance sampling and uniform sampling.","By extensive evaluation on standard XC as well as proprietary datasets with 120M labels, we demonstrate that ASTRA achieves SOTA precision, while reducing training time by 4x-15x relative to the second best."],"url":"http://arxiv.org/abs/2409.20156v1"}
{"created":"2024-09-30 09:55:39","title":"1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models","abstract":"In this paper, we propose the 1 Trillion Token Platform (1TT Platform), a novel framework designed to facilitate efficient data sharing with a transparent and equitable profit-sharing mechanism. The platform fosters collaboration between data contributors, who provide otherwise non-disclosed datasets, and a data consumer, who utilizes these datasets to enhance their own services. Data contributors are compensated in monetary terms, receiving a share of the revenue generated by the services of the data consumer. The data consumer is committed to sharing a portion of the revenue with contributors, according to predefined profit-sharing arrangements. By incorporating a transparent profit-sharing paradigm to incentivize large-scale data sharing, the 1TT Platform creates a collaborative environment to drive the advancement of NLP and LLM technologies.","sentences":["In this paper, we propose the 1 Trillion Token Platform (1TT Platform), a novel framework designed to facilitate efficient data sharing with a transparent and equitable profit-sharing mechanism.","The platform fosters collaboration between data contributors, who provide otherwise non-disclosed datasets, and a data consumer, who utilizes these datasets to enhance their own services.","Data contributors are compensated in monetary terms, receiving a share of the revenue generated by the services of the data consumer.","The data consumer is committed to sharing a portion of the revenue with contributors, according to predefined profit-sharing arrangements.","By incorporating a transparent profit-sharing paradigm to incentivize large-scale data sharing, the 1TT Platform creates a collaborative environment to drive the advancement of NLP and LLM technologies."],"url":"http://arxiv.org/abs/2409.20149v1"}
{"created":"2024-09-30 09:52:28","title":"Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language","abstract":"Natural language processing (NLP) in the medical domain can underperform in real-world applications involving small datasets in a non-English language with few labeled samples and imbalanced classes. There is yet no consensus on how to approach this problem. We evaluated a set of NLP models including BERT-like transformers, few-shot learning with sentence transformers (SetFit), and prompted large language models (LLM), using three datasets of radiology reports on magnetic resonance images of epilepsy patients in Danish, a low-resource language. Our results indicate that BERT-like models pretrained in the target domain of radiology reports currently offer the optimal performances for this scenario. Notably, the SetFit and LLM models underperformed compared to BERT-like models, with LLM performing the worst. Importantly, none of the models investigated was sufficiently accurate to allow for text classification without any supervision. However, they show potential for data filtering, which could reduce the amount of manual labeling required.","sentences":["Natural language processing (NLP) in the medical domain can underperform in real-world applications involving small datasets in a non-English language with few labeled samples and imbalanced classes.","There is yet no consensus on how to approach this problem.","We evaluated a set of NLP models including BERT-like transformers, few-shot learning with sentence transformers (SetFit), and prompted large language models (LLM), using three datasets of radiology reports on magnetic resonance images of epilepsy patients in Danish, a low-resource language.","Our results indicate that BERT-like models pretrained in the target domain of radiology reports currently offer the optimal performances for this scenario.","Notably, the SetFit and LLM models underperformed compared to BERT-like models, with LLM performing the worst.","Importantly, none of the models investigated was sufficiently accurate to allow for text classification without any supervision.","However, they show potential for data filtering, which could reduce the amount of manual labeling required."],"url":"http://arxiv.org/abs/2409.20147v1"}
{"created":"2024-09-30 09:45:08","title":"Signal Processing for Haptic Surface Modeling: a Review","abstract":"Haptic feedback has been integrated into Virtual and Augmented Reality, complementing acoustic and visual information and contributing to an all-round immersive experience in multiple fields, spanning from the medical domain to entertainment and gaming. Haptic technologies involve complex cross-disciplinary research that encompasses sensing, data representation, interactive rendering, perception, and quality of experience. The standard processing pipeline, consists of (I) sensing physical features in the real world using a transducer, (II) modeling and storing the collected information in some digital format, (III) communicating the information, and finally, (IV) rendering the haptic information through appropriate devices, thus producing a user experience (V) perceptually close to the original physical world. Among these areas, sensing, rendering and perception have been deeply investigated and are the subject of different comprehensive surveys available in the literature. Differently, research dealing with haptic surface modeling and data representation still lacks a comprehensive dissection. In this work, we aim at providing an overview on modeling and representation of haptic surfaces from a signal processing perspective, covering the aspects that lie in between haptic information acquisition on one side and rendering and perception on the other side. We analyze, categorize, and compare research papers that address the haptic surface modeling and data representation, pointing out existing gaps and possible research directions.","sentences":["Haptic feedback has been integrated into Virtual and Augmented Reality, complementing acoustic and visual information and contributing to an all-round immersive experience in multiple fields, spanning from the medical domain to entertainment and gaming.","Haptic technologies involve complex cross-disciplinary research that encompasses sensing, data representation, interactive rendering, perception, and quality of experience.","The standard processing pipeline, consists of (I) sensing physical features in the real world using a transducer, (II) modeling and storing the collected information in some digital format, (III) communicating the information, and finally, (IV) rendering the haptic information through appropriate devices, thus producing a user experience (V) perceptually close to the original physical world.","Among these areas, sensing, rendering and perception have been deeply investigated and are the subject of different comprehensive surveys available in the literature.","Differently, research dealing with haptic surface modeling and data representation still lacks a comprehensive dissection.","In this work, we aim at providing an overview on modeling and representation of haptic surfaces from a signal processing perspective, covering the aspects that lie in between haptic information acquisition on one side and rendering and perception on the other side.","We analyze, categorize, and compare research papers that address the haptic surface modeling and data representation, pointing out existing gaps and possible research directions."],"url":"http://arxiv.org/abs/2409.20142v1"}
{"created":"2024-09-30 09:41:34","title":"Characterizing Model Robustness via Natural Input Gradients","abstract":"Adversarially robust models are locally smooth around each data sample so that small perturbations cannot drastically change model outputs. In modern systems, such smoothness is usually obtained via Adversarial Training, which explicitly enforces models to perform well on perturbed examples. In this work, we show the surprising effectiveness of instead regularizing the gradient with respect to model inputs on natural examples only. Penalizing input Gradient Norm is commonly believed to be a much inferior approach. Our analyses identify that the performance of Gradient Norm regularization critically depends on the smoothness of activation functions, and are in fact extremely effective on modern vision transformers that adopt smooth activations over piecewise linear ones (eg, ReLU), contrary to prior belief. On ImageNet-1k, Gradient Norm training achieves > 90% the performance of state-of-the-art PGD-3 Adversarial Training} (52% vs.~56%), while using only 60% computation cost of the state-of-the-art without complex adversarial optimization. Our analyses also highlight the relationship between model robustness and properties of natural input gradients, such as asymmetric sample and channel statistics. Surprisingly, we find model robustness can be significantly improved by simply regularizing its gradients to concentrate on image edges without explicit conditioning on the gradient norm.","sentences":["Adversarially robust models are locally smooth around each data sample so that small perturbations cannot drastically change model outputs.","In modern systems, such smoothness is usually obtained via Adversarial Training, which explicitly enforces models to perform well on perturbed examples.","In this work, we show the surprising effectiveness of instead regularizing the gradient with respect to model inputs on natural examples only.","Penalizing input Gradient Norm is commonly believed to be a much inferior approach.","Our analyses identify that the performance of Gradient Norm regularization critically depends on the smoothness of activation functions, and are in fact extremely effective on modern vision transformers that adopt smooth activations over piecewise linear ones (eg, ReLU), contrary to prior belief.","On ImageNet-1k, Gradient Norm training achieves > 90% the performance of state-of-the-art PGD-3 Adversarial Training} (52% vs.~56%), while using only 60% computation cost of the state-of-the-art without complex adversarial optimization.","Our analyses also highlight the relationship between model robustness and properties of natural input gradients, such as asymmetric sample and channel statistics.","Surprisingly, we find model robustness can be significantly improved by simply regularizing its gradients to concentrate on image edges without explicit conditioning on the gradient norm."],"url":"http://arxiv.org/abs/2409.20139v1"}
{"created":"2024-09-30 09:34:31","title":"Federated Instruction Tuning of LLMs with Domain Coverage Augmentation","abstract":"Federated Domain-specific Instruction Tuning (FedDIT) leverages a few cross-client private data and server-side public data for instruction augmentation, enhancing model performance in specific domains. While the factors affecting FedDIT remain unclear and existing instruction augmentation methods mainly focus on the centralized setting without considering the distributed environment. Firstly, our experiments show that cross-client domain coverage, rather than data heterogeneity, drives model performance in FedDIT. Thus, we propose FedDCA, which maximizes domain coverage through greedy client center selection and retrieval-based augmentation. To reduce client-side computation, FedDCA$^*$ uses heterogeneous encoders with server-side feature alignment. Extensive experiments across four domains (code, medical, financial, and mathematical) validate the effectiveness of both methods. Additionally, we explore the privacy protection against memory extraction attacks with various amounts of public data and results show that there is no significant correlation between the amount of public data and the privacy-preserving capability. However, as the fine-tuning round increases, the risk of privacy leakage reduces or converges.","sentences":["Federated Domain-specific Instruction Tuning (FedDIT) leverages a few cross-client private data and server-side public data for instruction augmentation, enhancing model performance in specific domains.","While the factors affecting FedDIT remain unclear and existing instruction augmentation methods mainly focus on the centralized setting without considering the distributed environment.","Firstly, our experiments show that cross-client domain coverage, rather than data heterogeneity, drives model performance in FedDIT.","Thus, we propose FedDCA, which maximizes domain coverage through greedy client center selection and retrieval-based augmentation.","To reduce client-side computation, FedDCA$^*$ uses heterogeneous encoders with server-side feature alignment.","Extensive experiments across four domains (code, medical, financial, and mathematical) validate the effectiveness of both methods.","Additionally, we explore the privacy protection against memory extraction attacks with various amounts of public data and results show that there is no significant correlation between the amount of public data and the privacy-preserving capability.","However, as the fine-tuning round increases, the risk of privacy leakage reduces or converges."],"url":"http://arxiv.org/abs/2409.20135v1"}
{"created":"2024-09-30 09:33:30","title":"Machine Learning in Industrial Quality Control of Glass Bottle Prints","abstract":"In industrial manufacturing of glass bottles, quality control of bottle prints is necessary as numerous factors can negatively affect the printing process. Even minor defects in the bottle prints must be detected despite reflections in the glass or manufacturing-related deviations. In cooperation with our medium-sized industrial partner, two ML-based approaches for quality control of these bottle prints were developed and evaluated, which can also be used in this challenging scenario. Our first approach utilized different filters to supress reflections (e.g. Sobel or Canny) and image quality metrics for image comparison (e.g. MSE or SSIM) as features for different supervised classification models (e.g. SVM or k-Neighbors), which resulted in an accuracy of 84%. The images were aligned based on the ORB algorithm, which allowed us to estimate the rotations of the prints, which may serve as an indicator for anomalies in the manufacturing process. In our second approach, we fine-tuned different pre-trained CNN models (e.g. ResNet or VGG) for binary classification, which resulted in an accuracy of 87%. Utilizing Grad-Cam on our fine-tuned ResNet-34, we were able to localize and visualize frequently defective bottle print regions. This method allowed us to provide insights that could be used to optimize the actual manufacturing process. This paper also describes our general approach and the challenges we encountered in practice with data collection during ongoing production, unsupervised preselection, and labeling.","sentences":["In industrial manufacturing of glass bottles, quality control of bottle prints is necessary as numerous factors can negatively affect the printing process.","Even minor defects in the bottle prints must be detected despite reflections in the glass or manufacturing-related deviations.","In cooperation with our medium-sized industrial partner, two ML-based approaches for quality control of these bottle prints were developed and evaluated, which can also be used in this challenging scenario.","Our first approach utilized different filters to supress reflections (e.g. Sobel or Canny) and image quality metrics for image comparison (e.g. MSE or SSIM) as features for different supervised classification models (e.g. SVM or k-Neighbors), which resulted in an accuracy of 84%.","The images were aligned based on the ORB algorithm, which allowed us to estimate the rotations of the prints, which may serve as an indicator for anomalies in the manufacturing process.","In our second approach, we fine-tuned different pre-trained CNN models (e.g. ResNet or VGG) for binary classification, which resulted in an accuracy of 87%.","Utilizing Grad-Cam on our fine-tuned ResNet-34, we were able to localize and visualize frequently defective bottle print regions.","This method allowed us to provide insights that could be used to optimize the actual manufacturing process.","This paper also describes our general approach and the challenges we encountered in practice with data collection during ongoing production, unsupervised preselection, and labeling."],"url":"http://arxiv.org/abs/2409.20132v1"}
{"created":"2024-09-30 09:26:19","title":"DCAST: Diverse Class-Aware Self-Training Mitigates Selection Bias for Fairer Learning","abstract":"Fairness in machine learning seeks to mitigate model bias against individuals based on sensitive features such as sex or age, often caused by an uneven representation of the population in the training data due to selection bias. Notably, bias unascribed to sensitive features is challenging to identify and typically goes undiagnosed, despite its prominence in complex high-dimensional data from fields like computer vision and molecular biomedicine. Strategies to mitigate unidentified bias and evaluate mitigation methods are crucially needed, yet remain underexplored. We introduce: (i) Diverse Class-Aware Self-Training (DCAST), model-agnostic mitigation aware of class-specific bias, which promotes sample diversity to counter confirmation bias of conventional self-training while leveraging unlabeled samples for an improved representation of the underlying population; (ii) hierarchy bias, multivariate and class-aware bias induction without prior knowledge. Models learned with DCAST showed improved robustness to hierarchy and other biases across eleven datasets, against conventional self-training and six prominent domain adaptation techniques. Advantage was largest for higher-dimensional datasets, suggesting DCAST as a promising strategy to achieve fairer learning beyond identifiable bias.","sentences":["Fairness in machine learning seeks to mitigate model bias against individuals based on sensitive features such as sex or age, often caused by an uneven representation of the population in the training data due to selection bias.","Notably, bias unascribed to sensitive features is challenging to identify and typically goes undiagnosed, despite its prominence in complex high-dimensional data from fields like computer vision and molecular biomedicine.","Strategies to mitigate unidentified bias and evaluate mitigation methods are crucially needed, yet remain underexplored.","We introduce: (i) Diverse Class-Aware Self-Training (DCAST), model-agnostic mitigation aware of class-specific bias, which promotes sample diversity to counter confirmation bias of conventional self-training while leveraging unlabeled samples for an improved representation of the underlying population; (ii) hierarchy bias, multivariate and class-aware bias induction without prior knowledge.","Models learned with DCAST showed improved robustness to hierarchy and other biases across eleven datasets, against conventional self-training and six prominent domain adaptation techniques.","Advantage was largest for higher-dimensional datasets, suggesting DCAST as a promising strategy to achieve fairer learning beyond identifiable bias."],"url":"http://arxiv.org/abs/2409.20126v1"}
{"created":"2024-09-30 09:25:59","title":"Sliding Block (Slick) Hashing: An Implementation & Benchmarks","abstract":"With hash tables being one of the most used data structures, Lehmann, Sanders and Walzer propose a novel, light-weight hash table, referred to as Slick Hash. Their idea is to hit a sweet spot between space consumption and speed. Building on the theoretical ideas by the authors, an implementation and experiments are required to evaluate the practical performance of Slick Hash. This work contributes to fulfilling this requirement by providing a basic implementation of Slick Hash, an analysis of its performance, and an evaluation of the entry deletion, focusing on the impact of backyard cleaning. The findings are discussed, and a conclusion is drawn.","sentences":["With hash tables being one of the most used data structures, Lehmann, Sanders and Walzer propose a novel, light-weight hash table, referred to as Slick Hash.","Their idea is to hit a sweet spot between space consumption and speed.","Building on the theoretical ideas by the authors, an implementation and experiments are required to evaluate the practical performance of Slick Hash.","This work contributes to fulfilling this requirement by providing a basic implementation of Slick Hash, an analysis of its performance, and an evaluation of the entry deletion, focusing on the impact of backyard cleaning.","The findings are discussed, and a conclusion is drawn."],"url":"http://arxiv.org/abs/2409.20125v1"}
{"created":"2024-09-30 09:22:15","title":"DBNode: A Decentralized Storage System for Big Data Storage in Consortium Blockchains","abstract":"Storing big data directly on a blockchain poses a substantial burden due to the need to maintain a consistent ledger across all nodes. Numerous studies in decentralized storage systems have been conducted to tackle this particular challenge. Most state-of-the-art research concentrates on developing a general storage system that can accommodate diverse blockchain categories. However, it is essential to recognize the unique attributes of a consortium blockchain, such as data privacy and access control. Beyond ensuring high performance, these specific needs are often overlooked by general storage systems. This paper proposes a decentralized storage system for Hyperledger Fabric, which is a well-known consortium blockchain. First, we employ erasure coding to partition files, subsequently organizing these chunks into a hierarchical structure that fosters efficient and dependable data storage. Second, we design a two-layer hash-slots mechanism and a mirror strategy, enabling high data availability. Third, we design an access control mechanism based on a smart contract to regulate file access.","sentences":["Storing big data directly on a blockchain poses a substantial burden due to the need to maintain a consistent ledger across all nodes.","Numerous studies in decentralized storage systems have been conducted to tackle this particular challenge.","Most state-of-the-art research concentrates on developing a general storage system that can accommodate diverse blockchain categories.","However, it is essential to recognize the unique attributes of a consortium blockchain, such as data privacy and access control.","Beyond ensuring high performance, these specific needs are often overlooked by general storage systems.","This paper proposes a decentralized storage system for Hyperledger Fabric, which is a well-known consortium blockchain.","First, we employ erasure coding to partition files, subsequently organizing these chunks into a hierarchical structure that fosters efficient and dependable data storage.","Second, we design a two-layer hash-slots mechanism and a mirror strategy, enabling high data availability.","Third, we design an access control mechanism based on a smart contract to regulate file access."],"url":"http://arxiv.org/abs/2409.20123v1"}
{"created":"2024-09-30 09:17:04","title":"Masked Autoregressive Model for Weather Forecasting","abstract":"The growing impact of global climate change amplifies the need for accurate and reliable weather forecasting. Traditional autoregressive approaches, while effective for temporal modeling, suffer from error accumulation in long-term prediction tasks. The lead time embedding method has been suggested to address this issue, but it struggles to maintain crucial correlations in atmospheric events. To overcome these challenges, we propose the Masked Autoregressive Model for Weather Forecasting (MAM4WF). This model leverages masked modeling, where portions of the input data are masked during training, allowing the model to learn robust spatiotemporal relationships by reconstructing the missing information. MAM4WF combines the advantages of both autoregressive and lead time embedding methods, offering flexibility in lead time modeling while iteratively integrating predictions. We evaluate MAM4WF across weather, climate forecasting, and video frame prediction datasets, demonstrating superior performance on five test datasets.","sentences":["The growing impact of global climate change amplifies the need for accurate and reliable weather forecasting.","Traditional autoregressive approaches, while effective for temporal modeling, suffer from error accumulation in long-term prediction tasks.","The lead time embedding method has been suggested to address this issue, but it struggles to maintain crucial correlations in atmospheric events.","To overcome these challenges, we propose the Masked Autoregressive Model for Weather Forecasting (MAM4WF).","This model leverages masked modeling, where portions of the input data are masked during training, allowing the model to learn robust spatiotemporal relationships by reconstructing the missing information.","MAM4WF combines the advantages of both autoregressive and lead time embedding methods, offering flexibility in lead time modeling while iteratively integrating predictions.","We evaluate MAM4WF across weather, climate forecasting, and video frame prediction datasets, demonstrating superior performance on five test datasets."],"url":"http://arxiv.org/abs/2409.20117v1"}
{"created":"2024-09-30 09:03:38","title":"Simple Realizability of Abstract Topological Graphs","abstract":"An abstract topological graph (AT-graph) is a pair $A=(G,\\mathcal{X})$, where $G=(V,E)$ is a graph and $\\mathcal{X} \\subseteq {E \\choose 2}$ is a set of pairs of edges of $G$. A realization of $A$ is a drawing $\\Gamma_A$ of $G$ in the plane such that any two edges $e_1,e_2$ of $G$ cross in $\\Gamma_A$ if and only if $(e_1,e_2) \\in \\mathcal{X}$; $\\Gamma_A$ is simple if any two edges intersect at most once (either at a common endpoint or at a proper crossing). The AT-graph Realizability (ATR) problem asks whether an input AT-graph admits a realization. The version of this problem that requires a simple realization is called Simple AT-graph Realizability (SATR). It is a classical result that both ATR and SATR are NP-complete.   In this paper, we study the SATR problem from a new structural perspective. More precisely, we consider the size $\\mathrm{\\lambda}(A)$ of the largest connected component of the crossing graph of any realization of $A$, i.e., the graph ${\\cal C}(A) = (E, \\mathcal{X})$. This parameter represents a natural way to measure the level of interplay among edge crossings. First, we prove that SATR is NP-complete when $\\mathrm{\\lambda}(A) \\geq 6$. On the positive side, we give an optimal linear-time algorithm that solves SATR when $\\mathrm{\\lambda}(A) \\leq 3$ and returns a simple realization if one exists. Our algorithm is based on several ingredients, in particular the reduction to a new embedding problem subject to constraints that require certain pairs of edges to alternate (in the rotation system), and a sequence of transformations that exploit the interplay between alternation constraints and the SPQR-tree and PQ-tree data structures to eventually arrive at a simpler embedding problem that can be solved with standard techniques.","sentences":["An abstract topological graph (AT-graph) is a pair $A=(G,\\mathcal{X})$, where $G=(V,E)$ is a graph and $\\mathcal{X} \\subseteq {E \\choose 2}$ is a set of pairs of edges of $G$. A realization of $A$ is a drawing $\\Gamma_A$ of $G$ in the plane such that any two edges $e_1,e_2$ of $G$ cross in $\\Gamma_A$ if and only if $(e_1,e_2) \\in \\mathcal{X}$; $\\Gamma_A$ is simple if any two edges intersect at most once (either at a common endpoint or at a proper crossing).","The AT-graph Realizability (ATR) problem asks whether an input AT-graph admits a realization.","The version of this problem that requires a simple realization is called Simple AT-graph Realizability (SATR).","It is a classical result that both ATR and SATR are NP-complete.   ","In this paper, we study the SATR problem from a new structural perspective.","More precisely, we consider the size $\\mathrm{\\lambda}(A)$ of the largest connected component of the crossing graph of any realization of $A$, i.e., the graph ${\\cal C}(A) = (E, \\mathcal{X})$.","This parameter represents a natural way to measure the level of interplay among edge crossings.","First, we prove that SATR is NP-complete when $\\mathrm{\\lambda}(A)","\\geq","6$.","On the positive side, we give an optimal linear-time algorithm that solves SATR when $\\mathrm{\\lambda}(A) \\leq 3$ and returns a simple realization if one exists.","Our algorithm is based on several ingredients, in particular the reduction to a new embedding problem subject to constraints that require certain pairs of edges to alternate (in the rotation system), and a sequence of transformations that exploit the interplay between alternation constraints and the SPQR-tree and PQ-tree data structures to eventually arrive at a simpler embedding problem that can be solved with standard techniques."],"url":"http://arxiv.org/abs/2409.20108v1"}
{"created":"2024-09-30 08:51:15","title":"FastFlow in FPGA Stacks of Data Centers","abstract":"FPGA programming is more complex as compared to Central Processing Units (CPUs) and Graphics Processing Units (GPUs). The coding languages to define the abstraction of Register Transfer Level (RTL) in High Level Synthesis (HLS) for FPGA platforms have emerged due to the laborious complexity of Hardware Description Languages (HDL). The HDL and High Level Synthesis (HLS) became complex when FPGA is adopted in high-performance parallel programs in multicore platforms of data centers. Writing an efficient host-side parallel program to control the hardware kernels placed in stacks of FPGAs is challenging and strenuous. The unavailability of efficient high level parallel programming tools for multi core architectures makes multicore parallel programming very unpopular for the masses. This work proposes an extension of FastFlow where data flows in hardware kernels can be executed efficiently in FPGA stacks. Here host side codes are generated automatically from simple csv files. The programmer needs to specify four simple parameters in these csv file: FPGA IDs, source, destination nodes, hardware kernel names. The proposed tool flow uses FastFlow libraries with Vitis to develop efficient and scalable parallel programs for FPGA stacks in data centers. The evidence from the implementation shows that the integration of FastFlow with Vitis reduces 96 % coding effort (in terms of number of lines) as compared to existing Vitis solutions.","sentences":["FPGA programming is more complex as compared to Central Processing Units (CPUs) and Graphics Processing Units (GPUs).","The coding languages to define the abstraction of Register Transfer Level (RTL) in High Level Synthesis (HLS) for FPGA platforms have emerged due to the laborious complexity of Hardware Description Languages (HDL).","The HDL and High Level Synthesis (HLS) became complex when FPGA is adopted in high-performance parallel programs in multicore platforms of data centers.","Writing an efficient host-side parallel program to control the hardware kernels placed in stacks of FPGAs is challenging and strenuous.","The unavailability of efficient high level parallel programming tools for multi core architectures makes multicore parallel programming very unpopular for the masses.","This work proposes an extension of FastFlow where data flows in hardware kernels can be executed efficiently in FPGA stacks.","Here host side codes are generated automatically from simple csv files.","The programmer needs to specify four simple parameters in these csv file: FPGA IDs, source, destination nodes, hardware kernel names.","The proposed tool flow uses FastFlow libraries with Vitis to develop efficient and scalable parallel programs for FPGA stacks in data centers.","The evidence from the implementation shows that the integration of FastFlow with Vitis reduces 96 % coding effort (in terms of number of lines) as compared to existing Vitis solutions."],"url":"http://arxiv.org/abs/2409.20099v1"}
{"created":"2024-09-30 08:50:22","title":"Learning to Discover Generalized Facial Expressions","abstract":"We introduce Facial Expression Category Discovery (FECD), a novel task in the domain of open-world facial expression recognition (O-FER). While Generalized Category Discovery (GCD) has been explored in natural image datasets, applying it to facial expressions presents unique challenges. Specifically, we identify two key biases to better understand these challenges: Theoretical Bias-arising from the introduction of new categories in unlabeled training data, and Practical Bias-stemming from the imbalanced and fine-grained nature of facial expression data. To address these challenges, we propose FER-GCD, an adversarial approach that integrates both implicit and explicit debiasing components. In the implicit debiasing process, we devise F-discrepancy, a novel metric used to estimate the upper bound of Theoretical Bias, helping the model minimize this upper bound through adversarial training. The explicit debiasing process further optimizes the feature generator and classifier to reduce Practical Bias. Extensive experiments on GCD-based FER datasets demonstrate that our FER-GCD framework significantly improves accuracy on both old and new categories, achieving an average improvement of 9.8% over the baseline and outperforming state-of-the-art methods.","sentences":["We introduce Facial Expression Category Discovery (FECD), a novel task in the domain of open-world facial expression recognition (O-FER).","While Generalized Category Discovery (GCD) has been explored in natural image datasets, applying it to facial expressions presents unique challenges.","Specifically, we identify two key biases to better understand these challenges: Theoretical Bias-arising from the introduction of new categories in unlabeled training data, and Practical Bias-stemming from the imbalanced and fine-grained nature of facial expression data.","To address these challenges, we propose FER-GCD, an adversarial approach that integrates both implicit and explicit debiasing components.","In the implicit debiasing process, we devise F-discrepancy, a novel metric used to estimate the upper bound of Theoretical Bias, helping the model minimize this upper bound through adversarial training.","The explicit debiasing process further optimizes the feature generator and classifier to reduce Practical Bias.","Extensive experiments on GCD-based FER datasets demonstrate that our FER-GCD framework significantly improves accuracy on both old and new categories, achieving an average improvement of 9.8% over the baseline and outperforming state-of-the-art methods."],"url":"http://arxiv.org/abs/2409.20098v1"}
{"created":"2024-09-30 08:46:18","title":"Continuous-Time Linear Positional Embedding for Irregular Time Series Forecasting","abstract":"Irregularly sampled time series forecasting, characterized by non-uniform intervals, is prevalent in practical applications. However, previous research have been focused on regular time series forecasting, typically relying on transformer architectures. To extend transformers to handle irregular time series, we tackle the positional embedding which represents the temporal information of the data. We propose CTLPE, a method learning a continuous linear function for encoding temporal information. The two challenges of irregular time series, inconsistent observation patterns and irregular time gaps, are solved by learning a continuous-time function and concise representation of position. Additionally, the linear continuous function is empirically shown superior to other continuous functions by learning a neural controlled differential equation-based positional embedding, and theoretically supported with properties of ideal positional embedding. CTLPE outperforms existing techniques across various irregularly-sampled time series datasets, showcasing its enhanced efficacy.","sentences":["Irregularly sampled time series forecasting, characterized by non-uniform intervals, is prevalent in practical applications.","However, previous research have been focused on regular time series forecasting, typically relying on transformer architectures.","To extend transformers to handle irregular time series, we tackle the positional embedding which represents the temporal information of the data.","We propose CTLPE, a method learning a continuous linear function for encoding temporal information.","The two challenges of irregular time series, inconsistent observation patterns and irregular time gaps, are solved by learning a continuous-time function and concise representation of position.","Additionally, the linear continuous function is empirically shown superior to other continuous functions by learning a neural controlled differential equation-based positional embedding, and theoretically supported with properties of ideal positional embedding.","CTLPE outperforms existing techniques across various irregularly-sampled time series datasets, showcasing its enhanced efficacy."],"url":"http://arxiv.org/abs/2409.20092v1"}
{"created":"2024-09-30 08:33:50","title":"SurgPETL: Parameter-Efficient Image-to-Surgical-Video Transfer Learning for Surgical Phase Recognition","abstract":"Capitalizing on image-level pre-trained models for various downstream tasks has recently emerged with promising performance. However, the paradigm of \"image pre-training followed by video fine-tuning\" for high-dimensional video data inevitably poses significant performance bottlenecks. Furthermore, in the medical domain, many surgical video tasks encounter additional challenges posed by the limited availability of video data and the necessity for comprehensive spatial-temporal modeling. Recently, Parameter-Efficient Image-to-Video Transfer Learning has emerged as an efficient and effective paradigm for video action recognition tasks, which employs image-level pre-trained models with promising feature transferability and involves cross-modality temporal modeling with minimal fine-tuning. Nevertheless, the effectiveness and generalizability of this paradigm within intricate surgical domain remain unexplored. In this paper, we delve into a novel problem of efficiently adapting image-level pre-trained models to specialize in fine-grained surgical phase recognition, termed as Parameter-Efficient Image-to-Surgical-Video Transfer Learning. Firstly, we develop a parameter-efficient transfer learning benchmark SurgPETL for surgical phase recognition, and conduct extensive experiments with three advanced methods based on ViTs of two distinct scales pre-trained on five large-scale natural and medical datasets. Then, we introduce the Spatial-Temporal Adaptation module, integrating a standard spatial adapter with a novel temporal adapter to capture detailed spatial features and establish connections across temporal sequences for robust spatial-temporal modeling. Extensive experiments on three challenging datasets spanning various surgical procedures demonstrate the effectiveness of SurgPETL with STA.","sentences":["Capitalizing on image-level pre-trained models for various downstream tasks has recently emerged with promising performance.","However, the paradigm of \"image pre-training followed by video fine-tuning\" for high-dimensional video data inevitably poses significant performance bottlenecks.","Furthermore, in the medical domain, many surgical video tasks encounter additional challenges posed by the limited availability of video data and the necessity for comprehensive spatial-temporal modeling.","Recently, Parameter-Efficient Image-to-Video Transfer Learning has emerged as an efficient and effective paradigm for video action recognition tasks, which employs image-level pre-trained models with promising feature transferability and involves cross-modality temporal modeling with minimal fine-tuning.","Nevertheless, the effectiveness and generalizability of this paradigm within intricate surgical domain remain unexplored.","In this paper, we delve into a novel problem of efficiently adapting image-level pre-trained models to specialize in fine-grained surgical phase recognition, termed as Parameter-Efficient Image-to-Surgical-Video Transfer Learning.","Firstly, we develop a parameter-efficient transfer learning benchmark SurgPETL for surgical phase recognition, and conduct extensive experiments with three advanced methods based on ViTs of two distinct scales pre-trained on five large-scale natural and medical datasets.","Then, we introduce the Spatial-Temporal Adaptation module, integrating a standard spatial adapter with a novel temporal adapter to capture detailed spatial features and establish connections across temporal sequences for robust spatial-temporal modeling.","Extensive experiments on three challenging datasets spanning various surgical procedures demonstrate the effectiveness of SurgPETL with STA."],"url":"http://arxiv.org/abs/2409.20083v1"}
{"created":"2024-09-30 08:31:14","title":"ProFD: Prompt-Guided Feature Disentangling for Occluded Person Re-Identification","abstract":"To address the occlusion issues in person Re-Identification (ReID) tasks, many methods have been proposed to extract part features by introducing external spatial information. However, due to missing part appearance information caused by occlusion and noisy spatial information from external model, these purely vision-based approaches fail to correctly learn the features of human body parts from limited training data and struggle in accurately locating body parts, ultimately leading to misaligned part features. To tackle these challenges, we propose a Prompt-guided Feature Disentangling method (ProFD), which leverages the rich pre-trained knowledge in the textual modality facilitate model to generate well-aligned part features. ProFD first designs part-specific prompts and utilizes noisy segmentation mask to preliminarily align visual and textual embedding, enabling the textual prompts to have spatial awareness. Furthermore, to alleviate the noise from external masks, ProFD adopts a hybrid-attention decoder, ensuring spatial and semantic consistency during the decoding process to minimize noise impact. Additionally, to avoid catastrophic forgetting, we employ a self-distillation strategy, retaining pre-trained knowledge of CLIP to mitigate over-fitting. Evaluation results on the Market1501, DukeMTMC-ReID, Occluded-Duke, Occluded-ReID, and P-DukeMTMC datasets demonstrate that ProFD achieves state-of-the-art results. Our project is available at: https://github.com/Cuixxx/ProFD.","sentences":["To address the occlusion issues in person Re-Identification (ReID) tasks, many methods have been proposed to extract part features by introducing external spatial information.","However, due to missing part appearance information caused by occlusion and noisy spatial information from external model, these purely vision-based approaches fail to correctly learn the features of human body parts from limited training data and struggle in accurately locating body parts, ultimately leading to misaligned part features.","To tackle these challenges, we propose a Prompt-guided Feature Disentangling method (ProFD), which leverages the rich pre-trained knowledge in the textual modality facilitate model to generate well-aligned part features.","ProFD first designs part-specific prompts and utilizes noisy segmentation mask to preliminarily align visual and textual embedding, enabling the textual prompts to have spatial awareness.","Furthermore, to alleviate the noise from external masks, ProFD adopts a hybrid-attention decoder, ensuring spatial and semantic consistency during the decoding process to minimize noise impact.","Additionally, to avoid catastrophic forgetting, we employ a self-distillation strategy, retaining pre-trained knowledge of CLIP to mitigate over-fitting.","Evaluation results on the Market1501, DukeMTMC-ReID, Occluded-Duke, Occluded-ReID, and P-DukeMTMC datasets demonstrate that ProFD achieves state-of-the-art results.","Our project is available at: https://github.com/Cuixxx/ProFD."],"url":"http://arxiv.org/abs/2409.20081v1"}
{"created":"2024-09-30 08:22:21","title":"Whole-Graph Representation Learning For the Classification of Signed Networks","abstract":"Graphs are ubiquitous for modeling complex systems involving structured data and relationships. Consequently, graph representation learning, which aims to automatically learn low-dimensional representations of graphs, has drawn a lot of attention in recent years. The overwhelming majority of existing methods handle unsigned graphs. However, signed graphs appear in an increasing number of application domains to model systems involving two types of opposed relationships. Several authors took an interest in signed graphs and proposed methods for providing vertex-level representations, but only one exists for whole-graph representations, and it can handle only fully connected graphs. In this article, we tackle this issue by proposing two approaches to learning whole-graph representations of general signed graphs. The first is a SG2V, a signed generalization of the whole-graph embedding method Graph2vec that relies on a modification of the Weisfeiler--Lehman relabelling procedure. The second one is WSGCN, a whole-graph generalization of the signed vertex embedding method SGCN that relies on the introduction of master nodes into the GCN. We propose several variants of both these approaches. A bottleneck in the development of whole-graph-oriented methods is the lack of data. We constitute a benchmark composed of three collections of signed graphs with corresponding ground truths. We assess our methods on this benchmark, and our results show that the signed whole-graph methods learn better representations for this task. Overall, the baseline obtains an F-measure score of 58.57, when SG2V and WSGCN reach 73.01 and 81.20, respectively. Our source code and benchmark dataset are both publicly available online.","sentences":["Graphs are ubiquitous for modeling complex systems involving structured data and relationships.","Consequently, graph representation learning, which aims to automatically learn low-dimensional representations of graphs, has drawn a lot of attention in recent years.","The overwhelming majority of existing methods handle unsigned graphs.","However, signed graphs appear in an increasing number of application domains to model systems involving two types of opposed relationships.","Several authors took an interest in signed graphs and proposed methods for providing vertex-level representations, but only one exists for whole-graph representations, and it can handle only fully connected graphs.","In this article, we tackle this issue by proposing two approaches to learning whole-graph representations of general signed graphs.","The first is a SG2V, a signed generalization of the whole-graph embedding method Graph2vec that relies on a modification of the Weisfeiler--Lehman relabelling procedure.","The second one is WSGCN, a whole-graph generalization of the signed vertex embedding method SGCN that relies on the introduction of master nodes into the GCN.","We propose several variants of both these approaches.","A bottleneck in the development of whole-graph-oriented methods is the lack of data.","We constitute a benchmark composed of three collections of signed graphs with corresponding ground truths.","We assess our methods on this benchmark, and our results show that the signed whole-graph methods learn better representations for this task.","Overall, the baseline obtains an F-measure score of 58.57, when SG2V and WSGCN reach 73.01 and 81.20, respectively.","Our source code and benchmark dataset are both publicly available online."],"url":"http://arxiv.org/abs/2409.20073v1"}
{"created":"2024-09-30 08:07:29","title":"Knowledge Discovery using Unsupervised Cognition","abstract":"Knowledge discovery is key to understand and interpret a dataset, as well as to find the underlying relationships between its components. Unsupervised Cognition is a novel unsupervised learning algorithm that focus on modelling the learned data. This paper presents three techniques to perform knowledge discovery over an already trained Unsupervised Cognition model. Specifically, we present a technique for pattern mining, a technique for feature selection based on the previous pattern mining technique, and a technique for dimensionality reduction based on the previous feature selection technique. The final goal is to distinguish between relevant and irrelevant features and use them to build a model from which to extract meaningful patterns. We evaluated our proposals with empirical experiments and found that they overcome the state-of-the-art in knowledge discovery.","sentences":["Knowledge discovery is key to understand and interpret a dataset, as well as to find the underlying relationships between its components.","Unsupervised Cognition is a novel unsupervised learning algorithm that focus on modelling the learned data.","This paper presents three techniques to perform knowledge discovery over an already trained Unsupervised Cognition model.","Specifically, we present a technique for pattern mining, a technique for feature selection based on the previous pattern mining technique, and a technique for dimensionality reduction based on the previous feature selection technique.","The final goal is to distinguish between relevant and irrelevant features and use them to build a model from which to extract meaningful patterns.","We evaluated our proposals with empirical experiments and found that they overcome the state-of-the-art in knowledge discovery."],"url":"http://arxiv.org/abs/2409.20064v1"}
{"created":"2024-09-30 08:01:44","title":"Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis","abstract":"Neural metrics for machine translation (MT) evaluation have become increasingly prominent due to their superior correlation with human judgments compared to traditional lexical metrics. Researchers have therefore utilized neural metrics through quality-informed decoding strategies, achieving better results than likelihood-based methods. With the rise of Large Language Models (LLMs), preference-based alignment techniques have gained attention for their potential to enhance translation quality by optimizing model weights directly on preferences induced by quality estimators. This study focuses on Contrastive Preference Optimization (CPO) and conducts extensive experiments to evaluate the impact of preference-based alignment on translation quality. Our findings indicate that while CPO consistently outperforms Supervised Fine-Tuning (SFT) on high-quality data with regard to the alignment metric, it may lead to instability across downstream evaluation metrics, particularly between neural and lexical ones. Additionally, we demonstrate that relying solely on the base model for generating candidate translations achieves performance comparable to using multiple external systems, while ensuring better consistency across downstream metrics.","sentences":["Neural metrics for machine translation (MT) evaluation have become increasingly prominent due to their superior correlation with human judgments compared to traditional lexical metrics.","Researchers have therefore utilized neural metrics through quality-informed decoding strategies, achieving better results than likelihood-based methods.","With the rise of Large Language Models (LLMs), preference-based alignment techniques have gained attention for their potential to enhance translation quality by optimizing model weights directly on preferences induced by quality estimators.","This study focuses on Contrastive Preference Optimization (CPO) and conducts extensive experiments to evaluate the impact of preference-based alignment on translation quality.","Our findings indicate that while CPO consistently outperforms Supervised Fine-Tuning (SFT) on high-quality data with regard to the alignment metric, it may lead to instability across downstream evaluation metrics, particularly between neural and lexical ones.","Additionally, we demonstrate that relying solely on the base model for generating candidate translations achieves performance comparable to using multiple external systems, while ensuring better consistency across downstream metrics."],"url":"http://arxiv.org/abs/2409.20059v1"}
{"created":"2024-09-30 07:59:41","title":"Evaluating and explaining training strategies for zero-shot cross-lingual news sentiment analysis","abstract":"We investigate zero-shot cross-lingual news sentiment detection, aiming to develop robust sentiment classifiers that can be deployed across multiple languages without target-language training data. We introduce novel evaluation datasets in several less-resourced languages, and experiment with a range of approaches including the use of machine translation; in-context learning with large language models; and various intermediate training regimes including a novel task objective, POA, that leverages paragraph-level information. Our results demonstrate significant improvements over the state of the art, with in-context learning generally giving the best performance, but with the novel POA approach giving a competitive alternative with much lower computational overhead. We also show that language similarity is not in itself sufficient for predicting the success of cross-lingual transfer, but that similarity in semantic content and structure can be equally important.","sentences":["We investigate zero-shot cross-lingual news sentiment detection, aiming to develop robust sentiment classifiers that can be deployed across multiple languages without target-language training data.","We introduce novel evaluation datasets in several less-resourced languages, and experiment with a range of approaches including the use of machine translation; in-context learning with large language models; and various intermediate training regimes including a novel task objective, POA, that leverages paragraph-level information.","Our results demonstrate significant improvements over the state of the art, with in-context learning generally giving the best performance, but with the novel POA approach giving a competitive alternative with much lower computational overhead.","We also show that language similarity is not in itself sufficient for predicting the success of cross-lingual transfer, but that similarity in semantic content and structure can be equally important."],"url":"http://arxiv.org/abs/2409.20054v1"}
{"created":"2024-09-30 07:59:10","title":"GUNDAM: Aligning Large Language Models with Graph Understanding","abstract":"Large Language Models (LLMs) have achieved impressive results in processing text data, which has sparked interest in applying these models beyond textual data, such as graphs. In the field of graph learning, there is a growing interest in harnessing LLMs to comprehend and manipulate graph-structured data. Existing research predominantly focuses on graphs with rich textual features, such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to process text but inadequately addressing graph structure. This work specifically aims to assess and enhance LLMs' abilities to comprehend and utilize the structural knowledge inherent in graph data itself, rather than focusing solely on graphs rich in textual content. To achieve this, we introduce the \\textbf{G}raph \\textbf{U}nderstanding for \\textbf{N}atural Language \\textbf{D}riven \\textbf{A}nalytical \\textbf{M}odel (\\model). This model adapts LLMs to better understand and engage with the structure of graph data, enabling them to perform complex reasoning tasks by leveraging the graph's structure itself. Our experimental evaluations on graph reasoning benchmarks not only substantiate that \\model~ outperforms the SOTA baselines for comparisons. But also reveals key factors affecting the graph reasoning capabilities of LLMs. Moreover, we provide a theoretical analysis illustrating how reasoning paths can enhance LLMs' reasoning capabilities.","sentences":["Large Language Models (LLMs) have achieved impressive results in processing text data, which has sparked interest in applying these models beyond textual data, such as graphs.","In the field of graph learning, there is a growing interest in harnessing LLMs to comprehend and manipulate graph-structured data.","Existing research predominantly focuses on graphs with rich textual features, such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to process text but inadequately addressing graph structure.","This work specifically aims to assess and enhance LLMs' abilities to comprehend and utilize the structural knowledge inherent in graph data itself, rather than focusing solely on graphs rich in textual content.","To achieve this, we introduce the \\textbf{G}raph \\textbf{U}nderstanding for \\textbf{N}atural Language \\textbf{D}riven \\textbf{A}nalytical \\textbf{M}odel (\\model).","This model adapts LLMs to better understand and engage with the structure of graph data, enabling them to perform complex reasoning tasks by leveraging the graph's structure itself.","Our experimental evaluations on graph reasoning benchmarks not only substantiate that \\model~ outperforms the SOTA baselines for comparisons.","But also reveals key factors affecting the graph reasoning capabilities of LLMs.","Moreover, we provide a theoretical analysis illustrating how reasoning paths can enhance LLMs' reasoning capabilities."],"url":"http://arxiv.org/abs/2409.20053v1"}
{"created":"2024-09-30 07:53:39","title":"Depression detection in social media posts using transformer-based models and auxiliary features","abstract":"The detection of depression in social media posts is crucial due to the increasing prevalence of mental health issues. Traditional machine learning algorithms often fail to capture intricate textual patterns, limiting their effectiveness in identifying depression. Existing studies have explored various approaches to this problem but often fall short in terms of accuracy and robustness. To address these limitations, this research proposes a neural network architecture leveraging transformer-based models combined with metadata and linguistic markers. The study employs DistilBERT, extracting information from the last four layers of the transformer, applying learned weights, and averaging them to create a rich representation of the input text. This representation, augmented by metadata and linguistic markers, enhances the model's comprehension of each post. Dropout layers prevent overfitting, and a Multilayer Perceptron (MLP) is used for final classification. Data augmentation techniques, inspired by the Easy Data Augmentation (EDA) methods, are also employed to improve model performance. Using BERT, random insertion and substitution of phrases generate additional training data, focusing on balancing the dataset by augmenting underrepresented classes. The proposed model achieves weighted Precision, Recall, and F1-scores of 84.26%, 84.18%, and 84.15%, respectively. The augmentation techniques significantly enhance model performance, increasing the weighted F1-score from 72.59% to 84.15%.","sentences":["The detection of depression in social media posts is crucial due to the increasing prevalence of mental health issues.","Traditional machine learning algorithms often fail to capture intricate textual patterns, limiting their effectiveness in identifying depression.","Existing studies have explored various approaches to this problem but often fall short in terms of accuracy and robustness.","To address these limitations, this research proposes a neural network architecture leveraging transformer-based models combined with metadata and linguistic markers.","The study employs DistilBERT, extracting information from the last four layers of the transformer, applying learned weights, and averaging them to create a rich representation of the input text.","This representation, augmented by metadata and linguistic markers, enhances the model's comprehension of each post.","Dropout layers prevent overfitting, and a Multilayer Perceptron (MLP) is used for final classification.","Data augmentation techniques, inspired by the Easy Data Augmentation (EDA) methods, are also employed to improve model performance.","Using BERT, random insertion and substitution of phrases generate additional training data, focusing on balancing the dataset by augmenting underrepresented classes.","The proposed model achieves weighted Precision, Recall, and F1-scores of 84.26%, 84.18%, and 84.15%, respectively.","The augmentation techniques significantly enhance model performance, increasing the weighted F1-score from 72.59% to 84.15%."],"url":"http://arxiv.org/abs/2409.20048v1"}
{"created":"2024-09-30 07:49:30","title":"OPONeRF: One-Point-One NeRF for Robust Neural Rendering","abstract":"In this paper, we propose a One-Point-One NeRF (OPONeRF) framework for robust scene rendering. Existing NeRFs are designed based on a key assumption that the target scene remains unchanged between the training and test time. However, small but unpredictable perturbations such as object movements, light changes and data contaminations broadly exist in real-life 3D scenes, which lead to significantly defective or failed rendering results even for the recent state-of-the-art generalizable methods. To address this, we propose a divide-and-conquer framework in OPONeRF that adaptively responds to local scene variations via personalizing appropriate point-wise parameters, instead of fitting a single set of NeRF parameters that are inactive to test-time unseen changes. Moreover, to explicitly capture the local uncertainty, we decompose the point representation into deterministic mapping and probabilistic inference. In this way, OPONeRF learns the sharable invariance and unsupervisedly models the unexpected scene variations between the training and testing scenes. To validate the effectiveness of the proposed method, we construct benchmarks from both realistic and synthetic data with diverse test-time perturbations including foreground motions, illumination variations and multi-modality noises, which are more challenging than conventional generalization and temporal reconstruction benchmarks. Experimental results show that our OPONeRF outperforms state-of-the-art NeRFs on various evaluation metrics through benchmark experiments and cross-scene evaluations. We further show the efficacy of the proposed method via experimenting on other existing generalization-based benchmarks and incorporating the idea of One-Point-One NeRF into other advanced baseline methods.","sentences":["In this paper, we propose a One-Point-One NeRF (OPONeRF) framework for robust scene rendering.","Existing NeRFs are designed based on a key assumption that the target scene remains unchanged between the training and test time.","However, small but unpredictable perturbations such as object movements, light changes and data contaminations broadly exist in real-life 3D scenes, which lead to significantly defective or failed rendering results even for the recent state-of-the-art generalizable methods.","To address this, we propose a divide-and-conquer framework in OPONeRF that adaptively responds to local scene variations via personalizing appropriate point-wise parameters, instead of fitting a single set of NeRF parameters that are inactive to test-time unseen changes.","Moreover, to explicitly capture the local uncertainty, we decompose the point representation into deterministic mapping and probabilistic inference.","In this way, OPONeRF learns the sharable invariance and unsupervisedly models the unexpected scene variations between the training and testing scenes.","To validate the effectiveness of the proposed method, we construct benchmarks from both realistic and synthetic data with diverse test-time perturbations including foreground motions, illumination variations and multi-modality noises, which are more challenging than conventional generalization and temporal reconstruction benchmarks.","Experimental results show that our OPONeRF outperforms state-of-the-art NeRFs on various evaluation metrics through benchmark experiments and cross-scene evaluations.","We further show the efficacy of the proposed method via experimenting on other existing generalization-based benchmarks and incorporating the idea of One-Point-One NeRF into other advanced baseline methods."],"url":"http://arxiv.org/abs/2409.20043v1"}
{"created":"2024-09-30 07:35:50","title":"Acceleration Meets Inverse Maintenance: Faster $\\ell_{\\infty}$-Regression","abstract":"We propose a randomized multiplicative weight update (MWU) algorithm for $\\ell_{\\infty}$ regression that runs in $\\widetilde{O}\\left(n^{2+1/22.5} \\text{poly}(1/\\epsilon)\\right)$ time when $\\omega = 2+o(1)$, improving upon the previous best $\\widetilde{O}\\left(n^{2+1/18} \\text{poly} \\log(1/\\epsilon)\\right)$ runtime in the low-accuracy regime. Our algorithm combines state-of-the-art inverse maintenance data structures with acceleration. In order to do so, we propose a novel acceleration scheme for MWU that exhibits {\\it stabiliy} and {\\it robustness}, which are required for the efficient implementations of the inverse maintenance data structures.   We also design a faster {\\it deterministic} MWU algorithm that runs in $\\widetilde{O}\\left(n^{2+1/12}\\text{poly}(1/\\epsilon)\\right))$ time when $\\omega = 2+o(1)$, improving upon the previous best $\\widetilde{O}\\left(n^{2+1/6} \\text{poly} \\log(1/\\epsilon)\\right)$ runtime in the low-accuracy regime. We achieve this by showing a novel stability result that goes beyond the previous known works based on interior point methods (IPMs).   Our work is the first to use acceleration and inverse maintenance together efficiently, finally making the two most important building blocks of modern structured convex optimization compatible.","sentences":["We propose a randomized multiplicative weight update (MWU) algorithm for $\\ell_{\\infty}$ regression that runs in $\\widetilde{O}\\left(n^{2+1/22.5} \\text{poly}(1/\\epsilon)\\right)$ time when $\\omega = 2+o(1)$, improving upon the previous best $\\widetilde{O}\\left(n^{2+1/18} \\text{poly} \\log(1/\\epsilon)\\right)$ runtime in the low-accuracy regime.","Our algorithm combines state-of-the-art inverse maintenance data structures with acceleration.","In order to do so, we propose a novel acceleration scheme for MWU that exhibits {\\it stabiliy} and {\\it robustness}, which are required for the efficient implementations of the inverse maintenance data structures.   ","We also design a faster {\\it deterministic} MWU algorithm that runs in $\\widetilde{O}\\left(n^{2+1/12}\\text{poly}(1/\\epsilon)\\right))$ time when $\\omega = 2+o(1)$, improving upon the previous best $\\widetilde{O}\\left(n^{2+1/6} \\text{poly} \\log(1/\\epsilon)\\right)$ runtime in the low-accuracy regime.","We achieve this by showing a novel stability result that goes beyond the previous known works based on interior point methods (IPMs).   ","Our work is the first to use acceleration and inverse maintenance together efficiently, finally making the two most important building blocks of modern structured convex optimization compatible."],"url":"http://arxiv.org/abs/2409.20030v1"}
{"created":"2024-09-30 07:25:16","title":"Visual Context Window Extension: A New Perspective for Long Video Understanding","abstract":"Large Multimodal Models (LMMs) have demonstrated impressive performance in short video understanding tasks but face great challenges when applied to long video understanding. In contrast, Large Language Models (LLMs) exhibit outstanding capabilities in modeling long texts. Existing work attempts to address this issue by introducing long video-text pairs during training. However, these approaches require substantial computational and data resources. In this paper, we tackle the challenge of long video understanding from the perspective of context windows, aiming to apply LMMs to long video tasks without retraining on long video datasets. We first conduct an in-depth analysis of why pretrained LMMs struggle to understand lengthy video content, identifying that discrepancies between visual and language modalities lead to different context windows for visual and language tokens, making it difficult to directly extend the visual tokens to match the language context window. Based on this, we propose to adapt LMMs for long video understanding tasks by extending the visual context window, eliminating the need for retraining on large scalelong video datasets. To further mitigate the significant memory consumption caused by long sequences, we introduce a progressive pooling inference strategy that selectively adjusts the spatial resolution of frame embeddings, reducing the number of visual tokens while retaining important spatial information. Across multiple long video understanding benchmarks, our method consistently improves the performance as the number of video frames increases. On the MLVU benchmark, our method outperforms GPT-4o, even though our model size is only 7B. Additionally, in the 256-frame setting, our method reduces memory usage by approximately 45% compared to the baseline, without introducing any performance loss.","sentences":["Large Multimodal Models (LMMs) have demonstrated impressive performance in short video understanding tasks but face great challenges when applied to long video understanding.","In contrast, Large Language Models (LLMs) exhibit outstanding capabilities in modeling long texts.","Existing work attempts to address this issue by introducing long video-text pairs during training.","However, these approaches require substantial computational and data resources.","In this paper, we tackle the challenge of long video understanding from the perspective of context windows, aiming to apply LMMs to long video tasks without retraining on long video datasets.","We first conduct an in-depth analysis of why pretrained LMMs struggle to understand lengthy video content, identifying that discrepancies between visual and language modalities lead to different context windows for visual and language tokens, making it difficult to directly extend the visual tokens to match the language context window.","Based on this, we propose to adapt LMMs for long video understanding tasks by extending the visual context window, eliminating the need for retraining on large scalelong video datasets.","To further mitigate the significant memory consumption caused by long sequences, we introduce a progressive pooling inference strategy that selectively adjusts the spatial resolution of frame embeddings, reducing the number of visual tokens while retaining important spatial information.","Across multiple long video understanding benchmarks, our method consistently improves the performance as the number of video frames increases.","On the MLVU benchmark, our method outperforms GPT-4o, even though our model size is only 7B. Additionally, in the 256-frame setting, our method reduces memory usage by approximately 45% compared to the baseline, without introducing any performance loss."],"url":"http://arxiv.org/abs/2409.20018v1"}
{"created":"2024-09-30 07:14:31","title":"Towards Robust Multimodal Sentiment Analysis with Incomplete Data","abstract":"The field of Multimodal Sentiment Analysis (MSA) has recently witnessed an emerging direction seeking to tackle the issue of data incompleteness. Recognizing that the language modality typically contains dense sentiment information, we consider it as the dominant modality and present an innovative Language-dominated Noise-resistant Learning Network (LNLN) to achieve robust MSA. The proposed LNLN features a dominant modality correction (DMC) module and dominant modality based multimodal learning (DMML) module, which enhances the model's robustness across various noise scenarios by ensuring the quality of dominant modality representations. Aside from the methodical design, we perform comprehensive experiments under random data missing scenarios, utilizing diverse and meaningful settings on several popular datasets (\\textit{e.g.,} MOSI, MOSEI, and SIMS), providing additional uniformity, transparency, and fairness compared to existing evaluations in the literature. Empirically, LNLN consistently outperforms existing baselines, demonstrating superior performance across these challenging and extensive evaluation metrics.","sentences":["The field of Multimodal Sentiment Analysis (MSA) has recently witnessed an emerging direction seeking to tackle the issue of data incompleteness.","Recognizing that the language modality typically contains dense sentiment information, we consider it as the dominant modality and present an innovative Language-dominated Noise-resistant Learning Network (LNLN) to achieve robust MSA.","The proposed LNLN features a dominant modality correction (DMC) module and dominant modality based multimodal learning (DMML) module, which enhances the model's robustness across various noise scenarios by ensuring the quality of dominant modality representations.","Aside from the methodical design, we perform comprehensive experiments under random data missing scenarios, utilizing diverse and meaningful settings on several popular datasets (\\textit{e.g.,} MOSI, MOSEI, and SIMS), providing additional uniformity, transparency, and fairness compared to existing evaluations in the literature.","Empirically, LNLN consistently outperforms existing baselines, demonstrating superior performance across these challenging and extensive evaluation metrics."],"url":"http://arxiv.org/abs/2409.20012v1"}
{"created":"2024-09-30 07:08:28","title":"Customized Information and Domain-centric Knowledge Graph Construction with Large Language Models","abstract":"In this paper we propose a novel approach based on knowledge graphs to provide timely access to structured information, to enable actionable technology intelligence, and improve cyber-physical systems planning. Our framework encompasses a text mining process, which includes information retrieval, keyphrase extraction, semantic network creation, and topic map visualization. Following this data exploration process, we employ a selective knowledge graph construction (KGC) approach supported by an electronics and innovation ontology-backed pipeline for multi-objective decision-making with a focus on cyber-physical systems. We apply our methodology to the domain of automotive electrical systems to demonstrate the approach, which is scalable. Our results demonstrate that our construction process outperforms GraphGPT as well as our bi-LSTM and transformer REBEL with a pre-defined dataset by several times in terms of class recognition, relationship construction and correct \"sublass of\" categorization. Additionally, we outline reasoning applications and provide a comparison with Wikidata to show the differences and advantages of the approach.","sentences":["In this paper we propose a novel approach based on knowledge graphs to provide timely access to structured information, to enable actionable technology intelligence, and improve cyber-physical systems planning.","Our framework encompasses a text mining process, which includes information retrieval, keyphrase extraction, semantic network creation, and topic map visualization.","Following this data exploration process, we employ a selective knowledge graph construction (KGC) approach supported by an electronics and innovation ontology-backed pipeline for multi-objective decision-making with a focus on cyber-physical systems.","We apply our methodology to the domain of automotive electrical systems to demonstrate the approach, which is scalable.","Our results demonstrate that our construction process outperforms GraphGPT as well as our bi-LSTM and transformer REBEL with a pre-defined dataset by several times in terms of class recognition, relationship construction and correct \"sublass of\" categorization.","Additionally, we outline reasoning applications and provide a comparison with Wikidata to show the differences and advantages of the approach."],"url":"http://arxiv.org/abs/2409.20010v1"}
{"created":"2024-09-30 06:57:30","title":"Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification","abstract":"Transfer learning is a common practice that alleviates the need for extensive data to train neural networks. It is performed by pre-training a model using a source dataset and fine-tuning it for a target task. However, not every source dataset is appropriate for each target dataset, especially for time series. In this paper, we propose a novel method of selecting and using multiple datasets for transfer learning for time series classification. Specifically, our method combines multiple datasets as one source dataset for pre-training neural networks. Furthermore, for selecting multiple sources, our method measures the transferability of datasets based on shapelet discovery for effective source selection. While traditional transferability measures require considerable time for pre-training all the possible sources for source selection of each possible architecture, our method can be repeatedly used for every possible architecture with a single simple computation. Using the proposed method, we demonstrate that it is possible to increase the performance of temporal convolutional neural networks (CNN) on time series datasets.","sentences":["Transfer learning is a common practice that alleviates the need for extensive data to train neural networks.","It is performed by pre-training a model using a source dataset and fine-tuning it for a target task.","However, not every source dataset is appropriate for each target dataset, especially for time series.","In this paper, we propose a novel method of selecting and using multiple datasets for transfer learning for time series classification.","Specifically, our method combines multiple datasets as one source dataset for pre-training neural networks.","Furthermore, for selecting multiple sources, our method measures the transferability of datasets based on shapelet discovery for effective source selection.","While traditional transferability measures require considerable time for pre-training all the possible sources for source selection of each possible architecture, our method can be repeatedly used for every possible architecture with a single simple computation.","Using the proposed method, we demonstrate that it is possible to increase the performance of temporal convolutional neural networks (CNN) on time series datasets."],"url":"http://arxiv.org/abs/2409.20005v1"}
{"created":"2024-09-30 06:50:18","title":"Do Influence Functions Work on Large Language Models?","abstract":"Influence functions aim to quantify the impact of individual training data points on a model's predictions. While extensive research has been conducted on influence functions in traditional machine learning models, their application to large language models (LLMs) has been limited. In this work, we conduct a systematic study to address a key question: do influence functions work on LLMs? Specifically, we evaluate influence functions across multiple tasks and find that they consistently perform poorly in most settings. Our further investigation reveals that their poor performance can be attributed to: (1) inevitable approximation errors when estimating the iHVP component due to the scale of LLMs, (2) uncertain convergence during fine-tuning, and, more fundamentally, (3) the definition itself, as changes in model parameters do not necessarily correlate with changes in LLM behavior. Our study thus suggests the need for alternative approaches for identifying influential samples. To support future work, our code is made available at https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs.","sentences":["Influence functions aim to quantify the impact of individual training data points on a model's predictions.","While extensive research has been conducted on influence functions in traditional machine learning models, their application to large language models (LLMs) has been limited.","In this work, we conduct a systematic study to address a key question: do influence functions work on LLMs?","Specifically, we evaluate influence functions across multiple tasks and find that they consistently perform poorly in most settings.","Our further investigation reveals that their poor performance can be attributed to: (1) inevitable approximation errors when estimating the iHVP component due to the scale of LLMs, (2) uncertain convergence during fine-tuning, and, more fundamentally, (3) the definition itself, as changes in model parameters do not necessarily correlate with changes in LLM behavior.","Our study thus suggests the need for alternative approaches for identifying influential samples.","To support future work, our code is made available at https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs."],"url":"http://arxiv.org/abs/2409.19998v1"}
{"created":"2024-09-30 06:31:36","title":"Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges","abstract":"The advancement of Large Language Models (LLMs) has significantly impacted various domains, including Web search, healthcare, and software development. However, as these models scale, they become more vulnerable to cybersecurity risks, particularly backdoor attacks. By exploiting the potent memorization capacity of LLMs, adversaries can easily inject backdoors into LLMs by manipulating a small portion of training data, leading to malicious behaviors in downstream applications whenever the hidden backdoor is activated by the pre-defined triggers. Moreover, emerging learning paradigms like instruction tuning and reinforcement learning from human feedback (RLHF) exacerbate these risks as they rely heavily on crowdsourced data and human feedback, which are not fully controlled. In this paper, we present a comprehensive survey of emerging backdoor threats to LLMs that appear during LLM development or inference, and cover recent advancement in both defense and detection strategies for mitigating backdoor threats to LLMs. We also outline key challenges in addressing these threats, highlighting areas for future research.","sentences":["The advancement of Large Language Models (LLMs) has significantly impacted various domains, including Web search, healthcare, and software development.","However, as these models scale, they become more vulnerable to cybersecurity risks, particularly backdoor attacks.","By exploiting the potent memorization capacity of LLMs, adversaries can easily inject backdoors into LLMs by manipulating a small portion of training data, leading to malicious behaviors in downstream applications whenever the hidden backdoor is activated by the pre-defined triggers.","Moreover, emerging learning paradigms like instruction tuning and reinforcement learning from human feedback (RLHF) exacerbate these risks as they rely heavily on crowdsourced data and human feedback, which are not fully controlled.","In this paper, we present a comprehensive survey of emerging backdoor threats to LLMs that appear during LLM development or inference, and cover recent advancement in both defense and detection strategies for mitigating backdoor threats to LLMs.","We also outline key challenges in addressing these threats, highlighting areas for future research."],"url":"http://arxiv.org/abs/2409.19993v1"}
{"created":"2024-09-30 06:30:33","title":"A large-scale operational study of fingerprint quality and demographics","abstract":"Even though a few initial works have shown on small sets of data some level of bias in the performance of fingerprint recognition technology with respect to certain demographic groups, there is still not sufficient evidence to understand the impact that certain factors such as gender, age or finger-type may have on fingerprint quality and, in turn, also on fingerprint matching accuracy. The present work addresses this still under researched topic, on a large-scale database of operational data containing 10-print impressions of almost 16,000 subjects. The results reached provide further insight into the dependency of fingerprint quality and demographics, and show that there in fact exists a certain degree of performance variability in fingerprint-based recognition systems for different segments of the population. Based on the experimental evaluation, the work points out new observations based on data-driven evidence, provides plausible hypotheses to explain such observations, and concludes with potential follow-up actions that can help to reduce the observed fingerprint quality differences. This way, the current paper can be considered as a contribution to further increase the algorithmic fairness and equality of biometric technology.","sentences":["Even though a few initial works have shown on small sets of data some level of bias in the performance of fingerprint recognition technology with respect to certain demographic groups, there is still not sufficient evidence to understand the impact that certain factors such as gender, age or finger-type may have on fingerprint quality and, in turn, also on fingerprint matching accuracy.","The present work addresses this still under researched topic, on a large-scale database of operational data containing 10-print impressions of almost 16,000 subjects.","The results reached provide further insight into the dependency of fingerprint quality and demographics, and show that there in fact exists a certain degree of performance variability in fingerprint-based recognition systems for different segments of the population.","Based on the experimental evaluation, the work points out new observations based on data-driven evidence, provides plausible hypotheses to explain such observations, and concludes with potential follow-up actions that can help to reduce the observed fingerprint quality differences.","This way, the current paper can be considered as a contribution to further increase the algorithmic fairness and equality of biometric technology."],"url":"http://arxiv.org/abs/2409.19992v1"}
{"created":"2024-09-30 06:28:49","title":"Enhancing Security Using Random Binary Weights in Privacy-Preserving Federated Learning","abstract":"In this paper, we propose a novel method for enhancing security in privacy-preserving federated learning using the Vision Transformer. In federated learning, learning is performed by collecting updated information without collecting raw data from each client. However, the problem is that this raw data may be inferred from the updated information. Conventional data-guessing countermeasures (security enhancement methods) for addressing this issue have a trade-off relationship between privacy protection strength and learning efficiency, and they generally degrade model performance. In this paper, we propose a novel method of federated learning that does not degrade model performance and that is robust against data-guessing attacks on updated information. In the proposed method, each client independently prepares a sequence of binary (0 or 1) random numbers, multiplies it by the updated information, and sends it to a server for model learning. In experiments, the effectiveness of the proposed method is confirmed in terms of model performance and resistance to the APRIL (Attention PRIvacy Leakage) restoration attack.","sentences":["In this paper, we propose a novel method for enhancing security in privacy-preserving federated learning using the Vision Transformer.","In federated learning, learning is performed by collecting updated information without collecting raw data from each client.","However, the problem is that this raw data may be inferred from the updated information.","Conventional data-guessing countermeasures (security enhancement methods) for addressing this issue have a trade-off relationship between privacy protection strength and learning efficiency, and they generally degrade model performance.","In this paper, we propose a novel method of federated learning that does not degrade model performance and that is robust against data-guessing attacks on updated information.","In the proposed method, each client independently prepares a sequence of binary (0 or 1) random numbers, multiplies it by the updated information, and sends it to a server for model learning.","In experiments, the effectiveness of the proposed method is confirmed in terms of model performance and resistance to the APRIL (Attention PRIvacy Leakage) restoration attack."],"url":"http://arxiv.org/abs/2409.19988v1"}
{"created":"2024-09-30 06:24:43","title":"CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models","abstract":"Although language model scores are often treated as probabilities, their reliability as probability estimators has mainly been studied through calibration, overlooking other aspects. In particular, it is unclear whether language models produce the same value for different ways of assigning joint probabilities to word spans. Our work introduces a novel framework, ConTestS (Consistency Testing over Spans), involving statistical tests to assess score consistency across interchangeable completion and conditioning orders. We conduct experiments on post-release real and synthetic data to eliminate training effects. Our findings reveal that both Masked Language Models (MLMs) and autoregressive models exhibit inconsistent predictions, with autoregressive models showing larger discrepancies. Larger MLMs tend to produce more consistent predictions, while autoregressive models show the opposite trend. Moreover, for both model types, prediction entropies offer insights into the true word span likelihood and therefore can aid in selecting optimal decoding strategies. The inconsistencies revealed by our analysis, as well their connection to prediction entropies and differences between model types, can serve as useful guides for future research on addressing these limitations.","sentences":["Although language model scores are often treated as probabilities, their reliability as probability estimators has mainly been studied through calibration, overlooking other aspects.","In particular, it is unclear whether language models produce the same value for different ways of assigning joint probabilities to word spans.","Our work introduces a novel framework, ConTestS (Consistency Testing over Spans), involving statistical tests to assess score consistency across interchangeable completion and conditioning orders.","We conduct experiments on post-release real and synthetic data to eliminate training effects.","Our findings reveal that both Masked Language Models (MLMs) and autoregressive models exhibit inconsistent predictions, with autoregressive models showing larger discrepancies.","Larger MLMs tend to produce more consistent predictions, while autoregressive models show the opposite trend.","Moreover, for both model types, prediction entropies offer insights into the true word span likelihood and therefore can aid in selecting optimal decoding strategies.","The inconsistencies revealed by our analysis, as well their connection to prediction entropies and differences between model types, can serve as useful guides for future research on addressing these limitations."],"url":"http://arxiv.org/abs/2409.19984v1"}
{"created":"2024-09-30 06:04:04","title":"Learning Partial Differential Equations with Deep Parallel Neural Operators","abstract":"In recent years, Solving partial differential equations has shifted the focus of traditional neural network studies from finite-dimensional Euclidean spaces to generalized functional spaces in research. A novel methodology is to learn an operator as a means of approximating the mapping between outputs. Currently, researchers have proposed a variety of operator architectures. Nevertheless, the majority of these architectures adopt an iterative update architecture, whereby a single operator is learned from the same function space. In practical physical science problems, the numerical solutions of partial differential equations are complex, and a serial single operator is unable to accurately approximate the intricate mapping between input and output. So, We propose a deep parallel operator model (DPNO) for efficiently and accurately solving partial differential equations. DPNO employs convolutional neural networks to extract local features and map data into distinct latent spaces. Designing a parallel block of double Fourier neural operators to solve the iterative error problem. DPNO approximates complex mappings between inputs and outputs by learning multiple operators in different potential spaces in parallel blocks. DPNO achieved the best performance on five of them, with an average improvement of 10.5\\%, and ranked second on one dataset.","sentences":["In recent years, Solving partial differential equations has shifted the focus of traditional neural network studies from finite-dimensional Euclidean spaces to generalized functional spaces in research.","A novel methodology is to learn an operator as a means of approximating the mapping between outputs.","Currently, researchers have proposed a variety of operator architectures.","Nevertheless, the majority of these architectures adopt an iterative update architecture, whereby a single operator is learned from the same function space.","In practical physical science problems, the numerical solutions of partial differential equations are complex, and a serial single operator is unable to accurately approximate the intricate mapping between input and output.","So, We propose a deep parallel operator model (DPNO) for efficiently and accurately solving partial differential equations.","DPNO employs convolutional neural networks to extract local features and map data into distinct latent spaces.","Designing a parallel block of double Fourier neural operators to solve the iterative error problem.","DPNO approximates complex mappings between inputs and outputs by learning multiple operators in different potential spaces in parallel blocks.","DPNO achieved the best performance on five of them, with an average improvement of 10.5\\%, and ranked second on one dataset."],"url":"http://arxiv.org/abs/2409.19976v1"}
{"created":"2024-09-30 05:52:06","title":"A Hybrid Model and Learning-Based Force Estimation Framework for Surgical Robots","abstract":"Haptic feedback to the surgeon during robotic surgery would enable safer and more immersive surgeries but estimating tissue interaction forces at the tips of robotically controlled surgical instruments has proven challenging. Few existing surgical robots can measure interaction forces directly and the additional sensor may limit the life of instruments. We present a hybrid model and learning-based framework for force estimation for the Patient Side Manipulators (PSM) of a da Vinci Research Kit (dVRK). The model-based component identifies the dynamic parameters of the robot and estimates free-space joint torque, while the learning-based component compensates for environmental factors, such as the additional torque caused by trocar interaction between the PSM instrument and the patient's body wall. We evaluate our method in an abdominal phantom and achieve an error in force estimation of under 10% normalized root-mean-squared error. We show that by using a model-based method to perform dynamics identification, we reduce reliance on the training data covering the entire workspace. Although originally developed for the dVRK, the proposed method is a generalizable framework for other compliant surgical robots. The code is available at https://github.com/vu-maple-lab/dvrk_force_estimation.","sentences":["Haptic feedback to the surgeon during robotic surgery would enable safer and more immersive surgeries but estimating tissue interaction forces at the tips of robotically controlled surgical instruments has proven challenging.","Few existing surgical robots can measure interaction forces directly and the additional sensor may limit the life of instruments.","We present a hybrid model and learning-based framework for force estimation for the Patient Side Manipulators (PSM) of a da Vinci Research Kit (dVRK).","The model-based component identifies the dynamic parameters of the robot and estimates free-space joint torque, while the learning-based component compensates for environmental factors, such as the additional torque caused by trocar interaction between the PSM instrument and the patient's body wall.","We evaluate our method in an abdominal phantom and achieve an error in force estimation of under 10% normalized root-mean-squared error.","We show that by using a model-based method to perform dynamics identification, we reduce reliance on the training data covering the entire workspace.","Although originally developed for the dVRK, the proposed method is a generalizable framework for other compliant surgical robots.","The code is available at https://github.com/vu-maple-lab/dvrk_force_estimation."],"url":"http://arxiv.org/abs/2409.19970v1"}
{"created":"2024-09-30 05:35:18","title":"Variational Auto-encoder Based Solutions to Interactive Dynamic Influence Diagrams","abstract":"Addressing multiagent decision problems in AI, especially those involving collaborative or competitive agents acting concurrently in a partially observable and stochastic environment, remains a formidable challenge. While Interactive Dynamic Influence Diagrams~(I-DIDs) have offered a promising decision framework for such problems, they encounter limitations when the subject agent encounters unknown behaviors exhibited by other agents that are not explicitly modeled within the I-DID. This can lead to sub-optimal responses from the subject agent. In this paper, we propose a novel data-driven approach that utilizes an encoder-decoder architecture, particularly a variational autoencoder, to enhance I-DID solutions. By integrating a perplexity-based tree loss function into the optimization algorithm of the variational autoencoder, coupled with the advantages of Zig-Zag One-Hot encoding and decoding, we generate potential behaviors of other agents within the I-DID that are more likely to contain their true behaviors, even from limited interactions. This new approach enables the subject agent to respond more appropriately to unknown behaviors, thus improving its decision quality. We empirically demonstrate the effectiveness of the proposed approach in two well-established problem domains, highlighting its potential for handling multi-agent decision problems with unknown behaviors. This work is the first time of using neural networks based approaches to deal with the I-DID challenge in agent planning and learning problems.","sentences":["Addressing multiagent decision problems in AI, especially those involving collaborative or competitive agents acting concurrently in a partially observable and stochastic environment, remains a formidable challenge.","While Interactive Dynamic Influence Diagrams~(I-DIDs) have offered a promising decision framework for such problems, they encounter limitations when the subject agent encounters unknown behaviors exhibited by other agents that are not explicitly modeled within the I-DID.","This can lead to sub-optimal responses from the subject agent.","In this paper, we propose a novel data-driven approach that utilizes an encoder-decoder architecture, particularly a variational autoencoder, to enhance I-DID solutions.","By integrating a perplexity-based tree loss function into the optimization algorithm of the variational autoencoder, coupled with the advantages of Zig-Zag One-Hot encoding and decoding, we generate potential behaviors of other agents within the I-DID that are more likely to contain their true behaviors, even from limited interactions.","This new approach enables the subject agent to respond more appropriately to unknown behaviors, thus improving its decision quality.","We empirically demonstrate the effectiveness of the proposed approach in two well-established problem domains, highlighting its potential for handling multi-agent decision problems with unknown behaviors.","This work is the first time of using neural networks based approaches to deal with the I-DID challenge in agent planning and learning problems."],"url":"http://arxiv.org/abs/2409.19965v1"}
{"created":"2024-09-30 05:25:51","title":"Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval","abstract":"Cross-lingual cross-modal retrieval (CCR) aims to retrieve visually relevant content based on non-English queries, without relying on human-labeled cross-modal data pairs during training. One popular approach involves utilizing machine translation (MT) to create pseudo-parallel data pairs, establishing correspondence between visual and non-English textual data. However, aligning their representations poses challenges due to the significant semantic gap between vision and text, as well as the lower quality of non-English representations caused by pre-trained encoders and data noise. To overcome these challenges, we propose LECCR, a novel solution that incorporates the multi-modal large language model (MLLM) to improve the alignment between visual and non-English representations. Specifically, we first employ MLLM to generate detailed visual content descriptions and aggregate them into multi-view semantic slots that encapsulate different semantics. Then, we take these semantic slots as internal features and leverage them to interact with the visual features. By doing so, we enhance the semantic information within the visual features, narrowing the semantic gap between modalities and generating local visual semantics for subsequent multi-level matching. Additionally, to further enhance the alignment between visual and non-English features, we introduce softened matching under English guidance. This approach provides more comprehensive and reliable inter-modal correspondences between visual and non-English features. Extensive experiments on four CCR benchmarks, \\ie Multi30K, MSCOCO, VATEX, and MSR-VTT-CN, demonstrate the effectiveness of our proposed method. Code: \\url{https://github.com/LiJiaBei-7/leccr}.","sentences":["Cross-lingual cross-modal retrieval (CCR) aims to retrieve visually relevant content based on non-English queries, without relying on human-labeled cross-modal data pairs during training.","One popular approach involves utilizing machine translation (MT) to create pseudo-parallel data pairs, establishing correspondence between visual and non-English textual data.","However, aligning their representations poses challenges due to the significant semantic gap between vision and text, as well as the lower quality of non-English representations caused by pre-trained encoders and data noise.","To overcome these challenges, we propose LECCR, a novel solution that incorporates the multi-modal large language model (MLLM) to improve the alignment between visual and non-English representations.","Specifically, we first employ MLLM to generate detailed visual content descriptions and aggregate them into multi-view semantic slots that encapsulate different semantics.","Then, we take these semantic slots as internal features and leverage them to interact with the visual features.","By doing so, we enhance the semantic information within the visual features, narrowing the semantic gap between modalities and generating local visual semantics for subsequent multi-level matching.","Additionally, to further enhance the alignment between visual and non-English features, we introduce softened matching under English guidance.","This approach provides more comprehensive and reliable inter-modal correspondences between visual and non-English features.","Extensive experiments on four CCR benchmarks, \\ie Multi30K, MSCOCO, VATEX, and MSR-VTT-CN, demonstrate the effectiveness of our proposed method.","Code: \\url{https://github.com/LiJiaBei-7/leccr}."],"url":"http://arxiv.org/abs/2409.19961v1"}
{"created":"2024-09-30 05:24:01","title":"TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning","abstract":"Zero-shot inference, where pre-trained models perform tasks without specific training data, is an exciting emergent ability of large models like CLIP. Although there has been considerable exploration into enhancing zero-shot abilities in image captioning (IC) for popular datasets such as MSCOCO and Flickr8k, these approaches fall short with fine-grained datasets like CUB, FLO, UCM-Captions, and Sydney-Captions. These datasets require captions to discern between visually and semantically similar classes, focusing on detailed object parts and their attributes. To overcome this challenge, we introduce TRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption with additional object-part details using object detector proposals and Natural Language Processing techniques. It complements rather than alters the base caption, allowing seamless integration with other captioning methods and offering users enhanced flexibility. Our evaluations show that TROPE consistently boosts performance across all tested zero-shot IC approaches and achieves state-of-the-art results on fine-grained IC datasets.","sentences":["Zero-shot inference, where pre-trained models perform tasks without specific training data, is an exciting emergent ability of large models like CLIP.","Although there has been considerable exploration into enhancing zero-shot abilities in image captioning (IC) for popular datasets such as MSCOCO and Flickr8k, these approaches fall short with fine-grained datasets like CUB, FLO, UCM-Captions, and Sydney-Captions.","These datasets require captions to discern between visually and semantically similar classes, focusing on detailed object parts and their attributes.","To overcome this challenge, we introduce TRaining-Free Object-Part Enhancement (TROPE).","TROPE enriches a base caption with additional object-part details using object detector proposals and Natural Language Processing techniques.","It complements rather than alters the base caption, allowing seamless integration with other captioning methods and offering users enhanced flexibility.","Our evaluations show that TROPE consistently boosts performance across all tested zero-shot IC approaches and achieves state-of-the-art results on fine-grained IC datasets."],"url":"http://arxiv.org/abs/2409.19960v1"}
{"created":"2024-09-30 05:22:54","title":"Early review of Gender Bias of OpenAI o1-mini: Higher Intelligence of LLM does not necessarily solve Gender Bias and Stereotyping issues","abstract":"In this paper, we present an early evaluation of the OpenAI o1-mini model, analyzing its performance in gender inclusivity and bias. Our research, conducted on 700 personas 350 from GPT-4o mini and 350 from o1-mini, reveals that despite improvements in inclusivity regarding personality traits and preferences, significant gender biases remain. For instance, o1-mini rated male personas higher in competency, with a score of 8.06, compared to female personas at 7.88 and non-binary personas at 7.80. Additionally, o1-mini assigned PhD roles to 28% of male personas but only 22.4% of females and 0% of non-binary personas. Male personas were also more likely to be perceived as successful founders, at 69.4%, and CEOs, at 62.17%, compared to female personas at 67.97% and 61.11%, and non-binary personas at 65.7% and 58.37%. The analysis reveals persistent gender biases across fields like Engineering, Data, and Technology, where males dominate, reflecting traditional stereotypes. Conversely, fields like Design, Art, and Marketing show a stronger presence of females, reinforcing societal notions that associate creativity and communication with females. These findings highlight ongoing challenges in mitigating gender bias, reinforcing the need for further interventions to ensure equitable representation across all genders in AI models.","sentences":["In this paper, we present an early evaluation of the OpenAI o1-mini model, analyzing its performance in gender inclusivity and bias.","Our research, conducted on 700 personas 350 from GPT-4o mini and 350 from o1-mini, reveals that despite improvements in inclusivity regarding personality traits and preferences, significant gender biases remain.","For instance, o1-mini rated male personas higher in competency, with a score of 8.06, compared to female personas at 7.88 and non-binary personas at 7.80.","Additionally, o1-mini assigned PhD roles to 28% of male personas but only 22.4% of females and 0% of non-binary personas.","Male personas were also more likely to be perceived as successful founders, at 69.4%, and CEOs, at 62.17%, compared to female personas at 67.97% and 61.11%, and non-binary personas at 65.7% and 58.37%.","The analysis reveals persistent gender biases across fields like Engineering, Data, and Technology, where males dominate, reflecting traditional stereotypes.","Conversely, fields like Design, Art, and Marketing show a stronger presence of females, reinforcing societal notions that associate creativity and communication with females.","These findings highlight ongoing challenges in mitigating gender bias, reinforcing the need for further interventions to ensure equitable representation across all genders in AI models."],"url":"http://arxiv.org/abs/2409.19959v1"}
{"created":"2024-09-30 05:19:09","title":"Attribute-Text Guided Forgetting Compensation for Lifelong Person Re-Identification","abstract":"Lifelong person re-identification (LReID) aims to continuously learn from non-stationary data to match individuals in different environments. Each task is affected by variations in illumination and person-related information (such as pose and clothing), leading to task-wise domain gaps. Current LReID methods focus on task-specific knowledge and ignore intrinsic task-shared representations within domain gaps, limiting model performance. Bridging task-wise domain gaps is crucial for improving anti-forgetting and generalization capabilities, especially when accessing limited old classes during training. To address these issues, we propose a novel attribute-text guided forgetting compensation (ATFC) model, which explores text-driven global representations of identity-related information and attribute-related local representations of identity-free information for LReID. Due to the lack of paired text-image data, we design an attribute-text generator (ATG) to dynamically generate a text descriptor for each instance. We then introduce a text-guided aggregation network (TGA) to explore robust text-driven global representations for each identity and knowledge transfer. Furthermore, we propose an attribute compensation network (ACN) to investigate attribute-related local representations, which distinguish similar identities and bridge domain gaps. Finally, we develop an attribute anti-forgetting (AF) loss and knowledge transfer (KT) loss to minimize domain gaps and achieve knowledge transfer, improving model performance. Extensive experiments demonstrate that our ATFC method achieves superior performance, outperforming existing LReID methods by over 9.0$\\%$/7.4$\\%$ in average mAP/R-1 on the seen dataset.","sentences":["Lifelong person re-identification (LReID) aims to continuously learn from non-stationary data to match individuals in different environments.","Each task is affected by variations in illumination and person-related information (such as pose and clothing), leading to task-wise domain gaps.","Current LReID methods focus on task-specific knowledge and ignore intrinsic task-shared representations within domain gaps, limiting model performance.","Bridging task-wise domain gaps is crucial for improving anti-forgetting and generalization capabilities, especially when accessing limited old classes during training.","To address these issues, we propose a novel attribute-text guided forgetting compensation (ATFC) model, which explores text-driven global representations of identity-related information and attribute-related local representations of identity-free information for LReID.","Due to the lack of paired text-image data, we design an attribute-text generator (ATG) to dynamically generate a text descriptor for each instance.","We then introduce a text-guided aggregation network (TGA) to explore robust text-driven global representations for each identity and knowledge transfer.","Furthermore, we propose an attribute compensation network (ACN) to investigate attribute-related local representations, which distinguish similar identities and bridge domain gaps.","Finally, we develop an attribute anti-forgetting (AF) loss and knowledge transfer (KT) loss to minimize domain gaps and achieve knowledge transfer, improving model performance.","Extensive experiments demonstrate that our ATFC method achieves superior performance, outperforming existing LReID methods by over 9.0$\\%$/7.4$\\%$ in average mAP/R-1 on the seen dataset."],"url":"http://arxiv.org/abs/2409.19954v1"}
{"created":"2024-09-30 05:05:37","title":"Task-agnostic Pre-training and Task-guided Fine-tuning for Versatile Diffusion Planner","abstract":"Diffusion models have demonstrated their capabilities in modeling trajectories of multi-tasks. However, existing multi-task planners or policies typically rely on task-specific demonstrations via multi-task imitation, or require task-specific reward labels to facilitate policy optimization via Reinforcement Learning (RL). To address these challenges, we aim to develop a versatile diffusion planner that can leverage large-scale inferior data that contains task-agnostic sub-optimal trajectories, with the ability to fast adapt to specific tasks. In this paper, we propose \\textbf{SODP}, a two-stage framework that leverages \\textbf{S}ub-\\textbf{O}ptimal data to learn a \\textbf{D}iffusion \\textbf{P}lanner, which is generalizable for various downstream tasks. Specifically, in the pre-training stage, we train a foundation diffusion planner that extracts general planning capabilities by modeling the versatile distribution of multi-task trajectories, which can be sub-optimal and has wide data coverage. Then for downstream tasks, we adopt RL-based fine-tuning with task-specific rewards to fast refine the diffusion planner, which aims to generate action sequences with higher task-specific returns. Experimental results from multi-task domains including Meta-World and Adroit demonstrate that SODP outperforms state-of-the-art methods with only a small amount of data for reward-guided fine-tuning.","sentences":["Diffusion models have demonstrated their capabilities in modeling trajectories of multi-tasks.","However, existing multi-task planners or policies typically rely on task-specific demonstrations via multi-task imitation, or require task-specific reward labels to facilitate policy optimization via Reinforcement Learning (RL).","To address these challenges, we aim to develop a versatile diffusion planner that can leverage large-scale inferior data that contains task-agnostic sub-optimal trajectories, with the ability to fast adapt to specific tasks.","In this paper, we propose \\textbf{SODP}, a two-stage framework that leverages \\textbf{S}ub-\\textbf{O}ptimal data to learn a \\textbf{D}iffusion \\textbf{P}lanner, which is generalizable for various downstream tasks.","Specifically, in the pre-training stage, we train a foundation diffusion planner that extracts general planning capabilities by modeling the versatile distribution of multi-task trajectories, which can be sub-optimal and has wide data coverage.","Then for downstream tasks, we adopt RL-based fine-tuning with task-specific rewards to fast refine the diffusion planner, which aims to generate action sequences with higher task-specific returns.","Experimental results from multi-task domains including Meta-World and Adroit demonstrate that SODP outperforms state-of-the-art methods with only a small amount of data for reward-guided fine-tuning."],"url":"http://arxiv.org/abs/2409.19949v1"}
{"created":"2024-09-30 04:59:51","title":"Classification with a Network of Partially Informative Agents: Enabling Wise Crowds from Individually Myopic Classifiers","abstract":"We consider the problem of classification with a (peer-to-peer) network of heterogeneous and partially informative agents, each receiving local data generated by an underlying true class, and equipped with a classifier that can only distinguish between a subset of the entire set of classes. We propose an iterative algorithm that uses the posterior probabilities of the local classifier and recursively updates each agent's local belief on all the possible classes, based on its local signals and belief information from its neighbors. We then adopt a novel distributed min-rule to update each agent's global belief and enable learning of the true class for all agents. We show that under certain assumptions, the beliefs on the true class converge to one asymptotically almost surely. We provide the asymptotic convergence rate, and demonstrate the performance of our algorithm through simulation with image data and experimented with random forest classifiers and MobileNet.","sentences":["We consider the problem of classification with a (peer-to-peer) network of heterogeneous and partially informative agents, each receiving local data generated by an underlying true class, and equipped with a classifier that can only distinguish between a subset of the entire set of classes.","We propose an iterative algorithm that uses the posterior probabilities of the local classifier and recursively updates each agent's local belief on all the possible classes, based on its local signals and belief information from its neighbors.","We then adopt a novel distributed min-rule to update each agent's global belief and enable learning of the true class for all agents.","We show that under certain assumptions, the beliefs on the true class converge to one asymptotically almost surely.","We provide the asymptotic convergence rate, and demonstrate the performance of our algorithm through simulation with image data and experimented with random forest classifiers and MobileNet."],"url":"http://arxiv.org/abs/2409.19947v1"}
{"created":"2024-09-30 04:23:47","title":"Leveraging Pre-trained Models for Robust Federated Learning for Kidney Stone Type Recognition","abstract":"Deep learning developments have improved medical imaging diagnoses dramatically, increasing accuracy in several domains. Nonetheless, obstacles continue to exist because of the requirement for huge datasets and legal limitations on data exchange. A solution is provided by Federated Learning (FL), which permits decentralized model training while maintaining data privacy. However, FL models are susceptible to data corruption, which may result in performance degradation. Using pre-trained models, this research suggests a strong FL framework to improve kidney stone diagnosis. Two different kidney stone datasets, each with six different categories of images, are used in our experimental setting. Our method involves two stages: Learning Parameter Optimization (LPO) and Federated Robustness Validation (FRV). We achieved a peak accuracy of 84.1% with seven epochs and 10 rounds during LPO stage, and 77.2% during FRV stage, showing enhanced diagnostic accuracy and robustness against image corruption. This highlights the potential of merging pre-trained models with FL to address privacy and performance concerns in medical diagnostics, and guarantees improved patient care and enhanced trust in FL-based medical systems.","sentences":["Deep learning developments have improved medical imaging diagnoses dramatically, increasing accuracy in several domains.","Nonetheless, obstacles continue to exist because of the requirement for huge datasets and legal limitations on data exchange.","A solution is provided by Federated Learning (FL), which permits decentralized model training while maintaining data privacy.","However, FL models are susceptible to data corruption, which may result in performance degradation.","Using pre-trained models, this research suggests a strong FL framework to improve kidney stone diagnosis.","Two different kidney stone datasets, each with six different categories of images, are used in our experimental setting.","Our method involves two stages:","Learning Parameter Optimization (LPO) and Federated Robustness Validation (FRV).","We achieved a peak accuracy of 84.1% with seven epochs and 10 rounds during LPO stage, and 77.2% during FRV stage, showing enhanced diagnostic accuracy and robustness against image corruption.","This highlights the potential of merging pre-trained models with FL to address privacy and performance concerns in medical diagnostics, and guarantees improved patient care and enhanced trust in FL-based medical systems."],"url":"http://arxiv.org/abs/2409.19934v1"}
{"created":"2024-09-30 03:59:06","title":"Large Language Model Empowered Embedding Generator for Sequential Recommendation","abstract":"Sequential Recommender Systems (SRS) are extensively applied across various domains to predict users' next interaction by modeling their interaction sequences. However, these systems typically grapple with the long-tail problem, where they struggle to recommend items that are less popular. This challenge results in a decline in user discovery and reduced earnings for vendors, negatively impacting the system as a whole. Large Language Model (LLM) has the potential to understand the semantic connections between items, regardless of their popularity, positioning them as a viable solution to this dilemma. In our paper, we present LLMEmb, an innovative technique that harnesses LLM to create item embeddings that bolster the performance of SRS. To align the capabilities of general-purpose LLM with the needs of the recommendation domain, we introduce a method called Supervised Contrastive Fine-Tuning (SCFT). This method involves attribute-level data augmentation and a custom contrastive loss designed to tailor LLM for enhanced recommendation performance. Moreover, we highlight the necessity of incorporating collaborative filtering signals into LLM-generated embeddings and propose Recommendation Adaptation Training (RAT) for this purpose. RAT refines the embeddings to be optimally suited for SRS. The embeddings derived from LLMEmb can be easily integrated with any SRS model, showcasing its practical utility. Extensive experimentation on three real-world datasets has shown that LLMEmb significantly improves upon current methods when applied across different SRS models.","sentences":["Sequential Recommender Systems (SRS) are extensively applied across various domains to predict users' next interaction by modeling their interaction sequences.","However, these systems typically grapple with the long-tail problem, where they struggle to recommend items that are less popular.","This challenge results in a decline in user discovery and reduced earnings for vendors, negatively impacting the system as a whole.","Large Language Model (LLM) has the potential to understand the semantic connections between items, regardless of their popularity, positioning them as a viable solution to this dilemma.","In our paper, we present LLMEmb, an innovative technique that harnesses LLM to create item embeddings that bolster the performance of SRS.","To align the capabilities of general-purpose LLM with the needs of the recommendation domain, we introduce a method called Supervised Contrastive Fine-Tuning (SCFT).","This method involves attribute-level data augmentation and a custom contrastive loss designed to tailor LLM for enhanced recommendation performance.","Moreover, we highlight the necessity of incorporating collaborative filtering signals into LLM-generated embeddings and propose Recommendation Adaptation Training (RAT) for this purpose.","RAT refines the embeddings to be optimally suited for SRS.","The embeddings derived from LLMEmb can be easily integrated with any SRS model, showcasing its practical utility.","Extensive experimentation on three real-world datasets has shown that LLMEmb significantly improves upon current methods when applied across different SRS models."],"url":"http://arxiv.org/abs/2409.19925v1"}
{"created":"2024-09-30 03:48:54","title":"Understanding Higher-Order Correlations Among Semantic Components in Embeddings","abstract":"Independent Component Analysis (ICA) is an effective method for interpreting the intrinsic geometric structure of embeddings as semantic components. While ICA theory assumes that embeddings can be linearly decomposed into independent components, real-world data often do not satisfy this assumption. Consequently, there are remaining non-independencies between the estimated components that ICA cannot eliminate. We quantified these non-independencies using higher-order correlations and demonstrated that when the higher-order correlation between two components is large, it indicates a strong semantic association between them. The entire structure was revealed through visualization using a maximum spanning tree of semantic components. These findings allow for further understanding of embeddings through ICA.","sentences":["Independent Component Analysis (ICA) is an effective method for interpreting the intrinsic geometric structure of embeddings as semantic components.","While ICA theory assumes that embeddings can be linearly decomposed into independent components, real-world data often do not satisfy this assumption.","Consequently, there are remaining non-independencies between the estimated components that ICA cannot eliminate.","We quantified these non-independencies using higher-order correlations and demonstrated that when the higher-order correlation between two components is large, it indicates a strong semantic association between them.","The entire structure was revealed through visualization using a maximum spanning tree of semantic components.","These findings allow for further understanding of embeddings through ICA."],"url":"http://arxiv.org/abs/2409.19919v1"}
{"created":"2024-09-30 03:42:06","title":"Towards Effective Utilization of Mixed-Quality Demonstrations in Robotic Manipulation via Segment-Level Selection and Optimization","abstract":"Data is crucial for robotic manipulation, as it underpins the development of robotic systems for complex tasks. While high-quality, diverse datasets enhance the performance and adaptability of robotic manipulation policies, collecting extensive expert-level data is resource-intensive. Consequently, many current datasets suffer from quality inconsistencies due to operator variability, highlighting the need for methods to utilize mixed-quality data effectively. To mitigate these issues, we propose \"Select Segments to Imitate\" (S2I), a framework that selects and optimizes mixed-quality demonstration data at the segment level, while ensuring plug-and-play compatibility with existing robotic manipulation policies. The framework has three components: demonstration segmentation dividing origin data into meaningful segments, segment selection using contrastive learning to find high-quality segments, and trajectory optimization to refine suboptimal segments for better policy learning. We evaluate S2I through comprehensive experiments in simulation and real-world environments across six tasks, demonstrating that with only 3 expert demonstrations for reference, S2I can improve the performance of various downstream policies when trained with mixed-quality demonstrations. Project website: https://tonyfang.net/s2i/.","sentences":["Data is crucial for robotic manipulation, as it underpins the development of robotic systems for complex tasks.","While high-quality, diverse datasets enhance the performance and adaptability of robotic manipulation policies, collecting extensive expert-level data is resource-intensive.","Consequently, many current datasets suffer from quality inconsistencies due to operator variability, highlighting the need for methods to utilize mixed-quality data effectively.","To mitigate these issues, we propose \"Select Segments to Imitate\" (S2I), a framework that selects and optimizes mixed-quality demonstration data at the segment level, while ensuring plug-and-play compatibility with existing robotic manipulation policies.","The framework has three components: demonstration segmentation dividing origin data into meaningful segments, segment selection using contrastive learning to find high-quality segments, and trajectory optimization to refine suboptimal segments for better policy learning.","We evaluate S2I through comprehensive experiments in simulation and real-world environments across six tasks, demonstrating that with only 3 expert demonstrations for reference, S2I can improve the performance of various downstream policies when trained with mixed-quality demonstrations.","Project website: https://tonyfang.net/s2i/."],"url":"http://arxiv.org/abs/2409.19917v1"}
{"created":"2024-09-30 03:37:10","title":"Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming","abstract":"Object-Oriented Programming (OOP) has become a crucial paradigm for managing the growing complexity of modern software systems, particularly in fields like machine learning, deep learning, large language models (LLM), and data analytics. This work provides a comprehensive introduction to the integration of OOP techniques within these domains, with a focus on improving code modularity, maintainability, and scalability. We begin by outlining the evolution of computing and the rise of OOP, followed by an in-depth discussion of key OOP principles such as encapsulation, inheritance, polymorphism, and abstraction. The practical application of these principles is demonstrated using Python, a widely adopted language in AI and data science. Furthermore, we examine how design patterns and modular programming can be employed to enhance the structure and efficiency of machine learning systems. In subsequent sections, we apply these OOP concepts to real-world AI tasks, including the encapsulation of preprocessing workflows, machine learning model training, and evaluation. Detailed examples illustrate how OOP can be used to build reusable, scalable machine learning systems while maintaining code clarity and reducing redundancy.This work is intended to serve as a bridge for both beginners and experienced developers, equipping them with the necessary knowledge to apply OOP methodologies in AI-driven projects, ultimately fostering the development of more robust and maintainable systems.","sentences":["Object-Oriented Programming (OOP) has become a crucial paradigm for managing the growing complexity of modern software systems, particularly in fields like machine learning, deep learning, large language models (LLM), and data analytics.","This work provides a comprehensive introduction to the integration of OOP techniques within these domains, with a focus on improving code modularity, maintainability, and scalability.","We begin by outlining the evolution of computing and the rise of OOP, followed by an in-depth discussion of key OOP principles such as encapsulation, inheritance, polymorphism, and abstraction.","The practical application of these principles is demonstrated using Python, a widely adopted language in AI and data science.","Furthermore, we examine how design patterns and modular programming can be employed to enhance the structure and efficiency of machine learning systems.","In subsequent sections, we apply these OOP concepts to real-world AI tasks, including the encapsulation of preprocessing workflows, machine learning model training, and evaluation.","Detailed examples illustrate how OOP can be used to build reusable, scalable machine learning systems while maintaining code clarity and reducing redundancy.","This work is intended to serve as a bridge for both beginners and experienced developers, equipping them with the necessary knowledge to apply OOP methodologies in AI-driven projects, ultimately fostering the development of more robust and maintainable systems."],"url":"http://arxiv.org/abs/2409.19916v1"}
{"created":"2024-09-30 03:32:02","title":"Scaling Optimal LR Across Token Horizon","abstract":"State-of-the-art LLMs are powered by scaling -- scaling model size, dataset size and cluster size. It is economically infeasible to extensively tune hyperparameter for the largest runs. Instead, approximately optimal hyperparameters must be inferred or \\textit{transferred} from smaller experiments. Hyperparameter transfer across model sizes has been studied in Yang et al. However, hyperparameter transfer across dataset size -- or token horizon -- has not been studied yet. To remedy this we conduct a large scale empirical study on how optimal learning rate (LR) depends on token horizon in LLM training. We first demonstrate that the optimal LR changes significantly with token horizon -- longer training necessitates smaller LR. Secondly we demonstrate the the optimal LR follows a scaling law, and that the optimal LR for longer horizons can be accurately estimated from shorter horizons via our scaling laws. We also provide a rule-of-thumb for transferring LR across token horizons with zero overhead over current practices. Lastly we provide evidence that LLama-1 used too high LR, and estimate the performance hit from this. We thus argue that hyperparameter transfer across data size is an important and overlooked component of LLM training.","sentences":["State-of-the-art LLMs are powered by scaling -- scaling model size, dataset size and cluster size.","It is economically infeasible to extensively tune hyperparameter for the largest runs.","Instead, approximately optimal hyperparameters must be inferred or \\textit{transferred} from smaller experiments.","Hyperparameter transfer across model sizes has been studied in Yang et al.","However, hyperparameter transfer across dataset size -- or token horizon -- has not been studied yet.","To remedy this we conduct a large scale empirical study on how optimal learning rate (LR) depends on token horizon in LLM training.","We first demonstrate that the optimal LR changes significantly with token horizon -- longer training necessitates smaller LR.","Secondly we demonstrate the the optimal LR follows a scaling law, and that the optimal LR for longer horizons can be accurately estimated from shorter horizons via our scaling laws.","We also provide a rule-of-thumb for transferring LR across token horizons with zero overhead over current practices.","Lastly we provide evidence that LLama-1 used too high LR, and estimate the performance hit from this.","We thus argue that hyperparameter transfer across data size is an important and overlooked component of LLM training."],"url":"http://arxiv.org/abs/2409.19913v1"}
{"created":"2024-09-30 03:29:02","title":"HYDRA-FL: Hybrid Knowledge Distillation for Robust and Accurate Federated Learning","abstract":"Data heterogeneity among Federated Learning (FL) users poses a significant challenge, resulting in reduced global model performance. The community has designed various techniques to tackle this issue, among which Knowledge Distillation (KD)-based techniques are common.   While these techniques effectively improve performance under high heterogeneity, they inadvertently cause higher accuracy degradation under model poisoning attacks (known as attack amplification). This paper presents a case study to reveal this critical vulnerability in KD-based FL systems. We show why KD causes this issue through empirical evidence and use it as motivation to design a hybrid distillation technique. We introduce a novel algorithm, Hybrid Knowledge Distillation for Robust and Accurate FL (HYDRA-FL),   which reduces the impact of attacks in attack scenarios by offloading some of the KD loss to a shallow layer via an auxiliary classifier. We model HYDRA-FL as a generic framework and adapt it to two KD-based FL algorithms, FedNTD and MOON. Using these two as case studies, we demonstrate that our technique outperforms baselines in attack settings while maintaining comparable performance in benign settings.","sentences":["Data heterogeneity among Federated Learning (FL) users poses a significant challenge, resulting in reduced global model performance.","The community has designed various techniques to tackle this issue, among which Knowledge Distillation (KD)-based techniques are common.   ","While these techniques effectively improve performance under high heterogeneity, they inadvertently cause higher accuracy degradation under model poisoning attacks (known as attack amplification).","This paper presents a case study to reveal this critical vulnerability in KD-based FL systems.","We show why KD causes this issue through empirical evidence and use it as motivation to design a hybrid distillation technique.","We introduce a novel algorithm, Hybrid Knowledge Distillation for Robust and Accurate FL (HYDRA-FL),   which reduces the impact of attacks in attack scenarios by offloading some of the KD loss to a shallow layer via an auxiliary classifier.","We model HYDRA-FL as a generic framework and adapt it to two KD-based FL algorithms, FedNTD and MOON.","Using these two as case studies, we demonstrate that our technique outperforms baselines in attack settings while maintaining comparable performance in benign settings."],"url":"http://arxiv.org/abs/2409.19912v1"}
{"created":"2024-09-30 03:01:25","title":"SurvCORN: Survival Analysis with Conditional Ordinal Ranking Neural Network","abstract":"Survival analysis plays a crucial role in estimating the likelihood of future events for patients by modeling time-to-event data, particularly in healthcare settings where predictions about outcomes such as death and disease recurrence are essential. However, this analysis poses challenges due to the presence of censored data, where time-to-event information is missing for certain data points. Yet, censored data can offer valuable insights, provided we appropriately incorporate the censoring time during modeling. In this paper, we propose SurvCORN, a novel method utilizing conditional ordinal ranking networks to predict survival curves directly. Additionally, we introduce SurvMAE, a metric designed to evaluate the accuracy of model predictions in estimating time-to-event outcomes. Through empirical evaluation on two real-world cancer datasets, we demonstrate SurvCORN's ability to maintain accurate ordering between patient outcomes while improving individual time-to-event predictions. Our contributions extend recent advancements in ordinal regression to survival analysis, offering valuable insights into accurate prognosis in healthcare settings.","sentences":["Survival analysis plays a crucial role in estimating the likelihood of future events for patients by modeling time-to-event data, particularly in healthcare settings where predictions about outcomes such as death and disease recurrence are essential.","However, this analysis poses challenges due to the presence of censored data, where time-to-event information is missing for certain data points.","Yet, censored data can offer valuable insights, provided we appropriately incorporate the censoring time during modeling.","In this paper, we propose SurvCORN, a novel method utilizing conditional ordinal ranking networks to predict survival curves directly.","Additionally, we introduce SurvMAE, a metric designed to evaluate the accuracy of model predictions in estimating time-to-event outcomes.","Through empirical evaluation on two real-world cancer datasets, we demonstrate SurvCORN's ability to maintain accurate ordering between patient outcomes while improving individual time-to-event predictions.","Our contributions extend recent advancements in ordinal regression to survival analysis, offering valuable insights into accurate prognosis in healthcare settings."],"url":"http://arxiv.org/abs/2409.19901v1"}
{"created":"2024-09-30 02:58:05","title":"OpenKD: Opening Prompt Diversity for Zero- and Few-shot Keypoint Detection","abstract":"Exploiting the foundation models (e.g., CLIP) to build a versatile keypoint detector has gained increasing attention. Most existing models accept either the text prompt (e.g., ``the nose of a cat''), or the visual prompt (e.g., support image with keypoint annotations), to detect the corresponding keypoints in query image, thereby, exhibiting either zero-shot or few-shot detection ability. However, the research on taking multimodal prompt is still underexplored, and the prompt diversity in semantics and language is far from opened. For example, how to handle unseen text prompts for novel keypoint detection and the diverse text prompts like ``Can you detect the nose and ears of a cat?'' In this work, we open the prompt diversity from three aspects: modality, semantics (seen v.s. unseen), and language, to enable a more generalized zero- and few-shot keypoint detection (Z-FSKD). We propose a novel OpenKD model which leverages multimodal prototype set to support both visual and textual prompting. Further, to infer the keypoint location of unseen texts, we add the auxiliary keypoints and texts interpolated from visual and textual domains into training, which improves the spatial reasoning of our model and significantly enhances zero-shot novel keypoint detection. We also found large language model (LLM) is a good parser, which achieves over 96% accuracy to parse keypoints from texts. With LLM, OpenKD can handle diverse text prompts. Experimental results show that our method achieves state-of-the-art performance on Z-FSKD and initiates new ways to deal with unseen text and diverse texts. The source code and data are available at https://github.com/AlanLuSun/OpenKD.","sentences":["Exploiting the foundation models (e.g., CLIP) to build a versatile keypoint detector has gained increasing attention.","Most existing models accept either the text prompt (e.g., ``the nose of a cat''), or the visual prompt (e.g., support image with keypoint annotations), to detect the corresponding keypoints in query image, thereby, exhibiting either zero-shot or few-shot detection ability.","However, the research on taking multimodal prompt is still underexplored, and the prompt diversity in semantics and language is far from opened.","For example, how to handle unseen text prompts for novel keypoint detection and the diverse text prompts like ``Can you detect the nose and ears of a cat?''","In this work, we open the prompt diversity from three aspects: modality, semantics (seen v.s. unseen), and language, to enable a more generalized zero- and few-shot keypoint detection (Z-FSKD).","We propose a novel OpenKD model which leverages multimodal prototype set to support both visual and textual prompting.","Further, to infer the keypoint location of unseen texts, we add the auxiliary keypoints and texts interpolated from visual and textual domains into training, which improves the spatial reasoning of our model and significantly enhances zero-shot novel keypoint detection.","We also found large language model (LLM) is a good parser, which achieves over 96% accuracy to parse keypoints from texts.","With LLM, OpenKD can handle diverse text prompts.","Experimental results show that our method achieves state-of-the-art performance on Z-FSKD and initiates new ways to deal with unseen text and diverse texts.","The source code and data are available at https://github.com/AlanLuSun/OpenKD."],"url":"http://arxiv.org/abs/2409.19899v1"}
{"created":"2024-09-30 02:56:35","title":"UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs","abstract":"Existing benchmarks for summarization quality evaluation often lack diverse input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and struggle with subjective and coarse-grained annotation schemes. To address these shortcomings, we create UniSumEval benchmark, which extends the range of input context (e.g., domain, length) and provides fine-grained, multi-dimensional annotations. We use AI assistance in data creation, identifying potentially hallucinogenic input texts, and also helping human annotators reduce the difficulty of fine-grained annotation tasks. With UniSumEval, we benchmark nine latest language models as summarizers, offering insights into their performance across varying input contexts and evaluation dimensions. Furthermore, we conduct a thorough comparison of SOTA automated summary evaluators. Our benchmark data will be available at https://github.com/DISL-Lab/UniSumEval-v1.0.","sentences":["Existing benchmarks for summarization quality evaluation often lack diverse input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and struggle with subjective and coarse-grained annotation schemes.","To address these shortcomings, we create UniSumEval benchmark, which extends the range of input context (e.g., domain, length) and provides fine-grained, multi-dimensional annotations.","We use AI assistance in data creation, identifying potentially hallucinogenic input texts, and also helping human annotators reduce the difficulty of fine-grained annotation tasks.","With UniSumEval, we benchmark nine latest language models as summarizers, offering insights into their performance across varying input contexts and evaluation dimensions.","Furthermore, we conduct a thorough comparison of SOTA automated summary evaluators.","Our benchmark data will be available at https://github.com/DISL-Lab/UniSumEval-v1.0."],"url":"http://arxiv.org/abs/2409.19898v1"}
{"created":"2024-09-30 02:53:03","title":"TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation","abstract":"Code translation converts code from one programming language to another while maintaining its original functionality, which is crucial for software migration, system refactoring, and cross-platform development. Traditional rule-based methods rely on manually-written rules, which can be time-consuming and often result in less readable code. To overcome this, learning-based methods have been developed, leveraging parallel data to train models for automated code translation. More recently, the advance of Large Language Models (LLMs) further boosts learning-based code translation. Although promising, LLM-translated program still suffers from diverse quality issues (e.g., syntax errors and semantic errors). In particular, it can be challenging for LLMs to self-debug these errors when simply provided with the corresponding error messages.   In this work, we propose a novel LLM-based multi-agent system TRANSAGENT, which enhances LLM-based code translation by fixing the syntax errors and semantic errors with the synergy between four LLM-based agents, including Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error Fixer. The main insight of TRANSAGENT is to first localize the error code block in the target program based on the execution alignment between the target and source program, which can narrow down the fixing space and thus lower down the fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark from recent programming tasks to mitigate the potential data leakage issue. On our benchmark, TRANSAGENT outperforms the latest LLM-based code translation technique UniTrans in both translation effectiveness and efficiency; additionally, our evaluation on different LLMs show the generalization of TRANSAGENT and our ablation study shows the contribution of each agent.","sentences":["Code translation converts code from one programming language to another while maintaining its original functionality, which is crucial for software migration, system refactoring, and cross-platform development.","Traditional rule-based methods rely on manually-written rules, which can be time-consuming and often result in less readable code.","To overcome this, learning-based methods have been developed, leveraging parallel data to train models for automated code translation.","More recently, the advance of Large Language Models (LLMs) further boosts learning-based code translation.","Although promising, LLM-translated program still suffers from diverse quality issues (e.g., syntax errors and semantic errors).","In particular, it can be challenging for LLMs to self-debug these errors when simply provided with the corresponding error messages.   ","In this work, we propose a novel LLM-based multi-agent system TRANSAGENT, which enhances LLM-based code translation by fixing the syntax errors and semantic errors with the synergy between four LLM-based agents, including Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error Fixer.","The main insight of TRANSAGENT is to first localize the error code block in the target program based on the execution alignment between the target and source program, which can narrow down the fixing space and thus lower down the fixing difficulties.","To evaluate TRANSAGENT, we first construct a new benchmark from recent programming tasks to mitigate the potential data leakage issue.","On our benchmark, TRANSAGENT outperforms the latest LLM-based code translation technique UniTrans in both translation effectiveness and efficiency; additionally, our evaluation on different LLMs show the generalization of TRANSAGENT and our ablation study shows the contribution of each agent."],"url":"http://arxiv.org/abs/2409.19894v1"}
{"created":"2024-09-30 02:39:42","title":"Universal Medical Image Representation Learning with Compositional Decoders","abstract":"Visual-language models have advanced the development of universal models, yet their application in medical imaging remains constrained by specific functional requirements and the limited data. Current general-purpose models are typically designed with task-specific branches and heads, which restricts the shared feature space and the flexibility of model. To address these challenges, we have developed a decomposed-composed universal medical imaging paradigm (UniMed) that supports tasks at all levels. To this end, we first propose a decomposed decoder that can predict two types of outputs -- pixel and semantic, based on a defined input queue. Additionally, we introduce a composed decoder that unifies the input and output spaces and standardizes task annotations across different levels into a discrete token format. The coupled design of these two components enables the model to flexibly combine tasks and mutual benefits. Moreover, our joint representation learning strategy skilfully leverages large amounts of unlabeled data and unsupervised loss, achieving efficient one-stage pretraining for more robust performance. Experimental results show that UniMed achieves state-of-the-art performance on eight datasets across all three tasks and exhibits strong zero-shot and 100-shot transferability. We will release the code and trained models upon the paper's acceptance.","sentences":["Visual-language models have advanced the development of universal models, yet their application in medical imaging remains constrained by specific functional requirements and the limited data.","Current general-purpose models are typically designed with task-specific branches and heads, which restricts the shared feature space and the flexibility of model.","To address these challenges, we have developed a decomposed-composed universal medical imaging paradigm (UniMed) that supports tasks at all levels.","To this end, we first propose a decomposed decoder that can predict two types of outputs -- pixel and semantic, based on a defined input queue.","Additionally, we introduce a composed decoder that unifies the input and output spaces and standardizes task annotations across different levels into a discrete token format.","The coupled design of these two components enables the model to flexibly combine tasks and mutual benefits.","Moreover, our joint representation learning strategy skilfully leverages large amounts of unlabeled data and unsupervised loss, achieving efficient one-stage pretraining for more robust performance.","Experimental results show that UniMed achieves state-of-the-art performance on eight datasets across all three tasks and exhibits strong zero-shot and 100-shot transferability.","We will release the code and trained models upon the paper's acceptance."],"url":"http://arxiv.org/abs/2409.19890v1"}
