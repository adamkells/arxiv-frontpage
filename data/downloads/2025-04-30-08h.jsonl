{"created":"2025-04-29 17:59:48","title":"Toward Efficient Exploration by Large Language Model Agents","abstract":"A burgeoning area within reinforcement learning (RL) is the design of sequential decision-making agents centered around large language models (LLMs). While autonomous decision-making agents powered by modern LLMs could facilitate numerous real-world applications, such successes demand agents that are capable of data-efficient RL. One key obstacle to achieving data efficiency in RL is exploration, a challenge that we demonstrate many recent proposals for LLM agent designs struggle to contend with. Meanwhile, classic algorithms from the RL literature known to gracefully address exploration require technical machinery that can be challenging to operationalize in purely natural language settings. In this work, rather than relying on finetuning or in-context learning to coax LLMs into implicitly imitating a RL algorithm, we illustrate how LLMs can be used to explicitly implement an existing RL algorithm (Posterior Sampling for Reinforcement Learning) whose capacity for statistically-efficient exploration is already well-studied. We offer empirical results demonstrating how our LLM-based implementation of a known, data-efficient RL algorithm can be considerably more effective in natural language tasks that demand prudent exploration.","sentences":["A burgeoning area within reinforcement learning (RL) is the design of sequential decision-making agents centered around large language models (LLMs).","While autonomous decision-making agents powered by modern LLMs could facilitate numerous real-world applications, such successes demand agents that are capable of data-efficient RL.","One key obstacle to achieving data efficiency in RL is exploration, a challenge that we demonstrate many recent proposals for LLM agent designs struggle to contend with.","Meanwhile, classic algorithms from the RL literature known to gracefully address exploration require technical machinery that can be challenging to operationalize in purely natural language settings.","In this work, rather than relying on finetuning or in-context learning to coax LLMs into implicitly imitating a RL algorithm, we illustrate how LLMs can be used to explicitly implement an existing RL algorithm (Posterior Sampling for Reinforcement Learning) whose capacity for statistically-efficient exploration is already well-studied.","We offer empirical results demonstrating how our LLM-based implementation of a known, data-efficient RL algorithm can be considerably more effective in natural language tasks that demand prudent exploration."],"url":"http://arxiv.org/abs/2504.20997v1"}
{"created":"2025-04-29 17:59:45","title":"X-Fusion: Introducing New Modality to Frozen Large Language Models","abstract":"We propose X-Fusion, a framework that extends pretrained Large Language Models (LLMs) for multimodal tasks while preserving their language capabilities. X-Fusion employs a dual-tower design with modality-specific weights, keeping the LLM's parameters frozen while integrating vision-specific information for both understanding and generation. Our experiments demonstrate that X-Fusion consistently outperforms alternative architectures on both image-to-text and text-to-image tasks. We find that incorporating understanding-focused data improves generation quality, reducing image data noise enhances overall performance, and feature alignment accelerates convergence for smaller models but has minimal impact on larger ones. Our findings provide valuable insights into building efficient unified multimodal models.","sentences":["We propose X-Fusion, a framework that extends pretrained Large Language Models (LLMs) for multimodal tasks while preserving their language capabilities.","X-Fusion employs a dual-tower design with modality-specific weights, keeping the LLM's parameters frozen while integrating vision-specific information for both understanding and generation.","Our experiments demonstrate that X-Fusion consistently outperforms alternative architectures on both image-to-text and text-to-image tasks.","We find that incorporating understanding-focused data improves generation quality, reducing image data noise enhances overall performance, and feature alignment accelerates convergence for smaller models but has minimal impact on larger ones.","Our findings provide valuable insights into building efficient unified multimodal models."],"url":"http://arxiv.org/abs/2504.20996v1"}
{"created":"2025-04-29 17:55:52","title":"ACE: A Security Architecture for LLM-Integrated App Systems","abstract":"LLM-integrated app systems extend the utility of Large Language Models (LLMs) with third-party apps that are invoked by a system LLM using interleaved planning and execution phases to answer user queries. These systems introduce new attack vectors where malicious apps can cause integrity violation of planning or execution, availability breakdown, or privacy compromise during execution.   In this work, we identify new attacks impacting the integrity of planning, as well as the integrity and availability of execution in LLM-integrated apps, and demonstrate them against IsolateGPT, a recent solution designed to mitigate attacks from malicious apps. We propose Abstract-Concrete-Execute (ACE), a new secure architecture for LLM-integrated app systems that provides security guarantees for system planning and execution. Specifically, ACE decouples planning into two phases by first creating an abstract execution plan using only trusted information, and then mapping the abstract plan to a concrete plan using installed system apps. We verify that the plans generated by our system satisfy user-specified secure information flow constraints via static analysis on the structured plan output. During execution, ACE enforces data and capability barriers between apps, and ensures that the execution is conducted according to the trusted abstract plan. We show experimentally that our system is secure against attacks from the INJECAGENT benchmark, a standard benchmark for control flow integrity in the face of indirect prompt injection attacks, and our newly introduced attacks. Our architecture represents a significant advancement towards hardening LLM-based systems containing system facilities of varying levels of trustworthiness.","sentences":["LLM-integrated app systems extend the utility of Large Language Models (LLMs) with third-party apps that are invoked by a system LLM using interleaved planning and execution phases to answer user queries.","These systems introduce new attack vectors where malicious apps can cause integrity violation of planning or execution, availability breakdown, or privacy compromise during execution.   ","In this work, we identify new attacks impacting the integrity of planning, as well as the integrity and availability of execution in LLM-integrated apps, and demonstrate them against IsolateGPT, a recent solution designed to mitigate attacks from malicious apps.","We propose Abstract-Concrete-Execute (ACE), a new secure architecture for LLM-integrated app systems that provides security guarantees for system planning and execution.","Specifically, ACE decouples planning into two phases by first creating an abstract execution plan using only trusted information, and then mapping the abstract plan to a concrete plan using installed system apps.","We verify that the plans generated by our system satisfy user-specified secure information flow constraints via static analysis on the structured plan output.","During execution, ACE enforces data and capability barriers between apps, and ensures that the execution is conducted according to the trusted abstract plan.","We show experimentally that our system is secure against attacks from the INJECAGENT benchmark, a standard benchmark for control flow integrity in the face of indirect prompt injection attacks, and our newly introduced attacks.","Our architecture represents a significant advancement towards hardening LLM-based systems containing system facilities of varying levels of trustworthiness."],"url":"http://arxiv.org/abs/2504.20984v1"}
{"created":"2025-04-29 17:11:13","title":"Deep Learning Characterizes Depression and Suicidal Ideation from Eye Movements","abstract":"Identifying physiological and behavioral markers for mental health conditions is a longstanding challenge in psychiatry. Depression and suicidal ideation, in particular, lack objective biomarkers, with screening and diagnosis primarily relying on self-reports and clinical interviews. Here, we investigate eye tracking as a potential marker modality for screening purposes. Eye movements are directly modulated by neuronal networks and have been associated with attentional and mood-related patterns; however, their predictive value for depression and suicidality remains unclear. We recorded eye-tracking sequences from 126 young adults as they read and responded to affective sentences, and subsequently developed a deep learning framework to predict their clinical status. The proposed model included separate branches for trials of positive and negative sentiment, and used 2D time-series representations to account for both intra-trial and inter-trial variations. We were able to identify depression and suicidal ideation with an area under the receiver operating curve (AUC) of 0.793 (95% CI: 0.765-0.819) against healthy controls, and suicidality specifically with 0.826 AUC (95% CI: 0.797-0.852). The model also exhibited moderate, yet significant, accuracy in differentiating depressed from suicidal participants, with 0.609 AUC (95% CI 0.571-0.646). Discriminative patterns emerge more strongly when assessing the data relative to response generation than relative to the onset time of the final word of the sentences. The most pronounced effects were observed for negative-sentiment sentences, that are congruent to depressed and suicidal participants. Our findings highlight eye tracking as an objective tool for mental health assessment and underscore the modulatory impact of emotional stimuli on cognitive processes affecting oculomotor control.","sentences":["Identifying physiological and behavioral markers for mental health conditions is a longstanding challenge in psychiatry.","Depression and suicidal ideation, in particular, lack objective biomarkers, with screening and diagnosis primarily relying on self-reports and clinical interviews.","Here, we investigate eye tracking as a potential marker modality for screening purposes.","Eye movements are directly modulated by neuronal networks and have been associated with attentional and mood-related patterns; however, their predictive value for depression and suicidality remains unclear.","We recorded eye-tracking sequences from 126 young adults as they read and responded to affective sentences, and subsequently developed a deep learning framework to predict their clinical status.","The proposed model included separate branches for trials of positive and negative sentiment, and used 2D time-series representations to account for both intra-trial and inter-trial variations.","We were able to identify depression and suicidal ideation with an area under the receiver operating curve (AUC) of 0.793 (95% CI: 0.765-0.819) against healthy controls, and suicidality specifically with 0.826 AUC (95% CI: 0.797-0.852).","The model also exhibited moderate, yet significant, accuracy in differentiating depressed from suicidal participants, with 0.609 AUC (95% CI 0.571-0.646).","Discriminative patterns emerge more strongly when assessing the data relative to response generation than relative to the onset time of the final word of the sentences.","The most pronounced effects were observed for negative-sentiment sentences, that are congruent to depressed and suicidal participants.","Our findings highlight eye tracking as an objective tool for mental health assessment and underscore the modulatory impact of emotional stimuli on cognitive processes affecting oculomotor control."],"url":"http://arxiv.org/abs/2504.20944v1"}
{"created":"2025-04-29 17:05:55","title":"Conformal-DP: Differential Privacy on Riemannian Manifolds via Conformal Transformation","abstract":"Differential Privacy (DP) has been established as a safeguard for private data sharing by adding perturbations to information release. Prior research on DP has extended beyond data in the flat Euclidean space and addressed data on curved manifolds, e.g., diffusion tensor MRI, social networks, or organ shape analysis, by adding perturbations along geodesic distances. However, existing manifold-aware DP methods rely on the assumption that samples are uniformly distributed across the manifold. In reality, data densities vary, leading to a biased noise imbalance across manifold regions, weakening the privacy-utility trade-offs. To address this gap, we propose a novel mechanism: Conformal-DP, utilizing conformal transformations on the Riemannian manifold to equalize local sample density and to redefine geodesic distances accordingly while preserving the intrinsic geometry of the manifold. Our theoretical analysis yields two main results. First, we prove that the conformal factor computed from local kernel-density estimates is explicitly data-density-aware; Second, under the conformal metric, the mechanism satisfies $ \\varepsilon $-differential privacy on any complete Riemannian manifold and admits a closed-form upper bound on the expected geodesic error that depends only on the maximal density ratio, not on global curvatureof the manifold. Our experimental results validate that the mechanism achieves high utility while providing the $ \\varepsilon $-DP guarantee for both homogeneous and especially heterogeneous manifold data.","sentences":["Differential Privacy (DP) has been established as a safeguard for private data sharing by adding perturbations to information release.","Prior research on DP has extended beyond data in the flat Euclidean space and addressed data on curved manifolds, e.g., diffusion tensor MRI, social networks, or organ shape analysis, by adding perturbations along geodesic distances.","However, existing manifold-aware DP methods rely on the assumption that samples are uniformly distributed across the manifold.","In reality, data densities vary, leading to a biased noise imbalance across manifold regions, weakening the privacy-utility trade-offs.","To address this gap, we propose a novel mechanism: Conformal-DP, utilizing conformal transformations on the Riemannian manifold to equalize local sample density and to redefine geodesic distances accordingly while preserving the intrinsic geometry of the manifold.","Our theoretical analysis yields two main results.","First, we prove that the conformal factor computed from local kernel-density estimates is explicitly data-density-aware; Second, under the conformal metric, the mechanism satisfies $ \\varepsilon $-differential privacy on any complete Riemannian manifold and admits a closed-form upper bound on the expected geodesic error that depends only on the maximal density ratio, not on global curvatureof the manifold.","Our experimental results validate that the mechanism achieves high utility while providing the $ \\varepsilon $-DP guarantee for both homogeneous and especially heterogeneous manifold data."],"url":"http://arxiv.org/abs/2504.20941v1"}
{"created":"2025-04-29 17:02:57","title":"M\u00ecmir: A real-time interactive visualization library for CUDA programs","abstract":"Real-time visualization of computational simulations running over graphics processing units (GPU) is a valuable feature in modern science and technological research, as it allows researchers to visually assess the quality and correctness of their computational models during the simulation. Due to the high throughput involved in GPU-based simulations, classical visualization approaches such as ones based on copying to RAM or storage are not feasible anymore, as they imply large memory transfers between GPU and CPU at each moment, reducing both computational performance and interactivity. Implementing real-time visualizers for GPU simulation codes is a challenging task as it involves dealing with i) low-level integration of graphics APIs (e.g, OpenGL and Vulkan) into the general-purpose GPU code, ii) a careful and efficient handling of memory spaces and iii) finding a balance between rendering and computing as both need the GPU resources. In this work we present M\\`imir, a CUDA/Vulkan interoperability C++ library that allows users to add real-time 2D/3D visualization to CUDA codes with low programming effort. With M\\`imir, researchers can leverage state-of-the-art CUDA/Vulkan interoperability features without needing to invest time in learning the complex low-level technical aspects involved. Internally, M\\`imir streamlines the interoperability mapping between CUDA device memory containing simulation data and Vulkan graphics resources, so that changes on the data are instantly reflected in the visualization. This abstraction scheme allows generating visualizations with minimal alteration over the original source code, needing only to replace the GPU memory allocation lines of the data to be visualized by the API calls provided by M\\`imir among other optional changes.","sentences":["Real-time visualization of computational simulations running over graphics processing units (GPU) is a valuable feature in modern science and technological research, as it allows researchers to visually assess the quality and correctness of their computational models during the simulation.","Due to the high throughput involved in GPU-based simulations, classical visualization approaches such as ones based on copying to RAM or storage are not feasible anymore, as they imply large memory transfers between GPU and CPU at each moment, reducing both computational performance and interactivity.","Implementing real-time visualizers for GPU simulation codes is a challenging task as it involves dealing with i) low-level integration of graphics APIs (e.g, OpenGL and Vulkan) into the general-purpose GPU code, ii) a careful and efficient handling of memory spaces and iii) finding a balance between rendering and computing as both need the GPU resources.","In this work we present M\\`imir, a CUDA/Vulkan interoperability C++ library that allows users to add real-time 2D/3D visualization to CUDA codes with low programming effort.","With M\\`imir, researchers can leverage state-of-the-art CUDA/Vulkan interoperability features without needing to invest time in learning the complex low-level technical aspects involved.","Internally, M\\`imir streamlines the interoperability mapping between CUDA device memory containing simulation data and Vulkan graphics resources, so that changes on the data are instantly reflected in the visualization.","This abstraction scheme allows generating visualizations with minimal alteration over the original source code, needing only to replace the GPU memory allocation lines of the data to be visualized by the API calls provided by M\\`imir among other optional changes."],"url":"http://arxiv.org/abs/2504.20937v1"}
{"created":"2025-04-29 16:51:55","title":"DejaVuzz: Disclosing Transient Execution Bugs with Dynamic Swappable Memory and Differential Information Flow Tracking assisted Processor Fuzzing","abstract":"Transient execution vulnerabilities have emerged as a critical threat to modern processors. Hardware fuzzing testing techniques have recently shown promising results in discovering transient execution bugs in large-scale out-of-order processor designs. However, their poor microarchitectural controllability and observability prevent them from effectively and efficiently detecting transient execution vulnerabilities.   This paper proposes DejaVuzz, a novel pre-silicon stage processor transient execution bug fuzzer. DejaVuzz utilizes two innovative operating primitives: dynamic swappable memory and differential information flow tracking, enabling more effective and efficient transient execution vulnerability detection. The dynamic swappable memory enables the isolation of different instruction streams within the same address space. Leveraging this capability, DejaVuzz generates targeted training for arbitrary transient windows and eliminates ineffective training, enabling efficient triggering of diverse transient windows. The differential information flow tracking aids in observing the propagation of sensitive data across the microarchitecture. Based on taints, DejaVuzz designs the taint coverage matrix to guide mutation and uses taint liveness annotations to identify exploitable leakages. Our evaluation shows that DejaVuzz outperforms the state-of-the-art fuzzer SpecDoctor, triggering more comprehensive transient windows with lower training overhead and achieving a 4.7x coverage improvement. And DejaVuzz also mitigates control flow over-tainting with acceptable overhead and identifies 5 previously undiscovered transient execution vulnerabilities (with 6 CVEs assigned) on BOOM and XiangShan.","sentences":["Transient execution vulnerabilities have emerged as a critical threat to modern processors.","Hardware fuzzing testing techniques have recently shown promising results in discovering transient execution bugs in large-scale out-of-order processor designs.","However, their poor microarchitectural controllability and observability prevent them from effectively and efficiently detecting transient execution vulnerabilities.   ","This paper proposes DejaVuzz, a novel pre-silicon stage processor transient execution bug fuzzer.","DejaVuzz utilizes two innovative operating primitives: dynamic swappable memory and differential information flow tracking, enabling more effective and efficient transient execution vulnerability detection.","The dynamic swappable memory enables the isolation of different instruction streams within the same address space.","Leveraging this capability, DejaVuzz generates targeted training for arbitrary transient windows and eliminates ineffective training, enabling efficient triggering of diverse transient windows.","The differential information flow tracking aids in observing the propagation of sensitive data across the microarchitecture.","Based on taints, DejaVuzz designs the taint coverage matrix to guide mutation and uses taint liveness annotations to identify exploitable leakages.","Our evaluation shows that DejaVuzz outperforms the state-of-the-art fuzzer SpecDoctor, triggering more comprehensive transient windows with lower training overhead and achieving a 4.7x coverage improvement.","And DejaVuzz also mitigates control flow over-tainting with acceptable overhead and identifies 5 previously undiscovered transient execution vulnerabilities (with 6 CVEs assigned) on BOOM and XiangShan."],"url":"http://arxiv.org/abs/2504.20934v1"}
{"created":"2025-04-29 16:50:05","title":"Improvements of Dark Experience Replay and Reservoir Sampling towards Better Balance between Consolidation and Plasticity","abstract":"Continual learning is the one of the most essential abilities for autonomous agents, which can incrementally learn daily-life skills. For this ultimate goal, a simple but powerful method, dark experience replay (DER), has been proposed recently. DER mitigates catastrophic forgetting, in which the skills acquired in the past are unintentionally forgotten, by stochastically storing the streaming data in a reservoir sampling (RS) buffer and by relearning them or retaining the past outputs for them. However, since DER considers multiple objectives, it will not function properly without appropriate weighting of them. In addition, the ability to retain past outputs inhibits learning if the past outputs are incorrect due to distribution shift or other effects. This is due to a tradeoff between memory consolidation and plasticity. The tradeoff is hidden even in the RS buffer, which gradually stops storing new data for new skills in it as data is continuously passed to it. To alleviate the tradeoff and achieve better balance, this paper proposes improvement strategies to each of DER and RS. Specifically, DER is improved with automatic adaptation of weights, block of replaying erroneous data, and correction of past outputs. RS is also improved with generalization of acceptance probability, stratification of plural buffers, and intentional omission of unnecessary data. These improvements are verified through multiple benchmarks including regression, classification, and reinforcement learning problems. As a result, the proposed methods achieve steady improvements in learning performance by balancing the memory consolidation and plasticity.","sentences":["Continual learning is the one of the most essential abilities for autonomous agents, which can incrementally learn daily-life skills.","For this ultimate goal, a simple but powerful method, dark experience replay (DER), has been proposed recently.","DER mitigates catastrophic forgetting, in which the skills acquired in the past are unintentionally forgotten, by stochastically storing the streaming data in a reservoir sampling (RS) buffer and by relearning them or retaining the past outputs for them.","However, since DER considers multiple objectives, it will not function properly without appropriate weighting of them.","In addition, the ability to retain past outputs inhibits learning if the past outputs are incorrect due to distribution shift or other effects.","This is due to a tradeoff between memory consolidation and plasticity.","The tradeoff is hidden even in the RS buffer, which gradually stops storing new data for new skills in it as data is continuously passed to it.","To alleviate the tradeoff and achieve better balance, this paper proposes improvement strategies to each of DER and RS.","Specifically, DER is improved with automatic adaptation of weights, block of replaying erroneous data, and correction of past outputs.","RS is also improved with generalization of acceptance probability, stratification of plural buffers, and intentional omission of unnecessary data.","These improvements are verified through multiple benchmarks including regression, classification, and reinforcement learning problems.","As a result, the proposed methods achieve steady improvements in learning performance by balancing the memory consolidation and plasticity."],"url":"http://arxiv.org/abs/2504.20932v1"}
{"created":"2025-04-29 16:39:50","title":"Bipartite Randomized Response Mechanism for Local Differential Privacy","abstract":"With the increasing importance of data privacy, Local Differential Privacy (LDP) has recently become a strong measure of privacy for protecting each user's privacy from data analysts without relying on a trusted third party. In many cases, both data providers and data analysts hope to maximize the utility of released data. In this paper, we study the fundamental trade-off formulated as a constrained optimization problem: maximizing data utility subject to the constraint of LDP budgets. In particular, the Generalized Randomized Response (GRR) treats all discrete data equally except for the true data. For this, we introduce an adaptive LDP mechanism called Bipartite Randomized Response (BRR), which solves the above privacy-utility maximization problem from the global standpoint. We prove that for any utility function and any privacy level, solving the maximization problem is equivalent to confirming how many high-utility data to be treated equally as the true data on release probability, the outcome of which gives the optimal randomized response. Further, solving this linear program can be computationally cheap in theory. Several examples of utility functions defined by distance metrics and applications in decision trees and deep learning are presented. The results of various experiments show that our BRR significantly outperforms the state-of-the-art LDP mechanisms of both continuous and distributed types.","sentences":["With the increasing importance of data privacy, Local Differential Privacy (LDP) has recently become a strong measure of privacy for protecting each user's privacy from data analysts without relying on a trusted third party.","In many cases, both data providers and data analysts hope to maximize the utility of released data.","In this paper, we study the fundamental trade-off formulated as a constrained optimization problem: maximizing data utility subject to the constraint of LDP budgets.","In particular, the Generalized Randomized Response (GRR) treats all discrete data equally except for the true data.","For this, we introduce an adaptive LDP mechanism called Bipartite Randomized Response (BRR), which solves the above privacy-utility maximization problem from the global standpoint.","We prove that for any utility function and any privacy level, solving the maximization problem is equivalent to confirming how many high-utility data to be treated equally as the true data on release probability, the outcome of which gives the optimal randomized response.","Further, solving this linear program can be computationally cheap in theory.","Several examples of utility functions defined by distance metrics and applications in decision trees and deep learning are presented.","The results of various experiments show that our BRR significantly outperforms the state-of-the-art LDP mechanisms of both continuous and distributed types."],"url":"http://arxiv.org/abs/2504.20926v1"}
{"created":"2025-04-29 16:38:35","title":"A Domain-Agnostic Scalable AI Safety Ensuring Framework","abstract":"Ensuring the safety of AI systems has recently emerged as a critical priority for real-world deployment, particularly in physical AI applications. Current approaches to AI safety typically address predefined domain-specific safety conditions, limiting their ability to generalize across contexts.   We propose a novel AI safety framework that ensures AI systems comply with \\textbf{any user-defined constraint}, with \\textbf{any desired probability}, and across \\textbf{various domains}.   In this framework, we combine an AI component (e.g., neural network) with an optimization problem to produce responses that minimize objectives while satisfying user-defined constraints with probabilities exceeding user-defined thresholds. For credibility assessment of the AI component, we propose \\textit{internal test data}, a supplementary set of safety-labeled data, and a \\textit{conservative testing} methodology that provides statistical validity of using internal test data. We also present an approximation method of a loss function and how to compute its gradient for training.   We mathematically prove that probabilistic constraint satisfaction is guaranteed under specific, mild conditions and prove a scaling law between safety and the number of internal test data. We demonstrate our framework's effectiveness through experiments in diverse domains: demand prediction for production decision, safe reinforcement learning within the SafetyGym simulator, and guarding AI chatbot outputs. Through these experiments, we demonstrate that our method guarantees safety for user-specified constraints, outperforms {for \\textbf{up to several order of magnitudes}} existing methods in low safety threshold regions, and scales effectively with respect to the size of internal test data.","sentences":["Ensuring the safety of AI systems has recently emerged as a critical priority for real-world deployment, particularly in physical AI applications.","Current approaches to AI safety typically address predefined domain-specific safety conditions, limiting their ability to generalize across contexts.   ","We propose a novel AI safety framework that ensures AI systems comply with \\textbf{any user-defined constraint}, with \\textbf{any desired probability}, and across \\textbf{various domains}.   ","In this framework, we combine an AI component (e.g., neural network) with an optimization problem to produce responses that minimize objectives while satisfying user-defined constraints with probabilities exceeding user-defined thresholds.","For credibility assessment of the AI component, we propose \\textit{internal test data}, a supplementary set of safety-labeled data, and a \\textit{conservative testing} methodology that provides statistical validity of using internal test data.","We also present an approximation method of a loss function and how to compute its gradient for training.   ","We mathematically prove that probabilistic constraint satisfaction is guaranteed under specific, mild conditions and prove a scaling law between safety and the number of internal test data.","We demonstrate our framework's effectiveness through experiments in diverse domains: demand prediction for production decision, safe reinforcement learning within the SafetyGym simulator, and guarding AI chatbot outputs.","Through these experiments, we demonstrate that our method guarantees safety for user-specified constraints, outperforms {for \\textbf{up to several order of magnitudes}} existing methods in low safety threshold regions, and scales effectively with respect to the size of internal test data."],"url":"http://arxiv.org/abs/2504.20924v1"}
{"created":"2025-04-29 16:38:23","title":"End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based Approach with Cross-Dataset Evaluation","abstract":"Audio deepfakes represent a growing threat to digital security and trust, leveraging advanced generative models to produce synthetic speech that closely mimics real human voices. Detecting such manipulations is especially challenging under open-world conditions, where spoofing methods encountered during testing may differ from those seen during training. In this work, we propose an end-to-end deep learning framework for audio deepfake detection that operates directly on raw waveforms. Our model, RawNetLite, is a lightweight convolutional-recurrent architecture designed to capture both spectral and temporal features without handcrafted preprocessing. To enhance robustness, we introduce a training strategy that combines data from multiple domains and adopts Focal Loss to emphasize difficult or ambiguous samples. We further demonstrate that incorporating codec-based manipulations and applying waveform-level audio augmentations (e.g., pitch shifting, noise, and time stretching) leads to significant generalization improvements under realistic acoustic conditions. The proposed model achieves over 99.7% F1 and 0.25% EER on in-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging out-of-distribution test set (AVSpoof2021 + CodecFake). These findings highlight the importance of diverse training data, tailored objective functions and audio augmentations in building resilient and generalizable audio forgery detectors. Code and pretrained models are available at https://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/.","sentences":["Audio deepfakes represent a growing threat to digital security and trust, leveraging advanced generative models to produce synthetic speech that closely mimics real human voices.","Detecting such manipulations is especially challenging under open-world conditions, where spoofing methods encountered during testing may differ from those seen during training.","In this work, we propose an end-to-end deep learning framework for audio deepfake detection that operates directly on raw waveforms.","Our model, RawNetLite, is a lightweight convolutional-recurrent architecture designed to capture both spectral and temporal features without handcrafted preprocessing.","To enhance robustness, we introduce a training strategy that combines data from multiple domains and adopts Focal Loss to emphasize difficult or ambiguous samples.","We further demonstrate that incorporating codec-based manipulations and applying waveform-level audio augmentations (e.g., pitch shifting, noise, and time stretching) leads to significant generalization improvements under realistic acoustic conditions.","The proposed model achieves over 99.7% F1 and 0.25% EER on in-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging out-of-distribution test set (AVSpoof2021 + CodecFake).","These findings highlight the importance of diverse training data, tailored objective functions and audio augmentations in building resilient and generalizable audio forgery detectors.","Code and pretrained models are available at https://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/."],"url":"http://arxiv.org/abs/2504.20923v1"}
{"created":"2025-04-29 16:38:15","title":"DYNAMAX: Dynamic computing for Transformers and Mamba based architectures","abstract":"Early exits (EEs) offer a promising approach to reducing computational costs and latency by dynamically terminating inference once a satisfactory prediction confidence on a data sample is achieved. Although many works integrate EEs into encoder-only Transformers, their application to decoder-only architectures and, more importantly, Mamba models, a novel family of state-space architectures in the LLM realm, remains insufficiently explored. This work introduces DYNAMAX, the first framework to exploit the unique properties of Mamba architectures for early exit mechanisms. We not only integrate EEs into Mamba but also repurpose Mamba as an efficient EE classifier for both Mamba-based and transformer-based LLMs, showcasing its versatility. Our experiments employ the Mistral 7B transformer compared to the Codestral 7B Mamba model, using data sets such as TruthfulQA, CoQA, and TriviaQA to evaluate computational savings, accuracy, and consistency. The results highlight the adaptability of Mamba as a powerful EE classifier and its efficiency in balancing computational cost and performance quality across NLP tasks. By leveraging Mamba's inherent design for dynamic processing, we open pathways for scalable and efficient inference in embedded applications and resource-constrained environments. This study underscores the transformative potential of Mamba in redefining dynamic computing paradigms for LLMs.","sentences":["Early exits (EEs) offer a promising approach to reducing computational costs and latency by dynamically terminating inference once a satisfactory prediction confidence on a data sample is achieved.","Although many works integrate EEs into encoder-only Transformers, their application to decoder-only architectures and, more importantly, Mamba models, a novel family of state-space architectures in the LLM realm, remains insufficiently explored.","This work introduces DYNAMAX, the first framework to exploit the unique properties of Mamba architectures for early exit mechanisms.","We not only integrate EEs into Mamba but also repurpose Mamba as an efficient EE classifier for both Mamba-based and transformer-based LLMs, showcasing its versatility.","Our experiments employ the Mistral 7B transformer compared to the Codestral 7B Mamba model, using data sets such as TruthfulQA, CoQA, and TriviaQA to evaluate computational savings, accuracy, and consistency.","The results highlight the adaptability of Mamba as a powerful EE classifier and its efficiency in balancing computational cost and performance quality across NLP tasks.","By leveraging Mamba's inherent design for dynamic processing, we open pathways for scalable and efficient inference in embedded applications and resource-constrained environments.","This study underscores the transformative potential of Mamba in redefining dynamic computing paradigms for LLMs."],"url":"http://arxiv.org/abs/2504.20922v1"}
{"created":"2025-04-29 16:37:34","title":"Leveraging Generative AI Through Prompt Engineering and Rigorous Validation to Create Comprehensive Synthetic Datasets for AI Training in Healthcare","abstract":"Access to high-quality medical data is often restricted due to privacy concerns, posing significant challenges for training artificial intelligence (AI) algorithms within Electronic Health Record (EHR) applications. In this study, prompt engineering with the GPT-4 API was employed to generate high-quality synthetic datasets aimed at overcoming this limitation. The generated data encompassed a comprehensive array of patient admission information, including healthcare provider details, hospital departments, wards, bed assignments, patient demographics, emergency contacts, vital signs, immunizations, allergies, medical histories, appointments, hospital visits, laboratory tests, diagnoses, treatment plans, medications, clinical notes, visit logs, discharge summaries, and referrals. To ensure data quality and integrity, advanced validation techniques were implemented utilizing models such as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for overall plausibility, RoBERTa for logical consistency, autoencoders for anomaly detection, and conducted diversity analysis. Synthetic data that met all validation criteria were integrated into a comprehensive PostgreSQL database, serving as the data management system for the EHR application. This approach demonstrates that leveraging generative AI models with rigorous validation can effectively produce high-quality synthetic medical data, facilitating the training of AI algorithms while addressing privacy concerns associated with real patient data.","sentences":["Access to high-quality medical data is often restricted due to privacy concerns, posing significant challenges for training artificial intelligence (AI) algorithms within Electronic Health Record (EHR) applications.","In this study, prompt engineering with the GPT-4 API was employed to generate high-quality synthetic datasets aimed at overcoming this limitation.","The generated data encompassed a comprehensive array of patient admission information, including healthcare provider details, hospital departments, wards, bed assignments, patient demographics, emergency contacts, vital signs, immunizations, allergies, medical histories, appointments, hospital visits, laboratory tests, diagnoses, treatment plans, medications, clinical notes, visit logs, discharge summaries, and referrals.","To ensure data quality and integrity, advanced validation techniques were implemented utilizing models such as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for overall plausibility, RoBERTa for logical consistency, autoencoders for anomaly detection, and conducted diversity analysis.","Synthetic data that met all validation criteria were integrated into a comprehensive PostgreSQL database, serving as the data management system for the EHR application.","This approach demonstrates that leveraging generative AI models with rigorous validation can effectively produce high-quality synthetic medical data, facilitating the training of AI algorithms while addressing privacy concerns associated with real patient data."],"url":"http://arxiv.org/abs/2504.20921v1"}
{"created":"2025-04-29 16:34:06","title":"Statistical and Predictive Analysis to Identify Risk Factors and Effects of Post COVID-19 Syndrome","abstract":"Based on recent studies, some COVID-19 symptoms can persist for months after infection, leading to what is termed long COVID. Factors such as vaccination timing, patient characteristics, and symptoms during the acute phase of infection may contribute to the prolonged effects and intensity of long COVID. Each patient, based on their unique combination of factors, develops a specific risk or intensity of long COVID. In this work, we aim to achieve two objectives: (1) conduct a statistical analysis to identify relationships between various factors and long COVID, and (2) perform predictive analysis of long COVID intensity using these factors. We benchmark and interpret various data-driven approaches, including linear models, random forests, gradient boosting, and neural networks, using data from the Lifelines COVID-19 cohort. Our results show that Neural Networks (NN) achieve the best performance in terms of MAPE, with predictions averaging 19\\% error. Additionally, interpretability analysis reveals key factors such as loss of smell, headache, muscle pain, and vaccination timing as significant predictors, while chronic disease and gender are critical risk factors. These insights provide valuable guidance for understanding long COVID and developing targeted interventions.","sentences":["Based on recent studies, some COVID-19 symptoms can persist for months after infection, leading to what is termed long COVID.","Factors such as vaccination timing, patient characteristics, and symptoms during the acute phase of infection may contribute to the prolonged effects and intensity of long COVID.","Each patient, based on their unique combination of factors, develops a specific risk or intensity of long COVID.","In this work, we aim to achieve two objectives: (1) conduct a statistical analysis to identify relationships between various factors and long COVID, and (2) perform predictive analysis of long COVID intensity using these factors.","We benchmark and interpret various data-driven approaches, including linear models, random forests, gradient boosting, and neural networks, using data from the Lifelines COVID-19 cohort.","Our results show that Neural Networks (NN) achieve the best performance in terms of MAPE, with predictions averaging 19\\% error.","Additionally, interpretability analysis reveals key factors such as loss of smell, headache, muscle pain, and vaccination timing as significant predictors, while chronic disease and gender are critical risk factors.","These insights provide valuable guidance for understanding long COVID and developing targeted interventions."],"url":"http://arxiv.org/abs/2504.20915v1"}
{"created":"2025-04-29 16:32:22","title":"On the Secrecy-Sensing Optimization of RIS-assisted Full-Duplex Integrated Sensing and Communication Network","abstract":"Integrated sensing and communication (ISAC) has recently emerged as a viable technique for establishing sensing and communication using the same resources. Nonetheless, the operation of ISAC networks is often challenged by the absence of a direct link between the sensing node and the targets, and by the risk of disclosing confidential data to malicious targets when using the same signal for both tasks. In this paper, a robust reconfigurable intelligent surface (RIS)-aided scheme for securing a full-duplex (FD) ISAC network is proposed. The considered network consists of uplink and downlink users served in FD through a multi-antenna dual-functional radar communication base station (BS), which employs co-located multi-antenna communication-radar arrays to detect multiple malicious targets while preserving communication secrecy in their presence. Additionally, the BS utilizes an optimized artificial noise (AN) that serves to disrupt the malicious targets' reception and increase the sensing power. By optimally designing the RIS phase shifts, transmit beamforming, AN covariance, and uplink users' transmit power and combining vectors using an alternating optimization-based algorithm, the network's sensing performance is maximized under secrecy and total power constraints. Numerical results present the proposed scheme's efficacy, particularly when a direct link between the BS and the various nodes/targets is absent.","sentences":["Integrated sensing and communication (ISAC) has recently emerged as a viable technique for establishing sensing and communication using the same resources.","Nonetheless, the operation of ISAC networks is often challenged by the absence of a direct link between the sensing node and the targets, and by the risk of disclosing confidential data to malicious targets when using the same signal for both tasks.","In this paper, a robust reconfigurable intelligent surface (RIS)-aided scheme for securing a full-duplex (FD) ISAC network is proposed.","The considered network consists of uplink and downlink users served in FD through a multi-antenna dual-functional radar communication base station (BS), which employs co-located multi-antenna communication-radar arrays to detect multiple malicious targets while preserving communication secrecy in their presence.","Additionally, the BS utilizes an optimized artificial noise (AN) that serves to disrupt the malicious targets' reception and increase the sensing power.","By optimally designing the RIS phase shifts, transmit beamforming, AN covariance, and uplink users' transmit power and combining vectors using an alternating optimization-based algorithm, the network's sensing performance is maximized under secrecy and total power constraints.","Numerical results present the proposed scheme's efficacy, particularly when a direct link between the BS and the various nodes/targets is absent."],"url":"http://arxiv.org/abs/2504.20912v1"}
{"created":"2025-04-29 16:25:23","title":"MOSIC: Model-Agnostic Optimal Subgroup Identification with Multi-Constraint for Improved Reliability","abstract":"Identifying subgroups that benefit from specific treatments using observational data is a critical challenge in personalized medicine. Most existing approaches solely focus on identifying a subgroup with an improved treatment effect. However, practical considerations, such as ensuring a minimum subgroup size for representativeness or achieving sufficient confounder balance for reliability, are also important for making findings clinically meaningful and actionable. While some studies address these constraints individually, none offer a unified approach to handle them simultaneously. To bridge this gap, we propose a model-agnostic framework for optimal subgroup identification under multiple constraints. We reformulate this combinatorial problem as an unconstrained min-max optimization problem with novel modifications and solve it by a gradient descent ascent algorithm. We further prove its convergence to a feasible and locally optimal solution. Our method is stable and highly flexible, supporting various models and techniques for estimating and optimizing treatment effectiveness with observational data. Extensive experiments on both synthetic and real-world datasets demonstrate its effectiveness in identifying subgroups that satisfy multiple constraints, achieving higher treatment effects and better confounder balancing results across different group sizes.","sentences":["Identifying subgroups that benefit from specific treatments using observational data is a critical challenge in personalized medicine.","Most existing approaches solely focus on identifying a subgroup with an improved treatment effect.","However, practical considerations, such as ensuring a minimum subgroup size for representativeness or achieving sufficient confounder balance for reliability, are also important for making findings clinically meaningful and actionable.","While some studies address these constraints individually, none offer a unified approach to handle them simultaneously.","To bridge this gap, we propose a model-agnostic framework for optimal subgroup identification under multiple constraints.","We reformulate this combinatorial problem as an unconstrained min-max optimization problem with novel modifications and solve it by a gradient descent ascent algorithm.","We further prove its convergence to a feasible and locally optimal solution.","Our method is stable and highly flexible, supporting various models and techniques for estimating and optimizing treatment effectiveness with observational data.","Extensive experiments on both synthetic and real-world datasets demonstrate its effectiveness in identifying subgroups that satisfy multiple constraints, achieving higher treatment effects and better confounder balancing results across different group sizes."],"url":"http://arxiv.org/abs/2504.20908v1"}
{"created":"2025-04-29 16:19:38","title":"Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers","abstract":"A person downloading a pre-trained model from the web should be aware of its biases. Existing approaches for bias identification rely on datasets containing labels for the task of interest, something that a non-expert may not have access to, or may not have the necessary resources to collect: this greatly limits the number of tasks where model biases can be identified. In this work, we present Classifier-to-Bias (C2B), the first bias discovery framework that works without access to any labeled data: it only relies on a textual description of the classification task to identify biases in the target classification model. This description is fed to a large language model to generate bias proposals and corresponding captions depicting biases together with task-specific target labels. A retrieval model collects images for those captions, which are then used to assess the accuracy of the model w.r.t. the given biases. C2B is training-free, does not require any annotations, has no constraints on the list of biases, and can be applied to any pre-trained model on any classification task. Experiments on two publicly available datasets show that C2B discovers biases beyond those of the original datasets and outperforms a recent state-of-the-art bias detection baseline that relies on task-specific annotations, being a promising first step toward addressing task-agnostic unsupervised bias detection.","sentences":["A person downloading a pre-trained model from the web should be aware of its biases.","Existing approaches for bias identification rely on datasets containing labels for the task of interest, something that a non-expert may not have access to, or may not have the necessary resources to collect: this greatly limits the number of tasks where model biases can be identified.","In this work, we present Classifier-to-Bias (C2B), the first bias discovery framework that works without access to any labeled data: it only relies on a textual description of the classification task to identify biases in the target classification model.","This description is fed to a large language model to generate bias proposals and corresponding captions depicting biases together with task-specific target labels.","A retrieval model collects images for those captions, which are then used to assess the accuracy of the model w.r.t.","the given biases.","C2B is training-free, does not require any annotations, has no constraints on the list of biases, and can be applied to any pre-trained model on any classification task.","Experiments on two publicly available datasets show that C2B discovers biases beyond those of the original datasets and outperforms a recent state-of-the-art bias detection baseline that relies on task-specific annotations, being a promising first step toward addressing task-agnostic unsupervised bias detection."],"url":"http://arxiv.org/abs/2504.20902v1"}
{"created":"2025-04-29 16:16:51","title":"Evaluating Generative Models for Tabular Data: Novel Metrics and Benchmarking","abstract":"Generative models have revolutionized multiple domains, yet their application to tabular data remains underexplored. Evaluating generative models for tabular data presents unique challenges due to structural complexity, large-scale variability, and mixed data types, making it difficult to intuitively capture intricate patterns. Existing evaluation metrics offer only partial insights, lacking a comprehensive measure of generative performance. To address this limitation, we propose three novel evaluation metrics: FAED, FPCAD, and RFIS. Our extensive experimental analysis, conducted on three standard network intrusion detection datasets, compares these metrics with established evaluation methods such as Fidelity, Utility, TSTR, and TRTS. Our results demonstrate that FAED effectively captures generative modeling issues overlooked by existing metrics. While FPCAD exhibits promising performance, further refinements are necessary to enhance its reliability. Our proposed framework provides a robust and practical approach for assessing generative models in tabular data applications.","sentences":["Generative models have revolutionized multiple domains, yet their application to tabular data remains underexplored.","Evaluating generative models for tabular data presents unique challenges due to structural complexity, large-scale variability, and mixed data types, making it difficult to intuitively capture intricate patterns.","Existing evaluation metrics offer only partial insights, lacking a comprehensive measure of generative performance.","To address this limitation, we propose three novel evaluation metrics: FAED, FPCAD, and RFIS.","Our extensive experimental analysis, conducted on three standard network intrusion detection datasets, compares these metrics with established evaluation methods such as Fidelity, Utility, TSTR, and TRTS.","Our results demonstrate that FAED effectively captures generative modeling issues overlooked by existing metrics.","While FPCAD exhibits promising performance, further refinements are necessary to enhance its reliability.","Our proposed framework provides a robust and practical approach for assessing generative models in tabular data applications."],"url":"http://arxiv.org/abs/2504.20900v1"}
{"created":"2025-04-29 16:01:51","title":"Mapping a Movement: Exploring a Proposed Police Training Facility in Atlanta and the Stop Cop City Movement through Online Maps","abstract":"In 2021, the City of Atlanta and Atlanta Police Foundation launched plans to build a large police training facility in the South River Forest in unincorporated DeKalb County, GA. Residents of Atlanta and DeKalb County, environmental activists, police and prison abolitionists, and other activists and concerned individuals formed the movement in opposition to the facility, known as the Stop Cop City / Defend the Atlanta Forest movement. Social media and digital maps became common tools for communicating information about the facility and the movement. Here, we examine online maps about the facility and the opposition movement, originating from grassroots organizations, the City of Atlanta, news media outlets, the Atlanta Police Foundation, and individuals. We gather and examine 32 publicly available maps collected through the Google Search API, Twitter (now X), Instagram and reddit. Using a framework of critical cartography, we conduct a content analysis of these maps to identify the mapping technologies and techniques (data, cartographic elements, styles) used by different stakeholders and roles that maps and mapping technologies can play in social movements. We examine the extent to which these maps provide data to confirm or contradict concerns raised by grassroots organizations and local residents about the facility. We find that stakeholders and mapmakers use geospatial tools in different ways and likely have varied access to mapping technologies. We argue that documenting the use of maps to communicate information about a contentious project can help enumerate community positions and perspectives, and we advocate for accessible mapmaking tools. We conclude by discussing the implications of accessibility of mapping technology and posting maps to social media, and share example map images that extend the geographic information systems (GIS) techniques seen in the retrieved maps.","sentences":["In 2021, the City of Atlanta and Atlanta Police Foundation launched plans to build a large police training facility in the South River Forest in unincorporated DeKalb County, GA.","Residents of Atlanta and DeKalb County, environmental activists, police and prison abolitionists, and other activists and concerned individuals formed the movement in opposition to the facility, known as the Stop Cop City / Defend the Atlanta Forest movement.","Social media and digital maps became common tools for communicating information about the facility and the movement.","Here, we examine online maps about the facility and the opposition movement, originating from grassroots organizations, the City of Atlanta, news media outlets, the Atlanta Police Foundation, and individuals.","We gather and examine 32 publicly available maps collected through the Google Search API, Twitter (now X), Instagram and reddit.","Using a framework of critical cartography, we conduct a content analysis of these maps to identify the mapping technologies and techniques (data, cartographic elements, styles) used by different stakeholders and roles that maps and mapping technologies can play in social movements.","We examine the extent to which these maps provide data to confirm or contradict concerns raised by grassroots organizations and local residents about the facility.","We find that stakeholders and mapmakers use geospatial tools in different ways and likely have varied access to mapping technologies.","We argue that documenting the use of maps to communicate information about a contentious project can help enumerate community positions and perspectives, and we advocate for accessible mapmaking tools.","We conclude by discussing the implications of accessibility of mapping technology and posting maps to social media, and share example map images that extend the geographic information systems (GIS) techniques seen in the retrieved maps."],"url":"http://arxiv.org/abs/2504.20886v1"}
{"created":"2025-04-29 15:56:48","title":"Guessing Efficiently for Constrained Subspace Approximation","abstract":"In this paper we study constrained subspace approximation problem. Given a set of $n$ points $\\{a_1,\\ldots,a_n\\}$ in $\\mathbb{R}^d$, the goal of the {\\em subspace approximation} problem is to find a $k$ dimensional subspace that best approximates the input points. More precisely, for a given $p\\geq 1$, we aim to minimize the $p$th power of the $\\ell_p$ norm of the error vector $(\\|a_1-\\bm{P}a_1\\|,\\ldots,\\|a_n-\\bm{P}a_n\\|)$, where $\\bm{P}$ denotes the projection matrix onto the subspace and the norms are Euclidean. In \\emph{constrained} subspace approximation (CSA), we additionally have constraints on the projection matrix $\\bm{P}$. In its most general form, we require $\\bm{P}$ to belong to a given subset $\\mathcal{S}$ that is described explicitly or implicitly.   We introduce a general framework for constrained subspace approximation. Our approach, that we term coreset-guess-solve, yields either $(1+\\varepsilon)$-multiplicative or $\\varepsilon$-additive approximations for a variety of constraints. We show that it provides new algorithms for partition-constrained subspace approximation with applications to {\\it fair} subspace approximation, $k$-means clustering, and projected non-negative matrix factorization, among others. Specifically, while we reconstruct the best known bounds for $k$-means clustering in Euclidean spaces, we improve the known results for the remainder of the problems.","sentences":["In this paper we study constrained subspace approximation problem.","Given a set of $n$ points $\\{a_1,\\ldots,a_n\\}$ in $\\mathbb{R}^d$, the goal of the {\\em subspace approximation} problem is to find a $k$ dimensional subspace that best approximates the input points.","More precisely, for a given $p\\geq 1$, we aim to minimize the $p$th power of the $\\ell_p$ norm of the error vector $(\\|a_1-\\bm{P}a_1\\|,\\ldots,\\|a_n-\\bm{P}a_n\\|)$, where $\\bm{P}$ denotes the projection matrix onto the subspace and the norms are Euclidean.","In \\emph{constrained} subspace approximation (CSA), we additionally have constraints on the projection matrix $\\bm{P}$. In its most general form, we require $\\bm{P}$ to belong to a given subset $\\mathcal{S}$ that is described explicitly or implicitly.   ","We introduce a general framework for constrained subspace approximation.","Our approach, that we term coreset-guess-solve, yields either $(1+\\varepsilon)$-multiplicative or $\\varepsilon$-additive approximations for a variety of constraints.","We show that it provides new algorithms for partition-constrained subspace approximation with applications to {\\it fair} subspace approximation, $k$-means clustering, and projected non-negative matrix factorization, among others.","Specifically, while we reconstruct the best known bounds for $k$-means clustering in Euclidean spaces, we improve the known results for the remainder of the problems."],"url":"http://arxiv.org/abs/2504.20883v1"}
{"created":"2025-04-29 15:48:49","title":"The Leaderboard Illusion","abstract":"Measuring progress is fundamental to the advancement of any scientific field. As benchmarks play an increasingly central role, they also grow more susceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard for ranking the most capable AI systems. Yet, in this work we identify systematic issues that have resulted in a distorted playing field. We find that undisclosed private testing practices benefit a handful of providers who are able to test multiple variants before public release and retract scores if desired. We establish that the ability of these providers to choose the best score leads to biased Arena scores due to selective disclosure of performance results. At an extreme, we identify 27 private LLM variants tested by Meta in the lead-up to the Llama-4 release. We also establish that proprietary closed models are sampled at higher rates (number of battles) and have fewer models removed from the arena than open-weight and open-source alternatives. Both these policies lead to large data access asymmetries over time. Providers like Google and OpenAI have received an estimated 19.2% and 20.4% of all data on the arena, respectively. In contrast, a combined 83 open-weight models have only received an estimated 29.7% of the total data. We show that access to Chatbot Arena data yields substantial benefits; even limited additional data can result in relative performance gains of up to 112% on the arena distribution, based on our conservative estimates. Together, these dynamics result in overfitting to Arena-specific dynamics rather than general model quality. The Arena builds on the substantial efforts of both the organizers and an open community that maintains this valuable evaluation platform. We offer actionable recommendations to reform the Chatbot Arena's evaluation framework and promote fairer, more transparent benchmarking for the field","sentences":["Measuring progress is fundamental to the advancement of any scientific field.","As benchmarks play an increasingly central role, they also grow more susceptible to distortion.","Chatbot Arena has emerged as the go-to leaderboard for ranking the most capable AI systems.","Yet, in this work we identify systematic issues that have resulted in a distorted playing field.","We find that undisclosed private testing practices benefit a handful of providers who are able to test multiple variants before public release and retract scores if desired.","We establish that the ability of these providers to choose the best score leads to biased Arena scores due to selective disclosure of performance results.","At an extreme, we identify 27 private LLM variants tested by Meta in the lead-up to the Llama-4 release.","We also establish that proprietary closed models are sampled at higher rates (number of battles) and have fewer models removed from the arena than open-weight and open-source alternatives.","Both these policies lead to large data access asymmetries over time.","Providers like Google and OpenAI have received an estimated 19.2% and 20.4% of all data on the arena, respectively.","In contrast, a combined 83 open-weight models have only received an estimated 29.7% of the total data.","We show that access to Chatbot Arena data yields substantial benefits; even limited additional data can result in relative performance gains of up to 112% on the arena distribution, based on our conservative estimates.","Together, these dynamics result in overfitting to Arena-specific dynamics rather than general model quality.","The Arena builds on the substantial efforts of both the organizers and an open community that maintains this valuable evaluation platform.","We offer actionable recommendations to reform the Chatbot Arena's evaluation framework and promote fairer, more transparent benchmarking for the field"],"url":"http://arxiv.org/abs/2504.20879v1"}
{"created":"2025-04-29 15:44:02","title":"FLIM-based Salient Object Detection Networks with Adaptive Decoders","abstract":"Salient Object Detection (SOD) methods can locate objects that stand out in an image, assign higher values to their pixels in a saliency map, and binarize the map outputting a predicted segmentation mask. A recent tendency is to investigate pre-trained lightweight models rather than deep neural networks in SOD tasks, coping with applications under limited computational resources. In this context, we have investigated lightweight networks using a methodology named Feature Learning from Image Markers (FLIM), which assumes that the encoder's kernels can be estimated from marker pixels on discriminative regions of a few representative images. This work proposes flyweight networks, hundreds of times lighter than lightweight models, for SOD by combining a FLIM encoder with an adaptive decoder, whose weights are estimated for each input image by a given heuristic function. Such FLIM networks are trained from three to four representative images only and without backpropagation, making the models suitable for applications under labeled data constraints as well. We study five adaptive decoders; two of them are introduced here. Differently from the previous ones that rely on one neuron per pixel with shared weights, the heuristic functions of the new adaptive decoders estimate the weights of each neuron per pixel. We compare FLIM models with adaptive decoders for two challenging SOD tasks with three lightweight networks from the state-of-the-art, two FLIM networks with decoders trained by backpropagation, and one FLIM network whose labeled markers define the decoder's weights. The experiments demonstrate the advantages of the proposed networks over the baselines, revealing the importance of further investigating such methods in new applications.","sentences":["Salient Object Detection (SOD) methods can locate objects that stand out in an image, assign higher values to their pixels in a saliency map, and binarize the map outputting a predicted segmentation mask.","A recent tendency is to investigate pre-trained lightweight models rather than deep neural networks in SOD tasks, coping with applications under limited computational resources.","In this context, we have investigated lightweight networks using a methodology named Feature Learning from Image Markers (FLIM), which assumes that the encoder's kernels can be estimated from marker pixels on discriminative regions of a few representative images.","This work proposes flyweight networks, hundreds of times lighter than lightweight models, for SOD by combining a FLIM encoder with an adaptive decoder, whose weights are estimated for each input image by a given heuristic function.","Such FLIM networks are trained from three to four representative images only and without backpropagation, making the models suitable for applications under labeled data constraints as well.","We study five adaptive decoders; two of them are introduced here.","Differently from the previous ones that rely on one neuron per pixel with shared weights, the heuristic functions of the new adaptive decoders estimate the weights of each neuron per pixel.","We compare FLIM models with adaptive decoders for two challenging SOD tasks with three lightweight networks from the state-of-the-art, two FLIM networks with decoders trained by backpropagation, and one FLIM network whose labeled markers define the decoder's weights.","The experiments demonstrate the advantages of the proposed networks over the baselines, revealing the importance of further investigating such methods in new applications."],"url":"http://arxiv.org/abs/2504.20872v1"}
{"created":"2025-04-29 15:42:14","title":"Predicting the Performance of Scientific Workflow Tasks for Cluster Resource Management: An Overview of the State of the Art","abstract":"Scientific workflow management systems support large-scale data analysis on cluster infrastructures. For this, they interact with resource managers which schedule workflow tasks onto cluster nodes. In addition to workflow task descriptions, resource managers rely on task performance estimates such as main memory consumption and runtime to efficiently manage cluster resources. Such performance estimates should be automated, as user-based task performance estimates are error-prone.   In this book chapter, we describe key characteristics of methods for workflow task runtime and memory prediction, provide an overview and a detailed comparison of state-of-the-art methods from the literature, and discuss how workflow task performance prediction is useful for scheduling, energy-efficient and carbon-aware computing, and cost prediction.","sentences":["Scientific workflow management systems support large-scale data analysis on cluster infrastructures.","For this, they interact with resource managers which schedule workflow tasks onto cluster nodes.","In addition to workflow task descriptions, resource managers rely on task performance estimates such as main memory consumption and runtime to efficiently manage cluster resources.","Such performance estimates should be automated, as user-based task performance estimates are error-prone.   ","In this book chapter, we describe key characteristics of methods for workflow task runtime and memory prediction, provide an overview and a detailed comparison of state-of-the-art methods from the literature, and discuss how workflow task performance prediction is useful for scheduling, energy-efficient and carbon-aware computing, and cost prediction."],"url":"http://arxiv.org/abs/2504.20867v1"}
{"created":"2025-04-29 15:41:13","title":"AI-GenBench: A New Ongoing Benchmark for AI-Generated Image Detection","abstract":"The rapid advancement of generative AI has revolutionized image creation, enabling high-quality synthesis from text prompts while raising critical challenges for media authenticity. We present Ai-GenBench, a novel benchmark designed to address the urgent need for robust detection of AI-generated images in real-world scenarios. Unlike existing solutions that evaluate models on static datasets, Ai-GenBench introduces a temporal evaluation framework where detection methods are incrementally trained on synthetic images, historically ordered by their generative models, to test their ability to generalize to new generative models, such as the transition from GANs to diffusion models. Our benchmark focuses on high-quality, diverse visual content and overcomes key limitations of current approaches, including arbitrary dataset splits, unfair comparisons, and excessive computational demands. Ai-GenBench provides a comprehensive dataset, a standardized evaluation protocol, and accessible tools for both researchers and non-experts (e.g., journalists, fact-checkers), ensuring reproducibility while maintaining practical training requirements. By establishing clear evaluation rules and controlled augmentation strategies, Ai-GenBench enables meaningful comparison of detection methods and scalable solutions. Code and data are publicly available to ensure reproducibility and to support the development of robust forensic detectors to keep pace with the rise of new synthetic generators.","sentences":["The rapid advancement of generative AI has revolutionized image creation, enabling high-quality synthesis from text prompts while raising critical challenges for media authenticity.","We present Ai-GenBench, a novel benchmark designed to address the urgent need for robust detection of AI-generated images in real-world scenarios.","Unlike existing solutions that evaluate models on static datasets, Ai-GenBench introduces a temporal evaluation framework where detection methods are incrementally trained on synthetic images, historically ordered by their generative models, to test their ability to generalize to new generative models, such as the transition from GANs to diffusion models.","Our benchmark focuses on high-quality, diverse visual content and overcomes key limitations of current approaches, including arbitrary dataset splits, unfair comparisons, and excessive computational demands.","Ai-GenBench provides a comprehensive dataset, a standardized evaluation protocol, and accessible tools for both researchers and non-experts (e.g., journalists, fact-checkers), ensuring reproducibility while maintaining practical training requirements.","By establishing clear evaluation rules and controlled augmentation strategies, Ai-GenBench enables meaningful comparison of detection methods and scalable solutions.","Code and data are publicly available to ensure reproducibility and to support the development of robust forensic detectors to keep pace with the rise of new synthetic generators."],"url":"http://arxiv.org/abs/2504.20865v1"}
{"created":"2025-04-29 15:39:10","title":"Bayesian Optimization-based Tire Parameter and Uncertainty Estimation for Real-World Data","abstract":"This work presents a methodology to estimate tire parameters and their uncertainty using a Bayesian optimization approach. The literature mainly considers the estimation of tire parameters but lacks an evaluation of the parameter identification quality and the required slip ratios for an adequate model fit. Therefore, we examine the use of Stochastical Variational Inference as a methodology to estimate both - the parameters and their uncertainties. We evaluate the method compared to a state-of-the-art Nelder-Mead algorithm for theoretical and real-world application. The theoretical study considers parameter fitting at different slip ratios to evaluate the required excitation for an adequate fitting of each parameter. The results are compared to a sensitivity analysis for a Pacejka Magic Formula tire model. We show the application of the algorithm on real-world data acquired during the Abu Dhabi Autonomous Racing League and highlight the uncertainties in identifying the curvature and shape parameters due to insufficient excitation. The gathered insights can help assess the acquired data's limitations and instead utilize standardized parameters until higher slip ratios are captured. We show that our proposed method can be used to assess the mean values and the uncertainties of tire model parameters in real-world conditions and derive actions for the tire modeling based on our simulative study.","sentences":["This work presents a methodology to estimate tire parameters and their uncertainty using a Bayesian optimization approach.","The literature mainly considers the estimation of tire parameters but lacks an evaluation of the parameter identification quality and the required slip ratios for an adequate model fit.","Therefore, we examine the use of Stochastical Variational Inference as a methodology to estimate both - the parameters and their uncertainties.","We evaluate the method compared to a state-of-the-art Nelder-Mead algorithm for theoretical and real-world application.","The theoretical study considers parameter fitting at different slip ratios to evaluate the required excitation for an adequate fitting of each parameter.","The results are compared to a sensitivity analysis for a Pacejka Magic Formula tire model.","We show the application of the algorithm on real-world data acquired during the Abu Dhabi Autonomous Racing League and highlight the uncertainties in identifying the curvature and shape parameters due to insufficient excitation.","The gathered insights can help assess the acquired data's limitations and instead utilize standardized parameters until higher slip ratios are captured.","We show that our proposed method can be used to assess the mean values and the uncertainties of tire model parameters in real-world conditions and derive actions for the tire modeling based on our simulative study."],"url":"http://arxiv.org/abs/2504.20863v1"}
{"created":"2025-04-29 15:38:43","title":"Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private Data","abstract":"The remarkable success of Deep Learning approaches is often based and demonstrated on large public datasets. However, when applying such approaches to internal, private datasets, one frequently faces challenges arising from structural differences in the datasets, domain shift, and the lack of labels. In this work, we introduce Tabular Data Adapters (TDA), a novel method for generating soft labels for unlabeled tabular data in outlier detection tasks. By identifying statistically similar public datasets and transforming private data (based on a shared autoencoder) into a format compatible with state-of-the-art public models, our approach enables the generation of weak labels. It thereby can help to mitigate the cold start problem of labeling by basing on existing outlier detection models for public datasets. In experiments on 50 tabular datasets across different domains, we demonstrate that our method is able to provide more accurate annotations than baseline approaches while reducing computational time. Our approach offers a scalable, efficient, and cost-effective solution, to bridge the gap between public research models and real-world industrial applications.","sentences":["The remarkable success of Deep Learning approaches is often based and demonstrated on large public datasets.","However, when applying such approaches to internal, private datasets, one frequently faces challenges arising from structural differences in the datasets, domain shift, and the lack of labels.","In this work, we introduce Tabular Data Adapters (TDA), a novel method for generating soft labels for unlabeled tabular data in outlier detection tasks.","By identifying statistically similar public datasets and transforming private data (based on a shared autoencoder) into a format compatible with state-of-the-art public models, our approach enables the generation of weak labels.","It thereby can help to mitigate the cold start problem of labeling by basing on existing outlier detection models for public datasets.","In experiments on 50 tabular datasets across different domains, we demonstrate that our method is able to provide more accurate annotations than baseline approaches while reducing computational time.","Our approach offers a scalable, efficient, and cost-effective solution, to bridge the gap between public research models and real-world industrial applications."],"url":"http://arxiv.org/abs/2504.20862v1"}
{"created":"2025-04-29 15:36:51","title":"FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models","abstract":"Textual prompt tuning adapts Vision-Language Models (e.g., CLIP) in federated learning by tuning lightweight input tokens (or prompts) on local client data, while keeping network weights frozen. Post training, only the prompts are shared by the clients with the central server for aggregation. However, textual prompt tuning often struggles with overfitting to known concepts and may be overly reliant on memorized text features, limiting its adaptability to unseen concepts. To address this limitation, we propose Federated Multimodal Visual Prompt Tuning (FedMVP) that conditions the prompts on comprehensive contextual information -- image-conditioned features and textual attribute features of a class -- that is multimodal in nature. At the core of FedMVP is a PromptFormer module that synergistically aligns textual and visual features through cross-attention, enabling richer contexual integration. The dynamically generated multimodal visual prompts are then input to the frozen vision encoder of CLIP, and trained with a combination of CLIP similarity loss and a consistency loss. Extensive evaluation on 20 datasets spanning three generalization settings demonstrates that FedMVP not only preserves performance on in-distribution classes and domains, but also displays higher generalizability to unseen classes and domains when compared to state-of-the-art methods. Codes will be released upon acceptance.","sentences":["Textual prompt tuning adapts Vision-Language Models (e.g., CLIP) in federated learning by tuning lightweight input tokens (or prompts) on local client data, while keeping network weights frozen.","Post training, only the prompts are shared by the clients with the central server for aggregation.","However, textual prompt tuning often struggles with overfitting to known concepts and may be overly reliant on memorized text features, limiting its adaptability to unseen concepts.","To address this limitation, we propose Federated Multimodal Visual Prompt Tuning (FedMVP) that conditions the prompts on comprehensive contextual information -- image-conditioned features and textual attribute features of a class -- that is multimodal in nature.","At the core of FedMVP is a PromptFormer module that synergistically aligns textual and visual features through cross-attention, enabling richer contexual integration.","The dynamically generated multimodal visual prompts are then input to the frozen vision encoder of CLIP, and trained with a combination of CLIP similarity loss and a consistency loss.","Extensive evaluation on 20 datasets spanning three generalization settings demonstrates that FedMVP not only preserves performance on in-distribution classes and domains, but also displays higher generalizability to unseen classes and domains when compared to state-of-the-art methods.","Codes will be released upon acceptance."],"url":"http://arxiv.org/abs/2504.20860v1"}
{"created":"2025-04-29 15:33:20","title":"X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation","abstract":"As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents ``X-Cross'' -- a novel cross-domain sequential-recommendation model that recommends products in new domains by integrating several domain-specific language models; each model is fine-tuned with low-rank adapters (LoRA). Given a recommendation prompt, operating layer by layer, X-Cross dynamically refines the representation of each source language model by integrating knowledge from all other models. These refined representations are propagated from one layer to the next, leveraging the activations from each domain adapter to ensure domain-specific nuances are preserved while enabling adaptability across domains. Using Amazon datasets for sequential recommendation, X-Cross achieves performance comparable to a model that is fine-tuned with LoRA, while using only 25% of the additional parameters. In cross-domain tasks, such as adapting from Toys domain to Tools, Electronics or Sports, X-Cross demonstrates robust performance, while requiring about 50%-75% less fine-tuning data than LoRA to make fine-tuning effective. Furthermore, X-Cross achieves significant improvement in accuracy over alternative cross-domain baselines. Overall, X-Cross enables scalable and adaptive cross-domain recommendations, reducing computational overhead and providing an efficient solution for data-constrained environments.","sentences":["As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining.","This work presents ``X-Cross'' -- a novel cross-domain sequential-recommendation model that recommends products in new domains by integrating several domain-specific language models; each model is fine-tuned with low-rank adapters (LoRA).","Given a recommendation prompt, operating layer by layer, X-Cross dynamically refines the representation of each source language model by integrating knowledge from all other models.","These refined representations are propagated from one layer to the next, leveraging the activations from each domain adapter to ensure domain-specific nuances are preserved while enabling adaptability across domains.","Using Amazon datasets for sequential recommendation, X-Cross achieves performance comparable to a model that is fine-tuned with LoRA, while using only 25% of the additional parameters.","In cross-domain tasks, such as adapting from Toys domain to Tools, Electronics or Sports, X-Cross demonstrates robust performance, while requiring about 50%-75% less fine-tuning data than LoRA to make fine-tuning effective.","Furthermore, X-Cross achieves significant improvement in accuracy over alternative cross-domain baselines.","Overall, X-Cross enables scalable and adaptive cross-domain recommendations, reducing computational overhead and providing an efficient solution for data-constrained environments."],"url":"http://arxiv.org/abs/2504.20859v1"}
{"created":"2025-04-29 15:24:29","title":"Online General Knapsack with Reservation Costs","abstract":"In the online general knapsack problem, an algorithm is presented with an item $x=(s,v)$ of size $s$ and value $v$ and must irrevocably choose to pack such an item into the knapsack or reject it before the next item appears. The goal is to maximize the total value of the packed items without overflowing the knapsack's capacity.   As this classical setting is way too harsh for many real-life applications, we will analyze the online general knapsack problem under the reservation model. Here, instead of accepting or rejecting an item immediately, an algorithm can delay the decision of whether to pack the item by paying a fraction $0\\le \\alpha$ of the size or the value of the item. This models many practical applications, where, for example, decisions can be delayed for some costs e.g. cancellation fees. We present results for both variants: First, for costs depending on the size of the items and then for costs depending on the value of the items.   If the reservation costs depend on the size of the items, we find a matching upper and lower bound of $2$ for every $\\alpha$. On the other hand, if the reservation costs depend on the value of the items, we find that no algorithm is competitive for reservation costs larger than $1/2$ of the item value, and we find upper and lower bounds for the rest of the reservation range $0\\le\\alpha< 1/2$.","sentences":["In the online general knapsack problem, an algorithm is presented with an item $x=(s,v)$ of size $s$ and value $v$ and must irrevocably choose to pack such an item into the knapsack or reject it before the next item appears.","The goal is to maximize the total value of the packed items without overflowing the knapsack's capacity.   ","As this classical setting is way too harsh for many real-life applications, we will analyze the online general knapsack problem under the reservation model.","Here, instead of accepting or rejecting an item immediately, an algorithm can delay the decision of whether to pack the item by paying a fraction $0\\le \\alpha$ of the size or the value of the item.","This models many practical applications, where, for example, decisions can be delayed for some costs e.g. cancellation fees.","We present results for both variants:","First, for costs depending on the size of the items and then for costs depending on the value of the items.   ","If the reservation costs depend on the size of the items, we find a matching upper and lower bound of $2$ for every $\\alpha$. On the other hand, if the reservation costs depend on the value of the items, we find that no algorithm is competitive for reservation costs larger than $1/2$ of the item value, and we find upper and lower bounds for the rest of the reservation range $0\\le\\alpha< 1/2$."],"url":"http://arxiv.org/abs/2504.20855v1"}
{"created":"2025-04-29 15:19:06","title":"JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated Marketing Text in the Music Industry","abstract":"Online platforms are increasingly interested in using Data-to-Text technologies to generate content and help their users. Unfortunately, traditional generative methods often fall into repetitive patterns, resulting in monotonous galleries of texts after only a few iterations. In this paper, we investigate LLM-based data-to-text approaches to automatically generate marketing texts that are of sufficient quality and diverse enough for broad adoption. We leverage Language Models such as T5, GPT-3.5, GPT-4, and LLaMa2 in conjunction with fine-tuning, few-shot, and zero-shot approaches to set a baseline for diverse marketing texts. We also introduce a metric JaccDiv to evaluate the diversity of a set of texts. This research extends its relevance beyond the music industry, proving beneficial in various fields where repetitive automated content generation is prevalent.","sentences":["Online platforms are increasingly interested in using Data-to-Text technologies to generate content and help their users.","Unfortunately, traditional generative methods often fall into repetitive patterns, resulting in monotonous galleries of texts after only a few iterations.","In this paper, we investigate LLM-based data-to-text approaches to automatically generate marketing texts that are of sufficient quality and diverse enough for broad adoption.","We leverage Language Models such as T5, GPT-3.5, GPT-4, and LLaMa2 in conjunction with fine-tuning, few-shot, and zero-shot approaches to set a baseline for diverse marketing texts.","We also introduce a metric JaccDiv to evaluate the diversity of a set of texts.","This research extends its relevance beyond the music industry, proving beneficial in various fields where repetitive automated content generation is prevalent."],"url":"http://arxiv.org/abs/2504.20849v1"}
{"created":"2025-04-29 15:17:23","title":"Effect of Avatar Head Movement on Communication Behaviour, Experience of Presence and Conversation Success in Triadic Conversations","abstract":"Interactive communication in virtual reality can be used in experimental paradigms to increase the ecological validity of hearing device evaluations. This requires the virtual environment to elicit natural communication behaviour in listeners. This study evaluates the effect of virtual animated characters' head movements on participants' communication behaviour and experience.   Triadic conversations were conducted between a test participant and two confederates. To facilitate the manipulation of head movements, the conversation was conducted in telepresence using a system that transmitted audio, head movement data and video with low delay. The confederates were represented by virtual animated characters (avatars) with different levels of animation: Static heads, automated head movement animations based on speech level onsets, and animated head movements based on the transmitted head movements of the interlocutors. A condition was also included in which the videos of the interlocutors' heads were embedded in the visual scene.   The results show significant effects of animation level on the participants' speech and head movement behaviour as recorded by physical sensors, as well as on the subjective sense of presence and the success of the conversation. The largest effects were found for the range of head orientation during speech and the perceived realism of avatars. Participants reported that they were spoken to in a more helpful way when the avatars showed head movements transmitted from the interlocutors than when the avatars' heads were static.   We therefore conclude that the representation of interlocutors must include sufficiently realistic head movements in order to elicit natural communication behaviour.","sentences":["Interactive communication in virtual reality can be used in experimental paradigms to increase the ecological validity of hearing device evaluations.","This requires the virtual environment to elicit natural communication behaviour in listeners.","This study evaluates the effect of virtual animated characters' head movements on participants' communication behaviour and experience.   ","Triadic conversations were conducted between a test participant and two confederates.","To facilitate the manipulation of head movements, the conversation was conducted in telepresence using a system that transmitted audio, head movement data and video with low delay.","The confederates were represented by virtual animated characters (avatars) with different levels of animation: Static heads, automated head movement animations based on speech level onsets, and animated head movements based on the transmitted head movements of the interlocutors.","A condition was also included in which the videos of the interlocutors' heads were embedded in the visual scene.   ","The results show significant effects of animation level on the participants' speech and head movement behaviour as recorded by physical sensors, as well as on the subjective sense of presence and the success of the conversation.","The largest effects were found for the range of head orientation during speech and the perceived realism of avatars.","Participants reported that they were spoken to in a more helpful way when the avatars showed head movements transmitted from the interlocutors than when the avatars' heads were static.   ","We therefore conclude that the representation of interlocutors must include sufficiently realistic head movements in order to elicit natural communication behaviour."],"url":"http://arxiv.org/abs/2504.20844v1"}
{"created":"2025-04-29 15:00:25","title":"RadSAM: Segmenting 3D radiological images with a 2D promptable model","abstract":"Medical image segmentation is a crucial and time-consuming task in clinical care, where mask precision is extremely important. The Segment Anything Model (SAM) offers a promising approach, as it provides an interactive interface based on visual prompting and edition to refine an initial segmentation. This model has strong generalization capabilities, does not rely on predefined classes, and adapts to diverse objects; however, it is pre-trained on natural images and lacks the ability to process medical data effectively. In addition, this model is built for 2D images, whereas a whole medical domain is based on 3D images, such as CT and MRI. Recent adaptations of SAM for medical imaging are based on 2D models, thus requiring one prompt per slice to segment 3D objects, making the segmentation process tedious. They also lack important features such as editing. To bridge this gap, we propose RadSAM, a novel method for segmenting 3D objects with a 2D model from a single prompt. In practice, we train a 2D model using noisy masks as initial prompts, in addition to bounding boxes and points. We then use this novel prompt type with an iterative inference pipeline to reconstruct the 3D mask slice-by-slice. We introduce a benchmark to evaluate the model's ability to segment 3D objects in CT images from a single prompt and evaluate the models' out-of-domain transfer and edition capabilities. We demonstrate the effectiveness of our approach against state-of-the-art models on this benchmark using the AMOS abdominal organ segmentation dataset.","sentences":["Medical image segmentation is a crucial and time-consuming task in clinical care, where mask precision is extremely important.","The Segment Anything Model (SAM) offers a promising approach, as it provides an interactive interface based on visual prompting and edition to refine an initial segmentation.","This model has strong generalization capabilities, does not rely on predefined classes, and adapts to diverse objects; however, it is pre-trained on natural images and lacks the ability to process medical data effectively.","In addition, this model is built for 2D images, whereas a whole medical domain is based on 3D images, such as CT and MRI.","Recent adaptations of SAM for medical imaging are based on 2D models, thus requiring one prompt per slice to segment 3D objects, making the segmentation process tedious.","They also lack important features such as editing.","To bridge this gap, we propose RadSAM, a novel method for segmenting 3D objects with a 2D model from a single prompt.","In practice, we train a 2D model using noisy masks as initial prompts, in addition to bounding boxes and points.","We then use this novel prompt type with an iterative inference pipeline to reconstruct the 3D mask slice-by-slice.","We introduce a benchmark to evaluate the model's ability to segment 3D objects in CT images from a single prompt and evaluate the models' out-of-domain transfer and edition capabilities.","We demonstrate the effectiveness of our approach against state-of-the-art models on this benchmark using the AMOS abdominal organ segmentation dataset."],"url":"http://arxiv.org/abs/2504.20837v1"}
{"created":"2025-04-29 14:59:42","title":"Enhancing Non-Core Language Instruction-Following in Speech LLMs via Semi-Implicit Cross-Lingual CoT Reasoning","abstract":"Large language models have been extended to the speech domain, leading to the development of speech large language models (SLLMs). While existing SLLMs demonstrate strong performance in speech instruction-following for core languages (e.g., English), they often struggle with non-core languages due to the scarcity of paired speech-text data and limited multilingual semantic reasoning capabilities. To address this, we propose the semi-implicit Cross-lingual Speech Chain-of-Thought (XS-CoT) framework, which integrates speech-to-text translation into the reasoning process of SLLMs. The XS-CoT generates four types of tokens: instruction and response tokens in both core and non-core languages, enabling cross-lingual transfer of reasoning capabilities. To mitigate inference latency in generating target non-core response tokens, we incorporate a semi-implicit CoT scheme into XS-CoT, which progressively compresses the first three types of intermediate reasoning tokens while retaining global reasoning logic during training. By leveraging the robust reasoning capabilities of the core language, XS-CoT improves responses for non-core languages by up to 45\\% in GPT-4 score when compared to direct supervised fine-tuning on two representative SLLMs, Qwen2-Audio and SALMONN. Moreover, the semi-implicit XS-CoT reduces token delay by more than 50\\% with a slight drop in GPT-4 scores. Importantly, XS-CoT requires only a small amount of high-quality training data for non-core languages by leveraging the reasoning capabilities of core languages. To support training, we also develop a data pipeline and open-source speech instruction-following datasets in Japanese, German, and French.","sentences":["Large language models have been extended to the speech domain, leading to the development of speech large language models (SLLMs).","While existing SLLMs demonstrate strong performance in speech instruction-following for core languages (e.g., English), they often struggle with non-core languages due to the scarcity of paired speech-text data and limited multilingual semantic reasoning capabilities.","To address this, we propose the semi-implicit Cross-lingual Speech Chain-of-Thought (XS-CoT) framework, which integrates speech-to-text translation into the reasoning process of SLLMs.","The XS-CoT generates four types of tokens: instruction and response tokens in both core and non-core languages, enabling cross-lingual transfer of reasoning capabilities.","To mitigate inference latency in generating target non-core response tokens, we incorporate a semi-implicit CoT scheme into XS-CoT, which progressively compresses the first three types of intermediate reasoning tokens while retaining global reasoning logic during training.","By leveraging the robust reasoning capabilities of the core language, XS-CoT improves responses for non-core languages by up to 45\\% in GPT-4 score when compared to direct supervised fine-tuning on two representative SLLMs, Qwen2-Audio and SALMONN.","Moreover, the semi-implicit XS-CoT reduces token delay by more than 50\\% with a slight drop in GPT-4 scores.","Importantly, XS-CoT requires only a small amount of high-quality training data for non-core languages by leveraging the reasoning capabilities of core languages.","To support training, we also develop a data pipeline and open-source speech instruction-following datasets in Japanese, German, and French."],"url":"http://arxiv.org/abs/2504.20835v1"}
{"created":"2025-04-29 14:50:50","title":"DP-SMOTE: Integrating Differential Privacy and Oversampling Technique to Preserve Privacy in Smart Homes","abstract":"Smart homes represent intelligent environments where interconnected devices gather information, enhancing users living experiences by ensuring comfort, safety, and efficient energy management. To enhance the quality of life, companies in the smart device industry collect user data, including activities, preferences, and power consumption. However, sharing such data necessitates privacy-preserving practices. This paper introduces a robust method for secure sharing of data to service providers, grounded in differential privacy (DP). This empowers smart home residents to contribute usage statistics while safeguarding their privacy. The approach incorporates the Synthetic Minority Oversampling technique (SMOTe) and seamlessly integrates Gaussian noise to generate synthetic data, enabling data and statistics sharing while preserving individual privacy. The proposed method employs the SMOTe algorithm and applies Gaussian noise to generate data. Subsequently, it employs a k-anonymity function to assess reidentification risk before sharing the data. The simulation outcomes demonstrate that our method delivers strong performance in safeguarding privacy and in accuracy, recall, and f-measure metrics. This approach is particularly effective in smart homes, offering substantial utility in privacy at a reidentification risk of 30%, with Gaussian noise set to 0.3, SMOTe at 500%, and the application of a k-anonymity function with k = 2. Additionally, it shows a high classification accuracy, ranging from 90% to 98%, across various classification techniques.","sentences":["Smart homes represent intelligent environments where interconnected devices gather information, enhancing users living experiences by ensuring comfort, safety, and efficient energy management.","To enhance the quality of life, companies in the smart device industry collect user data, including activities, preferences, and power consumption.","However, sharing such data necessitates privacy-preserving practices.","This paper introduces a robust method for secure sharing of data to service providers, grounded in differential privacy (DP).","This empowers smart home residents to contribute usage statistics while safeguarding their privacy.","The approach incorporates the Synthetic Minority Oversampling technique (SMOTe) and seamlessly integrates Gaussian noise to generate synthetic data, enabling data and statistics sharing while preserving individual privacy.","The proposed method employs the SMOTe algorithm and applies Gaussian noise to generate data.","Subsequently, it employs a k-anonymity function to assess reidentification risk before sharing the data.","The simulation outcomes demonstrate that our method delivers strong performance in safeguarding privacy and in accuracy, recall, and f-measure metrics.","This approach is particularly effective in smart homes, offering substantial utility in privacy at a reidentification risk of 30%, with Gaussian noise set to 0.3, SMOTe at 500%, and the application of a k-anonymity function with k","= 2.","Additionally, it shows a high classification accuracy, ranging from 90% to 98%, across various classification techniques."],"url":"http://arxiv.org/abs/2504.20827v1"}
{"created":"2025-04-29 14:41:41","title":"Hybrid Quantum Recurrent Neural Network For Remaining Useful Life Prediction","abstract":"Predictive maintenance in aerospace heavily relies on accurate estimation of the remaining useful life of jet engines. In this paper, we introduce a Hybrid Quantum Recurrent Neural Network framework, combining Quantum Long Short-Term Memory layers with classical dense layers for Remaining Useful Life forecasting on NASA's Commercial Modular Aero-Propulsion System Simulation dataset. Each Quantum Long Short-Term Memory gate replaces conventional linear transformations with Quantum Depth-Infused circuits, allowing the network to learn high-frequency components more effectively. Experimental results demonstrate that, despite having fewer trainable parameters, the Hybrid Quantum Recurrent Neural Network achieves up to a 5% improvement over a Recurrent Neural Network based on stacked Long Short-Term Memory layers in terms of mean root mean squared error and mean absolute error. Moreover, a thorough comparison of our method with established techniques, including Random Forest, Convolutional Neural Network, and Multilayer Perceptron, demonstrates that our approach, which achieves a Root Mean Squared Error of 15.46, surpasses these baselines by approximately 13.68%, 16.21%, and 7.87%, respectively. Nevertheless, it remains outperformed by certain advanced joint architectures. Our findings highlight the potential of hybrid quantum-classical approaches for robust time-series forecasting under limited data conditions, offering new avenues for enhancing reliability in predictive maintenance tasks.","sentences":["Predictive maintenance in aerospace heavily relies on accurate estimation of the remaining useful life of jet engines.","In this paper, we introduce a Hybrid Quantum Recurrent Neural Network framework, combining Quantum Long Short-Term Memory layers with classical dense layers for Remaining Useful Life forecasting on NASA's Commercial Modular Aero-Propulsion System Simulation dataset.","Each Quantum Long Short-Term Memory gate replaces conventional linear transformations with Quantum Depth-Infused circuits, allowing the network to learn high-frequency components more effectively.","Experimental results demonstrate that, despite having fewer trainable parameters, the Hybrid Quantum Recurrent Neural Network achieves up to a 5% improvement over a Recurrent Neural Network based on stacked Long Short-Term Memory layers in terms of mean root mean squared error and mean absolute error.","Moreover, a thorough comparison of our method with established techniques, including Random Forest, Convolutional Neural Network, and Multilayer Perceptron, demonstrates that our approach, which achieves a Root Mean Squared Error of 15.46, surpasses these baselines by approximately 13.68%, 16.21%, and 7.87%, respectively.","Nevertheless, it remains outperformed by certain advanced joint architectures.","Our findings highlight the potential of hybrid quantum-classical approaches for robust time-series forecasting under limited data conditions, offering new avenues for enhancing reliability in predictive maintenance tasks."],"url":"http://arxiv.org/abs/2504.20823v1"}
{"created":"2025-04-29 14:40:21","title":"The When and How of Target Variable Transformations","abstract":"The machine learning pipeline typically involves the iterative process of (1) collecting the data, (2) preparing the data, (3) learning a model, and (4) evaluating a model. Practitioners recognize the importance of the data preparation phase in terms of its impact on the ability to learn accurate models. In this regard, significant attention is often paid to manipulating the feature set (e.g., selection, transformations, dimensionality reduction). A point that is less well appreciated is that transformations on the target variable can also have a large impact on whether it is possible to learn a suitable model. These transformations may include accounting for subject-specific biases (e.g., in how someone uses a rating scale), contexts (e.g., population size effects), and general trends (e.g., inflation). However, this point has received a much more cursory treatment in the existing literature. The goal of this paper is three-fold. First, we aim to highlight the importance of this problem by showing when transforming the target variable has been useful in practice. Second, we will provide a set of generic ``rules of thumb'' that indicate situations when transforming the target variable may be needed. Third, we will discuss which transformations should be considered in a given situation.","sentences":["The machine learning pipeline typically involves the iterative process of (1) collecting the data, (2) preparing the data, (3) learning a model, and (4) evaluating a model.","Practitioners recognize the importance of the data preparation phase in terms of its impact on the ability to learn accurate models.","In this regard, significant attention is often paid to manipulating the feature set (e.g., selection, transformations, dimensionality reduction).","A point that is less well appreciated is that transformations on the target variable can also have a large impact on whether it is possible to learn a suitable model.","These transformations may include accounting for subject-specific biases (e.g., in how someone uses a rating scale), contexts (e.g., population size effects), and general trends (e.g., inflation).","However, this point has received a much more cursory treatment in the existing literature.","The goal of this paper is three-fold.","First, we aim to highlight the importance of this problem by showing when transforming the target variable has been useful in practice.","Second, we will provide a set of generic ``rules of thumb'' that indicate situations when transforming the target variable may be needed.","Third, we will discuss which transformations should be considered in a given situation."],"url":"http://arxiv.org/abs/2504.20821v1"}
{"created":"2025-04-29 14:21:08","title":"SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings","abstract":"This paper introduces SoccerDiffusion, a transformer-based diffusion model designed to learn end-to-end control policies for humanoid robot soccer directly from real-world gameplay recordings. Using data collected from RoboCup competitions, the model predicts joint command trajectories from multi-modal sensor inputs, including vision, proprioception, and game state. We employ a distillation technique to enable real-time inference on embedded platforms that reduces the multi-step diffusion process to a single step. Our results demonstrate the model's ability to replicate complex motion behaviors such as walking, kicking, and fall recovery both in simulation and on physical robots. Although high-level tactical behavior remains limited, this work provides a robust foundation for subsequent reinforcement learning or preference optimization methods. We release the dataset, pretrained models, and code under: https://bit-bots.github.io/SoccerDiffusion","sentences":["This paper introduces SoccerDiffusion, a transformer-based diffusion model designed to learn end-to-end control policies for humanoid robot soccer directly from real-world gameplay recordings.","Using data collected from RoboCup competitions, the model predicts joint command trajectories from multi-modal sensor inputs, including vision, proprioception, and game state.","We employ a distillation technique to enable real-time inference on embedded platforms that reduces the multi-step diffusion process to a single step.","Our results demonstrate the model's ability to replicate complex motion behaviors such as walking, kicking, and fall recovery both in simulation and on physical robots.","Although high-level tactical behavior remains limited, this work provides a robust foundation for subsequent reinforcement learning or preference optimization methods.","We release the dataset, pretrained models, and code under: https://bit-bots.github.io/SoccerDiffusion"],"url":"http://arxiv.org/abs/2504.20808v1"}
{"created":"2025-04-29 14:14:30","title":"Unlocking User-oriented Pages: Intention-driven Black-box Scanner for Real-world Web Applications","abstract":"Black-box scanners have played a significant role in detecting vulnerabilities for web applications. A key focus in current black-box scanning is increasing test coverage (i.e., accessing more web pages). However, since many web applications are user-oriented, some deep pages can only be accessed through complex user interactions, which are difficult to reach by existing black-box scanners. To fill this gap, a key insight is that web pages contain a wealth of semantic information that can aid in understanding potential user intention. Based on this insight, we propose Hoyen, a black-box scanner that uses the Large Language Model to predict user intention and provide guidance for expanding the scanning scope. Hoyen has been rigorously evaluated on 12 popular open-source web applications and compared with 6 representative tools. The results demonstrate that Hoyen performs a comprehensive exploration of web applications, expanding the attack surface while achieving about 2x than the coverage of other scanners on average, with high request accuracy. Furthermore, Hoyen detected over 90% of its requests towards the core functionality of the application, detecting more vulnerabilities than other scanners, including unique vulnerabilities in well-known web applications. Our data/code is available at https://hoyen.tjunsl.com/","sentences":["Black-box scanners have played a significant role in detecting vulnerabilities for web applications.","A key focus in current black-box scanning is increasing test coverage (i.e., accessing more web pages).","However, since many web applications are user-oriented, some deep pages can only be accessed through complex user interactions, which are difficult to reach by existing black-box scanners.","To fill this gap, a key insight is that web pages contain a wealth of semantic information that can aid in understanding potential user intention.","Based on this insight, we propose Hoyen, a black-box scanner that uses the Large Language Model to predict user intention and provide guidance for expanding the scanning scope.","Hoyen has been rigorously evaluated on 12 popular open-source web applications and compared with 6 representative tools.","The results demonstrate that Hoyen performs a comprehensive exploration of web applications, expanding the attack surface while achieving about 2x than the coverage of other scanners on average, with high request accuracy.","Furthermore, Hoyen detected over 90% of its requests towards the core functionality of the application, detecting more vulnerabilities than other scanners, including unique vulnerabilities in well-known web applications.","Our data/code is available at https://hoyen.tjunsl.com/"],"url":"http://arxiv.org/abs/2504.20801v1"}
{"created":"2025-04-29 14:14:29","title":"Adept: Annotation-Denoising Auxiliary Tasks with Discrete Cosine Transform Map and Keypoint for Human-Centric Pretraining","abstract":"Human-centric perception is the core of diverse computer vision tasks and has been a long-standing research focus. However, previous research studied these human-centric tasks individually, whose performance is largely limited to the size of the public task-specific datasets. Recent human-centric methods leverage the additional modalities, e.g., depth, to learn fine-grained semantic information, which limits the benefit of pretraining models due to their sensitivity to camera views and the scarcity of RGB-D data on the Internet. This paper improves the data scalability of human-centric pretraining methods by discarding depth information and exploring semantic information of RGB images in the frequency space by Discrete Cosine Transform (DCT). We further propose new annotation denoising auxiliary tasks with keypoints and DCT maps to enforce the RGB image extractor to learn fine-grained semantic information of human bodies. Our extensive experiments show that when pretrained on large-scale datasets (COCO and AIC datasets) without depth annotation, our model achieves better performance than state-of-the-art methods by +0.5 mAP on COCO, +1.4 PCKh on MPII and -0.51 EPE on Human3.6M for pose estimation, by +4.50 mIoU on Human3.6M for human parsing, by -3.14 MAE on SHA and -0.07 MAE on SHB for crowd counting, by +1.1 F1 score on SHA and +0.8 F1 score on SHA for crowd localization, and by +0.1 mAP on Market1501 and +0.8 mAP on MSMT for person ReID. We also validate the effectiveness of our method on MPII+NTURGBD datasets","sentences":["Human-centric perception is the core of diverse computer vision tasks and has been a long-standing research focus.","However, previous research studied these human-centric tasks individually, whose performance is largely limited to the size of the public task-specific datasets.","Recent human-centric methods leverage the additional modalities, e.g., depth, to learn fine-grained semantic information, which limits the benefit of pretraining models due to their sensitivity to camera views and the scarcity of RGB-D data on the Internet.","This paper improves the data scalability of human-centric pretraining methods by discarding depth information and exploring semantic information of RGB images in the frequency space by Discrete Cosine Transform (DCT).","We further propose new annotation denoising auxiliary tasks with keypoints and DCT maps to enforce the RGB image extractor to learn fine-grained semantic information of human bodies.","Our extensive experiments show that when pretrained on large-scale datasets (COCO and AIC datasets) without depth annotation, our model achieves better performance than state-of-the-art methods by +0.5 mAP on COCO, +1.4 PCKh on MPII and -0.51 EPE on Human3.6M for pose estimation, by +4.50 mIoU on Human3.6M for human parsing, by -3.14 MAE on SHA and -0.07 MAE on SHB for crowd counting, by +1.1 F1 score on SHA and +0.8 F1 score on SHA for crowd localization, and by +0.1 mAP on Market1501 and +0.8 mAP on MSMT for person ReID.","We also validate the effectiveness of our method on MPII+NTURGBD datasets"],"url":"http://arxiv.org/abs/2504.20800v1"}
{"created":"2025-04-29 14:11:06","title":"Partitioned Memory Storage Inspired Few-Shot Class-Incremental learning","abstract":"Current mainstream deep learning techniques exhibit an over-reliance on extensive training data and a lack of adaptability to the dynamic world, marking a considerable disparity from human intelligence. To bridge this gap, Few-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous learning of new categories with limited samples without forgetting old knowledge. Existing FSCIL studies typically use a single model to learn knowledge across all sessions, inevitably leading to the stability-plasticity dilemma. Unlike machines, humans store varied knowledge in different cerebral cortices. Inspired by this characteristic, our paper aims to develop a method that learns independent models for each session. It can inherently prevent catastrophic forgetting. During the testing stage, our method integrates Uncertainty Quantification (UQ) for model deployment. Our method provides a fresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on CIFAR-100 and mini-ImageNet datasets.","sentences":["Current mainstream deep learning techniques exhibit an over-reliance on extensive training data and a lack of adaptability to the dynamic world, marking a considerable disparity from human intelligence.","To bridge this gap, Few-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous learning of new categories with limited samples without forgetting old knowledge.","Existing FSCIL studies typically use a single model to learn knowledge across all sessions, inevitably leading to the stability-plasticity dilemma.","Unlike machines, humans store varied knowledge in different cerebral cortices.","Inspired by this characteristic, our paper aims to develop a method that learns independent models for each session.","It can inherently prevent catastrophic forgetting.","During the testing stage, our method integrates Uncertainty Quantification (UQ) for model deployment.","Our method provides a fresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on CIFAR-100 and mini-ImageNet datasets."],"url":"http://arxiv.org/abs/2504.20797v1"}
{"created":"2025-04-29 14:10:39","title":"Effective Index Construction Algorithm for Optimal $(k,\u03b7)$-cores Computation","abstract":"Computing $(k,\\eta)$-cores from uncertain graphs is a fundamental problem in uncertain graph analysis. UCF-Index is the state-of-the-art resolution to support $(k,\\eta)$-core queries, allowing the $(k,\\eta)$-core for any combination of $k$ and $\\eta$ to be computed in an optimal time. However, this index constructed by current algorithm is usually incorrect. During decomposition, the key is to obtain the $k$-probabilities of its neighbors when the vertex with minimum $k$-probability is deleted. Current method uses recursive floating-point division to update it, which can lead to serious errors. We propose a correct and efficient index construction algorithm to address this issue. Firstly, we propose tight bounds on the $k$-probabilities of the vertices that need to be updated, and the accurate $k$-probabilities are recalculated in an on-demand manner. Secondly, vertices partitioning and progressive refinement strategy is devised to search the vertex with the minimum $k$-probability, thereby reducing initialization overhead for each $k$ and avoiding unnecessary recalculations. Finally, extensive experiments demonstrate the efficiency and scalability of our approach.","sentences":["Computing $(k,\\eta)$-cores from uncertain graphs is a fundamental problem in uncertain graph analysis.","UCF-Index is the state-of-the-art resolution to support $(k,\\eta)$-core queries, allowing the $(k,\\eta)$-core for any combination of $k$ and $\\eta$ to be computed in an optimal time.","However, this index constructed by current algorithm is usually incorrect.","During decomposition, the key is to obtain the $k$-probabilities of its neighbors when the vertex with minimum $k$-probability is deleted.","Current method uses recursive floating-point division to update it, which can lead to serious errors.","We propose a correct and efficient index construction algorithm to address this issue.","Firstly, we propose tight bounds on the $k$-probabilities of the vertices that need to be updated, and the accurate $k$-probabilities are recalculated in an on-demand manner.","Secondly, vertices partitioning and progressive refinement strategy is devised to search the vertex with the minimum $k$-probability, thereby reducing initialization overhead for each $k$ and avoiding unnecessary recalculations.","Finally, extensive experiments demonstrate the efficiency and scalability of our approach."],"url":"http://arxiv.org/abs/2504.20795v1"}
{"created":"2025-04-29 14:09:20","title":"RecGaze: The First Eye Tracking and User Interaction Dataset for Carousel Interfaces","abstract":"Carousel interfaces are widely used in e-commerce and streaming services, but little research has been devoted to them. Previous studies of interfaces for presenting search and recommendation results have focused on single ranked lists, but it appears their results cannot be extrapolated to carousels due to the added complexity. Eye tracking is a highly informative approach to understanding how users click, yet there are no eye tracking studies concerning carousels. There are very few interaction datasets on recommenders with carousel interfaces and none that contain gaze data.   We introduce the RecGaze dataset: the first comprehensive feedback dataset on carousels that includes eye tracking results, clicks, cursor movements, and selection explanations. The dataset comprises of interactions from 3 movie selection tasks with 40 different carousel interfaces per user. In total, 87 users and 3,477 interactions are logged. In addition to the dataset, its description and possible use cases, we provide results of a survey on carousel design and the first analysis of gaze data on carousels, which reveals a golden triangle or F-pattern browsing behavior.   Our work seeks to advance the field of carousel interfaces by providing the first dataset with eye tracking results on carousels. In this manner, we provide and encourage an empirical understanding of interactions with carousel interfaces, for building better recommender systems through gaze information, and also encourage the development of gaze-based recommenders.","sentences":["Carousel interfaces are widely used in e-commerce and streaming services, but little research has been devoted to them.","Previous studies of interfaces for presenting search and recommendation results have focused on single ranked lists, but it appears their results cannot be extrapolated to carousels due to the added complexity.","Eye tracking is a highly informative approach to understanding how users click, yet there are no eye tracking studies concerning carousels.","There are very few interaction datasets on recommenders with carousel interfaces and none that contain gaze data.   ","We introduce the RecGaze dataset: the first comprehensive feedback dataset on carousels that includes eye tracking results, clicks, cursor movements, and selection explanations.","The dataset comprises of interactions from 3 movie selection tasks with 40 different carousel interfaces per user.","In total, 87 users and 3,477 interactions are logged.","In addition to the dataset, its description and possible use cases, we provide results of a survey on carousel design and the first analysis of gaze data on carousels, which reveals a golden triangle or F-pattern browsing behavior.   ","Our work seeks to advance the field of carousel interfaces by providing the first dataset with eye tracking results on carousels.","In this manner, we provide and encourage an empirical understanding of interactions with carousel interfaces, for building better recommender systems through gaze information, and also encourage the development of gaze-based recommenders."],"url":"http://arxiv.org/abs/2504.20792v1"}
{"created":"2025-04-29 14:03:31","title":"Evaluating Effects of Augmented SELFIES for Molecular Understanding Using QK-LSTM","abstract":"Identifying molecular properties, including side effects, is a critical yet time-consuming step in drug development. Failing to detect these side effects before regulatory submission can result in significant financial losses and production delays, and overlooking them during the regulatory review can lead to catastrophic consequences. This challenge presents an opportunity for innovative machine learning approaches, particularly hybrid quantum-classical models like the Quantum Kernel-Based Long Short-Term Memory (QK-LSTM) network. The QK-LSTM integrates quantum kernel functions into the classical LSTM framework, enabling the capture of complex, non-linear patterns in sequential data. By mapping input data into a high-dimensional quantum feature space, the QK-LSTM model reduces the need for large parameter sets, allowing for model compression without sacrificing accuracy in sequence-based tasks. Recent advancements have been made in the classical domain using augmented variations of the Simplified Molecular Line-Entry System (SMILES). However, to the best of our knowledge, no research has explored the impact of augmented SMILES in the quantum domain, nor the role of augmented Self-Referencing Embedded Strings (SELFIES) in either classical or hybrid quantum-classical settings. This study presents the first analysis of these approaches, providing novel insights into their potential for enhancing molecular property prediction and side effect identification. Results reveal that augmenting SELFIES yields in statistically significant improvements from SMILES by a 5.97% improvement for the classical domain and a 5.91% improvement for the hybrid quantum-classical domain.","sentences":["Identifying molecular properties, including side effects, is a critical yet time-consuming step in drug development.","Failing to detect these side effects before regulatory submission can result in significant financial losses and production delays, and overlooking them during the regulatory review can lead to catastrophic consequences.","This challenge presents an opportunity for innovative machine learning approaches, particularly hybrid quantum-classical models like the Quantum Kernel-Based Long Short-Term Memory (QK-LSTM) network.","The QK-LSTM integrates quantum kernel functions into the classical LSTM framework, enabling the capture of complex, non-linear patterns in sequential data.","By mapping input data into a high-dimensional quantum feature space, the QK-LSTM model reduces the need for large parameter sets, allowing for model compression without sacrificing accuracy in sequence-based tasks.","Recent advancements have been made in the classical domain using augmented variations of the Simplified Molecular Line-Entry System (SMILES).","However, to the best of our knowledge, no research has explored the impact of augmented SMILES in the quantum domain, nor the role of augmented Self-Referencing Embedded Strings (SELFIES) in either classical or hybrid quantum-classical settings.","This study presents the first analysis of these approaches, providing novel insights into their potential for enhancing molecular property prediction and side effect identification.","Results reveal that augmenting SELFIES yields in statistically significant improvements from SMILES by a 5.97% improvement for the classical domain and a 5.91% improvement for the hybrid quantum-classical domain."],"url":"http://arxiv.org/abs/2504.20789v1"}
{"created":"2025-04-29 14:01:10","title":"Approximate Lifted Model Construction","abstract":"Probabilistic relational models such as parametric factor graphs enable efficient (lifted) inference by exploiting the indistinguishability of objects. In lifted inference, a representative of indistinguishable objects is used for computations. To obtain a relational (i.e., lifted) representation, the Advanced Colour Passing (ACP) algorithm is the state of the art. The ACP algorithm, however, requires underlying distributions, encoded as potential-based factorisations, to exactly match to identify and exploit indistinguishabilities. Hence, ACP is unsuitable for practical applications where potentials learned from data inevitably deviate even if associated objects are indistinguishable. To mitigate this problem, we introduce the $\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which allows for a deviation of potentials depending on a hyperparameter $\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits indistinguishabilities that are not exact. We prove that the approximation error induced by $\\varepsilon$-ACP is strictly bounded and our experiments show that the approximation error is close to zero in practice.","sentences":["Probabilistic relational models such as parametric factor graphs enable efficient (lifted) inference by exploiting the indistinguishability of objects.","In lifted inference, a representative of indistinguishable objects is used for computations.","To obtain a relational (i.e., lifted) representation, the Advanced Colour Passing (ACP) algorithm is the state of the art.","The ACP algorithm, however, requires underlying distributions, encoded as potential-based factorisations, to exactly match to identify and exploit indistinguishabilities.","Hence, ACP is unsuitable for practical applications where potentials learned from data inevitably deviate even if associated objects are indistinguishable.","To mitigate this problem, we introduce the $\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which allows for a deviation of potentials depending on a hyperparameter $\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits indistinguishabilities that are not exact.","We prove that the approximation error induced by $\\varepsilon$-ACP is strictly bounded and our experiments show that the approximation error is close to zero in practice."],"url":"http://arxiv.org/abs/2504.20784v1"}
{"created":"2025-04-29 13:59:33","title":"Deterministic Dynamic Maximal Matching in Sublinear Update Time","abstract":"We give a fully dynamic deterministic algorithm for maintaining a maximal matching of an $n$-vertex graph in $\\tilde{O}(n^{8/9})$ amortized update time. This breaks the long-standing $\\Omega(n)$-update-time barrier on dense graphs, achievable by trivially scanning all incident vertices of the updated edge, and affirmatively answers a major open question repeatedly asked in the literature [BGS15, BCHN18, Sol22]. We also present a faster randomized algorithm against an adaptive adversary with $\\tilde{O}(n^{3/4})$ amortized update time.   Our approach employs the edge degree constrained subgraph (EDCS), a central object for optimizing approximation ratio, in a completely novel way; we instead use it for maintaining a matching that matches all high degree vertices in sublinear update time so that it remains to handle low degree vertices rather straightforwardly. To optimize this approach, we employ tools never used in the dynamic matching literature prior to our work, including sublinear-time algorithms for matching high degree vertices, random walks on directed expanders, and the monotone Even-Shiloach tree for dynamic shortest paths.","sentences":["We give a fully dynamic deterministic algorithm for maintaining a maximal matching of an $n$-vertex graph in $\\tilde{O}(n^{8/9})$ amortized update time.","This breaks the long-standing $\\Omega(n)$-update-time barrier on dense graphs, achievable by trivially scanning all incident vertices of the updated edge, and affirmatively answers a major open question repeatedly asked in the literature [BGS15, BCHN18, Sol22].","We also present a faster randomized algorithm against an adaptive adversary with $\\tilde{O}(n^{3/4})$ amortized update time.   ","Our approach employs the edge degree constrained subgraph (EDCS), a central object for optimizing approximation ratio, in a completely novel way; we instead use it for maintaining a matching that matches all high degree vertices in sublinear update time so that it remains to handle low degree vertices rather straightforwardly.","To optimize this approach, we employ tools never used in the dynamic matching literature prior to our work, including sublinear-time algorithms for matching high degree vertices, random walks on directed expanders, and the monotone Even-Shiloach tree for dynamic shortest paths."],"url":"http://arxiv.org/abs/2504.20780v1"}
{"created":"2025-04-29 13:52:47","title":"Turing Machine Evaluation for Large Language Model","abstract":"With the rapid development and widespread application of Large Language Models (LLMs), rigorous evaluation has become particularly crucial. This research adopts a novel perspective, focusing on evaluating the core computational reasoning ability of LLMs, defined as the capacity of model to accurately understand rules, and execute logically computing operations. This capability assesses the reliability of LLMs as precise executors, and is critical to advanced tasks such as complex code generation and multi-step problem-solving. We propose an evaluation framework based on Universal Turing Machine (UTM) simulation. This framework requires LLMs to strictly follow instructions and track dynamic states, such as tape content and read/write head position, during multi-step computations. To enable standardized evaluation, we developed TMBench, a benchmark for systematically studying the computational reasoning capabilities of LLMs. TMBench provides several key advantages, including knowledge-agnostic evaluation, adjustable difficulty, foundational coverage through Turing machine encoding, and unlimited capacity for instance generation, ensuring scalability as models continue to evolve. We find that model performance on TMBench correlates strongly with performance on other recognized reasoning benchmarks (Pearson correlation coefficient is 0.73), clearly demonstrating that computational reasoning is a significant dimension for measuring the deep capabilities of LLMs. Code and data are available at https://github.com/HaitaoWuTJU/Turing-Machine-Bench.","sentences":["With the rapid development and widespread application of Large Language Models (LLMs), rigorous evaluation has become particularly crucial.","This research adopts a novel perspective, focusing on evaluating the core computational reasoning ability of LLMs, defined as the capacity of model to accurately understand rules, and execute logically computing operations.","This capability assesses the reliability of LLMs as precise executors, and is critical to advanced tasks such as complex code generation and multi-step problem-solving.","We propose an evaluation framework based on Universal Turing Machine (UTM) simulation.","This framework requires LLMs to strictly follow instructions and track dynamic states, such as tape content and read/write head position, during multi-step computations.","To enable standardized evaluation, we developed TMBench, a benchmark for systematically studying the computational reasoning capabilities of LLMs.","TMBench provides several key advantages, including knowledge-agnostic evaluation, adjustable difficulty, foundational coverage through Turing machine encoding, and unlimited capacity for instance generation, ensuring scalability as models continue to evolve.","We find that model performance on TMBench correlates strongly with performance on other recognized reasoning benchmarks (Pearson correlation coefficient is 0.73), clearly demonstrating that computational reasoning is a significant dimension for measuring the deep capabilities of LLMs.","Code and data are available at https://github.com/HaitaoWuTJU/Turing-Machine-Bench."],"url":"http://arxiv.org/abs/2504.20771v1"}
{"created":"2025-04-29 13:47:53","title":"LakeVilla: Multi-Table Transactions for Lakehouses","abstract":"Data lakehouses (LHs) are at the core of current cloud analytics stacks by providing elastic, relational compute on data in cloud data lakes across vendors. For relational semantics, they rely on open table formats (OTFs). Unfortunately, they have many missing features inherent to their metadata designs, like no support for multi-table transactions and recovery in case of an abort in concurrent, multi-query workloads. This, in turn, can lead to non-repeatable reads, stale data, and high costs in productive cloud systems. In this work, we introduce LakeVilla, a complementary solution that introduces recovery, multi-query/table transactions, and transaction isolation to state-of-the-art OTFs like Apache Iceberg and Delta Lake tables. We investigate its transactional guarantees and show it has minimal impact on performance (2% YCSB writes, 2.5% TPC-DS reads) and provides concurrency control for multiple readers and writers for arbitrary long transactions in OTFs in a non-invasive way.","sentences":["Data lakehouses (LHs) are at the core of current cloud analytics stacks by providing elastic, relational compute on data in cloud data lakes across vendors.","For relational semantics, they rely on open table formats (OTFs).","Unfortunately, they have many missing features inherent to their metadata designs, like no support for multi-table transactions and recovery in case of an abort in concurrent, multi-query workloads.","This, in turn, can lead to non-repeatable reads, stale data, and high costs in productive cloud systems.","In this work, we introduce LakeVilla, a complementary solution that introduces recovery, multi-query/table transactions, and transaction isolation to state-of-the-art OTFs like Apache Iceberg and Delta Lake tables.","We investigate its transactional guarantees and show it has minimal impact on performance (2% YCSB writes, 2.5% TPC-DS reads) and provides concurrency control for multiple readers and writers for arbitrary long transactions in OTFs in a non-invasive way."],"url":"http://arxiv.org/abs/2504.20768v1"}
{"created":"2025-04-29 13:33:29","title":"Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers","abstract":"Transformers have achieved great success in numerous NLP tasks but continue to exhibit notable gaps in multi-step factual reasoning, especially when real-world knowledge is sparse. Recent advances in grokking have demonstrated that neural networks can transition from memorizing to perfectly generalizing once they detect underlying logical patterns - yet these studies have primarily used small, synthetic tasks. In this paper, for the first time, we extend grokking to real-world factual data and address the challenge of dataset sparsity by augmenting existing knowledge graphs with carefully designed synthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts above the threshold required for grokking. Surprisingly, we find that even factually incorrect synthetic data can strengthen emergent reasoning circuits rather than degrade accuracy, as it forces the model to rely on relational structure rather than memorization. When evaluated on multi-hop reasoning benchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA - substantially improving over strong baselines and matching or exceeding current state-of-the-art results. We further provide an in-depth analysis of how increasing $\\phi_r$ drives the formation of generalizing circuits inside Transformers. Our findings suggest that grokking-based data augmentation can unlock implicit multi-hop reasoning capabilities, opening the door to more robust and interpretable factual reasoning in large-scale language models.","sentences":["Transformers have achieved great success in numerous NLP tasks but continue to exhibit notable gaps in multi-step factual reasoning, especially when real-world knowledge is sparse.","Recent advances in grokking have demonstrated that neural networks can transition from memorizing to perfectly generalizing once they detect underlying logical patterns - yet these studies have primarily used small, synthetic tasks.","In this paper, for the first time, we extend grokking to real-world factual data and address the challenge of dataset sparsity by augmenting existing knowledge graphs with carefully designed synthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts above the threshold required for grokking.","Surprisingly, we find that even factually incorrect synthetic data can strengthen emergent reasoning circuits rather than degrade accuracy, as it forces the model to rely on relational structure rather than memorization.","When evaluated on multi-hop reasoning benchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA - substantially improving over strong baselines and matching or exceeding current state-of-the-art results.","We further provide an in-depth analysis of how increasing $\\phi_r$ drives the formation of generalizing circuits inside Transformers.","Our findings suggest that grokking-based data augmentation can unlock implicit multi-hop reasoning capabilities, opening the door to more robust and interpretable factual reasoning in large-scale language models."],"url":"http://arxiv.org/abs/2504.20752v1"}
{"created":"2025-04-29 13:22:03","title":"Formal and Empirical Study of Metadata-Based Profiling for Resource Management in the Computing Continuum","abstract":"We present and formalize a general approach for profiling workload by leveraging only a priori available static metadata to supply appropriate resource needs. Understanding the requirements and characteristics of a workload's runtime is essential. Profiles are essential for the platform (or infrastructure) provider because they want to ensure that Service Level Agreements and their objectives (SLOs) are fulfilled and, at the same time, avoid allocating too many resources to the workload. When the infrastructure to manage is the computing continuum (i.e., from IoT to Edge to Cloud nodes), there is a big problem of placement and tradeoff or distribution and performance. Still, existing techniques either rely on static predictions or runtime profiling, which are proven to deliver poor performance in runtime environments or require laborious mechanisms to produce fast and reliable evaluations. We want to propose a new approach for it. Our profile combines the information from past execution traces with the related workload metadata, equipping an infrastructure orchestrator with a fast and precise association of newly submitted workloads. We differentiate from previous works because we extract the profile group metadata saliency from the groups generated by grouping similar runtime behavior. We first formalize its functioning and its main components. Subsequently, we implement and empirically analyze our proposed technique on two public data sources: Alibaba cloud machine learning workloads and Google cluster data. Despite relying on partially anonymized or obscured information, the approach provides accurate estimates of workload runtime behavior in real-time.","sentences":["We present and formalize a general approach for profiling workload by leveraging only a priori available static metadata to supply appropriate resource needs.","Understanding the requirements and characteristics of a workload's runtime is essential.","Profiles are essential for the platform (or infrastructure) provider because they want to ensure that Service Level Agreements and their objectives (SLOs) are fulfilled and, at the same time, avoid allocating too many resources to the workload.","When the infrastructure to manage is the computing continuum (i.e., from IoT to Edge to Cloud nodes), there is a big problem of placement and tradeoff or distribution and performance.","Still, existing techniques either rely on static predictions or runtime profiling, which are proven to deliver poor performance in runtime environments or require laborious mechanisms to produce fast and reliable evaluations.","We want to propose a new approach for it.","Our profile combines the information from past execution traces with the related workload metadata, equipping an infrastructure orchestrator with a fast and precise association of newly submitted workloads.","We differentiate from previous works because we extract the profile group metadata saliency from the groups generated by grouping similar runtime behavior.","We first formalize its functioning and its main components.","Subsequently, we implement and empirically analyze our proposed technique on two public data sources: Alibaba cloud machine learning workloads and Google cluster data.","Despite relying on partially anonymized or obscured information, the approach provides accurate estimates of workload runtime behavior in real-time."],"url":"http://arxiv.org/abs/2504.20740v1"}
{"created":"2025-04-29 13:21:27","title":"EDD-NSTE: Edge Data Distribution as a Network Steiner Tree Estimation in Edge Computing","abstract":"Edge computing is a distributed computing paradigm that brings computation and data storage closer to the user's geographical location to improve response times and save bandwidth. It also helps to power a variety of applications requiring low latency. These application data hosted on the cloud needs to be transferred to the respective edge servers in a specific area to help provide low-latency app functionalities to the users of that area. Meanwhile, these arbitrary heavy data transactions from the cloud to the edge servers result in high cost and time penalties. Thus, we need an application data distribution strategy that minimizes these penalties within the app vendors' specific latency constraint. In this work, we provide a refined formulation of an optimal approach to solve this Edge Data Distribution (EDD) problem using Integer Programming (IP) technique. Due to the time complexity limitation of the IP approach, we suggest an O(k) approximation algorithm based on network Steiner tree estimation (EDD-NSTE) for estimating solutions to dense, large-scale EDD problems. Integer Programming and EDD-NSTE are evaluated on a standard real-world EUA data set and the result demonstrates that EDD-NSTE significantly outperforms with a performance margin of 86.67% over the other three representative approaches and the state-of-the-art approach.","sentences":["Edge computing is a distributed computing paradigm that brings computation and data storage closer to the user's geographical location to improve response times and save bandwidth.","It also helps to power a variety of applications requiring low latency.","These application data hosted on the cloud needs to be transferred to the respective edge servers in a specific area to help provide low-latency app functionalities to the users of that area.","Meanwhile, these arbitrary heavy data transactions from the cloud to the edge servers result in high cost and time penalties.","Thus, we need an application data distribution strategy that minimizes these penalties within the app vendors' specific latency constraint.","In this work, we provide a refined formulation of an optimal approach to solve this Edge Data Distribution (EDD) problem using Integer Programming (IP) technique.","Due to the time complexity limitation of the IP approach, we suggest an O(k) approximation algorithm based on network Steiner tree estimation (EDD-NSTE) for estimating solutions to dense, large-scale EDD problems.","Integer Programming and EDD-NSTE are evaluated on a standard real-world EUA data set and the result demonstrates that EDD-NSTE significantly outperforms with a performance margin of 86.67% over the other three representative approaches and the state-of-the-art approach."],"url":"http://arxiv.org/abs/2504.20738v1"}
{"created":"2025-04-29 13:15:55","title":"Unsupervised Surrogate Anomaly Detection","abstract":"In this paper, we study unsupervised anomaly detection algorithms that learn a neural network representation, i.e. regular patterns of normal data, which anomalies are deviating from. Inspired by a similar concept in engineering, we refer to our methodology as surrogate anomaly detection. We formalize the concept of surrogate anomaly detection into a set of axioms required for optimal surrogate models and propose a new algorithm, named DEAN (Deep Ensemble ANomaly detection), designed to fulfill these criteria. We evaluate DEAN on 121 benchmark datasets, demonstrating its competitive performance against 19 existing methods, as well as the scalability and reliability of our method.","sentences":["In this paper, we study unsupervised anomaly detection algorithms that learn a neural network representation, i.e. regular patterns of normal data, which anomalies are deviating from.","Inspired by a similar concept in engineering, we refer to our methodology as surrogate anomaly detection.","We formalize the concept of surrogate anomaly detection into a set of axioms required for optimal surrogate models and propose a new algorithm, named DEAN (Deep Ensemble ANomaly detection), designed to fulfill these criteria.","We evaluate DEAN on 121 benchmark datasets, demonstrating its competitive performance against 19 existing methods, as well as the scalability and reliability of our method."],"url":"http://arxiv.org/abs/2504.20733v1"}
{"created":"2025-04-29 13:15:54","title":"Bayesian Inference in Quantum Programs","abstract":"Conditioning is a key feature in probabilistic programming to enable modeling the influence of data (also known as observations) to the probability distribution described by such programs. Determining the posterior distribution is also known as Bayesian inference. This paper equips a quantum while-language with conditioning, defines its denotational and operational semantics over infinite-dimensional Hilbert spaces, and shows their equivalence. We provide sufficient conditions for the existence of weakest (liberal) precondition-transformers and derive inductive characterizations of these transformers. It is shown how w(l)p-transformers can be used to assess the effect of Bayesian inference on (possibly diverging) quantum programs.","sentences":["Conditioning is a key feature in probabilistic programming to enable modeling the influence of data (also known as observations) to the probability distribution described by such programs.","Determining the posterior distribution is also known as Bayesian inference.","This paper equips a quantum while-language with conditioning, defines its denotational and operational semantics over infinite-dimensional Hilbert spaces, and shows their equivalence.","We provide sufficient conditions for the existence of weakest (liberal) precondition-transformers and derive inductive characterizations of these transformers.","It is shown how w(l)p-transformers can be used to assess the effect of Bayesian inference on (possibly diverging) quantum programs."],"url":"http://arxiv.org/abs/2504.20732v1"}
{"created":"2025-04-29 13:11:59","title":"Handling Large-Scale Network Flow Records: A Comparative Study on Lossy Compression","abstract":"Flow records, that summarize the characteristics of traffic flows, represent a practical and powerful way to monitor a network. While they already offer significant compression compared to full packet captures, their sheer volume remains daunting, especially for large Internet Service Providers (ISPs). In this paper, we investigate several lossy compression techniques to further reduce storage requirements while preserving the utility of flow records for key tasks, such as predicting the domain name of contacted servers. Our study evaluates scalar quantization, Principal Component Analysis (PCA), and vector quantization, applied to a real-world dataset from an operational campus network. Results reveal that scalar quantization provides the best tradeoff between compression and accuracy. PCA can preserve predictive accuracy but hampers subsequent entropic compression, and while vector quantization shows promise, it struggles with scalability due to the high-dimensional nature of the data. These findings result in practical strategies for optimizing flow record storage in large-scale monitoring scenarios.","sentences":["Flow records, that summarize the characteristics of traffic flows, represent a practical and powerful way to monitor a network.","While they already offer significant compression compared to full packet captures, their sheer volume remains daunting, especially for large Internet Service Providers (ISPs).","In this paper, we investigate several lossy compression techniques to further reduce storage requirements while preserving the utility of flow records for key tasks, such as predicting the domain name of contacted servers.","Our study evaluates scalar quantization, Principal Component Analysis (PCA), and vector quantization, applied to a real-world dataset from an operational campus network.","Results reveal that scalar quantization provides the best tradeoff between compression and accuracy.","PCA can preserve predictive accuracy but hampers subsequent entropic compression, and while vector quantization shows promise, it struggles with scalability due to the high-dimensional nature of the data.","These findings result in practical strategies for optimizing flow record storage in large-scale monitoring scenarios."],"url":"http://arxiv.org/abs/2504.20729v1"}
{"created":"2025-04-29 13:08:27","title":"Enhancing Vulnerability Reports with Automated and Augmented Description Summarization","abstract":"Public vulnerability databases, such as the National Vulnerability Database (NVD), document vulnerabilities and facilitate threat information sharing. However, they often suffer from short descriptions and outdated or insufficient information. In this paper, we introduce Zad, a system designed to enrich NVD vulnerability descriptions by leveraging external resources. Zad consists of two pipelines: one collects and filters supplementary data using two encoders to build a detailed dataset, while the other fine-tunes a pre-trained model on this dataset to generate enriched descriptions. By addressing brevity and improving content quality, Zad produces more comprehensive and cohesive vulnerability descriptions. We evaluate Zad using standard summarization metrics and human assessments, demonstrating its effectiveness in enhancing vulnerability information.","sentences":["Public vulnerability databases, such as the National Vulnerability Database (NVD), document vulnerabilities and facilitate threat information sharing.","However, they often suffer from short descriptions and outdated or insufficient information.","In this paper, we introduce Zad, a system designed to enrich NVD vulnerability descriptions by leveraging external resources.","Zad consists of two pipelines: one collects and filters supplementary data using two encoders to build a detailed dataset, while the other fine-tunes a pre-trained model on this dataset to generate enriched descriptions.","By addressing brevity and improving content quality, Zad produces more comprehensive and cohesive vulnerability descriptions.","We evaluate Zad using standard summarization metrics and human assessments, demonstrating its effectiveness in enhancing vulnerability information."],"url":"http://arxiv.org/abs/2504.20726v1"}
{"created":"2025-04-29 12:34:28","title":"BrightCookies at SemEval-2025 Task 9: Exploring Data Augmentation for Food Hazard Classification","abstract":"This paper presents our system developed for the SemEval-2025 Task 9: The Food Hazard Detection Challenge. The shared task's objective is to evaluate explainable classification systems for classifying hazards and products in two levels of granularity from food recall incident reports. In this work, we propose text augmentation techniques as a way to improve poor performance on minority classes and compare their effect for each category on various transformer and machine learning models. We explore three word-level data augmentation techniques, namely synonym replacement, random word swapping, and contextual word insertion. The results show that transformer models tend to have a better overall performance. None of the three augmentation techniques consistently improved overall performance for classifying hazards and products. We observed a statistically significant improvement (P < 0.05) in the fine-grained categories when using the BERT model to compare the baseline with each augmented model. Compared to the baseline, the contextual words insertion augmentation improved the accuracy of predictions for the minority hazard classes by 6%. This suggests that targeted augmentation of minority classes can improve the performance of transformer models.","sentences":["This paper presents our system developed for the SemEval-2025 Task 9: The Food Hazard Detection Challenge.","The shared task's objective is to evaluate explainable classification systems for classifying hazards and products in two levels of granularity from food recall incident reports.","In this work, we propose text augmentation techniques as a way to improve poor performance on minority classes and compare their effect for each category on various transformer and machine learning models.","We explore three word-level data augmentation techniques, namely synonym replacement, random word swapping, and contextual word insertion.","The results show that transformer models tend to have a better overall performance.","None of the three augmentation techniques consistently improved overall performance for classifying hazards and products.","We observed a statistically significant improvement (P < 0.05) in the fine-grained categories when using the BERT model to compare the baseline with each augmented model.","Compared to the baseline, the contextual words insertion augmentation improved the accuracy of predictions for the minority hazard classes by 6%.","This suggests that targeted augmentation of minority classes can improve the performance of transformer models."],"url":"http://arxiv.org/abs/2504.20703v1"}
{"created":"2025-04-29 12:31:37","title":"Building Trust in Healthcare with Privacy Techniques: Blockchain in the Cloud","abstract":"This study introduces a cutting-edge architecture developed for the NewbornTime project, which uses advanced AI to analyze video data at birth and during newborn resuscitation, with the aim of improving newborn care. The proposed architecture addresses the crucial issues of patient consent, data security, and investing trust in healthcare by integrating Ethereum blockchain with cloud computing. Our blockchain-based consent application simplifies patient consent's secure and transparent management. We explain the smart contract mechanisms and privacy measures employed, ensuring data protection while permitting controlled data sharing among authorized parties. This work demonstrates the potential of combining blockchain and cloud technologies in healthcare, emphasizing their role in maintaining data integrity, with implications for computer science and healthcare innovation.","sentences":["This study introduces a cutting-edge architecture developed for the NewbornTime project, which uses advanced AI to analyze video data at birth and during newborn resuscitation, with the aim of improving newborn care.","The proposed architecture addresses the crucial issues of patient consent, data security, and investing trust in healthcare by integrating Ethereum blockchain with cloud computing.","Our blockchain-based consent application simplifies patient consent's secure and transparent management.","We explain the smart contract mechanisms and privacy measures employed, ensuring data protection while permitting controlled data sharing among authorized parties.","This work demonstrates the potential of combining blockchain and cloud technologies in healthcare, emphasizing their role in maintaining data integrity, with implications for computer science and healthcare innovation."],"url":"http://arxiv.org/abs/2504.20700v1"}
{"created":"2025-04-29 12:14:47","title":"In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer","abstract":"Instruction-based image editing enables robust image modification via natural language prompts, yet current methods face a precision-efficiency tradeoff. Fine-tuning methods demand significant computational resources and large datasets, while training-free techniques struggle with instruction comprehension and edit quality. We resolve this dilemma by leveraging large-scale Diffusion Transformer (DiT)' enhanced generation capacity and native contextual awareness. Our solution introduces three contributions: (1) an in-context editing framework for zero-shot instruction compliance using in-context prompting, avoiding structural changes; (2) a LoRA-MoE hybrid tuning strategy that enhances flexibility with efficient adaptation and dynamic expert routing, without extensive retraining; and (3) an early filter inference-time scaling method using vision-language models (VLMs) to select better initial noise early, improving edit quality. Extensive evaluations demonstrate our method's superiority: it outperforms state-of-the-art approaches while requiring only 0.5% training data and 1% trainable parameters compared to conventional baselines. This work establishes a new paradigm that enables high-precision yet efficient instruction-guided editing. Codes and demos can be found in https://river-zhang.github.io/ICEdit-gh-pages/.","sentences":["Instruction-based image editing enables robust image modification via natural language prompts, yet current methods face a precision-efficiency tradeoff.","Fine-tuning methods demand significant computational resources and large datasets, while training-free techniques struggle with instruction comprehension and edit quality.","We resolve this dilemma by leveraging large-scale Diffusion Transformer (DiT)' enhanced generation capacity and native contextual awareness.","Our solution introduces three contributions: (1) an in-context editing framework for zero-shot instruction compliance using in-context prompting, avoiding structural changes; (2) a LoRA-MoE hybrid tuning strategy that enhances flexibility with efficient adaptation and dynamic expert routing, without extensive retraining; and (3) an early filter inference-time scaling method using vision-language models (VLMs) to select better initial noise early, improving edit quality.","Extensive evaluations demonstrate our method's superiority: it outperforms state-of-the-art approaches while requiring only 0.5% training data and 1% trainable parameters compared to conventional baselines.","This work establishes a new paradigm that enables high-precision yet efficient instruction-guided editing.","Codes and demos can be found in https://river-zhang.github.io/ICEdit-gh-pages/."],"url":"http://arxiv.org/abs/2504.20690v1"}
{"created":"2025-04-29 12:11:23","title":"DICOM Compatible, 3D Multimodality Image Encryption using Hyperchaotic Signal","abstract":"Medical image encryption plays an important role in protecting sensitive health information from cyberattacks and unauthorized access. In this paper, we introduce a secure and robust encryption scheme that is multi-modality compatible and works with MRI, CT, X-Ray and Ultrasound images for different anatomical region of interest. The method utilizes hyperchaotic signals and multi-level diffusion methods. The encryption starts by taking DICOM image as input, then padding to increase the image area. Chaotic signals are produced by a logistic map and are used to carry out pixel random permutation. Then, multi-level diffusion is carried out by 4-bit, 8-bit, radial and adjacent diffusion to provide high randomness and immunity against statistical attacks. In addition, we propose a captcha-based authentication scheme to further improve security. An algorithm generates alphanumeric captcha-based image which is encrypted with the same chaotic and diffusion methods as the medical image. Both encrypted images(DICOM image and captcha image) are then superimposed to create a final encrypted output, essentially integrating dual-layer security. Upon decryption, the superimposed image is again decomposed back to original medical and captcha images, and inverse operations are performed to obtain the original unencrypted data. Experimental results show that the proposed method provides strong protection with no loss in image integrity, thereby reducing unauthorized data breaches to a significant level. The dual-encryption approach not only protects the confidentiality of the medical images but also enhances authentication by incorporating captcha.","sentences":["Medical image encryption plays an important role in protecting sensitive health information from cyberattacks and unauthorized access.","In this paper, we introduce a secure and robust encryption scheme that is multi-modality compatible and works with MRI, CT, X-Ray and Ultrasound images for different anatomical region of interest.","The method utilizes hyperchaotic signals and multi-level diffusion methods.","The encryption starts by taking DICOM image as input, then padding to increase the image area.","Chaotic signals are produced by a logistic map and are used to carry out pixel random permutation.","Then, multi-level diffusion is carried out by 4-bit, 8-bit, radial and adjacent diffusion to provide high randomness and immunity against statistical attacks.","In addition, we propose a captcha-based authentication scheme to further improve security.","An algorithm generates alphanumeric captcha-based image which is encrypted with the same chaotic and diffusion methods as the medical image.","Both encrypted images(DICOM image and captcha image) are then superimposed to create a final encrypted output, essentially integrating dual-layer security.","Upon decryption, the superimposed image is again decomposed back to original medical and captcha images, and inverse operations are performed to obtain the original unencrypted data.","Experimental results show that the proposed method provides strong protection with no loss in image integrity, thereby reducing unauthorized data breaches to a significant level.","The dual-encryption approach not only protects the confidentiality of the medical images but also enhances authentication by incorporating captcha."],"url":"http://arxiv.org/abs/2504.20689v1"}
{"created":"2025-04-29 12:10:52","title":"What's Wrong with Your Synthetic Tabular Data? Using Explainable AI to Evaluate Generative Models","abstract":"Evaluating synthetic tabular data is challenging, since they can differ from the real data in so many ways. There exist numerous metrics of synthetic data quality, ranging from statistical distances to predictive performance, often providing conflicting results. Moreover, they fail to explain or pinpoint the specific weaknesses in the synthetic data. To address this, we apply explainable AI (XAI) techniques to a binary detection classifier trained to distinguish real from synthetic data. While the classifier identifies distributional differences, XAI concepts such as feature importance and feature effects, analyzed through methods like permutation feature importance, partial dependence plots, Shapley values and counterfactual explanations, reveal why synthetic data are distinguishable, highlighting inconsistencies, unrealistic dependencies, or missing patterns. This interpretability increases transparency in synthetic data evaluation and provides deeper insights beyond conventional metrics, helping diagnose and improve synthetic data quality. We apply our approach to two tabular datasets and generative models, showing that it uncovers issues overlooked by standard evaluation techniques.","sentences":["Evaluating synthetic tabular data is challenging, since they can differ from the real data in so many ways.","There exist numerous metrics of synthetic data quality, ranging from statistical distances to predictive performance, often providing conflicting results.","Moreover, they fail to explain or pinpoint the specific weaknesses in the synthetic data.","To address this, we apply explainable AI (XAI) techniques to a binary detection classifier trained to distinguish real from synthetic data.","While the classifier identifies distributional differences, XAI concepts such as feature importance and feature effects, analyzed through methods like permutation feature importance, partial dependence plots, Shapley values and counterfactual explanations, reveal why synthetic data are distinguishable, highlighting inconsistencies, unrealistic dependencies, or missing patterns.","This interpretability increases transparency in synthetic data evaluation and provides deeper insights beyond conventional metrics, helping diagnose and improve synthetic data quality.","We apply our approach to two tabular datasets and generative models, showing that it uncovers issues overlooked by standard evaluation techniques."],"url":"http://arxiv.org/abs/2504.20687v1"}
{"created":"2025-04-29 12:02:01","title":"OG-HFYOLO :Orientation gradient guidance and heterogeneous feature fusion for deformation table cell instance segmentation","abstract":"Table structure recognition is a key task in document analysis. However, the geometric deformation in deformed tables causes a weak correlation between content information and structure, resulting in downstream tasks not being able to obtain accurate content information. To obtain fine-grained spatial coordinates of cells, we propose the OG-HFYOLO model, which enhances the edge response by Gradient Orientation-aware Extractor, combines a Heterogeneous Kernel Cross Fusion module and a scale-aware loss function to adapt to multi-scale objective features, and introduces mask-driven non-maximal suppression in the post-processing, which replaces the traditional bounding box suppression mechanism. Furthermore, we also propose a data generator, filling the gap in the dataset for fine-grained deformation table cell spatial coordinate localization, and derive a large-scale dataset named Deformation Wired Table (DWTAL). Experiments show that our proposed model demonstrates excellent segmentation accuracy on all mainstream instance segmentation models. The dataset and the source code are open source: https://github.com/justliulong/OGHFYOLO.","sentences":["Table structure recognition is a key task in document analysis.","However, the geometric deformation in deformed tables causes a weak correlation between content information and structure, resulting in downstream tasks not being able to obtain accurate content information.","To obtain fine-grained spatial coordinates of cells, we propose the OG-HFYOLO model, which enhances the edge response by Gradient Orientation-aware Extractor, combines a Heterogeneous Kernel Cross Fusion module and a scale-aware loss function to adapt to multi-scale objective features, and introduces mask-driven non-maximal suppression in the post-processing, which replaces the traditional bounding box suppression mechanism.","Furthermore, we also propose a data generator, filling the gap in the dataset for fine-grained deformation table cell spatial coordinate localization, and derive a large-scale dataset named Deformation Wired Table (DWTAL).","Experiments show that our proposed model demonstrates excellent segmentation accuracy on all mainstream instance segmentation models.","The dataset and the source code are open source: https://github.com/justliulong/OGHFYOLO."],"url":"http://arxiv.org/abs/2504.20682v1"}
{"created":"2025-04-29 12:01:43","title":"Data Encryption Battlefield: A Deep Dive into the Dynamic Confrontations in Ransomware Attacks","abstract":"In the rapidly evolving landscape of cybersecurity threats, ransomware represents a significant challenge. Attackers increasingly employ sophisticated encryption methods, such as entropy reduction through Base64 encoding, and partial or intermittent encryption to evade traditional detection methods. This study explores the dynamic battle between adversaries who continuously refine encryption strategies and defenders developing advanced countermeasures to protect vulnerable data. We investigate the application of online incremental machine learning algorithms designed to predict file encryption activities despite adversaries evolving obfuscation techniques. Our analysis utilizes an extensive dataset of 32.6 GB, comprising 11,928 files across multiple formats, including Microsoft Word documents (doc), PowerPoint presentations (ppt), Excel spreadsheets (xlsx), image formats (jpg, jpeg, png, tif, gif), PDFs (pdf), audio (mp3), and video (mp4) files. These files were encrypted by 75 distinct ransomware families, facilitating a robust empirical evaluation of machine learning classifiers effectiveness against diverse encryption tactics. Results highlight the Hoeffding Tree algorithms superior incremental learning capability, particularly effective in detecting traditional and AES-Base64 encryption methods employed to lower entropy. Conversely, the Random Forest classifier with warm-start functionality excels at identifying intermittent encryption methods, demonstrating the necessity of tailored machine learning solutions to counter sophisticated ransomware strategies.","sentences":["In the rapidly evolving landscape of cybersecurity threats, ransomware represents a significant challenge.","Attackers increasingly employ sophisticated encryption methods, such as entropy reduction through Base64 encoding, and partial or intermittent encryption to evade traditional detection methods.","This study explores the dynamic battle between adversaries who continuously refine encryption strategies and defenders developing advanced countermeasures to protect vulnerable data.","We investigate the application of online incremental machine learning algorithms designed to predict file encryption activities despite adversaries evolving obfuscation techniques.","Our analysis utilizes an extensive dataset of 32.6 GB, comprising 11,928 files across multiple formats, including Microsoft Word documents (doc), PowerPoint presentations (ppt), Excel spreadsheets (xlsx), image formats (jpg, jpeg, png, tif, gif), PDFs (pdf), audio (mp3), and video (mp4) files.","These files were encrypted by 75 distinct ransomware families, facilitating a robust empirical evaluation of machine learning classifiers effectiveness against diverse encryption tactics.","Results highlight the Hoeffding Tree algorithms superior incremental learning capability, particularly effective in detecting traditional and AES-Base64 encryption methods employed to lower entropy.","Conversely, the Random Forest classifier with warm-start functionality excels at identifying intermittent encryption methods, demonstrating the necessity of tailored machine learning solutions to counter sophisticated ransomware strategies."],"url":"http://arxiv.org/abs/2504.20681v1"}
{"created":"2025-04-29 11:59:08","title":"Non-native Children's Automatic Speech Assessment Challenge (NOCASA)","abstract":"This paper presents the \"Non-native Children's Automatic Speech Assessment\" (NOCASA) - a data competition part of the IEEE MLSP 2025 conference. NOCASA challenges participants to develop new systems that can assess single-word pronunciations of young second language (L2) learners as part of a gamified pronunciation training app. To achieve this, several issues must be addressed, most notably the limited nature of available training data and the highly unbalanced distribution among the pronunciation level categories. To expedite the development, we provide a pseudo-anonymized training data (TeflonNorL2), containing 10,334 recordings from 44 speakers attempting to pronounce 205 distinct Norwegian words, human-rated on a 1 to 5 scale (number of stars that should be given in the game). In addition to the data, two already trained systems are released as official baselines: an SVM classifier trained on the ComParE_16 acoustic feature set and a multi-task wav2vec 2.0 model. The latter achieves the best performance on the challenge test set, with an unweighted average recall (UAR) of 36.37%.","sentences":["This paper presents the \"Non-native Children's Automatic Speech Assessment\" (NOCASA) - a data competition part of the IEEE MLSP 2025 conference.","NOCASA challenges participants to develop new systems that can assess single-word pronunciations of young second language (L2) learners as part of a gamified pronunciation training app.","To achieve this, several issues must be addressed, most notably the limited nature of available training data and the highly unbalanced distribution among the pronunciation level categories.","To expedite the development, we provide a pseudo-anonymized training data (TeflonNorL2), containing 10,334 recordings from 44 speakers attempting to pronounce 205 distinct Norwegian words, human-rated on a 1 to 5 scale (number of stars that should be given in the game).","In addition to the data, two already trained systems are released as official baselines: an SVM classifier trained on the ComParE_16 acoustic feature set and a multi-task wav2vec 2.0 model.","The latter achieves the best performance on the challenge test set, with an unweighted average recall (UAR) of 36.37%."],"url":"http://arxiv.org/abs/2504.20678v1"}
{"created":"2025-04-29 11:57:51","title":"DiffLiB: High-fidelity differentiable modeling of lithium-ion batteries and efficient gradient-based parameter identification","abstract":"The physics-based Doyle-Fuller-Newman (DFN) model, widely adopted for its precise electrochemical modeling, stands out among various simulation models of lithium-ion batteries (LIBs). Although the DFN model is powerful in forward predictive analysis, the inverse identification of its model parameters has remained a long-standing challenge. The numerous unknown parameters associated with the nonlinear, time-dependent, and multi-scale DFN model are extremely difficult to be determined accurately and efficiently, hindering the practical use of such battery simulation models in industrial applications. To tackle this challenge, we introduce DiffLiB, a high-fidelity finite-element-based LIB simulation framework, equipped with advanced differentiable programming techniques so that efficient gradient-based inverse parameter identification is enabled. Customized automatic differentiation rules are defined by identifying the VJP (vector-Jacobian product) structure in the chain rule and implemented using adjoint-based implicit differentiation methods. Four numerical examples, including both 2D and 3D forward predictions and inverse parameter identification, are presented to validate the accuracy and computational efficiency of DiffLiB. Benchmarking against COMSOL demonstrates excellent agreement in forward predictions, with terminal voltage discrepancies maintaining a root-mean-square error (RMSE) below 2 mV across all test conditions. In parameter identification tasks using experimentally measured voltage data, the proposed gradient-based optimization scheme achieves superior computational performance, with 96% fewer forward predictions and 72% less computational time compared with gradient-free approaches. These results demonstrate that DiffLiB is a versatile and powerful computational framework for the development of advanced LIBs.","sentences":["The physics-based Doyle-Fuller-Newman (DFN) model, widely adopted for its precise electrochemical modeling, stands out among various simulation models of lithium-ion batteries (LIBs).","Although the DFN model is powerful in forward predictive analysis, the inverse identification of its model parameters has remained a long-standing challenge.","The numerous unknown parameters associated with the nonlinear, time-dependent, and multi-scale DFN model are extremely difficult to be determined accurately and efficiently, hindering the practical use of such battery simulation models in industrial applications.","To tackle this challenge, we introduce DiffLiB, a high-fidelity finite-element-based LIB simulation framework, equipped with advanced differentiable programming techniques so that efficient gradient-based inverse parameter identification is enabled.","Customized automatic differentiation rules are defined by identifying the VJP (vector-Jacobian product) structure in the chain rule and implemented using adjoint-based implicit differentiation methods.","Four numerical examples, including both 2D and 3D forward predictions and inverse parameter identification, are presented to validate the accuracy and computational efficiency of DiffLiB. Benchmarking against COMSOL demonstrates excellent agreement in forward predictions, with terminal voltage discrepancies maintaining a root-mean-square error (RMSE) below 2 mV across all test conditions.","In parameter identification tasks using experimentally measured voltage data, the proposed gradient-based optimization scheme achieves superior computational performance, with 96% fewer forward predictions and 72% less computational time compared with gradient-free approaches.","These results demonstrate that DiffLiB is a versatile and powerful computational framework for the development of advanced LIBs."],"url":"http://arxiv.org/abs/2504.20674v1"}
{"created":"2025-04-29 11:57:23","title":"CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation","abstract":"Large language models (LLMs) play a crucial role in software engineering, excelling in tasks like code generation and maintenance. However, existing benchmarks are often narrow in scope, focusing on a specific task and lack a comprehensive evaluation framework that reflects real-world applications. To address these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark), designed to evaluate LLMs across four critical dimensions: code understanding, code generation, code modification, and code review. These dimensions capture essential developer needs, ensuring a more systematic and representative evaluation. CoCo-Bench includes multiple programming languages and varying task difficulties, with rigorous manual review to ensure data quality and accuracy. Empirical results show that CoCo-Bench aligns with existing benchmarks while uncovering significant variations in model performance, effectively highlighting strengths and weaknesses. By offering a holistic and objective evaluation, CoCo-Bench provides valuable insights to guide future research and technological advancements in code-oriented LLMs, establishing a reliable benchmark for the field.","sentences":["Large language models (LLMs) play a crucial role in software engineering, excelling in tasks like code generation and maintenance.","However, existing benchmarks are often narrow in scope, focusing on a specific task and lack a comprehensive evaluation framework that reflects real-world applications.","To address these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark), designed to evaluate LLMs across four critical dimensions: code understanding, code generation, code modification, and code review.","These dimensions capture essential developer needs, ensuring a more systematic and representative evaluation.","CoCo-Bench includes multiple programming languages and varying task difficulties, with rigorous manual review to ensure data quality and accuracy.","Empirical results show that CoCo-Bench aligns with existing benchmarks while uncovering significant variations in model performance, effectively highlighting strengths and weaknesses.","By offering a holistic and objective evaluation, CoCo-Bench provides valuable insights to guide future research and technological advancements in code-oriented LLMs, establishing a reliable benchmark for the field."],"url":"http://arxiv.org/abs/2504.20673v1"}
{"created":"2025-04-29 11:45:24","title":"SFi-Former: Sparse Flow Induced Attention for Graph Transformer","abstract":"Graph Transformers (GTs) have demonstrated superior performance compared to traditional message-passing graph neural networks in many studies, especially in processing graph data with long-range dependencies. However, GTs tend to suffer from weak inductive bias, overfitting and over-globalizing problems due to the dense attention. In this paper, we introduce SFi-attention, a novel attention mechanism designed to learn sparse pattern by minimizing an energy function based on network flows with l1-norm regularization, to relieve those issues caused by dense attention. Furthermore, SFi-Former is accordingly devised which can leverage the sparse attention pattern of SFi-attention to generate sparse network flows beyond adjacency matrix of graph data. Specifically, SFi-Former aggregates features selectively from other nodes through flexible adaptation of the sparse attention, leading to a more robust model. We validate our SFi-Former on various graph datasets, especially those graph data exhibiting long-range dependencies. Experimental results show that our SFi-Former obtains competitive performance on GNN Benchmark datasets and SOTA performance on LongRange Graph Benchmark (LRGB) datasets. Additionally, our model gives rise to smaller generalization gaps, which indicates that it is less prone to over-fitting. Click here for codes.","sentences":["Graph Transformers (GTs) have demonstrated superior performance compared to traditional message-passing graph neural networks in many studies, especially in processing graph data with long-range dependencies.","However, GTs tend to suffer from weak inductive bias, overfitting and over-globalizing problems due to the dense attention.","In this paper, we introduce SFi-attention, a novel attention mechanism designed to learn sparse pattern by minimizing an energy function based on network flows with l1-norm regularization, to relieve those issues caused by dense attention.","Furthermore, SFi-Former is accordingly devised which can leverage the sparse attention pattern of SFi-attention to generate sparse network flows beyond adjacency matrix of graph data.","Specifically, SFi-Former aggregates features selectively from other nodes through flexible adaptation of the sparse attention, leading to a more robust model.","We validate our SFi-Former on various graph datasets, especially those graph data exhibiting long-range dependencies.","Experimental results show that our SFi-Former obtains competitive performance on GNN Benchmark datasets and SOTA performance on LongRange Graph Benchmark (LRGB) datasets.","Additionally, our model gives rise to smaller generalization gaps, which indicates that it is less prone to over-fitting.","Click here for codes."],"url":"http://arxiv.org/abs/2504.20666v1"}
{"created":"2025-04-29 11:37:31","title":"On the Optimal Source Key Size of Secure Gradient Coding","abstract":"With gradient coding, a user node can efficiently aggregate gradients from server nodes processing local datasets, achieving low communication costs and maintaining resilience against straggling servers. This paper considers a secure gradient coding problem, where a user aims to compute the sum of the gradients from $K$ datasets with the assistance of $N$ distributed servers. The user should recover the sum of gradients by receiving transmissions from any $N_r$ servers, and each dataset is assigned to $N - N_r + m$ servers. The security constraint guarantees that even if the user receives transmissions from all servers, it cannot obtain any additional information about the datasets beyond the sum of gradients.   It has been shown in the literature that this security constraint does not increase the optimal communication cost of the gradient coding problem, provided enough source keys are shared among the servers. However, the minimum required source key size that ensures security while maintaining this optimal communication cost has only been studied for the special case $m = 1$. In this paper, we focus on the more general case $m \\geq 1$ and aim to determine the minimum required source key size for this purpose.   We propose a new information-theoretic converse bound on the source key size, as well as a new achievable scheme with carefully designed data assignments. Our scheme outperforms the existing optimal scheme based on the widely used cyclic data assignment and coincides with the converse bound under certain system parameters.","sentences":["With gradient coding, a user node can efficiently aggregate gradients from server nodes processing local datasets, achieving low communication costs and maintaining resilience against straggling servers.","This paper considers a secure gradient coding problem, where a user aims to compute the sum of the gradients from $K$ datasets with the assistance of $N$ distributed servers.","The user should recover the sum of gradients by receiving transmissions from any $N_r$ servers, and each dataset is assigned to $N - N_r + m$ servers.","The security constraint guarantees that even if the user receives transmissions from all servers, it cannot obtain any additional information about the datasets beyond the sum of gradients.   ","It has been shown in the literature that this security constraint does not increase the optimal communication cost of the gradient coding problem, provided enough source keys are shared among the servers.","However, the minimum required source key size that ensures security while maintaining this optimal communication cost has only been studied for the special case $m = 1$.","In this paper, we focus on the more general case $m \\geq 1$ and aim to determine the minimum required source key size for this purpose.   ","We propose a new information-theoretic converse bound on the source key size, as well as a new achievable scheme with carefully designed data assignments.","Our scheme outperforms the existing optimal scheme based on the widely used cyclic data assignment and coincides with the converse bound under certain system parameters."],"url":"http://arxiv.org/abs/2504.20662v1"}
{"created":"2025-04-29 11:36:08","title":"Quantum-Enhanced Hybrid Reinforcement Learning Framework for Dynamic Path Planning in Autonomous Systems","abstract":"In this paper, a novel quantum classical hybrid framework is proposed that synergizes quantum with Classical Reinforcement Learning. By leveraging the inherent parallelism of quantum computing, the proposed approach generates robust Q tables and specialized turn cost estimations, which are then integrated with a classical Reinforcement Learning pipeline. The Classical Quantum fusion results in rapid convergence of training, reducing the training time significantly and improved adaptability in scenarios featuring static, dynamic, and moving obstacles. Simulator based evaluations demonstrate significant enhancements in path efficiency, trajectory smoothness, and mission success rates, underscoring the potential of framework for real time, autonomous navigation in complex and unpredictable environments. Furthermore, the proposed framework was tested beyond simulations on practical scenarios, including real world map data such as the IIT Delhi campus, reinforcing its potential for real time, autonomous navigation in complex and unpredictable environments.","sentences":["In this paper, a novel quantum classical hybrid framework is proposed that synergizes quantum with Classical Reinforcement Learning.","By leveraging the inherent parallelism of quantum computing, the proposed approach generates robust Q tables and specialized turn cost estimations, which are then integrated with a classical Reinforcement Learning pipeline.","The Classical Quantum fusion results in rapid convergence of training, reducing the training time significantly and improved adaptability in scenarios featuring static, dynamic, and moving obstacles.","Simulator based evaluations demonstrate significant enhancements in path efficiency, trajectory smoothness, and mission success rates, underscoring the potential of framework for real time, autonomous navigation in complex and unpredictable environments.","Furthermore, the proposed framework was tested beyond simulations on practical scenarios, including real world map data such as the IIT Delhi campus, reinforcing its potential for real time, autonomous navigation in complex and unpredictable environments."],"url":"http://arxiv.org/abs/2504.20660v1"}
{"created":"2025-04-29 11:33:51","title":"Image deidentification in the XNAT ecosystem: use cases and solutions","abstract":"XNAT is a server-based data management platform widely used in academia for curating large databases of DICOM images for research projects. We describe in detail a deidentification workflow for DICOM data using facilities in XNAT, together with independent tools in the XNAT \"ecosystem\". We list different contexts in which deidentification might be needed, based on our prior experience. The starting point for participation in the Medical Image De-Identification Benchmark (MIDI-B) challenge was a set of pre-existing local methodologies, which were adapted during the validation phase of the challenge. Our result in the test phase was 97.91\\%, considerably lower than our peers, due largely to an arcane technical incompatibility of our methodology with the challenge's Synapse platform, which prevented us receiving feedback during the validation phase. Post-submission, additional discrepancy reports from the organisers and via the MIDI-B Continuous Benchmarking facility, enabled us to improve this score significantly to 99.61\\%. An entirely rule-based approach was shown to be capable of removing all name-related information in the test corpus, but exhibited failures in dealing fully with address data. Initial experiments using published machine-learning models to remove addresses were partially successful but showed the models to be \"over-aggressive\" on other types of free-text data, leading to a slight overall degradation in performance to 99.54\\%. Future development will therefore focus on improving address-recognition capabilities, but also on better removal of identifiable data burned into the image pixels. Several technical aspects relating to the \"answer key\" are still under discussion with the challenge organisers, but we estimate that our percentage of genuine deidentification failures on the MIDI-B test corpus currently stands at 0.19\\%. (Abridged from original for arXiv submission)","sentences":["XNAT is a server-based data management platform widely used in academia for curating large databases of DICOM images for research projects.","We describe in detail a deidentification workflow for DICOM data using facilities in XNAT, together with independent tools in the XNAT \"ecosystem\".","We list different contexts in which deidentification might be needed, based on our prior experience.","The starting point for participation in the Medical Image De-Identification Benchmark (MIDI-B) challenge was a set of pre-existing local methodologies, which were adapted during the validation phase of the challenge.","Our result in the test phase was 97.91\\%, considerably lower than our peers, due largely to an arcane technical incompatibility of our methodology with the challenge's Synapse platform, which prevented us receiving feedback during the validation phase.","Post-submission, additional discrepancy reports from the organisers and via the MIDI-B Continuous Benchmarking facility, enabled us to improve this score significantly to 99.61\\%.","An entirely rule-based approach was shown to be capable of removing all name-related information in the test corpus, but exhibited failures in dealing fully with address data.","Initial experiments using published machine-learning models to remove addresses were partially successful but showed the models to be \"over-aggressive\" on other types of free-text data, leading to a slight overall degradation in performance to 99.54\\%.","Future development will therefore focus on improving address-recognition capabilities, but also on better removal of identifiable data burned into the image pixels.","Several technical aspects relating to the \"answer key\" are still under discussion with the challenge organisers, but we estimate that our percentage of genuine deidentification failures on the MIDI-B test corpus currently stands at 0.19\\%.","(Abridged from original for arXiv submission)"],"url":"http://arxiv.org/abs/2504.20657v1"}
{"created":"2025-04-29 11:31:48","title":"Federated learning, ethics, and the double black box problem in medical AI","abstract":"Federated learning (FL) is a machine learning approach that allows multiple devices or institutions to collaboratively train a model without sharing their local data with a third-party. FL is considered a promising way to address patient privacy concerns in medical artificial intelligence. The ethical risks of medical FL systems themselves, however, have thus far been underexamined. This paper aims to address this gap. We argue that medical FL presents a new variety of opacity -- federation opacity -- that, in turn, generates a distinctive double black box problem in healthcare AI. We highlight several instances in which the anticipated benefits of medical FL may be exaggerated, and conclude by highlighting key challenges that must be overcome to make FL ethically feasible in medicine.","sentences":["Federated learning (FL) is a machine learning approach that allows multiple devices or institutions to collaboratively train a model without sharing their local data with a third-party.","FL is considered a promising way to address patient privacy concerns in medical artificial intelligence.","The ethical risks of medical FL systems themselves, however, have thus far been underexamined.","This paper aims to address this gap.","We argue that medical FL presents a new variety of opacity -- federation opacity -- that, in turn, generates a distinctive double black box problem in healthcare AI.","We highlight several instances in which the anticipated benefits of medical FL may be exaggerated, and conclude by highlighting key challenges that must be overcome to make FL ethically feasible in medicine."],"url":"http://arxiv.org/abs/2504.20656v1"}
{"created":"2025-04-29 11:21:11","title":"RuleKit 2: Faster and simpler rule learning","abstract":"Rules offer an invaluable combination of predictive and descriptive capabilities. Our package for rule-based data analysis, RuleKit, has proven its effectiveness in classification, regression, and survival problems. Here we present its second version. New algorithms and optimized implementations of those previously included, significantly improved the computational performance of our suite, reducing the analysis time of some data sets by two orders of magnitude. The usability of RuleKit 2 is provided by two new components: Python package and browser application with a graphical user interface. The former complies with scikit-learn, the most popular data mining library for Python, allowing RuleKit 2 to be straightforwardly integrated into existing data analysis pipelines. RuleKit 2 is available at GitHub under GNU AGPL 3 license (https://github.com/adaa-polsl/RuleKit)","sentences":["Rules offer an invaluable combination of predictive and descriptive capabilities.","Our package for rule-based data analysis, RuleKit, has proven its effectiveness in classification, regression, and survival problems.","Here we present its second version.","New algorithms and optimized implementations of those previously included, significantly improved the computational performance of our suite, reducing the analysis time of some data sets by two orders of magnitude.","The usability of RuleKit 2 is provided by two new components: Python package and browser application with a graphical user interface.","The former complies with scikit-learn, the most popular data mining library for Python, allowing RuleKit 2 to be straightforwardly integrated into existing data analysis pipelines.","RuleKit 2 is available at GitHub under GNU AGPL 3 license (https://github.com/adaa-polsl/RuleKit)"],"url":"http://arxiv.org/abs/2504.20650v1"}
{"created":"2025-04-29 11:18:38","title":"SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data","abstract":"Vision-language models (VLMs) work well in tasks ranging from image captioning to visual question answering (VQA), yet they struggle with spatial reasoning, a key skill for understanding our physical world that humans excel at. We find that spatial relations are generally rare in widely used VL datasets, with only a few being well represented, while most form a long tail of underrepresented relations. This gap leaves VLMs ill-equipped to handle diverse spatial relationships. To bridge it, we construct a synthetic VQA dataset focused on spatial reasoning generated from hyper-detailed image descriptions in Localized Narratives, DOCCI, and PixMo-Cap. Our dataset consists of 455k samples containing 3.4 million QA pairs. Trained on this dataset, our Spatial-Reasoning Enhanced (SpaRE) VLMs show strong improvements on spatial reasoning benchmarks, achieving up to a 49% performance gain on the What's Up benchmark, while maintaining strong results on general tasks. Our work narrows the gap between human and VLM spatial reasoning and makes VLMs more capable in real-world tasks such as robotics and navigation.","sentences":["Vision-language models (VLMs) work well in tasks ranging from image captioning to visual question answering (VQA), yet they struggle with spatial reasoning, a key skill for understanding our physical world that humans excel at.","We find that spatial relations are generally rare in widely used VL datasets, with only a few being well represented, while most form a long tail of underrepresented relations.","This gap leaves VLMs ill-equipped to handle diverse spatial relationships.","To bridge it, we construct a synthetic VQA dataset focused on spatial reasoning generated from hyper-detailed image descriptions in Localized Narratives, DOCCI, and PixMo-Cap.","Our dataset consists of 455k samples containing 3.4 million QA pairs.","Trained on this dataset, our Spatial-Reasoning Enhanced (SpaRE) VLMs show strong improvements on spatial reasoning benchmarks, achieving up to a 49% performance gain on the What's Up benchmark, while maintaining strong results on general tasks.","Our work narrows the gap between human and VLM spatial reasoning and makes VLMs more capable in real-world tasks such as robotics and navigation."],"url":"http://arxiv.org/abs/2504.20648v1"}
{"created":"2025-04-29 11:13:18","title":"Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection","abstract":"Selecting high-quality pre-training data for large language models (LLMs) is crucial for enhancing their overall performance under limited computation budget, improving both training and sample efficiency. Recent advancements in file selection primarily rely on using an existing or trained proxy model to assess the similarity of samples to a target domain, such as high quality sources BookCorpus and Wikipedia. However, upon revisiting these methods, the domain-similarity selection criteria demonstrates a diversity dilemma, i.e.dimensional collapse in the feature space, improving performance on the domain-related tasks but causing severe degradation on generic performance. To prevent collapse and enhance diversity, we propose a DiverSified File selection algorithm (DiSF), which selects the most decorrelated text files in the feature space. We approach this with a classical greedy algorithm to achieve more uniform eigenvalues in the feature covariance matrix of the selected texts, analyzing its approximation to the optimal solution under a formulation of $\\gamma$-weakly submodular optimization problem. Empirically, we establish a benchmark and conduct extensive experiments on the TinyLlama architecture with models from 120M to 1.1B parameters. Evaluating across nine tasks from the Harness framework, DiSF demonstrates a significant improvement on overall performance. Specifically, DiSF saves 98.5% of 590M training files in SlimPajama, outperforming the full-data pre-training within a 50B training budget, and achieving about 1.5x training efficiency and 5x data efficiency.","sentences":["Selecting high-quality pre-training data for large language models (LLMs) is crucial for enhancing their overall performance under limited computation budget, improving both training and sample efficiency.","Recent advancements in file selection primarily rely on using an existing or trained proxy model to assess the similarity of samples to a target domain, such as high quality sources BookCorpus and Wikipedia.","However, upon revisiting these methods, the domain-similarity selection criteria demonstrates a diversity dilemma, i.e.dimensional collapse in the feature space, improving performance on the domain-related tasks but causing severe degradation on generic performance.","To prevent collapse and enhance diversity, we propose a DiverSified File selection algorithm (DiSF), which selects the most decorrelated text files in the feature space.","We approach this with a classical greedy algorithm to achieve more uniform eigenvalues in the feature covariance matrix of the selected texts, analyzing its approximation to the optimal solution under a formulation of $\\gamma$-weakly submodular optimization problem.","Empirically, we establish a benchmark and conduct extensive experiments on the TinyLlama architecture with models from 120M to 1.1B parameters.","Evaluating across nine tasks from the Harness framework, DiSF demonstrates a significant improvement on overall performance.","Specifically, DiSF saves 98.5% of 590M training files in SlimPajama, outperforming the full-data pre-training within a 50B training budget, and achieving about 1.5x training efficiency and 5x data efficiency."],"url":"http://arxiv.org/abs/2504.20644v1"}
{"created":"2025-04-29 11:12:36","title":"Decision-centric fairness: Evaluation and optimization for resource allocation problems","abstract":"Data-driven decision support tools play an increasingly central role in decision-making across various domains. In this work, we focus on binary classification models for predicting positive-outcome scores and deciding on resource allocation, e.g., credit scores for granting loans or churn propensity scores for targeting customers with a retention campaign. Such models may exhibit discriminatory behavior toward specific demographic groups through their predicted scores, potentially leading to unfair resource allocation. We focus on demographic parity as a fairness metric to compare the proportions of instances that are selected based on their positive outcome scores across groups. In this work, we propose a decision-centric fairness methodology that induces fairness only within the decision-making region -- the range of relevant decision thresholds on the score that may be used to decide on resource allocation -- as an alternative to a global fairness approach that seeks to enforce parity across the entire score distribution. By restricting the induction of fairness to the decision-making region, the proposed decision-centric approach avoids imposing overly restrictive constraints on the model, which may unnecessarily degrade the quality of the predicted scores. We empirically compare our approach to a global fairness approach on multiple (semi-synthetic) datasets to identify scenarios in which focusing on fairness where it truly matters, i.e., decision-centric fairness, proves beneficial.","sentences":["Data-driven decision support tools play an increasingly central role in decision-making across various domains.","In this work, we focus on binary classification models for predicting positive-outcome scores and deciding on resource allocation, e.g., credit scores for granting loans or churn propensity scores for targeting customers with a retention campaign.","Such models may exhibit discriminatory behavior toward specific demographic groups through their predicted scores, potentially leading to unfair resource allocation.","We focus on demographic parity as a fairness metric to compare the proportions of instances that are selected based on their positive outcome scores across groups.","In this work, we propose a decision-centric fairness methodology that induces fairness only within the decision-making region -- the range of relevant decision thresholds on the score that may be used to decide on resource allocation -- as an alternative to a global fairness approach that seeks to enforce parity across the entire score distribution.","By restricting the induction of fairness to the decision-making region, the proposed decision-centric approach avoids imposing overly restrictive constraints on the model, which may unnecessarily degrade the quality of the predicted scores.","We empirically compare our approach to a global fairness approach on multiple (semi-synthetic) datasets to identify scenarios in which focusing on fairness where it truly matters, i.e., decision-centric fairness, proves beneficial."],"url":"http://arxiv.org/abs/2504.20642v1"}
{"created":"2025-04-29 11:04:28","title":"Bridging the Generalisation Gap: Synthetic Data Generation for Multi-Site Clinical Model Validation","abstract":"Ensuring the generalisability of clinical machine learning (ML) models across diverse healthcare settings remains a significant challenge due to variability in patient demographics, disease prevalence, and institutional practices. Existing model evaluation approaches often rely on real-world datasets, which are limited in availability, embed confounding biases, and lack the flexibility needed for systematic experimentation. Furthermore, while generative models aim for statistical realism, they often lack transparency and explicit control over factors driving distributional shifts. In this work, we propose a novel structured synthetic data framework designed for the controlled benchmarking of model robustness, fairness, and generalisability. Unlike approaches focused solely on mimicking observed data, our framework provides explicit control over the data generating process, including site-specific prevalence variations, hierarchical subgroup effects, and structured feature interactions. This enables targeted investigation into how models respond to specific distributional shifts and potential biases. Through controlled experiments, we demonstrate the framework's ability to isolate the impact of site variations, support fairness-aware audits, and reveal generalisation failures, particularly highlighting how model complexity interacts with site-specific effects. This work contributes a reproducible, interpretable, and configurable tool designed to advance the reliable deployment of ML in clinical settings.","sentences":["Ensuring the generalisability of clinical machine learning (ML) models across diverse healthcare settings remains a significant challenge due to variability in patient demographics, disease prevalence, and institutional practices.","Existing model evaluation approaches often rely on real-world datasets, which are limited in availability, embed confounding biases, and lack the flexibility needed for systematic experimentation.","Furthermore, while generative models aim for statistical realism, they often lack transparency and explicit control over factors driving distributional shifts.","In this work, we propose a novel structured synthetic data framework designed for the controlled benchmarking of model robustness, fairness, and generalisability.","Unlike approaches focused solely on mimicking observed data, our framework provides explicit control over the data generating process, including site-specific prevalence variations, hierarchical subgroup effects, and structured feature interactions.","This enables targeted investigation into how models respond to specific distributional shifts and potential biases.","Through controlled experiments, we demonstrate the framework's ability to isolate the impact of site variations, support fairness-aware audits, and reveal generalisation failures, particularly highlighting how model complexity interacts with site-specific effects.","This work contributes a reproducible, interpretable, and configurable tool designed to advance the reliable deployment of ML in clinical settings."],"url":"http://arxiv.org/abs/2504.20635v1"}
{"created":"2025-04-29 10:55:40","title":"Cognitive maps are generative programs","abstract":"Making sense of the world and acting in it relies on building simplified mental representations that abstract away aspects of reality. This principle of cognitive mapping is universal to agents with limited resources. Living organisms, people, and algorithms all face the problem of forming functional representations of their world under various computing constraints. In this work, we explore the hypothesis that human resource-efficient planning may arise from representing the world as predictably structured. Building on the metaphor of concepts as programs, we propose that cognitive maps can take the form of generative programs that exploit predictability and redundancy, in contrast to directly encoding spatial layouts. We use a behavioral experiment to show that people who navigate in structured spaces rely on modular planning strategies that align with programmatic map representations. We describe a computational model that predicts human behavior in a variety of structured scenarios. This model infers a small distribution over possible programmatic cognitive maps conditioned on human prior knowledge of the world, and uses this distribution to generate resource-efficient plans. Our models leverages a Large Language Model as an embedding of human priors, implicitly learned through training on a vast corpus of human data. Our model demonstrates improved computational efficiency, requires drastically less memory, and outperforms unstructured planning algorithms with cognitive constraints at predicting human behavior, suggesting that human planning strategies rely on programmatic cognitive maps.","sentences":["Making sense of the world and acting in it relies on building simplified mental representations that abstract away aspects of reality.","This principle of cognitive mapping is universal to agents with limited resources.","Living organisms, people, and algorithms all face the problem of forming functional representations of their world under various computing constraints.","In this work, we explore the hypothesis that human resource-efficient planning may arise from representing the world as predictably structured.","Building on the metaphor of concepts as programs, we propose that cognitive maps can take the form of generative programs that exploit predictability and redundancy, in contrast to directly encoding spatial layouts.","We use a behavioral experiment to show that people who navigate in structured spaces rely on modular planning strategies that align with programmatic map representations.","We describe a computational model that predicts human behavior in a variety of structured scenarios.","This model infers a small distribution over possible programmatic cognitive maps conditioned on human prior knowledge of the world, and uses this distribution to generate resource-efficient plans.","Our models leverages a Large Language Model as an embedding of human priors, implicitly learned through training on a vast corpus of human data.","Our model demonstrates improved computational efficiency, requires drastically less memory, and outperforms unstructured planning algorithms with cognitive constraints at predicting human behavior, suggesting that human planning strategies rely on programmatic cognitive maps."],"url":"http://arxiv.org/abs/2504.20628v1"}
{"created":"2025-04-29 10:52:07","title":"DiffusionRIR: Room Impulse Response Interpolation using Diffusion Models","abstract":"Room Impulse Responses (RIRs) characterize acoustic environments and are crucial in multiple audio signal processing tasks. High-quality RIR estimates drive applications such as virtual microphones, sound source localization, augmented reality, and data augmentation. However, obtaining RIR measurements with high spatial resolution is resource-intensive, making it impractical for large spaces or when dense sampling is required. This research addresses the challenge of estimating RIRs at unmeasured locations within a room using Denoising Diffusion Probabilistic Models (DDPM). Our method leverages the analogy between RIR matrices and image inpainting, transforming RIR data into a format suitable for diffusion-based reconstruction.   Using simulated RIR data based on the image method, we demonstrate our approach's effectiveness on microphone arrays of different curvatures, from linear to semi-circular. Our method successfully reconstructs missing RIRs, even in large gaps between microphones. Under these conditions, it achieves accurate reconstruction, significantly outperforming baseline Spline Cubic Interpolation in terms of Normalized Mean Square Error and Cosine Distance between actual and interpolated RIRs.   This research highlights the potential of using generative models for effective RIR interpolation, paving the way for generating additional data from limited real-world measurements.","sentences":["Room Impulse Responses (RIRs) characterize acoustic environments and are crucial in multiple audio signal processing tasks.","High-quality RIR estimates drive applications such as virtual microphones, sound source localization, augmented reality, and data augmentation.","However, obtaining RIR measurements with high spatial resolution is resource-intensive, making it impractical for large spaces or when dense sampling is required.","This research addresses the challenge of estimating RIRs at unmeasured locations within a room using Denoising Diffusion Probabilistic Models (DDPM).","Our method leverages the analogy between RIR matrices and image inpainting, transforming RIR data into a format suitable for diffusion-based reconstruction.   ","Using simulated RIR data based on the image method, we demonstrate our approach's effectiveness on microphone arrays of different curvatures, from linear to semi-circular.","Our method successfully reconstructs missing RIRs, even in large gaps between microphones.","Under these conditions, it achieves accurate reconstruction, significantly outperforming baseline Spline Cubic Interpolation in terms of Normalized Mean Square Error and Cosine Distance between actual and interpolated RIRs.   ","This research highlights the potential of using generative models for effective RIR interpolation, paving the way for generating additional data from limited real-world measurements."],"url":"http://arxiv.org/abs/2504.20625v1"}
{"created":"2025-04-29 10:40:19","title":"Breaking the Barrier of Self-Concordant Barriers: Faster Interior Point Methods for M-Matrices","abstract":"We study two fundamental optimization problems: (1) scaling a symmetric positive definite matrix by a positive diagonal matrix so that the resulting matrix has row and column sums equal to 1; and (2) minimizing a quadratic function subject to hard non-negativity constraints. Both problems lend themselves to efficient algorithms based on interior point methods (IPMs). For general instances, standard self-concordance theory places a limit on the iteration complexity of these methods at $\\widetilde{O}\\left(n^{1/2}\\right)$, where $n$ denotes the matrix dimension. We show via an amortized analysis that, when the input matrix is an M-matrix, an IPM with adaptive step sizes solves both problems in only $\\widetilde{O}\\left(n^{1/3}\\right)$ iterations. As a corollary, using fast Laplacian solvers, we obtain an $\\ell_{2}$ flow diffusion algorithm with depth $\\widetilde{O}\\left(n^{1/3}\\right)$ and work $\\widetilde{O}$$\\left(n^{1/3}\\cdot\\text{nnz}\\right)$. This result marks a significant instance in which a standard log-barrier IPM permits provably fewer than $\\Theta\\left(n^{1/2}\\right)$ iterations.","sentences":["We study two fundamental optimization problems: (1) scaling a symmetric positive definite matrix by a positive diagonal matrix so that the resulting matrix has row and column sums equal to 1; and (2) minimizing a quadratic function subject to hard non-negativity constraints.","Both problems lend themselves to efficient algorithms based on interior point methods (IPMs).","For general instances, standard self-concordance theory places a limit on the iteration complexity of these methods at $\\widetilde{O}\\left(n^{1/2}\\right)$, where $n$ denotes the matrix dimension.","We show via an amortized analysis that, when the input matrix is an M-matrix, an IPM with adaptive step sizes solves both problems in only $\\widetilde{O}\\left(n^{1/3}\\right)$ iterations.","As a corollary, using fast Laplacian solvers, we obtain an $\\ell_{2}$ flow diffusion algorithm with depth $\\widetilde{O}\\left(n^{1/3}\\right)$ and work $\\widetilde{O}$$\\left(n^{1/3}\\cdot\\text{nnz}\\right)$.","This result marks a significant instance in which a standard log-barrier IPM permits provably fewer than $\\Theta\\left(n^{1/2}\\right)$ iterations."],"url":"http://arxiv.org/abs/2504.20619v1"}
{"created":"2025-04-29 10:29:00","title":"Multi-Sensor Fusion for Quadruped Robot State Estimation using Invariant Filtering and Smoothing","abstract":"This letter introduces two multi-sensor state estimation frameworks for quadruped robots, built on the Invariant Extended Kalman Filter (InEKF) and Invariant Smoother (IS). The proposed methods, named E-InEKF and E-IS, fuse kinematics, IMU, LiDAR, and GPS data to mitigate position drift, particularly along the z-axis, a common issue in proprioceptive-based approaches. We derived observation models that satisfy group-affine properties to integrate LiDAR odometry and GPS into InEKF and IS. LiDAR odometry is incorporated using Iterative Closest Point (ICP) registration on a parallel thread, preserving the computational efficiency of proprioceptive-based state estimation. We evaluate E-InEKF and E-IS with and without exteroceptive sensors, benchmarking them against LiDAR-based odometry methods in indoor and outdoor experiments using the KAIST HOUND2 robot. Our methods achieve lower Relative Position Errors (RPE) and significantly reduce Absolute Trajectory Error (ATE), with improvements of up to 28% indoors and 40% outdoors compared to LIO-SAM and FAST-LIO2. Additionally, we compare E-InEKF and E-IS in terms of computational efficiency and accuracy.","sentences":["This letter introduces two multi-sensor state estimation frameworks for quadruped robots, built on the Invariant Extended Kalman Filter (InEKF) and Invariant Smoother (IS).","The proposed methods, named E-InEKF and E-IS, fuse kinematics, IMU, LiDAR, and GPS data to mitigate position drift, particularly along the z-axis, a common issue in proprioceptive-based approaches.","We derived observation models that satisfy group-affine properties to integrate LiDAR odometry and GPS into InEKF and IS.","LiDAR odometry is incorporated using Iterative Closest Point (ICP) registration on a parallel thread, preserving the computational efficiency of proprioceptive-based state estimation.","We evaluate E-InEKF and E-IS with and without exteroceptive sensors, benchmarking them against LiDAR-based odometry methods in indoor and outdoor experiments using the KAIST HOUND2 robot.","Our methods achieve lower Relative Position Errors (RPE) and significantly reduce Absolute Trajectory Error (ATE), with improvements of up to 28% indoors and 40% outdoors compared to LIO-SAM and FAST-LIO2.","Additionally, we compare E-InEKF and E-IS in terms of computational efficiency and accuracy."],"url":"http://arxiv.org/abs/2504.20615v1"}
{"created":"2025-04-29 10:21:40","title":"Information Retrieval in the Age of Generative AI: The RGB Model","abstract":"The advent of Large Language Models (LLMs) and generative AI is fundamentally transforming information retrieval and processing on the Internet, bringing both great potential and significant concerns regarding content authenticity and reliability. This paper presents a novel quantitative approach to shed light on the complex information dynamics arising from the growing use of generative AI tools. Despite their significant impact on the digital ecosystem, these dynamics remain largely uncharted and poorly understood. We propose a stochastic model to characterize the generation, indexing, and dissemination of information in response to new topics. This scenario particularly challenges current LLMs, which often rely on real-time Retrieval-Augmented Generation (RAG) techniques to overcome their static knowledge limitations. Our findings suggest that the rapid pace of generative AI adoption, combined with increasing user reliance, can outpace human verification, escalating the risk of inaccurate information proliferation across digital resources. An in-depth analysis of Stack Exchange data confirms that high-quality answers inevitably require substantial time and human effort to emerge. This underscores the considerable risks associated with generating persuasive text in response to new questions and highlights the critical need for responsible development and deployment of future generative AI tools.","sentences":["The advent of Large Language Models (LLMs) and generative AI is fundamentally transforming information retrieval and processing on the Internet, bringing both great potential and significant concerns regarding content authenticity and reliability.","This paper presents a novel quantitative approach to shed light on the complex information dynamics arising from the growing use of generative AI tools.","Despite their significant impact on the digital ecosystem, these dynamics remain largely uncharted and poorly understood.","We propose a stochastic model to characterize the generation, indexing, and dissemination of information in response to new topics.","This scenario particularly challenges current LLMs, which often rely on real-time Retrieval-Augmented Generation (RAG) techniques to overcome their static knowledge limitations.","Our findings suggest that the rapid pace of generative AI adoption, combined with increasing user reliance, can outpace human verification, escalating the risk of inaccurate information proliferation across digital resources.","An in-depth analysis of Stack Exchange data confirms that high-quality answers inevitably require substantial time and human effort to emerge.","This underscores the considerable risks associated with generating persuasive text in response to new questions and highlights the critical need for responsible development and deployment of future generative AI tools."],"url":"http://arxiv.org/abs/2504.20610v1"}
{"created":"2025-04-29 10:19:05","title":"WenyanGPT: A Large Language Model for Classical Chinese Tasks","abstract":"Classical Chinese, as the core carrier of Chinese culture, plays a crucial role in the inheritance and study of ancient literature. However, existing natural language processing models primarily optimize for Modern Chinese, resulting in inadequate performance on Classical Chinese. This paper presents a comprehensive solution for Classical Chinese language processing. By continuing pre-training and instruction fine-tuning on the LLaMA3-8B-Chinese model, we construct a large language model, WenyanGPT, which is specifically designed for Classical Chinese tasks. Additionally, we develop an evaluation benchmark dataset, WenyanBENCH. Experimental results on WenyanBENCH demonstrate that WenyanGPT significantly outperforms current advanced LLMs in various Classical Chinese tasks. We make the model's training data, instruction fine-tuning data\\footnote, and evaluation benchmark dataset publicly available to promote further research and development in the field of Classical Chinese processing.","sentences":["Classical Chinese, as the core carrier of Chinese culture, plays a crucial role in the inheritance and study of ancient literature.","However, existing natural language processing models primarily optimize for Modern Chinese, resulting in inadequate performance on Classical Chinese.","This paper presents a comprehensive solution for Classical Chinese language processing.","By continuing pre-training and instruction fine-tuning on the LLaMA3-8B-Chinese model, we construct a large language model, WenyanGPT, which is specifically designed for Classical Chinese tasks.","Additionally, we develop an evaluation benchmark dataset, WenyanBENCH.","Experimental results on WenyanBENCH demonstrate that WenyanGPT significantly outperforms current advanced LLMs in various Classical Chinese tasks.","We make the model's training data, instruction fine-tuning data\\footnote, and evaluation benchmark dataset publicly available to promote further research and development in the field of Classical Chinese processing."],"url":"http://arxiv.org/abs/2504.20609v1"}
{"created":"2025-04-29 09:56:29","title":"PartHOI: Part-based Hand-Object Interaction Transfer via Generalized Cylinders","abstract":"Learning-based methods to understand and model hand-object interactions (HOI) require a large amount of high-quality HOI data. One way to create HOI data is to transfer hand poses from a source object to another based on the objects' geometry. However, current methods for transferring hand poses between objects rely on shape matching, limiting the ability to transfer poses across different categories due to differences in their shapes and sizes. We observe that HOI often involves specific semantic parts of objects, which often have more consistent shapes across categories. In addition, constructing size-invariant correspondences between these parts is important for cross-category transfer. Based on these insights, we introduce a novel method PartHOI for part-based HOI transfer. Using a generalized cylinder representation to parameterize an object parts' geometry, PartHOI establishes a robust geometric correspondence between object parts, and enables the transfer of contact points. Given the transferred points, we optimize a hand pose to fit the target object well. Qualitative and quantitative results demonstrate that our method can generalize HOI transfers well even for cross-category objects, and produce high-fidelity results that are superior to the existing methods.","sentences":["Learning-based methods to understand and model hand-object interactions (HOI) require a large amount of high-quality HOI data.","One way to create HOI data is to transfer hand poses from a source object to another based on the objects' geometry.","However, current methods for transferring hand poses between objects rely on shape matching, limiting the ability to transfer poses across different categories due to differences in their shapes and sizes.","We observe that HOI often involves specific semantic parts of objects, which often have more consistent shapes across categories.","In addition, constructing size-invariant correspondences between these parts is important for cross-category transfer.","Based on these insights, we introduce a novel method PartHOI for part-based HOI transfer.","Using a generalized cylinder representation to parameterize an object parts' geometry, PartHOI establishes a robust geometric correspondence between object parts, and enables the transfer of contact points.","Given the transferred points, we optimize a hand pose to fit the target object well.","Qualitative and quantitative results demonstrate that our method can generalize HOI transfers well even for cross-category objects, and produce high-fidelity results that are superior to the existing methods."],"url":"http://arxiv.org/abs/2504.20599v1"}
{"created":"2025-04-29 09:56:23","title":"Natural Language Processing tools for Pharmaceutical Manufacturing Information Extraction from Patents Natural Language Processing (NLP) tools for Pharmaceutical Manufacturing Information Extraction from Patents","abstract":"Abundant and diverse data on medicines manufacturing and other lifecycle components has been made easily accessible in the last decades. However, a significant proportion of this information is characterised by not being tabulated and usable for machine learning purposes. Thus, natural language processing tools have been used to build databases in domains such as biomedical and chemical to address this limitation. This has allowed the development of artificial intelligence applications, which have improved drug discovery and treatments. In the pharmaceutical manufacturing context, some initiatives and datasets for primary processing can be found, but the manufacturing of drug products is an area which is still lacking, to the best of our knowledge. This works aims to explore and adapt NLP tools used in other domains to extract information on both primary and secondary manufacturing, employing patents as the main source of data. Thus, two independent, but complementary, models were developed comprising a method to select fragments of text that contain manufacturing data, and a named entity recognition system that enables extracting information on operations, materials, and conditions of a process. For the first model, the identification of relevant sections was achieved using an unsupervised approach combining Latent Dirichlet Allocation and k-Means clustering. The performance of this model measured as a Cohen's kappa between model output and manual revision was higher than 90%. NER model consisted of a deep neural network, and an f1-score micro average of 84.2% was obtained which is comparable to other works. Some considerations for these tools to be used in data extraction are discussed throughout this document.","sentences":["Abundant and diverse data on medicines manufacturing and other lifecycle components has been made easily accessible in the last decades.","However, a significant proportion of this information is characterised by not being tabulated and usable for machine learning purposes.","Thus, natural language processing tools have been used to build databases in domains such as biomedical and chemical to address this limitation.","This has allowed the development of artificial intelligence applications, which have improved drug discovery and treatments.","In the pharmaceutical manufacturing context, some initiatives and datasets for primary processing can be found, but the manufacturing of drug products is an area which is still lacking, to the best of our knowledge.","This works aims to explore and adapt NLP tools used in other domains to extract information on both primary and secondary manufacturing, employing patents as the main source of data.","Thus, two independent, but complementary, models were developed comprising a method to select fragments of text that contain manufacturing data, and a named entity recognition system that enables extracting information on operations, materials, and conditions of a process.","For the first model, the identification of relevant sections was achieved using an unsupervised approach combining Latent Dirichlet Allocation and k-Means clustering.","The performance of this model measured as a Cohen's kappa between model output and manual revision was higher than 90%.","NER model consisted of a deep neural network, and an f1-score micro average of 84.2% was obtained which is comparable to other works.","Some considerations for these tools to be used in data extraction are discussed throughout this document."],"url":"http://arxiv.org/abs/2504.20598v1"}
{"created":"2025-04-29 09:49:28","title":"ReasonIR: Training Retrievers for Reasoning Tasks","abstract":"We present ReasonIR-8B, the first retriever specifically trained for general reasoning tasks. Existing retrievers have shown limited gains on reasoning tasks, in part because existing training datasets focus on short factual queries tied to documents that straightforwardly answer them. We develop a synthetic data generation pipeline that, for each document, our pipeline creates a challenging and relevant query, along with a plausibly related but ultimately unhelpful hard negative. By training on a mixture of our synthetic data and existing public data, ReasonIR-8B achieves a new state-of-the-art of 29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a widely-used reasoning-intensive information retrieval (IR) benchmark. When applied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4% and 22.6% respectively, relative to the closed-book baseline, outperforming other retrievers and search engines. In addition, ReasonIR-8B uses test-time compute more effectively: on BRIGHT, its performance consistently increases with longer and more information-rich rewritten queries; it continues to outperform other retrievers when combined with an LLM reranker. Our training recipe is general and can be easily extended to future LLMs; to this end, we open-source our code, data, and model.","sentences":["We present ReasonIR-8B, the first retriever specifically trained for general reasoning tasks.","Existing retrievers have shown limited gains on reasoning tasks, in part because existing training datasets focus on short factual queries tied to documents that straightforwardly answer them.","We develop a synthetic data generation pipeline that, for each document, our pipeline creates a challenging and relevant query, along with a plausibly related but ultimately unhelpful hard negative.","By training on a mixture of our synthetic data and existing public data, ReasonIR-8B achieves a new state-of-the-art of 29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a widely-used reasoning-intensive information retrieval (IR) benchmark.","When applied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4% and 22.6% respectively, relative to the closed-book baseline, outperforming other retrievers and search engines.","In addition, ReasonIR-8B uses test-time compute more effectively: on BRIGHT, its performance consistently increases with longer and more information-rich rewritten queries; it continues to outperform other retrievers when combined with an LLM reranker.","Our training recipe is general and can be easily extended to future LLMs; to this end, we open-source our code, data, and model."],"url":"http://arxiv.org/abs/2504.20595v1"}
{"created":"2025-04-29 09:33:56","title":"Representation Learning Preserving Ignorability and Covariate Matching for Treatment Effects","abstract":"Estimating treatment effects from observational data is challenging due to two main reasons: (a) hidden confounding, and (b) covariate mismatch (control and treatment groups not having identical distributions). Long lines of works exist that address only either of these issues. To address the former, conventional techniques that require detailed knowledge in the form of causal graphs have been proposed. For the latter, covariate matching and importance weighting methods have been used. Recently, there has been progress in combining testable independencies with partial side information for tackling hidden confounding. A common framework to address both hidden confounding and selection bias is missing. We propose neural architectures that aim to learn a representation of pre-treatment covariates that is a valid adjustment and also satisfies covariate matching constraints. We combine two different neural architectures: one based on gradient matching across domains created by subsampling a suitable anchor variable that assumes causal side information, followed by the other, a covariate matching transformation. We prove that approximately invariant representations yield approximate valid adjustment sets which would enable an interval around the true causal effect. In contrast to usual sensitivity analysis, where an unknown nuisance parameter is varied, we have a testable approximation yielding a bound on the effect estimate. We also outperform various baselines with respect to ATE and PEHE errors on causal benchmarks that include IHDP, Jobs, Cattaneo, and an image-based Crowd Management dataset.","sentences":["Estimating treatment effects from observational data is challenging due to two main reasons: (a) hidden confounding, and (b) covariate mismatch (control and treatment groups not having identical distributions).","Long lines of works exist that address only either of these issues.","To address the former, conventional techniques that require detailed knowledge in the form of causal graphs have been proposed.","For the latter, covariate matching and importance weighting methods have been used.","Recently, there has been progress in combining testable independencies with partial side information for tackling hidden confounding.","A common framework to address both hidden confounding and selection bias is missing.","We propose neural architectures that aim to learn a representation of pre-treatment covariates that is a valid adjustment and also satisfies covariate matching constraints.","We combine two different neural architectures: one based on gradient matching across domains created by subsampling a suitable anchor variable that assumes causal side information, followed by the other, a covariate matching transformation.","We prove that approximately invariant representations yield approximate valid adjustment sets which would enable an interval around the true causal effect.","In contrast to usual sensitivity analysis, where an unknown nuisance parameter is varied, we have a testable approximation yielding a bound on the effect estimate.","We also outperform various baselines with respect to ATE and PEHE errors on causal benchmarks that include IHDP, Jobs, Cattaneo, and an image-based Crowd Management dataset."],"url":"http://arxiv.org/abs/2504.20579v1"}
{"created":"2025-04-29 09:24:30","title":"Reinforcement Learning for Reasoning in Large Language Models with One Training Example","abstract":"We show that reinforcement learning with verifiable reward using one training example (1-shot RLVR) is effective in incentivizing the math reasoning capabilities of large language models (LLMs). Applying RLVR to the base model Qwen2.5-Math-1.5B, we identify a single example that elevates model performance on MATH500 from 36.0% to 73.6%, and improves the average performance across six common mathematical reasoning benchmarks from 17.6% to 35.7%. This result matches the performance obtained using the 1.2k DeepScaleR subset (MATH500: 73.6%, average: 35.9%), which includes the aforementioned example. Similar substantial improvements are observed across various models (Qwen2.5-Math-7B, Llama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and PPO), and different math examples (many of which yield approximately 30% or greater improvement on MATH500 when employed as a single training example). In addition, we identify some interesting phenomena during 1-shot RLVR, including cross-domain generalization, increased frequency of self-reflection, and sustained test performance improvement even after the training accuracy has saturated, a phenomenon we term post-saturation generalization. Moreover, we verify that the effectiveness of 1-shot RLVR primarily arises from the policy gradient loss, distinguishing it from the \"grokking\" phenomenon. We also show the critical role of promoting exploration (e.g., by adding entropy loss with an appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe that applying entropy loss alone, without any outcome reward, significantly enhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%. These findings can inspire future work on RLVR data efficiency and encourage a re-examination of both recent progress and the underlying mechanisms in RLVR. Our code, model, and data are open source at https://github.com/ypwang61/One-Shot-RLVR","sentences":["We show that reinforcement learning with verifiable reward using one training example (1-shot RLVR) is effective in incentivizing the math reasoning capabilities of large language models (LLMs).","Applying RLVR to the base model Qwen2.5-Math-1.5B, we identify a single example that elevates model performance on MATH500 from 36.0% to 73.6%, and improves the average performance across six common mathematical reasoning benchmarks from 17.6% to 35.7%.","This result matches the performance obtained using the 1.2k DeepScaleR subset (MATH500: 73.6%, average: 35.9%), which includes the aforementioned example.","Similar substantial improvements are observed across various models (Qwen2.5-Math-7B, Llama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and PPO), and different math examples (many of which yield approximately 30% or greater improvement on MATH500 when employed as a single training example).","In addition, we identify some interesting phenomena during 1-shot RLVR, including cross-domain generalization, increased frequency of self-reflection, and sustained test performance improvement even after the training accuracy has saturated, a phenomenon we term post-saturation generalization.","Moreover, we verify that the effectiveness of 1-shot RLVR primarily arises from the policy gradient loss, distinguishing it from the \"grokking\" phenomenon.","We also show the critical role of promoting exploration (e.g., by adding entropy loss with an appropriate coefficient) in 1-shot RLVR training.","As a bonus, we observe that applying entropy loss alone, without any outcome reward, significantly enhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%.","These findings can inspire future work on RLVR data efficiency and encourage a re-examination of both recent progress and the underlying mechanisms in RLVR.","Our code, model, and data are open source at https://github.com/ypwang61/One-Shot-RLVR"],"url":"http://arxiv.org/abs/2504.20571v1"}
{"created":"2025-04-29 09:23:19","title":"ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models","abstract":"Parameter-efficient fine-tuning (PEFT) has emerged as a practical solution for adapting large language models (LLMs) to custom datasets with significantly reduced computational cost. When carrying out PEFT under collaborative learning scenarios (e.g., federated learning), it is often required to exchange model updates (or gradients) across parties. These gradients, even with limited dimensions, can cause severe breach of data privacy. Recent works have shown that both contextual prefixes and personally identifiable information (PII) can be exposed through gradients. However, \\emph{simultaneously} and \\emph{accurately} recovering both components from the same training instance remains infeasible due to the following challenges: 1) limited number of PEFT parameters; 2) high-dimensional token spaces; and 3) large batch sizes. We propose ReCIT, a novel privacy attack that addresses all challenges, and achieves recovery of \\emph{full} private data from PEFT gradients with high fidelity. Specifically, ReCIT proposes to enhance the memorization capability of the pre-trained model through malicious fine-tuning with Personal Notes; ReCIT also proposes a novel filter-based token extraction technique and a token pairing mechanism, to accurately reconstruct tokens from the training sequences with large batch sizes. Extensive evaluations show that ReCIT consistently outperforms state-of-the-art gradient inversion and memorization-based attacks across different PEFT paradigms. It achieves up to 10$\\times$ higher PII recovery rates and remains effective across varying batch sizes, especially in settings where prefix reconstruction is intractable for conventional approaches. These findings highlight an urgent need to reassess the privacy guarantees of PEFT, especially in decentralized or shared training environments.","sentences":["Parameter-efficient fine-tuning (PEFT) has emerged as a practical solution for adapting large language models (LLMs) to custom datasets with significantly reduced computational cost.","When carrying out PEFT under collaborative learning scenarios (e.g., federated learning), it is often required to exchange model updates (or gradients) across parties.","These gradients, even with limited dimensions, can cause severe breach of data privacy.","Recent works have shown that both contextual prefixes and personally identifiable information (PII) can be exposed through gradients.","However, \\emph{simultaneously} and \\emph{accurately} recovering both components from the same training instance remains infeasible due to the following challenges: 1) limited number of PEFT parameters; 2) high-dimensional token spaces; and 3) large batch sizes.","We propose ReCIT, a novel privacy attack that addresses all challenges, and achieves recovery of \\emph{full} private data from PEFT gradients with high fidelity.","Specifically, ReCIT proposes to enhance the memorization capability of the pre-trained model through malicious fine-tuning with Personal Notes; ReCIT also proposes a novel filter-based token extraction technique and a token pairing mechanism, to accurately reconstruct tokens from the training sequences with large batch sizes.","Extensive evaluations show that ReCIT consistently outperforms state-of-the-art gradient inversion and memorization-based attacks across different PEFT paradigms.","It achieves up to 10$\\times$ higher PII recovery rates and remains effective across varying batch sizes, especially in settings where prefix reconstruction is intractable for conventional approaches.","These findings highlight an urgent need to reassess the privacy guarantees of PEFT, especially in decentralized or shared training environments."],"url":"http://arxiv.org/abs/2504.20570v1"}
{"created":"2025-04-29 09:13:00","title":"Inclusive Training Separation and Implicit Knowledge Interaction for Balanced Online Class-Incremental Learning","abstract":"Online class-incremental learning (OCIL) focuses on gradually learning new classes (called plasticity) from a stream of data in a single-pass, while concurrently preserving knowledge of previously learned classes (called stability). The primary challenge in OCIL lies in maintaining a good balance between the knowledge of old and new classes within the continually updated model. Most existing methods rely on explicit knowledge interaction through experience replay, and often employ exclusive training separation to address bias problems. Nevertheless, it still remains a big challenge to achieve a well-balanced learner, as these methods often exhibit either reduced plasticity or limited stability due to difficulties in continually integrating knowledge in the OCIL setting. In this paper, we propose a novel replay-based method, called Balanced Online Incremental Learning (BOIL), which can achieve both high plasticity and stability, thus ensuring more balanced performance in OCIL. Our BOIL method proposes an inclusive training separation strategy using dual classifiers so that knowledge from both old and new classes can effectively be integrated into the model, while introducing implicit approaches for transferring knowledge across the two classifiers. Extensive experimental evaluations over three widely-used OCIL benchmark datasets demonstrate the superiority of BOIL, showing more balanced yet better performance compared to state-of-the-art replay-based OCIL methods.","sentences":["Online class-incremental learning (OCIL) focuses on gradually learning new classes (called plasticity) from a stream of data in a single-pass, while concurrently preserving knowledge of previously learned classes (called stability).","The primary challenge in OCIL lies in maintaining a good balance between the knowledge of old and new classes within the continually updated model.","Most existing methods rely on explicit knowledge interaction through experience replay, and often employ exclusive training separation to address bias problems.","Nevertheless, it still remains a big challenge to achieve a well-balanced learner, as these methods often exhibit either reduced plasticity or limited stability due to difficulties in continually integrating knowledge in the OCIL setting.","In this paper, we propose a novel replay-based method, called Balanced Online Incremental Learning (BOIL), which can achieve both high plasticity and stability, thus ensuring more balanced performance in OCIL.","Our BOIL method proposes an inclusive training separation strategy using dual classifiers so that knowledge from both old and new classes can effectively be integrated into the model, while introducing implicit approaches for transferring knowledge across the two classifiers.","Extensive experimental evaluations over three widely-used OCIL benchmark datasets demonstrate the superiority of BOIL, showing more balanced yet better performance compared to state-of-the-art replay-based OCIL methods."],"url":"http://arxiv.org/abs/2504.20566v1"}
{"created":"2025-04-29 09:04:22","title":"Generate more than one child in your co-evolutionary semi-supervised learning GAN","abstract":"Generative Adversarial Networks (GANs) are very useful methods to address semi-supervised learning (SSL) datasets, thanks to their ability to generate samples similar to real data. This approach, called SSL-GAN has attracted many researchers in the last decade. Evolutionary algorithms have been used to guide the evolution and training of SSL-GANs with great success. In particular, several co-evolutionary approaches have been applied where the two networks of a GAN (the generator and the discriminator) are evolved in separate populations. The co-evolutionary approaches published to date assume some spatial structure of the populations, based on the ideas of cellular evolutionary algorithms. They also create one single individual per generation and follow a generational replacement strategy in the evolution. In this paper, we re-consider those algorithmic design decisions and propose a new co-evolutionary approach, called Co-evolutionary Elitist SSL-GAN (CE-SSLGAN), with panmictic population, elitist replacement, and more than one individual in the offspring. We evaluate the performance of our proposed method using three standard benchmark datasets. The results show that creating more than one offspring per population and using elitism improves the results in comparison with a classical SSL-GAN.","sentences":["Generative Adversarial Networks (GANs) are very useful methods to address semi-supervised learning (SSL) datasets, thanks to their ability to generate samples similar to real data.","This approach, called SSL-GAN has attracted many researchers in the last decade.","Evolutionary algorithms have been used to guide the evolution and training of SSL-GANs with great success.","In particular, several co-evolutionary approaches have been applied where the two networks of a GAN (the generator and the discriminator) are evolved in separate populations.","The co-evolutionary approaches published to date assume some spatial structure of the populations, based on the ideas of cellular evolutionary algorithms.","They also create one single individual per generation and follow a generational replacement strategy in the evolution.","In this paper, we re-consider those algorithmic design decisions and propose a new co-evolutionary approach, called Co-evolutionary Elitist SSL-GAN (CE-SSLGAN), with panmictic population, elitist replacement, and more than one individual in the offspring.","We evaluate the performance of our proposed method using three standard benchmark datasets.","The results show that creating more than one offspring per population and using elitism improves the results in comparison with a classical SSL-GAN."],"url":"http://arxiv.org/abs/2504.20560v1"}
{"created":"2025-04-29 08:49:38","title":"Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for Electronic Health Records","abstract":"The lack of standardized evaluation benchmarks in the medical domain for text inputs can be a barrier to widely adopting and leveraging the potential of natural language models for health-related downstream tasks. This paper revisited an openly available MIMIC-IV benchmark for electronic health records (EHRs) to address this issue. First, we integrate the MIMIC-IV data within the Hugging Face datasets library to allow an easy share and use of this collection. Second, we investigate the application of templates to convert EHR tabular data to text. Experiments using fine-tuned and zero-shot LLMs on the mortality of patients task show that fine-tuned text-based models are competitive against robust tabular classifiers. In contrast, zero-shot LLMs struggle to leverage EHR representations. This study underlines the potential of text-based approaches in the medical field and highlights areas for further improvement.","sentences":["The lack of standardized evaluation benchmarks in the medical domain for text inputs can be a barrier to widely adopting and leveraging the potential of natural language models for health-related downstream tasks.","This paper revisited an openly available MIMIC-IV benchmark for electronic health records (EHRs) to address this issue.","First, we integrate the MIMIC-IV data within the Hugging Face datasets library to allow an easy share and use of this collection.","Second, we investigate the application of templates to convert EHR tabular data to text.","Experiments using fine-tuned and zero-shot LLMs on the mortality of patients task show that fine-tuned text-based models are competitive against robust tabular classifiers.","In contrast, zero-shot LLMs struggle to leverage EHR representations.","This study underlines the potential of text-based approaches in the medical field and highlights areas for further improvement."],"url":"http://arxiv.org/abs/2504.20547v1"}
{"created":"2025-04-29 08:42:01","title":"Efficient patient-centric EMR sharing block tree","abstract":"Flexible sharing of electronic medical records (EMRs) is an urgent need in healthcare, as fragmented storage creates EMR management complexity for both practitioners and patients. Blockchain has emerged as a promising solution to address the limitations of centralized EMR systems regarding interoperability, data ownership, and trust concerns. Whilst its healthcare implementation continues to face scalability challenges, particularly in uploading lag time as EMR volumes increase. In this paper, we describe the design of a novel blockchain-based data structure, MedBlockTree, which aims to solve the scalability issue in blockchain-based EMR systems, particularly low block throughput and patient awareness. MedBlockTree leverages a chameleon hash function to generate collision blocks for existing patients and expand a single chain into a growing block tree with $n$ branches that are capable of processing $n$ new blocks in a single consensus round. We also introduce the EnhancedPro consensus algorithm to manage multiple branches and maintain network consistency. Our comprehensive simulation evaluates performance across four dimensions: branch number, worker number, collision rate, and network latency. Comparative analysis against a traditional blockchain-based EMR system demonstrates outstanding throughput improvements across all dimensions, achieving processing speeds $\\nu\\cdot n$ times faster than conventional approaches.","sentences":["Flexible sharing of electronic medical records (EMRs) is an urgent need in healthcare, as fragmented storage creates EMR management complexity for both practitioners and patients.","Blockchain has emerged as a promising solution to address the limitations of centralized EMR systems regarding interoperability, data ownership, and trust concerns.","Whilst its healthcare implementation continues to face scalability challenges, particularly in uploading lag time as EMR volumes increase.","In this paper, we describe the design of a novel blockchain-based data structure, MedBlockTree, which aims to solve the scalability issue in blockchain-based EMR systems, particularly low block throughput and patient awareness.","MedBlockTree leverages a chameleon hash function to generate collision blocks for existing patients and expand a single chain into a growing block tree with $n$ branches that are capable of processing $n$ new blocks in a single consensus round.","We also introduce the EnhancedPro consensus algorithm to manage multiple branches and maintain network consistency.","Our comprehensive simulation evaluates performance across four dimensions: branch number, worker number, collision rate, and network latency.","Comparative analysis against a traditional blockchain-based EMR system demonstrates outstanding throughput improvements across all dimensions, achieving processing speeds $\\nu\\cdot n$ times faster than conventional approaches."],"url":"http://arxiv.org/abs/2504.20544v1"}
{"created":"2025-04-29 08:38:30","title":"Digital Twin-Empowered Cooperative Autonomous Car-sharing Services: Proof-of-Concept","abstract":"This paper presents a digital twin-empowered real-time optimal delivery system specifically validated through a proof-of-concept (PoC) demonstration of a real-world autonomous car-sharing service. This study integrates real-time data from roadside units (RSUs) and connected and autonomous vehicles (CAVs) within a digital twin of a campus environment to address the dynamic challenges of urban traffic. The proposed system leverages the Age of Information (AoI) metric to optimize vehicle routing by maintaining data freshness and dynamically adapting to real-time traffic conditions. Experimental results from the PoC demonstrate a 22% improvement in delivery efficiency compared to conventional shortest-path methods that do not consider information freshness. Furthermore, digital twin-based simulation results demonstrate that this proposed system improves overall delivery efficiency by 12% and effectively reduces the peak average AoI by 23% compared to the conventional method, where each vehicle selects the shortest route without considering information freshness. This study confirms the practical feasibility of cooperative driving systems, highlighting their potential to enhance smart mobility solutions through scalable digital twin deployments in complex urban environments.","sentences":["This paper presents a digital twin-empowered real-time optimal delivery system specifically validated through a proof-of-concept (PoC) demonstration of a real-world autonomous car-sharing service.","This study integrates real-time data from roadside units (RSUs) and connected and autonomous vehicles (CAVs) within a digital twin of a campus environment to address the dynamic challenges of urban traffic.","The proposed system leverages the Age of Information (AoI) metric to optimize vehicle routing by maintaining data freshness and dynamically adapting to real-time traffic conditions.","Experimental results from the PoC demonstrate a 22% improvement in delivery efficiency compared to conventional shortest-path methods that do not consider information freshness.","Furthermore, digital twin-based simulation results demonstrate that this proposed system improves overall delivery efficiency by 12% and effectively reduces the peak average AoI by 23% compared to the conventional method, where each vehicle selects the shortest route without considering information freshness.","This study confirms the practical feasibility of cooperative driving systems, highlighting their potential to enhance smart mobility solutions through scalable digital twin deployments in complex urban environments."],"url":"http://arxiv.org/abs/2504.20542v1"}
{"created":"2025-04-29 08:36:52","title":"Autoencoder Models for Point Cloud Environmental Synthesis from WiFi Channel State Information: A Preliminary Study","abstract":"This paper introduces a deep learning framework for generating point clouds from WiFi Channel State Information data. We employ a two-stage autoencoder approach: a PointNet autoencoder with convolutional layers for point cloud generation, and a Convolutional Neural Network autoencoder to map CSI data to a matching latent space. By aligning these latent spaces, our method enables accurate environmental point cloud reconstruction from WiFi data. Experimental results validate the effectiveness of our approach, highlighting its potential for wireless sensing and environmental mapping applications.","sentences":["This paper introduces a deep learning framework for generating point clouds from WiFi Channel State Information data.","We employ a two-stage autoencoder approach: a PointNet autoencoder with convolutional layers for point cloud generation, and a Convolutional Neural Network autoencoder to map CSI data to a matching latent space.","By aligning these latent spaces, our method enables accurate environmental point cloud reconstruction from WiFi data.","Experimental results validate the effectiveness of our approach, highlighting its potential for wireless sensing and environmental mapping applications."],"url":"http://arxiv.org/abs/2504.20541v1"}
{"created":"2025-04-29 07:47:38","title":"Taxonomic Trace Links: Rethinking Traceability and its Benefits","abstract":"Traceability greatly supports knowledge-intensive tasks, e.g., coverage check and impact analysis. Despite its clear benefits, the \\emph{practical} implementation of traceability poses significant challenges, leading to a reduced focus on the creation and maintenance of trace links. We propose a new approach -- Taxonomic Trace Links (TTL) -- which rethinks traceability and its benefits. With TTL, trace links are created indirectly through a domain-specific taxonomy, a simplified version of a domain model. TTL has the potential to address key traceability challenges, such as the granularity of trace links, the lack of a common data structure among software development artifacts, and unclear responsibility for traceability. We explain how TTL addresses these challenges and perform an initial validation with practitioners. We identified six challenges associated with TTL implementation that need to be addressed. Finally, we propose a research roadmap to further develop and evaluate the technical solution of TTL. TTL appears to be particularly feasible in practice where a domain taxonomy is already established","sentences":["Traceability greatly supports knowledge-intensive tasks, e.g., coverage check and impact analysis.","Despite its clear benefits, the \\emph{practical} implementation of traceability poses significant challenges, leading to a reduced focus on the creation and maintenance of trace links.","We propose a new approach -- Taxonomic Trace Links (TTL) -- which rethinks traceability and its benefits.","With TTL, trace links are created indirectly through a domain-specific taxonomy, a simplified version of a domain model.","TTL has the potential to address key traceability challenges, such as the granularity of trace links, the lack of a common data structure among software development artifacts, and unclear responsibility for traceability.","We explain how TTL addresses these challenges and perform an initial validation with practitioners.","We identified six challenges associated with TTL implementation that need to be addressed.","Finally, we propose a research roadmap to further develop and evaluate the technical solution of TTL.","TTL appears to be particularly feasible in practice where a domain taxonomy is already established"],"url":"http://arxiv.org/abs/2504.20507v1"}
{"created":"2025-04-29 07:46:14","title":"MuRAL: A Multi-Resident Ambient Sensor Dataset Annotated with Natural Language for Activities of Daily Living","abstract":"Recent advances in Large Language Models (LLMs) have shown promising potential for human activity recognition (HAR) using ambient sensors, especially through natural language reasoning and zero-shot learning. However, existing datasets such as CASAS, ARAS, and MARBLE were not originally designed with LLMs in mind and therefore lack the contextual richness, complexity, and annotation granularity required to fully exploit LLM capabilities. In this paper, we introduce MuRAL, the first Multi-Resident Ambient sensor dataset with natural Language, comprising over 21 hours of multi-user sensor data collected from 21 sessions in a smart-home environment. MuRAL is annotated with fine-grained natural language descriptions, resident identities, and high-level activity labels, all situated in dynamic, realistic multi-resident settings. We benchmark MuRAL using state-of-the-art LLMs for three core tasks: subject assignment, action description, and activity classification. Our results demonstrate that while LLMs can provide rich semantic interpretations of ambient data, current models still face challenges in handling multi-user ambiguity and under-specified sensor contexts. We release MuRAL to support future research on LLM-powered, explainable, and socially aware activity understanding in smart environments. For access to the dataset, please reach out to us via the provided contact information. A direct link for dataset retrieval will be made available at this location in due course.","sentences":["Recent advances in Large Language Models (LLMs) have shown promising potential for human activity recognition (HAR) using ambient sensors, especially through natural language reasoning and zero-shot learning.","However, existing datasets such as CASAS, ARAS, and MARBLE were not originally designed with LLMs in mind and therefore lack the contextual richness, complexity, and annotation granularity required to fully exploit LLM capabilities.","In this paper, we introduce MuRAL, the first Multi-Resident Ambient sensor dataset with natural Language, comprising over 21 hours of multi-user sensor data collected from 21 sessions in a smart-home environment.","MuRAL is annotated with fine-grained natural language descriptions, resident identities, and high-level activity labels, all situated in dynamic, realistic multi-resident settings.","We benchmark MuRAL using state-of-the-art LLMs for three core tasks: subject assignment, action description, and activity classification.","Our results demonstrate that while LLMs can provide rich semantic interpretations of ambient data, current models still face challenges in handling multi-user ambiguity and under-specified sensor contexts.","We release MuRAL to support future research on LLM-powered, explainable, and socially aware activity understanding in smart environments.","For access to the dataset, please reach out to us via the provided contact information.","A direct link for dataset retrieval will be made available at this location in due course."],"url":"http://arxiv.org/abs/2504.20505v1"}
{"created":"2025-04-29 07:40:00","title":"UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation","abstract":"We present UniDetox, a universally applicable method designed to mitigate toxicity across various large language models (LLMs). Previous detoxification methods are typically model-specific, addressing only individual models or model families, and require careful hyperparameter tuning due to the trade-off between detoxification efficacy and language modeling performance. In contrast, UniDetox provides a detoxification technique that can be universally applied to a wide range of LLMs without the need for separate model-specific tuning. Specifically, we propose a novel and efficient dataset distillation technique for detoxification using contrastive decoding. This approach distills detoxifying representations in the form of synthetic text data, enabling universal detoxification of any LLM through fine-tuning with the distilled text. Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models, including OPT, Falcon, and LLaMA-2. Furthermore, UniDetox eliminates the need for separate hyperparameter tuning for each model, as a single hyperparameter configuration can be seamlessly applied across different models. Additionally, analysis of the detoxifying text reveals a reduction in politically biased content, providing insights into the attributes necessary for effective detoxification of LLMs.","sentences":["We present UniDetox, a universally applicable method designed to mitigate toxicity across various large language models (LLMs).","Previous detoxification methods are typically model-specific, addressing only individual models or model families, and require careful hyperparameter tuning due to the trade-off between detoxification efficacy and language modeling performance.","In contrast, UniDetox provides a detoxification technique that can be universally applied to a wide range of LLMs without the need for separate model-specific tuning.","Specifically, we propose a novel and efficient dataset distillation technique for detoxification using contrastive decoding.","This approach distills detoxifying representations in the form of synthetic text data, enabling universal detoxification of any LLM through fine-tuning with the distilled text.","Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models, including OPT, Falcon, and LLaMA-2.","Furthermore, UniDetox eliminates the need for separate hyperparameter tuning for each model, as a single hyperparameter configuration can be seamlessly applied across different models.","Additionally, analysis of the detoxifying text reveals a reduction in politically biased content, providing insights into the attributes necessary for effective detoxification of LLMs."],"url":"http://arxiv.org/abs/2504.20500v1"}
{"created":"2025-04-29 07:38:37","title":"Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection","abstract":"Single-source Domain Generalization (SDG) in object detection aims to develop a detector using only data from a source domain that can exhibit strong generalization capability when applied to unseen target domains. Existing methods are built upon CNN-based detectors and primarily improve robustness by employing carefully designed data augmentation strategies integrated with feature alignment techniques. However, data augmentation methods have inherent drawbacks; they are only effective when the augmented sample distribution approximates or covers the unseen scenarios, thus failing to enhance generalization across all unseen domains. Furthermore, while the recent Detection Transformer (DETR) has demonstrated superior generalization capability in domain adaptation tasks due to its efficient global information extraction, its potential in SDG tasks remains unexplored. To this end, we introduce a strong DETR-based detector named the Style-Adaptive Detection Transformer (SA-DETR) for SDG in object detection. Specifically, we present a domain style adapter that projects the style representation of the unseen target domain into the training domain, enabling dynamic style adaptation. Then, we propose an object-aware contrastive learning module to guide the detector in extracting domain-invariant features through contrastive learning. By using object-aware gating masks to constrain feature aggregation in both spatial and semantic dimensions, this module achieves cross-domain contrast of instance-level features, thereby enhancing generalization. Extensive experiments demonstrate the superior performance and generalization capability of SA-DETR across five different weather scenarios. Code is released at https://github.com/h751410234/SA-DETR.","sentences":["Single-source Domain Generalization (SDG) in object detection aims to develop a detector using only data from a source domain that can exhibit strong generalization capability when applied to unseen target domains.","Existing methods are built upon CNN-based detectors and primarily improve robustness by employing carefully designed data augmentation strategies integrated with feature alignment techniques.","However, data augmentation methods have inherent drawbacks; they are only effective when the augmented sample distribution approximates or covers the unseen scenarios, thus failing to enhance generalization across all unseen domains.","Furthermore, while the recent Detection Transformer (DETR) has demonstrated superior generalization capability in domain adaptation tasks due to its efficient global information extraction, its potential in SDG tasks remains unexplored.","To this end, we introduce a strong DETR-based detector named the Style-Adaptive Detection Transformer (SA-DETR) for SDG in object detection.","Specifically, we present a domain style adapter that projects the style representation of the unseen target domain into the training domain, enabling dynamic style adaptation.","Then, we propose an object-aware contrastive learning module to guide the detector in extracting domain-invariant features through contrastive learning.","By using object-aware gating masks to constrain feature aggregation in both spatial and semantic dimensions, this module achieves cross-domain contrast of instance-level features, thereby enhancing generalization.","Extensive experiments demonstrate the superior performance and generalization capability of SA-DETR across five different weather scenarios.","Code is released at https://github.com/h751410234/SA-DETR."],"url":"http://arxiv.org/abs/2504.20498v1"}
{"created":"2025-04-29 07:37:51","title":"Large-scale visual SLAM for in-the-wild videos","abstract":"Accurate and robust 3D scene reconstruction from casual, in-the-wild videos can significantly simplify robot deployment to new environments. However, reliable camera pose estimation and scene reconstruction from such unconstrained videos remains an open challenge. Existing visual-only SLAM methods perform well on benchmark datasets but struggle with real-world footage which often exhibits uncontrolled motion including rapid rotations and pure forward movements, textureless regions, and dynamic objects. We analyze the limitations of current methods and introduce a robust pipeline designed to improve 3D reconstruction from casual videos. We build upon recent deep visual odometry methods but increase robustness in several ways. Camera intrinsics are automatically recovered from the first few frames using structure-from-motion. Dynamic objects and less-constrained areas are masked with a predictive model. Additionally, we leverage monocular depth estimates to regularize bundle adjustment, mitigating errors in low-parallax situations. Finally, we integrate place recognition and loop closure to reduce long-term drift and refine both intrinsics and pose estimates through global bundle adjustment. We demonstrate large-scale contiguous 3D models from several online videos in various environments. In contrast, baseline methods typically produce locally inconsistent results at several points, producing separate segments or distorted maps. In lieu of ground-truth pose data, we evaluate map consistency, execution time and visual accuracy of re-rendered NeRF models. Our proposed system establishes a new baseline for visual reconstruction from casual uncontrolled videos found online, demonstrating more consistent reconstructions over longer sequences of in-the-wild videos than previously achieved.","sentences":["Accurate and robust 3D scene reconstruction from casual, in-the-wild videos can significantly simplify robot deployment to new environments.","However, reliable camera pose estimation and scene reconstruction from such unconstrained videos remains an open challenge.","Existing visual-only SLAM methods perform well on benchmark datasets but struggle with real-world footage which often exhibits uncontrolled motion including rapid rotations and pure forward movements, textureless regions, and dynamic objects.","We analyze the limitations of current methods and introduce a robust pipeline designed to improve 3D reconstruction from casual videos.","We build upon recent deep visual odometry methods but increase robustness in several ways.","Camera intrinsics are automatically recovered from the first few frames using structure-from-motion.","Dynamic objects and less-constrained areas are masked with a predictive model.","Additionally, we leverage monocular depth estimates to regularize bundle adjustment, mitigating errors in low-parallax situations.","Finally, we integrate place recognition and loop closure to reduce long-term drift and refine both intrinsics and pose estimates through global bundle adjustment.","We demonstrate large-scale contiguous 3D models from several online videos in various environments.","In contrast, baseline methods typically produce locally inconsistent results at several points, producing separate segments or distorted maps.","In lieu of ground-truth pose data, we evaluate map consistency, execution time and visual accuracy of re-rendered NeRF models.","Our proposed system establishes a new baseline for visual reconstruction from casual uncontrolled videos found online, demonstrating more consistent reconstructions over longer sequences of in-the-wild videos than previously achieved."],"url":"http://arxiv.org/abs/2504.20496v1"}
{"created":"2025-04-29 07:32:55","title":"Triadic Closure-Heterogeneity-Harmony GCN for Link Prediction","abstract":"Link prediction aims to estimate the likelihood of connections between pairs of nodes in complex networks, which is beneficial to many applications from friend recommendation to metabolic network reconstruction. Traditional heuristic-based methodologies in the field of complex networks typically depend on predefined assumptions about node connectivity, limiting their generalizability across diverse networks. While recent graph neural network (GNN) approaches capture global structural features effectively, they often neglect node attributes and intrinsic structural relationships between node pairs. To address this, we propose TriHetGCN, an extension of traditional Graph Convolutional Networks (GCNs) that incorporates explicit topological indicators -- triadic closure and degree heterogeneity. TriHetGCN consists of three modules: topology feature construction, graph structural representation, and connection probability prediction. The topology feature module constructs node features using shortest path distances to anchor nodes, enhancing global structure perception. The graph structural module integrates topological indicators into the GCN framework to model triadic closure and heterogeneity. The connection probability module uses deep learning to predict links. Evaluated on nine real-world datasets, from traditional networks without node attributes to large-scale networks with rich features, TriHetGCN achieves state-of-the-art performance, outperforming mainstream methods. This highlights its strong generalization across diverse network types, offering a promising framework that bridges statistical physics and graph deep learning.","sentences":["Link prediction aims to estimate the likelihood of connections between pairs of nodes in complex networks, which is beneficial to many applications from friend recommendation to metabolic network reconstruction.","Traditional heuristic-based methodologies in the field of complex networks typically depend on predefined assumptions about node connectivity, limiting their generalizability across diverse networks.","While recent graph neural network (GNN) approaches capture global structural features effectively, they often neglect node attributes and intrinsic structural relationships between node pairs.","To address this, we propose TriHetGCN, an extension of traditional Graph Convolutional Networks (GCNs) that incorporates explicit topological indicators -- triadic closure and degree heterogeneity.","TriHetGCN consists of three modules: topology feature construction, graph structural representation, and connection probability prediction.","The topology feature module constructs node features using shortest path distances to anchor nodes, enhancing global structure perception.","The graph structural module integrates topological indicators into the GCN framework to model triadic closure and heterogeneity.","The connection probability module uses deep learning to predict links.","Evaluated on nine real-world datasets, from traditional networks without node attributes to large-scale networks with rich features, TriHetGCN achieves state-of-the-art performance, outperforming mainstream methods.","This highlights its strong generalization across diverse network types, offering a promising framework that bridges statistical physics and graph deep learning."],"url":"http://arxiv.org/abs/2504.20492v1"}
{"created":"2025-04-29 07:27:54","title":"Hetu v2: A General and Scalable Deep Learning System with Hierarchical and Heterogeneous Single Program Multiple Data Annotations","abstract":"The Single Program Multiple Data (SPMD) paradigm provides a unified abstraction to annotate various parallel dimensions in distributed deep learning (DL) training. With SPMD, users can write training programs from the viewpoint of a single device, and the system will automatically deduce the tensor sharding and communication patterns. However, with the recent development in large-scale DL models, distributed training exhibits spatial and temporal workload heterogeneity, arising from both device disparities (e.g., mixed hardware, failures) and data variations (e.g., uneven sequence lengths). Such heterogeneity violates SPMD's assumption of uniform workload partitioning, which restricts its ability to express and optimize heterogeneous parallel strategies effectively.   To address this, we propose HSPMD within the Hetu v2 system to achieve general and scalable DL training. HSPMD extends SPMD's annotations to support asymmetric sharding and composes standard communication primitives for hierarchical communication, all while retaining the simplicity of a single-device declarative programming model. Leveraging HSPMD, Hetu handles spatial heterogeneity through progressive graph specialization, enabling device-specific execution logic, and addresses temporal heterogeneity via dynamic graph switching. Evaluations on heterogeneous clusters, elastic training, and mixed-length data scenarios show that HSPMD matches or outperforms specialized systems, providing a flexible and efficient solution for modern large-scale model training.","sentences":["The Single Program Multiple Data (SPMD) paradigm provides a unified abstraction to annotate various parallel dimensions in distributed deep learning (DL) training.","With SPMD, users can write training programs from the viewpoint of a single device, and the system will automatically deduce the tensor sharding and communication patterns.","However, with the recent development in large-scale DL models, distributed training exhibits spatial and temporal workload heterogeneity, arising from both device disparities (e.g., mixed hardware, failures) and data variations (e.g., uneven sequence lengths).","Such heterogeneity violates SPMD's assumption of uniform workload partitioning, which restricts its ability to express and optimize heterogeneous parallel strategies effectively.   ","To address this, we propose HSPMD within the Hetu v2 system to achieve general and scalable DL training.","HSPMD extends SPMD's annotations to support asymmetric sharding and composes standard communication primitives for hierarchical communication, all while retaining the simplicity of a single-device declarative programming model.","Leveraging HSPMD, Hetu handles spatial heterogeneity through progressive graph specialization, enabling device-specific execution logic, and addresses temporal heterogeneity via dynamic graph switching.","Evaluations on heterogeneous clusters, elastic training, and mixed-length data scenarios show that HSPMD matches or outperforms specialized systems, providing a flexible and efficient solution for modern large-scale model training."],"url":"http://arxiv.org/abs/2504.20490v1"}
{"created":"2025-04-29 07:24:25","title":"Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training","abstract":"Large language models (LLMs) exhibit remarkable multilingual capabilities despite English-dominated pre-training, attributed to cross-lingual mechanisms during pre-training. Existing methods for enhancing cross-lingual transfer remain constrained by parallel resources, suffering from limited linguistic and domain coverage. We propose Cross-lingual In-context Pre-training (CrossIC-PT), a simple and scalable approach that enhances cross-lingual transfer by leveraging semantically related bilingual texts via simple next-word prediction. We construct CrossIC-PT samples by interleaving semantic-related bilingual Wikipedia documents into a single context window. To access window size constraints, we implement a systematic segmentation policy to split long bilingual document pairs into chunks while adjusting the sliding window mechanism to preserve contextual coherence. We further extend data availability through a semantic retrieval framework to construct CrossIC-PT samples from web-crawled corpus. Experimental results demonstrate that CrossIC-PT improves multilingual performance on three models (Llama-3.1-8B, Qwen2.5-7B, and Qwen2.5-1.5B) across six target languages, yielding performance gains of 3.79%, 3.99%, and 1.95%, respectively, with additional improvements after data augmentation.","sentences":["Large language models (LLMs) exhibit remarkable multilingual capabilities despite English-dominated pre-training, attributed to cross-lingual mechanisms during pre-training.","Existing methods for enhancing cross-lingual transfer remain constrained by parallel resources, suffering from limited linguistic and domain coverage.","We propose Cross-lingual In-context Pre-training (CrossIC-PT), a simple and scalable approach that enhances cross-lingual transfer by leveraging semantically related bilingual texts via simple next-word prediction.","We construct CrossIC-PT samples by interleaving semantic-related bilingual Wikipedia documents into a single context window.","To access window size constraints, we implement a systematic segmentation policy to split long bilingual document pairs into chunks while adjusting the sliding window mechanism to preserve contextual coherence.","We further extend data availability through a semantic retrieval framework to construct CrossIC-PT samples from web-crawled corpus.","Experimental results demonstrate that CrossIC-PT improves multilingual performance on three models (Llama-3.1-8B, Qwen2.5-7B, and Qwen2.5-1.5B) across six target languages, yielding performance gains of 3.79%, 3.99%, and 1.95%, respectively, with additional improvements after data augmentation."],"url":"http://arxiv.org/abs/2504.20484v1"}
{"created":"2025-04-29 07:13:53","title":"Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction","abstract":"Large language models (LLMs) have demonstrated impressive performance and have come to dominate the field of natural language processing (NLP) across various tasks. However, due to their strong instruction-following capabilities and inability to distinguish between instructions and data content, LLMs are vulnerable to prompt injection attacks. These attacks manipulate LLMs into deviating from the original input instructions and executing maliciously injected instructions within data content, such as web documents retrieved from search engines. Existing defense methods, including prompt-engineering and fine-tuning approaches, typically instruct models to follow the original input instructions while suppressing their tendencies to execute injected instructions. However, our experiments reveal that suppressing instruction-following tendencies is challenging. Through analyzing failure cases, we observe that although LLMs tend to respond to any recognized instructions, they are aware of which specific instructions they are executing and can correctly reference them within the original prompt. Motivated by these findings, we propose a novel defense method that leverages, rather than suppresses, the instruction-following abilities of LLMs. Our approach prompts LLMs to generate responses that include both answers and their corresponding instruction references. Based on these references, we filter out answers not associated with the original input instructions. Comprehensive experiments demonstrate that our method outperforms prompt-engineering baselines and achieves performance comparable to fine-tuning methods, reducing the attack success rate (ASR) to 0 percent in some scenarios. Moreover, our approach has minimal impact on overall utility.","sentences":["Large language models (LLMs) have demonstrated impressive performance and have come to dominate the field of natural language processing (NLP) across various tasks.","However, due to their strong instruction-following capabilities and inability to distinguish between instructions and data content, LLMs are vulnerable to prompt injection attacks.","These attacks manipulate LLMs into deviating from the original input instructions and executing maliciously injected instructions within data content, such as web documents retrieved from search engines.","Existing defense methods, including prompt-engineering and fine-tuning approaches, typically instruct models to follow the original input instructions while suppressing their tendencies to execute injected instructions.","However, our experiments reveal that suppressing instruction-following tendencies is challenging.","Through analyzing failure cases, we observe that although LLMs tend to respond to any recognized instructions, they are aware of which specific instructions they are executing and can correctly reference them within the original prompt.","Motivated by these findings, we propose a novel defense method that leverages, rather than suppresses, the instruction-following abilities of LLMs.","Our approach prompts LLMs to generate responses that include both answers and their corresponding instruction references.","Based on these references, we filter out answers not associated with the original input instructions.","Comprehensive experiments demonstrate that our method outperforms prompt-engineering baselines and achieves performance comparable to fine-tuning methods, reducing the attack success rate (ASR) to 0 percent in some scenarios.","Moreover, our approach has minimal impact on overall utility."],"url":"http://arxiv.org/abs/2504.20472v1"}
{"created":"2025-04-29 07:13:28","title":"The Estimation of Continual Causal Effect for Dataset Shifting Streams","abstract":"Causal effect estimation has been widely used in marketing optimization. The framework of an uplift model followed by a constrained optimization algorithm is popular in practice. To enhance performance in the online environment, the framework needs to be improved to address the complexities caused by temporal dataset shift. This paper focuses on capturing the dataset shift from user behavior and domain distribution changing over time. We propose an Incremental Causal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle this challenge. The ICE-PKD framework includes two components: (i) a multi-treatment uplift network that eliminates confounding bias using counterfactual regression; (ii) an incremental training strategy that adapts to the temporal dataset shift by updating with the latest data and protects generalization via replay-based knowledge distillation. We also revisit the uplift modeling metrics and introduce a novel metric for more precise online evaluation in multiple treatment scenarios. Extensive experiments on both simulated and online datasets show that the proposed framework achieves better performance. The ICE-PKD framework has been deployed in the marketing system of Huaxiaozhu, a ride-hailing platform in China.","sentences":["Causal effect estimation has been widely used in marketing optimization.","The framework of an uplift model followed by a constrained optimization algorithm is popular in practice.","To enhance performance in the online environment, the framework needs to be improved to address the complexities caused by temporal dataset shift.","This paper focuses on capturing the dataset shift from user behavior and domain distribution changing over time.","We propose an Incremental Causal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle this challenge.","The ICE-PKD framework includes two components: (i) a multi-treatment uplift network that eliminates confounding bias using counterfactual regression; (ii) an incremental training strategy that adapts to the temporal dataset shift by updating with the latest data and protects generalization via replay-based knowledge distillation.","We also revisit the uplift modeling metrics and introduce a novel metric for more precise online evaluation in multiple treatment scenarios.","Extensive experiments on both simulated and online datasets show that the proposed framework achieves better performance.","The ICE-PKD framework has been deployed in the marketing system of Huaxiaozhu, a ride-hailing platform in China."],"url":"http://arxiv.org/abs/2504.20471v1"}
{"created":"2025-04-29 07:05:24","title":"Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception","abstract":"Large Vision-Language Models (LVLMs) have achieved impressive results across various cross-modal tasks. However, hallucinations, i.e., the models generating counterfactual responses, remain a challenge. Though recent studies have attempted to alleviate object perception hallucinations, they focus on the models' response generation, and overlooking the task question itself. This paper discusses the vulnerability of LVLMs in solving counterfactual presupposition questions (CPQs), where the models are prone to accept the presuppositions of counterfactual objects and produce severe hallucinatory responses. To this end, we introduce \"Antidote\", a unified, synthetic data-driven post-training framework for mitigating both types of hallucination above. It leverages synthetic data to incorporate factual priors into questions to achieve self-correction, and decouple the mitigation process into a preference optimization problem. Furthermore, we construct \"CP-Bench\", a novel benchmark to evaluate LVLMs' ability to correctly handle CPQs and produce factual responses. Applied to the LLaVA series, Antidote can simultaneously enhance performance on CP-Bench by over 50%, POPE by 1.8-3.3%, and CHAIR & SHR by 30-50%, all without relying on external supervision from stronger LVLMs or human feedback and introducing noticeable catastrophic forgetting issues.","sentences":["Large Vision-Language Models (LVLMs) have achieved impressive results across various cross-modal tasks.","However, hallucinations, i.e., the models generating counterfactual responses, remain a challenge.","Though recent studies have attempted to alleviate object perception hallucinations, they focus on the models' response generation, and overlooking the task question itself.","This paper discusses the vulnerability of LVLMs in solving counterfactual presupposition questions (CPQs), where the models are prone to accept the presuppositions of counterfactual objects and produce severe hallucinatory responses.","To this end, we introduce \"Antidote\", a unified, synthetic data-driven post-training framework for mitigating both types of hallucination above.","It leverages synthetic data to incorporate factual priors into questions to achieve self-correction, and decouple the mitigation process into a preference optimization problem.","Furthermore, we construct \"CP-Bench\", a novel benchmark to evaluate LVLMs' ability to correctly handle CPQs and produce factual responses.","Applied to the LLaVA series, Antidote can simultaneously enhance performance on CP-Bench by over 50%, POPE by 1.8-3.3%, and CHAIR & SHR by 30-50%, all without relying on external supervision from stronger LVLMs or human feedback and introducing noticeable catastrophic forgetting issues."],"url":"http://arxiv.org/abs/2504.20468v1"}
{"created":"2025-04-29 06:50:48","title":"TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data","abstract":"With the development of distributed systems, microservices and cloud native technologies have become central to modern enterprise software development. Despite bringing significant advantages, these technologies also increase system complexity and operational challenges. Traditional root cause analysis (RCA) struggles to achieve automated fault response, heavily relying on manual intervention. In recent years, large language models (LLMs) have made breakthroughs in contextual inference and domain knowledge integration, providing new solutions for Artificial Intelligence for Operations (AIOps). However, Existing LLM-based approaches face three key challenges: text input constraints, dynamic service dependency hallucinations, and context window limitations. To address these issues, we propose a tool-assisted LLM agent with multi-modality observation data, namely TAMO, for fine-grained RCA. It unifies multi-modal observational data into time-aligned representations to extract consistent features and employs specialized root cause localization and fault classification tools for perceiving the contextual environment. This approach overcomes the limitations of LLM in handling real-time changing service dependencies and raw observational data and guides LLM to generate repair strategies aligned with system contexts by structuring key information into a prompt. Experimental results show that TAMO performs well in root cause analysis when dealing with public datasets characterized by heterogeneity and common fault types, demonstrating its effectiveness.","sentences":["With the development of distributed systems, microservices and cloud native technologies have become central to modern enterprise software development.","Despite bringing significant advantages, these technologies also increase system complexity and operational challenges.","Traditional root cause analysis (RCA) struggles to achieve automated fault response, heavily relying on manual intervention.","In recent years, large language models (LLMs) have made breakthroughs in contextual inference and domain knowledge integration, providing new solutions for Artificial Intelligence for Operations (AIOps).","However, Existing LLM-based approaches face three key challenges: text input constraints, dynamic service dependency hallucinations, and context window limitations.","To address these issues, we propose a tool-assisted LLM agent with multi-modality observation data, namely TAMO, for fine-grained RCA.","It unifies multi-modal observational data into time-aligned representations to extract consistent features and employs specialized root cause localization and fault classification tools for perceiving the contextual environment.","This approach overcomes the limitations of LLM in handling real-time changing service dependencies and raw observational data and guides LLM to generate repair strategies aligned with system contexts by structuring key information into a prompt.","Experimental results show that TAMO performs well in root cause analysis when dealing with public datasets characterized by heterogeneity and common fault types, demonstrating its effectiveness."],"url":"http://arxiv.org/abs/2504.20462v1"}
{"created":"2025-04-29 06:37:30","title":"Search-Based Interaction For Conversation Recommendation via Generative Reward Model Based Simulated User","abstract":"Conversational recommendation systems (CRSs) use multi-turn interaction to capture user preferences and provide personalized recommendations. A fundamental challenge in CRSs lies in effectively understanding user preferences from conversations. User preferences can be multifaceted and complex, posing significant challenges for accurate recommendations even with access to abundant external knowledge. While interaction with users can clarify their true preferences, frequent user involvement can lead to a degraded user experience.   To address this problem, we propose a generative reward model based simulated user, named GRSU, for automatic interaction with CRSs. The simulated user provides feedback to the items recommended by CRSs, enabling them to better capture intricate user preferences through multi-turn interaction. Inspired by generative reward models, we design two types of feedback actions for the simulated user: i.e., generative item scoring, which offers coarse-grained feedback, and attribute-based item critique, which provides fine-grained feedback. To ensure seamless integration, these feedback actions are unified into an instruction-based format, allowing the development of a unified simulated user via instruction tuning on synthesized data. With this simulated user, automatic multi-turn interaction with CRSs can be effectively conducted. Furthermore, to strike a balance between effectiveness and efficiency, we draw inspiration from the paradigm of reward-guided search in complex reasoning tasks and employ beam search for the interaction process. On top of this, we propose an efficient candidate ranking method to improve the recommendation results derived from interaction. Extensive experiments on public datasets demonstrate the effectiveness, efficiency, and transferability of our approach.","sentences":["Conversational recommendation systems (CRSs) use multi-turn interaction to capture user preferences and provide personalized recommendations.","A fundamental challenge in CRSs lies in effectively understanding user preferences from conversations.","User preferences can be multifaceted and complex, posing significant challenges for accurate recommendations even with access to abundant external knowledge.","While interaction with users can clarify their true preferences, frequent user involvement can lead to a degraded user experience.   ","To address this problem, we propose a generative reward model based simulated user, named GRSU, for automatic interaction with CRSs.","The simulated user provides feedback to the items recommended by CRSs, enabling them to better capture intricate user preferences through multi-turn interaction.","Inspired by generative reward models, we design two types of feedback actions for the simulated user: i.e., generative item scoring, which offers coarse-grained feedback, and attribute-based item critique, which provides fine-grained feedback.","To ensure seamless integration, these feedback actions are unified into an instruction-based format, allowing the development of a unified simulated user via instruction tuning on synthesized data.","With this simulated user, automatic multi-turn interaction with CRSs can be effectively conducted.","Furthermore, to strike a balance between effectiveness and efficiency, we draw inspiration from the paradigm of reward-guided search in complex reasoning tasks and employ beam search for the interaction process.","On top of this, we propose an efficient candidate ranking method to improve the recommendation results derived from interaction.","Extensive experiments on public datasets demonstrate the effectiveness, efficiency, and transferability of our approach."],"url":"http://arxiv.org/abs/2504.20458v1"}
{"created":"2025-04-29 06:33:13","title":"Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding","abstract":"In arbitrary-order language models, it is an open question how to sample tokens in parallel from the correct joint distribution. With discrete diffusion models, the more tokens they generate in parallel, the less their predicted distributions adhere to the originally learned data distribution, as they rely on a conditional independence assumption that only works with infinitesimally small timesteps. We find that a different class of models, any-subset autoregressive models (AS-ARMs), holds the solution. As implied by the name, AS-ARMs can generate tokens in any order, and in parallel. Moreover, AS-ARMs support parallelized joint probability density estimation, allowing them to correct their own parallel-generated token distributions, via our Any-Subset Speculative Decoding (ASSD) algorithm. ASSD provably enables generation of tokens from the correct joint distribution, with the number of neural network calls upper bounded by the number of tokens predicted. We empirically verify that ASSD speeds up language generation, without sacrificing quality. Furthermore, we provide a mathematically justified scheme for training AS-ARMs for generation, and show that AS-ARMs achieve state-of-the-art performance among sub-200M parameter models on infilling benchmark tasks, and nearly match the performance of models 50X larger on code generation. Our theoretical and empirical results indicate that the once-forgotten AS-ARMs are a promising direction of language modeling.","sentences":["In arbitrary-order language models, it is an open question how to sample tokens in parallel from the correct joint distribution.","With discrete diffusion models, the more tokens they generate in parallel, the less their predicted distributions adhere to the originally learned data distribution, as they rely on a conditional independence assumption that only works with infinitesimally small timesteps.","We find that a different class of models, any-subset autoregressive models (AS-ARMs), holds the solution.","As implied by the name, AS-ARMs can generate tokens in any order, and in parallel.","Moreover, AS-ARMs support parallelized joint probability density estimation, allowing them to correct their own parallel-generated token distributions, via our Any-Subset Speculative Decoding (ASSD) algorithm.","ASSD provably enables generation of tokens from the correct joint distribution, with the number of neural network calls upper bounded by the number of tokens predicted.","We empirically verify that ASSD speeds up language generation, without sacrificing quality.","Furthermore, we provide a mathematically justified scheme for training AS-ARMs for generation, and show that AS-ARMs achieve state-of-the-art performance among sub-200M parameter models on infilling benchmark tasks, and nearly match the performance of models 50X larger on code generation.","Our theoretical and empirical results indicate that the once-forgotten AS-ARMs are a promising direction of language modeling."],"url":"http://arxiv.org/abs/2504.20456v1"}
{"created":"2025-04-29 06:02:16","title":"Enhancing News Recommendation with Hierarchical LLM Prompting","abstract":"Personalized news recommendation systems often struggle to effectively capture the complexity of user preferences, as they rely heavily on shallow representations, such as article titles and abstracts. To address this problem, we introduce a novel method, namely PNR-LLM, for Large Language Models for Personalized News Recommendation. Specifically, PNR-LLM harnesses the generation capabilities of LLMs to enrich news titles and abstracts, and consequently improves recommendation quality. PNR-LLM contains a novel module, News Enrichment via LLMs, which generates deeper semantic information and relevant entities from articles, transforming shallow contents into richer representations. We further propose an attention mechanism to aggregate enriched semantic- and entity-level data, forming unified user and news embeddings that reveal a more accurate user-news match. Extensive experiments on MIND datasets show that PNR-LLM outperforms state-of-the-art baselines. Moreover, the proposed data enrichment module is model-agnostic, and we empirically show that applying our proposed module to multiple existing models can further improve their performance, verifying the advantage of our design.","sentences":["Personalized news recommendation systems often struggle to effectively capture the complexity of user preferences, as they rely heavily on shallow representations, such as article titles and abstracts.","To address this problem, we introduce a novel method, namely PNR-LLM, for Large Language Models for Personalized News Recommendation.","Specifically, PNR-LLM harnesses the generation capabilities of LLMs to enrich news titles and abstracts, and consequently improves recommendation quality.","PNR-LLM contains a novel module, News Enrichment via LLMs, which generates deeper semantic information and relevant entities from articles, transforming shallow contents into richer representations.","We further propose an attention mechanism to aggregate enriched semantic- and entity-level data, forming unified user and news embeddings that reveal a more accurate user-news match.","Extensive experiments on MIND datasets show that PNR-LLM outperforms state-of-the-art baselines.","Moreover, the proposed data enrichment module is model-agnostic, and we empirically show that applying our proposed module to multiple existing models can further improve their performance, verifying the advantage of our design."],"url":"http://arxiv.org/abs/2504.20452v1"}
{"created":"2025-04-29 05:44:59","title":"FT-MoE: Sustainable-learning Mixture of Experts Model for Fault-Tolerant Computing with Multiple Tasks","abstract":"Intelligent fault-tolerant (FT) computing has recently demonstrated significant advantages of predicting and diagnosing faults in advance, enabling reliable service delivery. However, due to heterogeneity of fault knowledge and complex dependence relationships of time series log data, existing deep learning-based FT algorithms further improve detection performance relying on single neural network model with difficulty. To this end, we propose FT-MoE, a sustainable-learning mixture-of-experts model for fault-tolerant computing with multiple tasks, which enables different parameters learning distinct fault knowledge to achieve high-reliability for service system. Firstly, we use decoder-based transformer models to obtain fault prototype vectors of decoupling long-distance dependencies. Followed by, we present a dual mixture of experts networks for high-accurate prediction for both fault detection and classification tasks. Then, we design a two-stage optimization scheme of offline training and online tuning, which allows that in operation FT-MoE can also keep learning to adapt to dynamic service environments. Finally, to verify the effectiveness of FT-MoE, we conduct extensive experiments on the FT benchmark. Experimental results show that FT-MoE achieves superior performance compared to the state-of-the-art methods. Code will be available upon publication.","sentences":["Intelligent fault-tolerant (FT) computing has recently demonstrated significant advantages of predicting and diagnosing faults in advance, enabling reliable service delivery.","However, due to heterogeneity of fault knowledge and complex dependence relationships of time series log data, existing deep learning-based FT algorithms further improve detection performance relying on single neural network model with difficulty.","To this end, we propose FT-MoE, a sustainable-learning mixture-of-experts model for fault-tolerant computing with multiple tasks, which enables different parameters learning distinct fault knowledge to achieve high-reliability for service system.","Firstly, we use decoder-based transformer models to obtain fault prototype vectors of decoupling long-distance dependencies.","Followed by, we present a dual mixture of experts networks for high-accurate prediction for both fault detection and classification tasks.","Then, we design a two-stage optimization scheme of offline training and online tuning, which allows that in operation FT-MoE can also keep learning to adapt to dynamic service environments.","Finally, to verify the effectiveness of FT-MoE, we conduct extensive experiments on the FT benchmark.","Experimental results show that FT-MoE achieves superior performance compared to the state-of-the-art methods.","Code will be available upon publication."],"url":"http://arxiv.org/abs/2504.20446v1"}
{"created":"2025-04-29 05:32:43","title":"Multidimensional precipitation index prediction based on CNN-LSTM hybrid framework","abstract":"With the intensification of global climate change, accurate prediction of weather indicators is of great significance in disaster prevention and mitigation, agricultural production, and transportation. Precipitation, as one of the key meteorological indicators, plays a crucial role in water resource management, agricultural production, and urban flood control. This study proposes a multidimensional precipitation index prediction model based on a CNN- LSTM hybrid framework, aiming to improve the accuracy of precipitation forecasts. The dataset is sourced from Pune, Maharashtra, India, covering monthly mean precipitation data from 1972 to 2002. This dataset includes nearly 31 years (1972-2002) of monthly average precipitation, reflecting the long-term fluctuations and seasonal variations of precipitation in the region. By analyzing these time series data, the CNN-LSTM model effectively captures local features and long-term dependencies. Experimental results show that the model achieves a root mean square error (RMSE) of 6.752, which demonstrates a significant advantage over traditional time series prediction methods in terms of prediction accuracy and generalization ability. Furthermore, this study provides new research ideas for precipitation prediction. However, the model requires high computational resources when dealing with large-scale datasets, and its predictive ability for multidimensional precipitation data still needs improvement. Future research could extend the model to support and predict multidimensional precipitation data, thereby promoting the development of more accurate and efficient meteorological prediction technologies.","sentences":["With the intensification of global climate change, accurate prediction of weather indicators is of great significance in disaster prevention and mitigation, agricultural production, and transportation.","Precipitation, as one of the key meteorological indicators, plays a crucial role in water resource management, agricultural production, and urban flood control.","This study proposes a multidimensional precipitation index prediction model based on a CNN- LSTM hybrid framework, aiming to improve the accuracy of precipitation forecasts.","The dataset is sourced from Pune, Maharashtra, India, covering monthly mean precipitation data from 1972 to 2002.","This dataset includes nearly 31 years (1972-2002) of monthly average precipitation, reflecting the long-term fluctuations and seasonal variations of precipitation in the region.","By analyzing these time series data, the CNN-LSTM model effectively captures local features and long-term dependencies.","Experimental results show that the model achieves a root mean square error (RMSE) of 6.752, which demonstrates a significant advantage over traditional time series prediction methods in terms of prediction accuracy and generalization ability.","Furthermore, this study provides new research ideas for precipitation prediction.","However, the model requires high computational resources when dealing with large-scale datasets, and its predictive ability for multidimensional precipitation data still needs improvement.","Future research could extend the model to support and predict multidimensional precipitation data, thereby promoting the development of more accurate and efficient meteorological prediction technologies."],"url":"http://arxiv.org/abs/2504.20442v1"}
{"created":"2025-04-29 05:23:27","title":"Network Attack Traffic Detection With Hybrid Quantum-Enhanced Convolution Neural Network","abstract":"The emerging paradigm of Quantum Machine Learning (QML) combines features of quantum computing and machine learning (ML). QML enables the generation and recognition of statistical data patterns that classical computers and classical ML methods struggle to effectively execute. QML utilizes quantum systems to enhance algorithmic computation speed and real-time data processing capabilities, making it one of the most promising tools in the field of ML. Quantum superposition and entanglement features also hold the promise to potentially expand the potential feature representation capabilities of ML. Therefore, in this study, we explore how quantum computing affects ML and whether it can further improve the detection performance on network traffic detection, especially on unseen attacks which are types of malicious traffic that do not exist in the ML training dataset. Classical ML models often perform poorly in detecting these unseen attacks because they have not been trained on such traffic. Hence, this paper focuses on designing and proposing novel hybrid structures of Quantum Convolutional Neural Network (QCNN) to achieve the detection of malicious traffic. The detection performance, generalization, and robustness of the QML solutions are evaluated and compared with classical ML running on classical computers. The emphasis lies in assessing whether the QML-based malicious traffic detection outperforms classical solutions. Based on experiment results, QCNN models demonstrated superior performance compared to classical ML approaches on unseen attack detection.","sentences":["The emerging paradigm of Quantum Machine Learning (QML) combines features of quantum computing and machine learning (ML).","QML enables the generation and recognition of statistical data patterns that classical computers and classical ML methods struggle to effectively execute.","QML utilizes quantum systems to enhance algorithmic computation speed and real-time data processing capabilities, making it one of the most promising tools in the field of ML.","Quantum superposition and entanglement features also hold the promise to potentially expand the potential feature representation capabilities of ML.","Therefore, in this study, we explore how quantum computing affects ML and whether it can further improve the detection performance on network traffic detection, especially on unseen attacks which are types of malicious traffic that do not exist in the ML training dataset.","Classical ML models often perform poorly in detecting these unseen attacks because they have not been trained on such traffic.","Hence, this paper focuses on designing and proposing novel hybrid structures of Quantum Convolutional Neural Network (QCNN) to achieve the detection of malicious traffic.","The detection performance, generalization, and robustness of the QML solutions are evaluated and compared with classical ML running on classical computers.","The emphasis lies in assessing whether the QML-based malicious traffic detection outperforms classical solutions.","Based on experiment results, QCNN models demonstrated superior performance compared to classical ML approaches on unseen attack detection."],"url":"http://arxiv.org/abs/2504.20436v1"}
{"created":"2025-04-29 04:42:02","title":"RV-Syn: Rational and Verifiable Mathematical Reasoning Data Synthesis based on Structured Function Library","abstract":"The advancement of reasoning capabilities in Large Language Models (LLMs) requires substantial amounts of high-quality reasoning data, particularly in mathematics. Existing data synthesis methods, such as data augmentation from annotated training sets or direct question generation based on relevant knowledge points and documents, have expanded datasets but face challenges in mastering the inner logic of the problem during generation and ensuring the verifiability of the solutions. To address these issues, we propose RV-Syn, a novel Rational and Verifiable mathematical Synthesis approach. RV-Syn constructs a structured mathematical operation function library based on initial seed problems and generates computational graphs as solutions by combining Python-formatted functions from this library. These graphs are then back-translated into complex problems. Based on the constructed computation graph, we achieve solution-guided logic-aware problem generation. Furthermore, the executability of the computational graph ensures the verifiability of the solving process. Experimental results show that RV-Syn surpasses existing synthesis methods, including those involving human-generated problems, achieving greater efficient data scaling. This approach provides a scalable framework for generating high-quality reasoning datasets.","sentences":["The advancement of reasoning capabilities in Large Language Models (LLMs) requires substantial amounts of high-quality reasoning data, particularly in mathematics.","Existing data synthesis methods, such as data augmentation from annotated training sets or direct question generation based on relevant knowledge points and documents, have expanded datasets but face challenges in mastering the inner logic of the problem during generation and ensuring the verifiability of the solutions.","To address these issues, we propose RV-Syn, a novel Rational and Verifiable mathematical Synthesis approach.","RV-Syn constructs a structured mathematical operation function library based on initial seed problems and generates computational graphs as solutions by combining Python-formatted functions from this library.","These graphs are then back-translated into complex problems.","Based on the constructed computation graph, we achieve solution-guided logic-aware problem generation.","Furthermore, the executability of the computational graph ensures the verifiability of the solving process.","Experimental results show that RV-Syn surpasses existing synthesis methods, including those involving human-generated problems, achieving greater efficient data scaling.","This approach provides a scalable framework for generating high-quality reasoning datasets."],"url":"http://arxiv.org/abs/2504.20426v1"}
{"created":"2025-04-29 04:32:03","title":"A Geography-Inspired and Self-Adaptive Clustering Algorithm: A Study in Channel Measurement","abstract":"The phenomenon that multi-path components (MPCs) arrive in clusters has been verified by channel measurements, and is widely adopted by cluster-based channel models. As a crucial intermediate processing step, MPC clustering bridges raw data in channel measurement and cluster characteristics for channel modeling. In this paper, a physical-interpretable and self-adaptive MPC clustering algorithm is proposed, which can locate both single-point and wide-spread scatterers without prior knowledge. Inspired by the concept in geography, a novel metaphor that interprets features of MPC attributes in the power-delay-angle profile (PDAP) as topographic concepts is developed. In light of the interpretation, the proposed algorithm disassembles the PDAP by constructing contour lines and identifying characteristic points that indicate the skeleton of MPC clusters, which are fitted by analytical models that associate MPCs with physical scatterer locations. Besides, a new clustering performance index, the power gradient consistency index, is proposed. Calculated as the weighted Spearman correlation coefficient between the power and the distance to the center, the index captures the intrinsic property of MPC clusters that the dominant high-power path is surrounded by lower-power paths. The performance of the proposed algorithm is analyzed and compared with the counterparts of conventional clustering algorithms based on the channel measurement conducted in an outdoor scenario. The proposed algorithm performs better in average Silhouette index and weighted Spearman correlation coefficient, and the average root mean square error (RMSE) of the estimated scatterer location is 0.1 m.","sentences":["The phenomenon that multi-path components (MPCs) arrive in clusters has been verified by channel measurements, and is widely adopted by cluster-based channel models.","As a crucial intermediate processing step, MPC clustering bridges raw data in channel measurement and cluster characteristics for channel modeling.","In this paper, a physical-interpretable and self-adaptive MPC clustering algorithm is proposed, which can locate both single-point and wide-spread scatterers without prior knowledge.","Inspired by the concept in geography, a novel metaphor that interprets features of MPC attributes in the power-delay-angle profile (PDAP) as topographic concepts is developed.","In light of the interpretation, the proposed algorithm disassembles the PDAP by constructing contour lines and identifying characteristic points that indicate the skeleton of MPC clusters, which are fitted by analytical models that associate MPCs with physical scatterer locations.","Besides, a new clustering performance index, the power gradient consistency index, is proposed.","Calculated as the weighted Spearman correlation coefficient between the power and the distance to the center, the index captures the intrinsic property of MPC clusters that the dominant high-power path is surrounded by lower-power paths.","The performance of the proposed algorithm is analyzed and compared with the counterparts of conventional clustering algorithms based on the channel measurement conducted in an outdoor scenario.","The proposed algorithm performs better in average Silhouette index and weighted Spearman correlation coefficient, and the average root mean square error (RMSE) of the estimated scatterer location is 0.1 m."],"url":"http://arxiv.org/abs/2504.20420v1"}
{"created":"2025-04-29 04:23:10","title":"Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation","abstract":"Searchable Symmetric Encryption (SSE) enables efficient search capabilities over encrypted data, allowing users to maintain privacy while utilizing cloud storage. However, SSE schemes are vulnerable to leakage attacks that exploit access patterns, search frequency, and volume information. Existing studies frequently assume that adversaries possess a substantial fraction of the encrypted dataset to mount effective inference attacks, implying there is a database leakage of such documents, thus, an assumption that may not hold in real-world scenarios. In this work, we investigate the feasibility of enhancing leakage attacks under a more realistic threat model in which adversaries have access to minimal leaked data. We propose a novel approach that leverages large language models (LLMs), specifically GPT-4 variants, to generate synthetic documents that statistically and semantically resemble the real-world dataset of Enron emails. Using the email corpus as a case study, we evaluate the effectiveness of synthetic data generated via random sampling and hierarchical clustering methods on the performance of the SAP (Search Access Pattern) keyword inference attack restricted to token volumes only. Our results demonstrate that, while the choice of LLM has limited effect, increasing dataset size and employing clustering-based generation significantly improve attack accuracy, achieving comparable performance to attacks using larger amounts of real data. We highlight the growing relevance of LLMs in adversarial contexts.","sentences":["Searchable Symmetric Encryption (SSE) enables efficient search capabilities over encrypted data, allowing users to maintain privacy while utilizing cloud storage.","However, SSE schemes are vulnerable to leakage attacks that exploit access patterns, search frequency, and volume information.","Existing studies frequently assume that adversaries possess a substantial fraction of the encrypted dataset to mount effective inference attacks, implying there is a database leakage of such documents, thus, an assumption that may not hold in real-world scenarios.","In this work, we investigate the feasibility of enhancing leakage attacks under a more realistic threat model in which adversaries have access to minimal leaked data.","We propose a novel approach that leverages large language models (LLMs), specifically GPT-4 variants, to generate synthetic documents that statistically and semantically resemble the real-world dataset of Enron emails.","Using the email corpus as a case study, we evaluate the effectiveness of synthetic data generated via random sampling and hierarchical clustering methods on the performance of the SAP (Search Access Pattern) keyword inference attack restricted to token volumes only.","Our results demonstrate that, while the choice of LLM has limited effect, increasing dataset size and employing clustering-based generation significantly improve attack accuracy, achieving comparable performance to attacks using larger amounts of real data.","We highlight the growing relevance of LLMs in adversarial contexts."],"url":"http://arxiv.org/abs/2504.20414v1"}
{"created":"2025-04-29 04:17:39","title":"ADiff4TPP: Asynchronous Diffusion Models for Temporal Point Processes","abstract":"This work introduces a novel approach to modeling temporal point processes using diffusion models with an asynchronous noise schedule. At each step of the diffusion process, the noise schedule injects noise of varying scales into different parts of the data. With a careful design of the noise schedules, earlier events are generated faster than later ones, thus providing stronger conditioning for forecasting the more distant future. We derive an objective to effectively train these models for a general family of noise schedules based on conditional flow matching. Our method models the joint distribution of the latent representations of events in a sequence and achieves state-of-the-art results in predicting both the next inter-event time and event type on benchmark datasets. Additionally, it flexibly accommodates varying lengths of observation and prediction windows in different forecasting settings by adjusting the starting and ending points of the generation process. Finally, our method shows superior performance in long-horizon prediction tasks, outperforming existing baseline methods.","sentences":["This work introduces a novel approach to modeling temporal point processes using diffusion models with an asynchronous noise schedule.","At each step of the diffusion process, the noise schedule injects noise of varying scales into different parts of the data.","With a careful design of the noise schedules, earlier events are generated faster than later ones, thus providing stronger conditioning for forecasting the more distant future.","We derive an objective to effectively train these models for a general family of noise schedules based on conditional flow matching.","Our method models the joint distribution of the latent representations of events in a sequence and achieves state-of-the-art results in predicting both the next inter-event time and event type on benchmark datasets.","Additionally, it flexibly accommodates varying lengths of observation and prediction windows in different forecasting settings by adjusting the starting and ending points of the generation process.","Finally, our method shows superior performance in long-horizon prediction tasks, outperforming existing baseline methods."],"url":"http://arxiv.org/abs/2504.20411v1"}
{"created":"2025-04-29 04:15:52","title":"Terahertz Wireless Data Center: Gaussian Beam or Airy Beam?","abstract":"Terahertz (THz) communication is emerging as a pivotal enabler for 6G and beyond wireless systems owing to its multi-GHz bandwidth. One of its novel applications is in wireless data centers, where it enables ultra-high data rates while enhancing network reconfigurability and scalability. However, due to numerous racks, supporting walls, and densely deployed antennas, the line-of-sight (LoS) path in data centers is often instead of fully obstructed, resulting in quasi-LoS propagation and degradation of spectral efficiency. To address this issue, Airy beam-based hybrid beamforming is investigated in this paper as a promising technique to mitigate quasi-LoS propagation and enhance spectral efficiency in THz wireless data centers. Specifically, a cascaded geometrical and wave-based channel model (CGWCM) is proposed for quasi-LoS scenarios, which accounts for diffraction effects while being more simplified than conventional wave-based model. Then, the characteristics and generation of the Airy beam are analyzed, and beam search methods for quasi-LoS scenarios are proposed, including hierarchical focusing-Airy beam search, and low-complexity beam search. Simulation results validate the effectiveness of the CGWCM and demonstrate the superiority of the Airy beam over Gaussian beams in mitigating blockages, verifying its potential for practical THz wireless communication in data centers.","sentences":["Terahertz (THz) communication is emerging as a pivotal enabler for 6G and beyond wireless systems owing to its multi-GHz bandwidth.","One of its novel applications is in wireless data centers, where it enables ultra-high data rates while enhancing network reconfigurability and scalability.","However, due to numerous racks, supporting walls, and densely deployed antennas, the line-of-sight (LoS) path in data centers is often instead of fully obstructed, resulting in quasi-LoS propagation and degradation of spectral efficiency.","To address this issue, Airy beam-based hybrid beamforming is investigated in this paper as a promising technique to mitigate quasi-LoS propagation and enhance spectral efficiency in THz wireless data centers.","Specifically, a cascaded geometrical and wave-based channel model (CGWCM) is proposed for quasi-LoS scenarios, which accounts for diffraction effects while being more simplified than conventional wave-based model.","Then, the characteristics and generation of the Airy beam are analyzed, and beam search methods for quasi-LoS scenarios are proposed, including hierarchical focusing-Airy beam search, and low-complexity beam search.","Simulation results validate the effectiveness of the CGWCM and demonstrate the superiority of the Airy beam over Gaussian beams in mitigating blockages, verifying its potential for practical THz wireless communication in data centers."],"url":"http://arxiv.org/abs/2504.20410v1"}
{"created":"2025-04-29 04:15:33","title":"GarmentX: Autoregressive Parametric Representations for High-Fidelity 3D Garment Generation","abstract":"This work presents GarmentX, a novel framework for generating diverse, high-fidelity, and wearable 3D garments from a single input image. Traditional garment reconstruction methods directly predict 2D pattern edges and their connectivity, an overly unconstrained approach that often leads to severe self-intersections and physically implausible garment structures. In contrast, GarmentX introduces a structured and editable parametric representation compatible with GarmentCode, ensuring that the decoded sewing patterns always form valid, simulation-ready 3D garments while allowing for intuitive modifications of garment shape and style. To achieve this, we employ a masked autoregressive model that sequentially predicts garment parameters, leveraging autoregressive modeling for structured generation while mitigating inconsistencies in direct pattern prediction. Additionally, we introduce GarmentX dataset, a large-scale dataset of 378,682 garment parameter-image pairs, constructed through an automatic data generation pipeline that synthesizes diverse and high-quality garment images conditioned on parametric garment representations. Through integrating our method with GarmentX dataset, we achieve state-of-the-art performance in geometric fidelity and input image alignment, significantly outperforming prior approaches. We will release GarmentX dataset upon publication.","sentences":["This work presents GarmentX, a novel framework for generating diverse, high-fidelity, and wearable 3D garments from a single input image.","Traditional garment reconstruction methods directly predict 2D pattern edges and their connectivity, an overly unconstrained approach that often leads to severe self-intersections and physically implausible garment structures.","In contrast, GarmentX introduces a structured and editable parametric representation compatible with GarmentCode, ensuring that the decoded sewing patterns always form valid, simulation-ready 3D garments while allowing for intuitive modifications of garment shape and style.","To achieve this, we employ a masked autoregressive model that sequentially predicts garment parameters, leveraging autoregressive modeling for structured generation while mitigating inconsistencies in direct pattern prediction.","Additionally, we introduce GarmentX dataset, a large-scale dataset of 378,682 garment parameter-image pairs, constructed through an automatic data generation pipeline that synthesizes diverse and high-quality garment images conditioned on parametric garment representations.","Through integrating our method with GarmentX dataset, we achieve state-of-the-art performance in geometric fidelity and input image alignment, significantly outperforming prior approaches.","We will release GarmentX dataset upon publication."],"url":"http://arxiv.org/abs/2504.20409v1"}
{"created":"2025-04-29 03:23:06","title":"Manifold Clustering with Schatten p-norm Maximization","abstract":"Manifold clustering, with its exceptional ability to capture complex data structures, holds a pivotal position in cluster analysis. However, existing methods often focus only on finding the optimal combination between K-means and manifold learning, and overlooking the consistency between the data structure and labels. To address this issue, we deeply explore the relationship between K-means and manifold learning, and on this basis, fuse them to develop a new clustering framework. Specifically, the algorithm uses labels to guide the manifold structure and perform clustering on it, which ensures the consistency between the data structure and labels. Furthermore, in order to naturally maintain the class balance in the clustering process, we maximize the Schatten p-norm of labels, and provide a theoretical proof to support this. Additionally, our clustering framework is designed to be flexible and compatible with many types of distance functions, which facilitates efficient processing of nonlinear separable data. The experimental results of several databases confirm the superiority of our proposed model.","sentences":["Manifold clustering, with its exceptional ability to capture complex data structures, holds a pivotal position in cluster analysis.","However, existing methods often focus only on finding the optimal combination between K-means and manifold learning, and overlooking the consistency between the data structure and labels.","To address this issue, we deeply explore the relationship between K-means and manifold learning, and on this basis, fuse them to develop a new clustering framework.","Specifically, the algorithm uses labels to guide the manifold structure and perform clustering on it, which ensures the consistency between the data structure and labels.","Furthermore, in order to naturally maintain the class balance in the clustering process, we maximize the Schatten p-norm of labels, and provide a theoretical proof to support this.","Additionally, our clustering framework is designed to be flexible and compatible with many types of distance functions, which facilitates efficient processing of nonlinear separable data.","The experimental results of several databases confirm the superiority of our proposed model."],"url":"http://arxiv.org/abs/2504.20390v1"}
{"created":"2025-04-29 03:09:46","title":"FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video Understanding","abstract":"Recent advancements in video understanding within visual large language models (VLLMs) have led to notable progress. However, the complexity of video data and contextual processing limitations still hinder long-video comprehension. A common approach is video feature compression to reduce token input to large language models, yet many methods either fail to prioritize essential features, leading to redundant inter-frame information, or introduce computationally expensive modules.To address these issues, we propose FiLA(Fine-grained Vision Language Model)-Video, a novel framework that leverages a lightweight dynamic-weight multi-frame fusion strategy, which adaptively integrates multiple frames into a single representation while preserving key video information and reducing computational costs. To enhance frame selection for fusion, we introduce a keyframe selection strategy, effectively identifying informative frames from a larger pool for improved summarization. Additionally, we present a simple yet effective long-video training data generation strategy, boosting model performance without extensive manual annotation. Experimental results demonstrate that FiLA-Video achieves superior efficiency and accuracy in long-video comprehension compared to existing methods.","sentences":["Recent advancements in video understanding within visual large language models (VLLMs) have led to notable progress.","However, the complexity of video data and contextual processing limitations still hinder long-video comprehension.","A common approach is video feature compression to reduce token input to large language models, yet many methods either fail to prioritize essential features, leading to redundant inter-frame information, or introduce computationally expensive modules.","To address these issues, we propose FiLA(Fine-grained Vision Language Model)-Video, a novel framework that leverages a lightweight dynamic-weight multi-frame fusion strategy, which adaptively integrates multiple frames into a single representation while preserving key video information and reducing computational costs.","To enhance frame selection for fusion, we introduce a keyframe selection strategy, effectively identifying informative frames from a larger pool for improved summarization.","Additionally, we present a simple yet effective long-video training data generation strategy, boosting model performance without extensive manual annotation.","Experimental results demonstrate that FiLA-Video achieves superior efficiency and accuracy in long-video comprehension compared to existing methods."],"url":"http://arxiv.org/abs/2504.20384v1"}
{"created":"2025-04-29 02:38:44","title":"Generative Learning for Slow Manifolds and Bifurcation Diagrams","abstract":"In dynamical systems characterized by separation of time scales, the approximation of so called ``slow manifolds'', on which the long term dynamics lie, is a useful step for model reduction. Initializing on such slow manifolds is a useful step in modeling, since it circumvents fast transients, and is crucial in multiscale algorithms alternating between fine scale (fast) and coarser scale (slow) simulations. In a similar spirit, when one studies the infinite time dynamics of systems depending on parameters, the system attractors (e.g., its steady states) lie on bifurcation diagrams. Sampling these manifolds gives us representative attractors (here, steady states of ODEs or PDEs) at different parameter values. Algorithms for the systematic construction of these manifolds are required parts of the ``traditional'' numerical nonlinear dynamics toolkit.   In more recent years, as the field of Machine Learning develops, conditional score-based generative models (cSGMs) have demonstrated capabilities in generating plausible data from target distributions that are conditioned on some given label. It is tempting to exploit such generative models to produce samples of data distributions conditioned on some quantity of interest (QoI). In this work, we present a framework for using cSGMs to quickly (a) initialize on a low-dimensional (reduced-order) slow manifold of a multi-time-scale system consistent with desired value(s) of a QoI (a ``label'') on the manifold, and (b) approximate steady states in a bifurcation diagram consistent with a (new, out-of-sample) parameter value. This conditional sampling can help uncover the geometry of the reduced slow-manifold and/or approximately ``fill in'' missing segments of steady states in a bifurcation diagram.","sentences":["In dynamical systems characterized by separation of time scales, the approximation of so called ``slow manifolds'', on which the long term dynamics lie, is a useful step for model reduction.","Initializing on such slow manifolds is a useful step in modeling, since it circumvents fast transients, and is crucial in multiscale algorithms alternating between fine scale (fast) and coarser scale (slow) simulations.","In a similar spirit, when one studies the infinite time dynamics of systems depending on parameters, the system attractors (e.g., its steady states) lie on bifurcation diagrams.","Sampling these manifolds gives us representative attractors (here, steady states of ODEs or PDEs) at different parameter values.","Algorithms for the systematic construction of these manifolds are required parts of the ``traditional'' numerical nonlinear dynamics toolkit.   ","In more recent years, as the field of Machine Learning develops, conditional score-based generative models (cSGMs) have demonstrated capabilities in generating plausible data from target distributions that are conditioned on some given label.","It is tempting to exploit such generative models to produce samples of data distributions conditioned on some quantity of interest (QoI).","In this work, we present a framework for using cSGMs to quickly (a) initialize on a low-dimensional (reduced-order) slow manifold of a multi-time-scale system consistent with desired value(s) of a QoI (a ``label'') on the manifold, and (b) approximate steady states in a bifurcation diagram consistent with a (new, out-of-sample) parameter value.","This conditional sampling can help uncover the geometry of the reduced slow-manifold and/or approximately ``fill in'' missing segments of steady states in a bifurcation diagram."],"url":"http://arxiv.org/abs/2504.20375v1"}
{"created":"2025-04-29 02:30:00","title":"Approximately Dominating Sets in Elections","abstract":"Condorcet's paradox is a fundamental result in social choice theory which states that there exist elections in which, no matter which candidate wins, a majority of voters prefer a different candidate. In fact, even if we can select any $k$ winners, there still may exist another candidate that would beat each of the winners in a majority vote. That is, elections may require arbitrarily large dominating sets.   We show that approximately dominating sets of constant size always exist. In particular, for every $\\varepsilon > 0$, every election (irrespective of the number of voters or candidates) can select $O(\\frac{1}{\\varepsilon ^2})$ winners such that no other candidate beats each of the winners by a margin of more than $\\varepsilon$ fraction of voters.   Our proof uses a simple probabilistic construction using samples from a maximal lottery, a well-studied distribution over candidates derived from the Nash equilibrium of a two-player game. In stark contrast to general approximate equilibria, which may require support logarithmic in the number of pure strategies, we show that maximal lotteries can be approximated with constant support size. These approximate maximal lotteries may be of independent interest.","sentences":["Condorcet's paradox is a fundamental result in social choice theory which states that there exist elections in which, no matter which candidate wins, a majority of voters prefer a different candidate.","In fact, even if we can select any $k$ winners, there still may exist another candidate that would beat each of the winners in a majority vote.","That is, elections may require arbitrarily large dominating sets.   ","We show that approximately dominating sets of constant size always exist.","In particular, for every $\\varepsilon > 0$, every election (irrespective of the number of voters or candidates) can select $O(\\frac{1}{\\varepsilon ^2})$ winners such that no other candidate beats each of the winners by a margin of more than $\\varepsilon$ fraction of voters.   ","Our proof uses a simple probabilistic construction using samples from a maximal lottery, a well-studied distribution over candidates derived from the Nash equilibrium of a two-player game.","In stark contrast to general approximate equilibria, which may require support logarithmic in the number of pure strategies, we show that maximal lotteries can be approximated with constant support size.","These approximate maximal lotteries may be of independent interest."],"url":"http://arxiv.org/abs/2504.20372v1"}
{"created":"2025-04-29 02:14:11","title":"Perception-aware Sampling for Scatterplot Visualizations","abstract":"Visualizing data is often a crucial first step in data analytics workflows, but growing data sizes pose challenges due to computational and visual perception limitations. As a result, data analysts commonly down-sample their data and work with subsets. Deriving representative samples, however, remains a challenge. This paper focuses on scatterplots, a widely-used visualization type, and introduces a novel sampling objective -- perception-awareness -- aiming to improve sample efficacy by targeting humans' perception of a visualization.   We make the following contributions: (1) We propose perception-augmented databases and design PAwS: a novel perception-aware sampling method for scatterplots that leverages saliency maps -- a computer vision tool for predicting areas of attention focus in visualizations -- and models perception-awareness via saliency, density, and coverage objectives. (2) We design ApproPAwS: a fast, perception-aware method for approximate visualizations, which exploits the fact that small visual perturbations are often imperceptible to humans. (3) We introduce the concept of perceptual similarity as a metric for sample quality, and present a novel method that compares saliency maps to measure it. (4) Our extensive experimental evaluation shows that our methods consistently outperform prior art in producing samples with high perceptual similarity, while ApproPAwS achieves up to 100x speed-ups with minimal loss in visual fidelity. Our user study shows that PAwS is often preferred by humans, validating our quantitative findings.","sentences":["Visualizing data is often a crucial first step in data analytics workflows, but growing data sizes pose challenges due to computational and visual perception limitations.","As a result, data analysts commonly down-sample their data and work with subsets.","Deriving representative samples, however, remains a challenge.","This paper focuses on scatterplots, a widely-used visualization type, and introduces a novel sampling objective -- perception-awareness -- aiming to improve sample efficacy by targeting humans' perception of a visualization.   ","We make the following contributions: (1) We propose perception-augmented databases and design PAwS: a novel perception-aware sampling method for scatterplots that leverages saliency maps -- a computer vision tool for predicting areas of attention focus in visualizations -- and models perception-awareness via saliency, density, and coverage objectives.","(2) We design ApproPAwS: a fast, perception-aware method for approximate visualizations, which exploits the fact that small visual perturbations are often imperceptible to humans.","(3) We introduce the concept of perceptual similarity as a metric for sample quality, and present a novel method that compares saliency maps to measure it.","(4) Our extensive experimental evaluation shows that our methods consistently outperform prior art in producing samples with high perceptual similarity, while ApproPAwS achieves up to 100x speed-ups with minimal loss in visual fidelity.","Our user study shows that PAwS is often preferred by humans, validating our quantitative findings."],"url":"http://arxiv.org/abs/2504.20369v1"}
{"created":"2025-04-29 02:00:08","title":"TTTFusion: A Test-Time Training-Based Strategy for Multimodal Medical Image Fusion in Surgical Robots","abstract":"With the increasing use of surgical robots in clinical practice, enhancing their ability to process multimodal medical images has become a key research challenge. Although traditional medical image fusion methods have made progress in improving fusion accuracy, they still face significant challenges in real-time performance, fine-grained feature extraction, and edge preservation.In this paper, we introduce TTTFusion, a Test-Time Training (TTT)-based image fusion strategy that dynamically adjusts model parameters during inference to efficiently fuse multimodal medical images. By adapting the model during the test phase, our method optimizes the parameters based on the input image data, leading to improved accuracy and better detail preservation in the fusion results.Experimental results demonstrate that TTTFusion significantly enhances the fusion quality of multimodal images compared to traditional fusion methods, particularly in fine-grained feature extraction and edge preservation. This approach not only improves image fusion accuracy but also offers a novel technical solution for real-time image processing in surgical robots.","sentences":["With the increasing use of surgical robots in clinical practice, enhancing their ability to process multimodal medical images has become a key research challenge.","Although traditional medical image fusion methods have made progress in improving fusion accuracy, they still face significant challenges in real-time performance, fine-grained feature extraction, and edge preservation.","In this paper, we introduce TTTFusion, a Test-Time Training (TTT)-based image fusion strategy that dynamically adjusts model parameters during inference to efficiently fuse multimodal medical images.","By adapting the model during the test phase, our method optimizes the parameters based on the input image data, leading to improved accuracy and better detail preservation in the fusion results.","Experimental results demonstrate that TTTFusion significantly enhances the fusion quality of multimodal images compared to traditional fusion methods, particularly in fine-grained feature extraction and edge preservation.","This approach not only improves image fusion accuracy but also offers a novel technical solution for real-time image processing in surgical robots."],"url":"http://arxiv.org/abs/2504.20362v1"}
{"created":"2025-04-29 01:49:09","title":"What Causes Knowledge Loss in Multilingual Language Models?","abstract":"Cross-lingual transfer in natural language processing (NLP) models enhances multilingual performance by leveraging shared linguistic knowledge. However, traditional methods that process all data simultaneously often fail to mimic real-world scenarios, leading to challenges like catastrophic forgetting, where fine-tuning on new tasks degrades performance on previously learned ones. Our study explores this issue in multilingual contexts, focusing on linguistic differences affecting representational learning rather than just model parameters. We experiment with 52 languages using LoRA adapters of varying ranks to evaluate non-shared, partially shared, and fully shared parameters. Our aim is to see if parameter sharing through adapters can mitigate forgetting while preserving prior knowledge. We find that languages using non-Latin scripts are more susceptible to catastrophic forgetting, whereas those written in Latin script facilitate more effective cross-lingual transfer.","sentences":["Cross-lingual transfer in natural language processing (NLP) models enhances multilingual performance by leveraging shared linguistic knowledge.","However, traditional methods that process all data simultaneously often fail to mimic real-world scenarios, leading to challenges like catastrophic forgetting, where fine-tuning on new tasks degrades performance on previously learned ones.","Our study explores this issue in multilingual contexts, focusing on linguistic differences affecting representational learning rather than just model parameters.","We experiment with 52 languages using LoRA adapters of varying ranks to evaluate non-shared, partially shared, and fully shared parameters.","Our aim is to see if parameter sharing through adapters can mitigate forgetting while preserving prior knowledge.","We find that languages using non-Latin scripts are more susceptible to catastrophic forgetting, whereas those written in Latin script facilitate more effective cross-lingual transfer."],"url":"http://arxiv.org/abs/2504.20356v1"}
{"created":"2025-04-29 01:31:23","title":"Clustering-Based Evolutionary Federated Multiobjective Optimization and Learning","abstract":"Federated learning enables decentralized model training while preserving data privacy, yet it faces challenges in balancing communication efficiency, model performance, and privacy protection. To address these trade-offs, we formulate FL as a federated multiobjective optimization problem and propose FedMOEAC, a clustering-based evolutionary algorithm that efficiently navigates the Pareto-optimal solution space. Our approach integrates quantization, weight sparsification, and differential privacy to reduce communication overhead while ensuring model robustness and privacy. The clustering mechanism en-hances population diversity, preventing premature convergence and improving optimization efficiency. Experimental results on MNIST and CIFAR-10 demonstrate that FedMOEAC achieves 98.2% accuracy, reduces communication overhead by 45%, and maintains a privacy budget below 1.0, outperforming NSGA-II in convergence speed by 33%. This work provides a scalable and efficient FL framework, ensuring an optimal balance between accuracy, communication efficiency, and privacy in resource-constrained environments.","sentences":["Federated learning enables decentralized model training while preserving data privacy, yet it faces challenges in balancing communication efficiency, model performance, and privacy protection.","To address these trade-offs, we formulate FL as a federated multiobjective optimization problem and propose FedMOEAC, a clustering-based evolutionary algorithm that efficiently navigates the Pareto-optimal solution space.","Our approach integrates quantization, weight sparsification, and differential privacy to reduce communication overhead while ensuring model robustness and privacy.","The clustering mechanism en-hances population diversity, preventing premature convergence and improving optimization efficiency.","Experimental results on MNIST and CIFAR-10 demonstrate that FedMOEAC achieves 98.2% accuracy, reduces communication overhead by 45%, and maintains a privacy budget below 1.0, outperforming NSGA-II in convergence speed by 33%.","This work provides a scalable and efficient FL framework, ensuring an optimal balance between accuracy, communication efficiency, and privacy in resource-constrained environments."],"url":"http://arxiv.org/abs/2504.20346v1"}
{"created":"2025-04-29 01:20:30","title":"DRO: Doppler-Aware Direct Radar Odometry","abstract":"A renaissance in radar-based sensing for mobile robotic applications is underway. Compared to cameras or lidars, millimetre-wave radars have the ability to `see' through thin walls, vegetation, and adversarial weather conditions such as heavy rain, fog, snow, and dust. In this paper, we propose a novel SE(2) odometry approach for spinning frequency-modulated continuous-wave radars. Our method performs scan-to-local-map registration of the incoming radar data in a direct manner using all the radar intensity information without the need for feature or point cloud extraction. The method performs locally continuous trajectory estimation and accounts for both motion and Doppler distortion of the radar scans. If the radar possesses a specific frequency modulation pattern that makes radial Doppler velocities observable, an additional Doppler-based constraint is formulated to improve the velocity estimate and enable odometry in geometrically feature-deprived scenarios (e.g., featureless tunnels). Our method has been validated on over 250km of on-road data sourced from public datasets (Boreas and MulRan) and collected using our automotive platform. With the aid of a gyroscope, it outperforms state-of-the-art methods and achieves an average relative translation error of 0.26% on the Boreas leaderboard. When using data with the appropriate Doppler-enabling frequency modulation pattern, the translation error is reduced to 0.18% in similar environments. We also benchmarked our algorithm using 1.5 hours of data collected with a mobile robot in off-road environments with various levels of structure to demonstrate its versatility. Our real-time implementation is publicly available: https://github.com/utiasASRL/dro.","sentences":["A renaissance in radar-based sensing for mobile robotic applications is underway.","Compared to cameras or lidars, millimetre-wave radars have the ability to `see' through thin walls, vegetation, and adversarial weather conditions such as heavy rain, fog, snow, and dust.","In this paper, we propose a novel SE(2) odometry approach for spinning frequency-modulated continuous-wave radars.","Our method performs scan-to-local-map registration of the incoming radar data in a direct manner using all the radar intensity information without the need for feature or point cloud extraction.","The method performs locally continuous trajectory estimation and accounts for both motion and Doppler distortion of the radar scans.","If the radar possesses a specific frequency modulation pattern that makes radial Doppler velocities observable, an additional Doppler-based constraint is formulated to improve the velocity estimate and enable odometry in geometrically feature-deprived scenarios (e.g., featureless tunnels).","Our method has been validated on over 250km of on-road data sourced from public datasets (Boreas and MulRan) and collected using our automotive platform.","With the aid of a gyroscope, it outperforms state-of-the-art methods and achieves an average relative translation error of 0.26% on the Boreas leaderboard.","When using data with the appropriate Doppler-enabling frequency modulation pattern, the translation error is reduced to 0.18% in similar environments.","We also benchmarked our algorithm using 1.5 hours of data collected with a mobile robot in off-road environments with various levels of structure to demonstrate its versatility.","Our real-time implementation is publicly available: https://github.com/utiasASRL/dro."],"url":"http://arxiv.org/abs/2504.20339v1"}
