{"created":"2024-02-08 18:59:53","title":"InstaGen: Enhancing Object Detection by Training on Synthetic Dataset","abstract":"In this paper, we introduce a novel paradigm to enhance the ability of object detector, e.g., expanding categories or improving detection performance, by training on synthetic dataset generated from diffusion models. Specifically, we integrate an instance-level grounding head into a pre-trained, generative diffusion model, to augment it with the ability of localising arbitrary instances in the generated images. The grounding head is trained to align the text embedding of category names with the regional visual feature of the diffusion model, using supervision from an off-the-shelf object detector, and a novel self-training scheme on (novel) categories not covered by the detector. This enhanced version of diffusion model, termed as InstaGen, can serve as a data synthesizer for object detection. We conduct thorough experiments to show that, object detector can be enhanced while training on the synthetic dataset from InstaGen, demonstrating superior performance over existing state-of-the-art methods in open-vocabulary (+4.5 AP) and data-sparse (+1.2 to 5.2 AP) scenarios.","sentences":["In this paper, we introduce a novel paradigm to enhance the ability of object detector, e.g., expanding categories or improving detection performance, by training on synthetic dataset generated from diffusion models.","Specifically, we integrate an instance-level grounding head into a pre-trained, generative diffusion model, to augment it with the ability of localising arbitrary instances in the generated images.","The grounding head is trained to align the text embedding of category names with the regional visual feature of the diffusion model, using supervision from an off-the-shelf object detector, and a novel self-training scheme on (novel) categories not covered by the detector.","This enhanced version of diffusion model, termed as InstaGen, can serve as a data synthesizer for object detection.","We conduct thorough experiments to show that, object detector can be enhanced while training on the synthetic dataset from InstaGen, demonstrating superior performance over existing state-of-the-art methods in open-vocabulary (+4.5 AP) and data-sparse (+1.2 to 5.2 AP) scenarios."],"url":"http://arxiv.org/abs/2402.05937v1"}
{"created":"2024-02-08 18:59:48","title":"SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models","abstract":"We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM) series developed upon SPHINX. To improve the architecture and training efficiency, we modify the SPHINX framework by removing redundant visual encoders, bypassing fully-padded sub-images with skip tokens, and simplifying multi-stage training into a one-stage all-in-one paradigm. To fully unleash the potential of MLLMs, we assemble a comprehensive multi-domain and multimodal dataset covering publicly available resources in language, vision, and vision-language tasks. We further enrich this collection with our curated OCR intensive and Set-of-Mark datasets, extending the diversity and generality. By training over different base LLMs including TinyLlama1.1B, InternLM2-7B, LLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in parameter size and multilingual capabilities. Comprehensive benchmarking reveals a strong correlation between the multi-modal performance with the data and parameter scales. Code and models are released at https://github.com/Alpha-VLLM/LLaMA2-Accessory","sentences":["We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM) series developed upon SPHINX.","To improve the architecture and training efficiency, we modify the SPHINX framework by removing redundant visual encoders, bypassing fully-padded sub-images with skip tokens, and simplifying multi-stage training into a one-stage all-in-one paradigm.","To fully unleash the potential of MLLMs, we assemble a comprehensive multi-domain and multimodal dataset covering publicly available resources in language, vision, and vision-language tasks.","We further enrich this collection with our curated OCR intensive and Set-of-Mark datasets, extending the diversity and generality.","By training over different base LLMs including TinyLlama1.1B, InternLM2-7B, LLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in parameter size and multilingual capabilities.","Comprehensive benchmarking reveals a strong correlation between the multi-modal performance with the data and parameter scales.","Code and models are released at https://github.com/Alpha-VLLM/LLaMA2-Accessory"],"url":"http://arxiv.org/abs/2402.05935v1"}
{"created":"2024-02-08 18:58:02","title":"An Interactive Agent Foundation Model","abstract":"The development of artificial intelligence systems is transitioning from creating static, task-specific models to dynamic, agent-based systems capable of performing well in a wide range of applications. We propose an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks. Our training paradigm unifies diverse pre-training strategies, including visual masked auto-encoders, language modeling, and next-action prediction, enabling a versatile and adaptable AI framework. We demonstrate the performance of our framework across three separate domains -- Robotics, Gaming AI, and Healthcare. Our model demonstrates its ability to generate meaningful and contextually relevant outputs in each area. The strength of our approach lies in its generality, leveraging a variety of data sources such as robotics sequences, gameplay data, large-scale video datasets, and textual information for effective multimodal and multi-task learning. Our approach provides a promising avenue for developing generalist, action-taking, multimodal systems.","sentences":["The development of artificial intelligence systems is transitioning from creating static, task-specific models to dynamic, agent-based systems capable of performing well in a wide range of applications.","We propose an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks.","Our training paradigm unifies diverse pre-training strategies, including visual masked auto-encoders, language modeling, and next-action prediction, enabling a versatile and adaptable AI framework.","We demonstrate the performance of our framework across three separate domains -- Robotics, Gaming AI, and Healthcare.","Our model demonstrates its ability to generate meaningful and contextually relevant outputs in each area.","The strength of our approach lies in its generality, leveraging a variety of data sources such as robotics sequences, gameplay data, large-scale video datasets, and textual information for effective multimodal and multi-task learning.","Our approach provides a promising avenue for developing generalist, action-taking, multimodal systems."],"url":"http://arxiv.org/abs/2402.05929v1"}
{"created":"2024-02-08 18:58:02","title":"WebLINX: Real-World Website Navigation with Multi-Turn Dialogue","abstract":"We propose the problem of conversational web navigation, where a digital agent controls a web browser and follows user instructions to solve real-world tasks in a multi-turn dialogue fashion. To support this problem, we introduce WEBLINX - a large-scale benchmark of 100K interactions across 2300 expert demonstrations of conversational web navigation. Our benchmark covers a broad range of patterns on over 150 real-world websites and can be used to train and evaluate agents in diverse scenarios. Due to the magnitude of information present, Large Language Models (LLMs) cannot process entire web pages in real-time. To solve this bottleneck, we design a retrieval-inspired model that efficiently prunes HTML pages by ranking relevant elements. We use the selected elements, along with screenshots and action history, to assess a variety of models for their ability to replicate human behavior when navigating the web. Our experiments span from small text-only to proprietary multimodal LLMs. We find that smaller finetuned decoders surpass the best zero-shot LLMs (including GPT-4V), but also larger finetuned multimodal models which were explicitly pretrained on screenshots. However, all finetuned models struggle to generalize to unseen websites. Our findings highlight the need for large multimodal models that can generalize to novel settings. Our code, data and models are available for research: https://mcgill-nlp.github.io/weblinx","sentences":["We propose the problem of conversational web navigation, where a digital agent controls a web browser and follows user instructions to solve real-world tasks in a multi-turn dialogue fashion.","To support this problem, we introduce WEBLINX - a large-scale benchmark of 100K interactions across 2300 expert demonstrations of conversational web navigation.","Our benchmark covers a broad range of patterns on over 150 real-world websites and can be used to train and evaluate agents in diverse scenarios.","Due to the magnitude of information present, Large Language Models (LLMs) cannot process entire web pages in real-time.","To solve this bottleneck, we design a retrieval-inspired model that efficiently prunes HTML pages by ranking relevant elements.","We use the selected elements, along with screenshots and action history, to assess a variety of models for their ability to replicate human behavior when navigating the web.","Our experiments span from small text-only to proprietary multimodal LLMs.","We find that smaller finetuned decoders surpass the best zero-shot LLMs (including GPT-4V), but also larger finetuned multimodal models which were explicitly pretrained on screenshots.","However, all finetuned models struggle to generalize to unseen websites.","Our findings highlight the need for large multimodal models that can generalize to novel settings.","Our code, data and models are available for research: https://mcgill-nlp.github.io/weblinx"],"url":"http://arxiv.org/abs/2402.05930v1"}
{"created":"2024-02-08 18:57:42","title":"Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss","abstract":"In this work, we study statistical learning with dependent ($\\beta$-mixing) data and square loss in a hypothesis class $\\mathscr{F}\\subset L_{\\Psi_p}$ where $\\Psi_p$ is the norm $\\|f\\|_{\\Psi_p} \\triangleq \\sup_{m\\geq 1} m^{-1/p} \\|f\\|_{L^m} $ for some $p\\in [2,\\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data. Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \\emph{multiplicatively} by the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\\Psi_p$ are comparable on our hypothesis class $\\mathscr{F}$ -- that is, $\\mathscr{F}$ is a weakly sub-Gaussian class: $\\|f\\|_{\\Psi_p} \\lesssim \\|f\\|_{L^2}^\\eta$ for some $\\eta\\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. Our result holds whether the problem is realizable or not and we refer to this as a \\emph{near mixing-free rate}, since direct dependence on mixing is relegated to an additive higher order term. We arrive at our result by combining the above notion of a weakly sub-Gaussian class with mixed tail generic chaining. This combination allows us to compute sharp, instance-optimal rates for a wide range of problems. %Our approach, reliant on mixed tail generic chaining, allows us to obtain sharp, instance-optimal rates. Examples that satisfy our framework include sub-Gaussian linear regression, more general smoothly parameterized function classes, finite hypothesis classes, and bounded smoothness classes.","sentences":["In this work, we study statistical learning with dependent ($\\beta$-mixing) data and square loss in a hypothesis class $\\mathscr{F}\\subset L_{\\Psi_p}$ where $\\Psi_p$ is the norm $\\|f\\|_{\\Psi_p} \\triangleq \\sup_{m\\geq 1} m^{-1/p} \\|f\\|_{L^m} $ for some $p\\in [2,\\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data.","Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \\emph{multiplicatively} by the mixing time of the underlying covariates process.","We show that whenever the topologies of $L^2$ and $\\Psi_p$ are comparable on our hypothesis class $\\mathscr{F}$ -- that is, $\\mathscr{F}$ is a weakly sub-Gaussian class: $\\|f\\|_{\\Psi_p} \\lesssim \\|f\\|_{L^2}^\\eta$ for some $\\eta\\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term.","Our result holds whether the problem is realizable or not and we refer to this as a \\emph{near mixing-free rate}, since direct dependence on mixing is relegated to an additive higher order term.","We arrive at our result by combining the above notion of a weakly sub-Gaussian class with mixed tail generic chaining.","This combination allows us to compute sharp, instance-optimal rates for a wide range of problems.","%Our approach, reliant on mixed tail generic chaining, allows us to obtain sharp, instance-optimal rates.","Examples that satisfy our framework include sub-Gaussian linear regression, more general smoothly parameterized function classes, finite hypothesis classes, and bounded smoothness classes."],"url":"http://arxiv.org/abs/2402.05928v1"}
{"created":"2024-02-08 18:53:21","title":"Collaborative Control for Geometry-Conditioned PBR Image Generation","abstract":"Current 3D content generation builds on generative models that output RGB images. Modern graphics pipelines, however, require physically-based rendering (PBR) material properties. We propose to model the PBR image distribution directly to avoid photometric inaccuracies in RGB generation and the inherent ambiguity in extracting PBR from RGB. Existing paradigms for cross-modal finetuning are not suited for PBR generation due to a lack of data and the high dimensionality of the output modalities: we overcome both challenges by retaining a frozen RGB model and tightly linking a newly trained PBR model using a novel cross-network communication paradigm. As the base RGB model is fully frozen, the proposed method does not risk catastrophic forgetting during finetuning and remains compatible with techniques such as IPAdapter pretrained for the base RGB model. We validate our design choices, robustness to data sparsity, and compare against existing paradigms with an extensive experimental section.","sentences":["Current 3D content generation builds on generative models that output RGB images.","Modern graphics pipelines, however, require physically-based rendering (PBR) material properties.","We propose to model the PBR image distribution directly to avoid photometric inaccuracies in RGB generation and the inherent ambiguity in extracting PBR from RGB.","Existing paradigms for cross-modal finetuning are not suited for PBR generation due to a lack of data and the high dimensionality of the output modalities: we overcome both challenges by retaining a frozen RGB model and tightly linking a newly trained PBR model using a novel cross-network communication paradigm.","As the base RGB model is fully frozen, the proposed method does not risk catastrophic forgetting during finetuning and remains compatible with techniques such as IPAdapter pretrained for the base RGB model.","We validate our design choices, robustness to data sparsity, and compare against existing paradigms with an extensive experimental section."],"url":"http://arxiv.org/abs/2402.05919v1"}
{"created":"2024-02-08 18:52:23","title":"Point-VOS: Pointing Up Video Object Segmentation","abstract":"Current state-of-the-art Video Object Segmentation (VOS) methods rely on dense per-object mask annotations both during training and testing. This requires time-consuming and costly video annotation mechanisms. We propose a novel Point-VOS task with a spatio-temporally sparse point-wise annotation scheme that substantially reduces the annotation effort. We apply our annotation scheme to two large-scale video datasets with text descriptions and annotate over 19M points across 133K objects in 32K videos. Based on our annotations, we propose a new Point-VOS benchmark, and a corresponding point-based training mechanism, which we use to establish strong baseline results. We show that existing VOS methods can easily be adapted to leverage our point annotations during training, and can achieve results close to the fully-supervised performance when trained on pseudo-masks generated from these points. In addition, we show that our data can be used to improve models that connect vision and language, by evaluating it on the Video Narrative Grounding (VNG) task. We will make our code and annotations available at https://pointvos.github.io.","sentences":["Current state-of-the-art Video Object Segmentation (VOS) methods rely on dense per-object mask annotations both during training and testing.","This requires time-consuming and costly video annotation mechanisms.","We propose a novel Point-VOS task with a spatio-temporally sparse point-wise annotation scheme that substantially reduces the annotation effort.","We apply our annotation scheme to two large-scale video datasets with text descriptions and annotate over 19M points across 133K objects in 32K videos.","Based on our annotations, we propose a new Point-VOS benchmark, and a corresponding point-based training mechanism, which we use to establish strong baseline results.","We show that existing VOS methods can easily be adapted to leverage our point annotations during training, and can achieve results close to the fully-supervised performance when trained on pseudo-masks generated from these points.","In addition, we show that our data can be used to improve models that connect vision and language, by evaluating it on the Video Narrative Grounding (VNG) task.","We will make our code and annotations available at https://pointvos.github.io."],"url":"http://arxiv.org/abs/2402.05917v1"}
{"created":"2024-02-08 18:51:55","title":"GenEFT: Understanding Statics and Dynamics of Model Generalization via Effective Theory","abstract":"We present GenEFT: an effective theory framework for shedding light on the statics and dynamics of neural network generalization, and illustrate it with graph learning examples. We first investigate the generalization phase transition as data size increases, comparing experimental results with information-theory-based approximations. We find generalization in a Goldilocks zone where the decoder is neither too weak nor too powerful. We then introduce an effective theory for the dynamics of representation learning, where latent-space representations are modeled as interacting particles (repons), and find that it explains our experimentally observed phase transition between generalization and overfitting as encoder and decoder learning rates are scanned. This highlights the power of physics-inspired effective theories for bridging the gap between theoretical predictions and practice in machine learning.","sentences":["We present GenEFT: an effective theory framework for shedding light on the statics and dynamics of neural network generalization, and illustrate it with graph learning examples.","We first investigate the generalization phase transition as data size increases, comparing experimental results with information-theory-based approximations.","We find generalization in a Goldilocks zone where the decoder is neither too weak nor too powerful.","We then introduce an effective theory for the dynamics of representation learning, where latent-space representations are modeled as interacting particles (repons), and find that it explains our experimentally observed phase transition between generalization and overfitting as encoder and decoder learning rates are scanned.","This highlights the power of physics-inspired effective theories for bridging the gap between theoretical predictions and practice in machine learning."],"url":"http://arxiv.org/abs/2402.05916v1"}
{"created":"2024-02-08 18:33:21","title":"Large Language Model Meets Graph Neural Network in Knowledge Distillation","abstract":"Despite recent community revelations about the advancements and potential of Large Language Models (LLMs) in understanding Text-Attributed Graphs (TAG), the deployment of LLMs for production is hindered by their high computational and storage requirements, as well as long latencies during inference. Simultaneously, although traditional Graph Neural Networks (GNNs) are light weight and adept at learning structural features of graphs, their ability to grasp the complex semantics in TAGs is somewhat constrained for real applications. To address these limitations, we concentrate on the downstream task of node classification in TAG and propose a novel graph knowledge distillation framework, termed Linguistic Graph Knowledge Distillation (LinguGKD), using LLMs as teacher models and GNNs as student models for knowledge distillation. It involves TAG-oriented instruction tuning of LLM on designed node classification prompts, followed by aligning the hierarchically learned node features of the teacher LLM and the student GNN in latent space, employing a layer-adaptive contrastive learning strategy. Through extensive experiments on a variety of LLM and GNN models and multiple benchmark datasets, the proposed LinguGKD significantly boosts the student GNN's predictive accuracy and convergence rate, without the need of extra data or model parameters. Compared to teacher LLM, distilled GNN achieves superior inference speed equipped with much fewer computing and storage demands, when surpassing the teacher LLM's classification performance on some of benchmark datasets.","sentences":["Despite recent community revelations about the advancements and potential of Large Language Models (LLMs) in understanding Text-Attributed Graphs (TAG), the deployment of LLMs for production is hindered by their high computational and storage requirements, as well as long latencies during inference.","Simultaneously, although traditional Graph Neural Networks (GNNs) are light weight and adept at learning structural features of graphs, their ability to grasp the complex semantics in TAGs is somewhat constrained for real applications.","To address these limitations, we concentrate on the downstream task of node classification in TAG and propose a novel graph knowledge distillation framework, termed Linguistic Graph Knowledge Distillation (LinguGKD), using LLMs as teacher models and GNNs as student models for knowledge distillation.","It involves TAG-oriented instruction tuning of LLM on designed node classification prompts, followed by aligning the hierarchically learned node features of the teacher LLM and the student GNN in latent space, employing a layer-adaptive contrastive learning strategy.","Through extensive experiments on a variety of LLM and GNN models and multiple benchmark datasets, the proposed LinguGKD significantly boosts the student GNN's predictive accuracy and convergence rate, without the need of extra data or model parameters.","Compared to teacher LLM, distilled GNN achieves superior inference speed equipped with much fewer computing and storage demands, when surpassing the teacher LLM's classification performance on some of benchmark datasets."],"url":"http://arxiv.org/abs/2402.05894v1"}
{"created":"2024-02-08 18:30:50","title":"Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data","abstract":"In recent years, Transformers have become the de-facto architecture for sequence modeling on text and a variety of multi-dimensional data, such as images and video. However, the use of self-attention layers in a Transformer incurs prohibitive compute and memory complexity that scales quadratically w.r.t. the sequence length. A recent architecture, Mamba, based on state space models has been shown to achieve comparable performance for modeling text sequences, while scaling linearly with the sequence length. In this work, we present Mamba-ND, a generalized design extending the Mamba architecture to arbitrary multi-dimensional data. Our design alternatively unravels the input data across different dimensions following row-major orderings. We provide a systematic comparison of Mamba-ND with several other alternatives, based on prior multi-dimensional extensions such as Bi-directional LSTMs and S4ND. Empirically, we show that Mamba-ND demonstrates performance competitive with the state-of-the-art on a variety of multi-dimensional benchmarks, including ImageNet-1K classification, HMDB-51 action recognition, and ERA5 weather forecasting.","sentences":["In recent years, Transformers have become the de-facto architecture for sequence modeling on text and a variety of multi-dimensional data, such as images and video.","However, the use of self-attention layers in a Transformer incurs prohibitive compute and memory complexity that scales quadratically w.r.t.","the sequence length.","A recent architecture, Mamba, based on state space models has been shown to achieve comparable performance for modeling text sequences, while scaling linearly with the sequence length.","In this work, we present Mamba-ND, a generalized design extending the Mamba architecture to arbitrary multi-dimensional data.","Our design alternatively unravels the input data across different dimensions following row-major orderings.","We provide a systematic comparison of Mamba-ND with several other alternatives, based on prior multi-dimensional extensions such as Bi-directional LSTMs and S4ND.","Empirically, we show that Mamba-ND demonstrates performance competitive with the state-of-the-art on a variety of multi-dimensional benchmarks, including ImageNet-1K classification, HMDB-51 action recognition, and ERA5 weather forecasting."],"url":"http://arxiv.org/abs/2402.05892v1"}
{"created":"2024-02-08 18:27:22","title":"CREMA: Multimodal Compositional Video Reasoning via Efficient Modular Adaptation and Fusion","abstract":"Despite impressive advancements in multimodal compositional reasoning approaches, they are still limited in their flexibility and efficiency by processing fixed modality inputs while updating a lot of model parameters. This paper tackles these critical challenges and proposes CREMA, an efficient and modular modality-fusion framework for injecting any new modality into video reasoning. We first augment multiple informative modalities (such as optical flow, 3D point cloud, audio) from given videos without extra human annotation by leveraging existing pre-trained models. Next, we introduce a query transformer with multiple parameter-efficient modules associated with each accessible modality. It projects diverse modality features to the LLM token embedding space, allowing the model to integrate different data types for response generation. Furthermore, we propose a fusion module designed to compress multimodal queries, maintaining computational efficiency in the LLM while combining additional modalities. We validate our method on video-3D, video-audio, and video-language reasoning tasks and achieve better/equivalent performance against strong multimodal LLMs, including BLIP-2, 3D-LLM, and SeViLA while using 96% fewer trainable parameters. We provide extensive analyses of CREMA, including the impact of each modality on reasoning domains, the design of the fusion module, and example visualizations.","sentences":["Despite impressive advancements in multimodal compositional reasoning approaches, they are still limited in their flexibility and efficiency by processing fixed modality inputs while updating a lot of model parameters.","This paper tackles these critical challenges and proposes CREMA, an efficient and modular modality-fusion framework for injecting any new modality into video reasoning.","We first augment multiple informative modalities (such as optical flow, 3D point cloud, audio) from given videos without extra human annotation by leveraging existing pre-trained models.","Next, we introduce a query transformer with multiple parameter-efficient modules associated with each accessible modality.","It projects diverse modality features to the LLM token embedding space, allowing the model to integrate different data types for response generation.","Furthermore, we propose a fusion module designed to compress multimodal queries, maintaining computational efficiency in the LLM while combining additional modalities.","We validate our method on video-3D, video-audio, and video-language reasoning tasks and achieve better/equivalent performance against strong multimodal LLMs, including BLIP-2, 3D-LLM, and SeViLA while using 96% fewer trainable parameters.","We provide extensive analyses of CREMA, including the impact of each modality on reasoning domains, the design of the fusion module, and example visualizations."],"url":"http://arxiv.org/abs/2402.05889v1"}
{"created":"2024-02-08 18:23:05","title":"EUGENE: Explainable Unsupervised Approximation of Graph Edit Distance","abstract":"The need to identify graphs having small structural distance from a query arises in biology, chemistry, recommender systems, and social network analysis. Among several methods to measure inter graph distance, Graph Edit Distance (GED) is preferred for its comprehensibility, yet hindered by the NP-hardness of its computation. State-of-the-art GED approximations predominantly employ neural methods, which, however, (i) lack an explanatory edit path corresponding to the approximated GED; (ii) require the NP-hard generation of ground-truth GEDs for training; and (iii) necessitate separate training on each dataset. In this paper, we propose an efficient algebraic unsuper vised method, EUGENE, that approximates GED and yields edit paths corresponding to the approx imated cost, while eliminating the need for ground truth generation and data-specific training. Extensive experimental evaluation demonstrates that the aforementioned benefits of EUGENE do not come at the cost of efficacy. Specifically, EUGENE consistently ranks among the most accurate methods across all of the benchmark datasets and outperforms majority of the neural approaches.","sentences":["The need to identify graphs having small structural distance from a query arises in biology, chemistry, recommender systems, and social network analysis.","Among several methods to measure inter graph distance, Graph Edit Distance (GED) is preferred for its comprehensibility, yet hindered by the NP-hardness of its computation.","State-of-the-art GED approximations predominantly employ neural methods, which, however, (i) lack an explanatory edit path corresponding to the approximated GED; (ii) require the NP-hard generation of ground-truth GEDs for training; and (iii) necessitate separate training on each dataset.","In this paper, we propose an efficient algebraic unsuper vised method, EUGENE, that approximates GED and yields edit paths corresponding to the approx imated cost, while eliminating the need for ground truth generation and data-specific training.","Extensive experimental evaluation demonstrates that the aforementioned benefits of EUGENE do not come at the cost of efficacy.","Specifically, EUGENE consistently ranks among the most accurate methods across all of the benchmark datasets and outperforms majority of the neural approaches."],"url":"http://arxiv.org/abs/2402.05885v1"}
{"created":"2024-02-08 18:16:47","title":"GET-Tok: A GenAI-Enriched Multimodal TikTok Dataset Documenting the 2022 Attempted Coup in Peru","abstract":"TikTok is one of the largest and fastest-growing social media sites in the world. TikTok features, however, such as voice transcripts, are often missing and other important features, such as OCR or video descriptions, do not exist. We introduce the Generative AI Enriched TikTok (GET-Tok) data, a pipeline for collecting TikTok videos and enriched data by augmenting the TikTok Research API with generative AI models. As a case study, we collect videos about the attempted coup in Peru initiated by its former President, Pedro Castillo, and its accompanying protests. The data includes information on 43,697 videos published from November 20, 2022 to March 1, 2023 (102 days). Generative AI augments the collected data via transcripts of TikTok videos, text descriptions of what is shown in the videos, what text is displayed within the video, and the stances expressed in the video. Overall, this pipeline will contribute to a better understanding of online discussion in a multimodal setting with applications of Generative AI, especially outlining the utility of this pipeline in non-English-language social media. Our code used to produce the pipeline is in a public Github repository: https://github.com/gabbypinto/GET-Tok-Peru.","sentences":["TikTok is one of the largest and fastest-growing social media sites in the world.","TikTok features, however, such as voice transcripts, are often missing and other important features, such as OCR or video descriptions, do not exist.","We introduce the Generative AI Enriched TikTok (GET-Tok) data, a pipeline for collecting TikTok videos and enriched data by augmenting the TikTok Research API with generative AI models.","As a case study, we collect videos about the attempted coup in Peru initiated by its former President, Pedro Castillo, and its accompanying protests.","The data includes information on 43,697 videos published from November 20, 2022 to March 1, 2023 (102 days).","Generative AI augments the collected data via transcripts of TikTok videos, text descriptions of what is shown in the videos, what text is displayed within the video, and the stances expressed in the video.","Overall, this pipeline will contribute to a better understanding of online discussion in a multimodal setting with applications of Generative AI, especially outlining the utility of this pipeline in non-English-language social media.","Our code used to produce the pipeline is in a public Github repository: https://github.com/gabbypinto/GET-Tok-Peru."],"url":"http://arxiv.org/abs/2402.05882v1"}
{"created":"2024-02-08 18:09:17","title":"Federated Offline Reinforcement Learning: Collaborative Single-Policy Coverage Suffices","abstract":"Offline reinforcement learning (RL), which seeks to learn an optimal policy using offline data, has garnered significant interest due to its potential in critical applications where online data collection is infeasible or expensive. This work explores the benefit of federated learning for offline RL, aiming at collaboratively leveraging offline datasets at multiple agents. Focusing on finite-horizon episodic tabular Markov decision processes (MDPs), we design FedLCB-Q, a variant of the popular model-free Q-learning algorithm tailored for federated offline RL. FedLCB-Q updates local Q-functions at agents with novel learning rate schedules and aggregates them at a central server using importance averaging and a carefully designed pessimistic penalty term. Our sample complexity analysis reveals that, with appropriately chosen parameters and synchronization schedules, FedLCB-Q achieves linear speedup in terms of the number of agents without requiring high-quality datasets at individual agents, as long as the local datasets collectively cover the state-action space visited by the optimal policy, highlighting the power of collaboration in the federated setting. In fact, the sample complexity almost matches that of the single-agent counterpart, as if all the data are stored at a central location, up to polynomial factors of the horizon length. Furthermore, FedLCB-Q is communication-efficient, where the number of communication rounds is only linear with respect to the horizon length up to logarithmic factors.","sentences":["Offline reinforcement learning (RL), which seeks to learn an optimal policy using offline data, has garnered significant interest due to its potential in critical applications where online data collection is infeasible or expensive.","This work explores the benefit of federated learning for offline RL, aiming at collaboratively leveraging offline datasets at multiple agents.","Focusing on finite-horizon episodic tabular Markov decision processes (MDPs), we design FedLCB-Q, a variant of the popular model-free Q-learning algorithm tailored for federated offline RL.","FedLCB-Q updates local Q-functions at agents with novel learning rate schedules and aggregates them at a central server using importance averaging and a carefully designed pessimistic penalty term.","Our sample complexity analysis reveals that, with appropriately chosen parameters and synchronization schedules, FedLCB-Q achieves linear speedup in terms of the number of agents without requiring high-quality datasets at individual agents, as long as the local datasets collectively cover the state-action space visited by the optimal policy, highlighting the power of collaboration in the federated setting.","In fact, the sample complexity almost matches that of the single-agent counterpart, as if all the data are stored at a central location, up to polynomial factors of the horizon length.","Furthermore, FedLCB-Q is communication-efficient, where the number of communication rounds is only linear with respect to the horizon length up to logarithmic factors."],"url":"http://arxiv.org/abs/2402.05876v1"}
{"created":"2024-02-08 18:01:19","title":"You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for Semantic and Property Prediction","abstract":"Robots must be able to understand their surroundings to perform complex tasks in challenging environments and many of these complex tasks require estimates of physical properties such as friction or weight. Estimating such properties using learning is challenging due to the large amounts of labelled data required for training and the difficulty of updating these learned models online at run time. To overcome these challenges, this paper introduces a novel, multi-modal approach for representing semantic predictions and physical property estimates jointly in a probabilistic manner. By using conjugate pairs, the proposed method enables closed-form Bayesian updates given visual and tactile measurements without requiring additional training data. The efficacy of the proposed algorithm is demonstrated through several hardware experiments. In particular, this paper illustrates that by conditioning semantic classifications on physical properties, the proposed method quantitatively outperforms state-of-the-art semantic classification methods that rely on vision alone. To further illustrate its utility, the proposed method is used in several applications including to represent affordance-based properties probabilistically and a challenging terrain traversal task using a legged robot. In the latter task, the proposed method represents the coefficient of friction of the terrain probabilistically, which enables the use of an on-line risk-aware planner that switches the legged robot from a dynamic gait to a static, stable gait when the expected value of the coefficient of friction falls below a given threshold. Videos of these case studies are presented in the multimedia attachment. The proposed framework includes an open-source C++ and ROS interface.","sentences":["Robots must be able to understand their surroundings to perform complex tasks in challenging environments and many of these complex tasks require estimates of physical properties such as friction or weight.","Estimating such properties using learning is challenging due to the large amounts of labelled data required for training and the difficulty of updating these learned models online at run time.","To overcome these challenges, this paper introduces a novel, multi-modal approach for representing semantic predictions and physical property estimates jointly in a probabilistic manner.","By using conjugate pairs, the proposed method enables closed-form Bayesian updates given visual and tactile measurements without requiring additional training data.","The efficacy of the proposed algorithm is demonstrated through several hardware experiments.","In particular, this paper illustrates that by conditioning semantic classifications on physical properties, the proposed method quantitatively outperforms state-of-the-art semantic classification methods that rely on vision alone.","To further illustrate its utility, the proposed method is used in several applications including to represent affordance-based properties probabilistically and a challenging terrain traversal task using a legged robot.","In the latter task, the proposed method represents the coefficient of friction of the terrain probabilistically, which enables the use of an on-line risk-aware planner that switches the legged robot from a dynamic gait to a static, stable gait when the expected value of the coefficient of friction falls below a given threshold.","Videos of these case studies are presented in the multimedia attachment.","The proposed framework includes an open-source C++ and ROS interface."],"url":"http://arxiv.org/abs/2402.05872v1"}
{"created":"2024-02-08 17:57:11","title":"PromptCrypt: Prompt Encryption for Secure Communication with Large Language Models","abstract":"Cloud-based large language models (LLMs) such as ChatGPT have increasingly become integral to daily operations, serving as vital tools across various applications. While these models offer substantial benefits in terms of accessibility and functionality, they also introduce significant privacy concerns: the transmission and storage of user data in cloud infrastructures pose substantial risks of data breaches and unauthorized access to sensitive information; even if the transmission and storage of data is encrypted, the LLM service provider itself still knows the real contents of the data, preventing individuals or entities from confidently using such LLM services. To address these concerns, this paper proposes a simple yet effective mechanism PromptCrypt to protect user privacy. It uses Emoji to encrypt the user inputs before sending them to LLM, effectively rendering them indecipherable to human or LLM's examination while retaining the original intent of the prompt, thus ensuring the model's performance remains unaffected. We conduct experiments on three tasks, personalized recommendation, sentiment analysis, and tabular data analysis. Experiment results reveal that PromptCrypt can encrypt personal information within prompts in such a manner that not only prevents the discernment of sensitive data by humans or LLM itself, but also maintains or even improves the precision without further tuning, achieving comparable or even better task accuracy than directly prompting the LLM without prompt encryption. These results highlight the practicality of adopting encryption measures that safeguard user privacy without compromising the functional integrity and performance of LLMs. Code and dataset are available at https://github.com/agiresearch/PromptCrypt.","sentences":["Cloud-based large language models (LLMs) such as ChatGPT have increasingly become integral to daily operations, serving as vital tools across various applications.","While these models offer substantial benefits in terms of accessibility and functionality, they also introduce significant privacy concerns: the transmission and storage of user data in cloud infrastructures pose substantial risks of data breaches and unauthorized access to sensitive information; even if the transmission and storage of data is encrypted, the LLM service provider itself still knows the real contents of the data, preventing individuals or entities from confidently using such LLM services.","To address these concerns, this paper proposes a simple yet effective mechanism PromptCrypt to protect user privacy.","It uses Emoji to encrypt the user inputs before sending them to LLM, effectively rendering them indecipherable to human or LLM's examination while retaining the original intent of the prompt, thus ensuring the model's performance remains unaffected.","We conduct experiments on three tasks, personalized recommendation, sentiment analysis, and tabular data analysis.","Experiment results reveal that PromptCrypt can encrypt personal information within prompts in such a manner that not only prevents the discernment of sensitive data by humans or LLM itself, but also maintains or even improves the precision without further tuning, achieving comparable or even better task accuracy than directly prompting the LLM without prompt encryption.","These results highlight the practicality of adopting encryption measures that safeguard user privacy without compromising the functional integrity and performance of LLMs.","Code and dataset are available at https://github.com/agiresearch/PromptCrypt."],"url":"http://arxiv.org/abs/2402.05868v1"}
{"created":"2024-02-08 17:51:44","title":"Let Your Graph Do the Talking: Encoding Structured Data for LLMs","abstract":"How can we best encode structured data into sequential form for use in large language models (LLMs)? In this work, we introduce a parameter-efficient method to explicitly represent structured data for LLMs. Our method, GraphToken, learns an encoding function to extend prompts with explicit structured information. Unlike other work which focuses on limited domains (e.g. knowledge graph representation), our work is the first effort focused on the general encoding of structured data to be used for various reasoning tasks. We show that explicitly representing the graph structure allows significant improvements to graph reasoning tasks. Specifically, we see across the board improvements - up to 73% points - on node, edge and, graph-level tasks from the GraphQA benchmark.","sentences":["How can we best encode structured data into sequential form for use in large language models (LLMs)?","In this work, we introduce a parameter-efficient method to explicitly represent structured data for LLMs.","Our method, GraphToken, learns an encoding function to extend prompts with explicit structured information.","Unlike other work which focuses on limited domains (e.g. knowledge graph representation), our work is the first effort focused on the general encoding of structured data to be used for various reasoning tasks.","We show that explicitly representing the graph structure allows significant improvements to graph reasoning tasks.","Specifically, we see across the board improvements - up to 73% points - on node, edge and, graph-level tasks from the GraphQA benchmark."],"url":"http://arxiv.org/abs/2402.05862v1"}
{"created":"2024-02-08 17:44:06","title":"Privacy-Preserving Synthetic Continual Semantic Segmentation for Robotic Surgery","abstract":"Deep Neural Networks (DNNs) based semantic segmentation of the robotic instruments and tissues can enhance the precision of surgical activities in robot-assisted surgery. However, in biological learning, DNNs cannot learn incremental tasks over time and exhibit catastrophic forgetting, which refers to the sharp decline in performance on previously learned tasks after learning a new one. Specifically, when data scarcity is the issue, the model shows a rapid drop in performance on previously learned instruments after learning new data with new instruments. The problem becomes worse when it limits releasing the dataset of the old instruments for the old model due to privacy concerns and the unavailability of the data for the new or updated version of the instruments for the continual learning model. For this purpose, we develop a privacy-preserving synthetic continual semantic segmentation framework by blending and harmonizing (i) open-source old instruments foreground to the synthesized background without revealing real patient data in public and (ii) new instruments foreground to extensively augmented real background. To boost the balanced logit distillation from the old model to the continual learning model, we design overlapping class-aware temperature normalization (CAT) by controlling model learning utility. We also introduce multi-scale shifted-feature distillation (SD) to maintain long and short-range spatial relationships among the semantic objects where conventional short-range spatial features with limited information reduce the power of feature distillation. We demonstrate the effectiveness of our framework on the EndoVis 2017 and 2018 instrument segmentation dataset with a generalized continual learning setting. Code is available at~\\url{https://github.com/XuMengyaAmy/Synthetic_CAT_SD}.","sentences":["Deep Neural Networks (DNNs) based semantic segmentation of the robotic instruments and tissues can enhance the precision of surgical activities in robot-assisted surgery.","However, in biological learning, DNNs cannot learn incremental tasks over time and exhibit catastrophic forgetting, which refers to the sharp decline in performance on previously learned tasks after learning a new one.","Specifically, when data scarcity is the issue, the model shows a rapid drop in performance on previously learned instruments after learning new data with new instruments.","The problem becomes worse when it limits releasing the dataset of the old instruments for the old model due to privacy concerns and the unavailability of the data for the new or updated version of the instruments for the continual learning model.","For this purpose, we develop a privacy-preserving synthetic continual semantic segmentation framework by blending and harmonizing (i) open-source old instruments foreground to the synthesized background without revealing real patient data in public and (ii) new instruments foreground to extensively augmented real background.","To boost the balanced logit distillation from the old model to the continual learning model, we design overlapping class-aware temperature normalization (CAT) by controlling model learning utility.","We also introduce multi-scale shifted-feature distillation (SD) to maintain long and short-range spatial relationships among the semantic objects where conventional short-range spatial features with limited information reduce the power of feature distillation.","We demonstrate the effectiveness of our framework on the EndoVis 2017 and 2018 instrument segmentation dataset with a generalized continual learning setting.","Code is available at~\\url{https://github.com/XuMengyaAmy/Synthetic_CAT_SD}."],"url":"http://arxiv.org/abs/2402.05860v1"}
{"created":"2024-02-08 17:43:22","title":"Learning to Route Among Specialized Experts for Zero-Shot Generalization","abstract":"Recently, there has been a widespread proliferation of \"expert\" language models that are specialized to a specific task or domain through parameter-efficient fine-tuning. How can we recycle large collections of expert language models to improve zero-shot generalization to unseen tasks? In this work, we propose Post-Hoc Adaptive Tokenwise Gating Over an Ocean of Specialized Experts (PHATGOOSE), which learns to route among specialized modules that were produced through parameter-efficient fine-tuning. Unlike past methods that learn to route among specialized models, PHATGOOSE explores the possibility that zero-shot generalization will be improved if different experts can be adaptively chosen for each token and at each layer in the model. Crucially, our method is post-hoc - it does not require simultaneous access to the datasets used to create the specialized models and only requires a modest amount of additional compute after each expert model is trained. In experiments covering a range of specialized model collections and zero-shot generalization benchmarks, we find that PHATGOOSE outperforms past methods for post-hoc routing and, in some cases, outperforms explicit multitask training (which requires simultaneous data access). To better understand the routing strategy learned by PHATGOOSE, we perform qualitative experiments to validate that PHATGOOSE's performance stems from its ability to make adaptive per-token and per-module expert choices. We release all of our code to support future work on improving zero-shot generalization by recycling specialized experts.","sentences":["Recently, there has been a widespread proliferation of \"expert\" language models that are specialized to a specific task or domain through parameter-efficient fine-tuning.","How can we recycle large collections of expert language models to improve zero-shot generalization to unseen tasks?","In this work, we propose Post-Hoc Adaptive Tokenwise Gating Over an Ocean of Specialized Experts (PHATGOOSE), which learns to route among specialized modules that were produced through parameter-efficient fine-tuning.","Unlike past methods that learn to route among specialized models, PHATGOOSE explores the possibility that zero-shot generalization will be improved if different experts can be adaptively chosen for each token and at each layer in the model.","Crucially, our method is post-hoc - it does not require simultaneous access to the datasets used to create the specialized models and only requires a modest amount of additional compute after each expert model is trained.","In experiments covering a range of specialized model collections and zero-shot generalization benchmarks, we find that PHATGOOSE outperforms past methods for post-hoc routing and, in some cases, outperforms explicit multitask training (which requires simultaneous data access).","To better understand the routing strategy learned by PHATGOOSE, we perform qualitative experiments to validate that PHATGOOSE's performance stems from its ability to make adaptive per-token and per-module expert choices.","We release all of our code to support future work on improving zero-shot generalization by recycling specialized experts."],"url":"http://arxiv.org/abs/2402.05859v1"}
{"created":"2024-02-08 17:12:49","title":"How Much is Unseen Depends Chiefly on Information About the Seen","abstract":"It might seem counter-intuitive at first: We find that, in expectation, the proportion of data points in an unknown population-that belong to classes that do not appear in the training data-is almost entirely determined by the number $f_k$ of classes that do appear in the training data the same number of times. While in theory we show that the difference of the induced estimator decays exponentially in the size of the sample, in practice the high variance prevents us from using it directly for an estimator of the sample coverage. However, our precise characterization of the dependency between $f_k$'s induces a large search space of different representations of the expected value, which can be deterministically instantiated as estimators. Hence, we turn to optimization and develop a genetic algorithm that, given only the sample, searches for an estimator with minimal mean-squared error (MSE). In our experiments, our genetic algorithm discovers estimators that have a substantially smaller MSE than the state-of-the-art Good-Turing estimator. This holds for over 96% of runs when there are at least as many samples as classes. Our estimators' MSE is roughly 80% of the Good-Turing estimator's.","sentences":["It might seem counter-intuitive at first: We find that, in expectation, the proportion of data points in an unknown population-that belong to classes that do not appear in the training data-is almost entirely determined by the number $f_k$ of classes that do appear in the training data the same number of times.","While in theory we show that the difference of the induced estimator decays exponentially in the size of the sample, in practice the high variance prevents us from using it directly for an estimator of the sample coverage.","However, our precise characterization of the dependency between $f_k$'s induces a large search space of different representations of the expected value, which can be deterministically instantiated as estimators.","Hence, we turn to optimization and develop a genetic algorithm that, given only the sample, searches for an estimator with minimal mean-squared error (MSE).","In our experiments, our genetic algorithm discovers estimators that have a substantially smaller MSE than the state-of-the-art Good-Turing estimator.","This holds for over 96% of runs when there are at least as many samples as classes.","Our estimators' MSE is roughly 80% of the Good-Turing estimator's."],"url":"http://arxiv.org/abs/2402.05835v1"}
{"created":"2024-02-08 17:09:12","title":"Sparse-VQ Transformer: An FFN-Free Framework with Vector Quantization for Enhanced Time Series Forecasting","abstract":"Time series analysis is vital for numerous applications, and transformers have become increasingly prominent in this domain. Leading methods customize the transformer architecture from NLP and CV, utilizing a patching technique to convert continuous signals into segments. Yet, time series data are uniquely challenging due to significant distribution shifts and intrinsic noise levels. To address these two challenges,we introduce the Sparse Vector Quantized FFN-Free Transformer (Sparse-VQ). Our methodology capitalizes on a sparse vector quantization technique coupled with Reverse Instance Normalization (RevIN) to reduce noise impact and capture sufficient statistics for forecasting, serving as an alternative to the Feed-Forward layer (FFN) in the transformer architecture. Our FFN-free approach trims the parameter count, enhancing computational efficiency and reducing overfitting. Through evaluations across ten benchmark datasets, including the newly introduced CAISO dataset, Sparse-VQ surpasses leading models with a 7.84% and 4.17% decrease in MAE for univariate and multivariate time series forecasting, respectively. Moreover, it can be seamlessly integrated with existing transformer-based models to elevate their performance.","sentences":["Time series analysis is vital for numerous applications, and transformers have become increasingly prominent in this domain.","Leading methods customize the transformer architecture from NLP and CV, utilizing a patching technique to convert continuous signals into segments.","Yet, time series data are uniquely challenging due to significant distribution shifts and intrinsic noise levels.","To address these two challenges,we introduce the Sparse Vector Quantized FFN-Free Transformer (Sparse-VQ).","Our methodology capitalizes on a sparse vector quantization technique coupled with Reverse Instance Normalization (RevIN) to reduce noise impact and capture sufficient statistics for forecasting, serving as an alternative to the Feed-Forward layer (FFN) in the transformer architecture.","Our FFN-free approach trims the parameter count, enhancing computational efficiency and reducing overfitting.","Through evaluations across ten benchmark datasets, including the newly introduced CAISO dataset, Sparse-VQ surpasses leading models with a 7.84% and 4.17% decrease in MAE for univariate and multivariate time series forecasting, respectively.","Moreover, it can be seamlessly integrated with existing transformer-based models to elevate their performance."],"url":"http://arxiv.org/abs/2402.05830v1"}
{"created":"2024-02-08 17:08:08","title":"Limitations of Agents Simulated by Predictive Models","abstract":"There is increasing focus on adapting predictive models into agent-like systems, most notably AI assistants based on language models. We outline two structural reasons for why these models can fail when turned into agents. First, we discuss auto-suggestive delusions. Prior work has shown theoretically that models fail to imitate agents that generated the training data if the agents relied on hidden observations: the hidden observations act as confounding variables, and the models treat actions they generate as evidence for nonexistent observations. Second, we introduce and formally study a related, novel limitation: predictor-policy incoherence. When a model generates a sequence of actions, the model's implicit prediction of the policy that generated those actions can serve as a confounding variable. The result is that models choose actions as if they expect future actions to be suboptimal, causing them to be overly conservative. We show that both of those failures are fixed by including a feedback loop from the environment, that is, re-training the models on their own actions. We give simple demonstrations of both limitations using Decision Transformers and confirm that empirical results agree with our conceptual and formal analysis. Our treatment provides a unifying view of those failure modes, and informs the question of why fine-tuning offline learned policies with online learning makes them more effective.","sentences":["There is increasing focus on adapting predictive models into agent-like systems, most notably AI assistants based on language models.","We outline two structural reasons for why these models can fail when turned into agents.","First, we discuss auto-suggestive delusions.","Prior work has shown theoretically that models fail to imitate agents that generated the training data if the agents relied on hidden observations: the hidden observations act as confounding variables, and the models treat actions they generate as evidence for nonexistent observations.","Second, we introduce and formally study a related, novel limitation: predictor-policy incoherence.","When a model generates a sequence of actions, the model's implicit prediction of the policy that generated those actions can serve as a confounding variable.","The result is that models choose actions as if they expect future actions to be suboptimal, causing them to be overly conservative.","We show that both of those failures are fixed by including a feedback loop from the environment, that is, re-training the models on their own actions.","We give simple demonstrations of both limitations using Decision Transformers and confirm that empirical results agree with our conceptual and formal analysis.","Our treatment provides a unifying view of those failure modes, and informs the question of why fine-tuning offline learned policies with online learning makes them more effective."],"url":"http://arxiv.org/abs/2402.05829v1"}
{"created":"2024-02-08 17:03:10","title":"FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework for Robust Solar Power Forecasting","abstract":"Accurate solar power forecasting is crucial to integrate photovoltaic plants into the electric grid, schedule and secure the power grid safety. This problem becomes more demanding for those newly installed solar plants which lack sufficient data. Current research predominantly relies on historical solar power data or numerical weather prediction in a single-modality format, ignoring the complementary information provided in different modalities. In this paper, we propose a multi-modality fusion framework to integrate historical power data, numerical weather prediction, and satellite images, significantly improving forecast performance. We introduce a vector quantized framework that aligns modalities with varying information densities, striking a balance between integrating sufficient information and averting model overfitting. Our framework demonstrates strong zero-shot forecasting capability, which is especially useful for those newly installed plants. Moreover, we collect and release a multi-modal solar power (MMSP) dataset from real-world plants to further promote the research of multi-modal solar forecasting algorithms. Our extensive experiments show that our model not only operates with robustness but also boosts accuracy in both zero-shot forecasting and scenarios rich with training data, surpassing leading models. We have incorporated it into our eForecaster platform and deployed it for more than 300 solar plants with a capacity of over 15GW.","sentences":["Accurate solar power forecasting is crucial to integrate photovoltaic plants into the electric grid, schedule and secure the power grid safety.","This problem becomes more demanding for those newly installed solar plants which lack sufficient data.","Current research predominantly relies on historical solar power data or numerical weather prediction in a single-modality format, ignoring the complementary information provided in different modalities.","In this paper, we propose a multi-modality fusion framework to integrate historical power data, numerical weather prediction, and satellite images, significantly improving forecast performance.","We introduce a vector quantized framework that aligns modalities with varying information densities, striking a balance between integrating sufficient information and averting model overfitting.","Our framework demonstrates strong zero-shot forecasting capability, which is especially useful for those newly installed plants.","Moreover, we collect and release a multi-modal solar power (MMSP) dataset from real-world plants to further promote the research of multi-modal solar forecasting algorithms.","Our extensive experiments show that our model not only operates with robustness but also boosts accuracy in both zero-shot forecasting and scenarios rich with training data, surpassing leading models.","We have incorporated it into our eForecaster platform and deployed it for more than 300 solar plants with a capacity of over 15GW."],"url":"http://arxiv.org/abs/2402.05823v1"}
{"created":"2024-02-08 16:50:01","title":"Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models","abstract":"The aim of this study is to investigate Machine Unlearning (MU), a burgeoning field focused on addressing concerns related to neural models inadvertently retaining personal or sensitive data. Here, a novel approach is introduced to achieve precise and selective forgetting within language models. Unlike previous methodologies that adopt completely opposing training objectives, this approach aims to mitigate adverse effects on language model performance, particularly in generation tasks. Furthermore, two innovative evaluation metrics are proposed: Sensitive Information Extraction Likelihood (S-EL) and Sensitive Information Memory Accuracy (S-MA), designed to gauge the effectiveness of sensitive information elimination. To reinforce the forgetting framework, an effective method for annotating sensitive scopes is presented, involving both online and offline strategies. The online selection mechanism leverages language probability scores to ensure computational efficiency, while the offline annotation entails a robust two-stage process based on Large Language Models (LLMs).","sentences":["The aim of this study is to investigate Machine Unlearning (MU), a burgeoning field focused on addressing concerns related to neural models inadvertently retaining personal or sensitive data.","Here, a novel approach is introduced to achieve precise and selective forgetting within language models.","Unlike previous methodologies that adopt completely opposing training objectives, this approach aims to mitigate adverse effects on language model performance, particularly in generation tasks.","Furthermore, two innovative evaluation metrics are proposed: Sensitive Information Extraction Likelihood (S-EL) and Sensitive Information Memory Accuracy (S-MA), designed to gauge the effectiveness of sensitive information elimination.","To reinforce the forgetting framework, an effective method for annotating sensitive scopes is presented, involving both online and offline strategies.","The online selection mechanism leverages language probability scores to ensure computational efficiency, while the offline annotation entails a robust two-stage process based on Large Language Models (LLMs)."],"url":"http://arxiv.org/abs/2402.05813v1"}
{"created":"2024-02-08 16:46:26","title":"Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning","abstract":"In this paper, we propose R$^3$: Learning Reasoning through Reverse Curriculum Reinforcement Learning (RL), a novel method that employs only outcome supervision to achieve the benefits of process supervision for large language models. The core challenge in applying RL to complex reasoning is to identify a sequence of actions that result in positive rewards and provide appropriate supervision for optimization. Outcome supervision provides sparse rewards for final results without identifying error locations, whereas process supervision offers step-wise rewards but requires extensive manual annotation. R$^3$ overcomes these limitations by learning from correct demonstrations. Specifically, R$^3$ progressively slides the start state of reasoning from a demonstration's end to its beginning, facilitating easier model exploration at all stages. Thus, R$^3$ establishes a step-wise curriculum, allowing outcome supervision to offer step-level signals and precisely pinpoint errors. Using Llama2-7B, our method surpasses RL baseline on eight reasoning tasks by $4.1$ points on average. Notebaly, in program-based reasoning on GSM8K, it exceeds the baseline by $4.2$ points across three backbone models, and without any extra data, Codellama-7B + R$^3$ performs comparable to larger models or closed-source models.","sentences":["In this paper, we propose R$^3$: Learning Reasoning through Reverse Curriculum Reinforcement Learning (RL), a novel method that employs only outcome supervision to achieve the benefits of process supervision for large language models.","The core challenge in applying RL to complex reasoning is to identify a sequence of actions that result in positive rewards and provide appropriate supervision for optimization.","Outcome supervision provides sparse rewards for final results without identifying error locations, whereas process supervision offers step-wise rewards but requires extensive manual annotation.","R$^3$ overcomes these limitations by learning from correct demonstrations.","Specifically, R$^3$ progressively slides the start state of reasoning from a demonstration's end to its beginning, facilitating easier model exploration at all stages.","Thus, R$^3$ establishes a step-wise curriculum, allowing outcome supervision to offer step-level signals and precisely pinpoint errors.","Using Llama2-7B, our method surpasses RL baseline on eight reasoning tasks by $4.1$ points on average.","Notebaly, in program-based reasoning on GSM8K, it exceeds the baseline by $4.2$ points across three backbone models, and without any extra data, Codellama-7B + R$^3$ performs comparable to larger models or closed-source models."],"url":"http://arxiv.org/abs/2402.05808v1"}
{"created":"2024-02-08 16:38:13","title":"Visual Harmony: Text-Visual Interplay in Circular Infographics","abstract":"Infographics are visual representations designed for efficient and effective communication of data and knowledge. One crucial aspect of infographic design is the interplay between text and visual elements, particularly in circular visualizations where the textual descriptions can either be embedded within the graphics or placed adjacent to the visual representation. While several studies have examined text layout design in visualizations in general, the text-visual interplay in infographics and its subsequent perceptual effects remain underexplored. To address this, our study investigates how varying text placement and descriptiveness impact pleasantness, comprehension and overall memorability in the infographics viewing experience. We recruited 30 participants and presented them with a collection of 15 infographics across a diverse set of topics, including media and public events, health and nutrition, science and research, and sustainability. The text placement (embed, side-to-side) and descriptiveness (simplistic, normal, descriptive) were systematically manipulated, resulting in a total of six experimental conditions. Our key findings indicate that text placement can significantly influence the memorability of infographics, whereas descriptiveness can significantly impact the pleasantness of the viewing experience. Embedding text placement and simplistic text can potentially contribute to more effective infographic designs. These results offer valuable insights for infographic designers, contributing to the creation of more effective and memorable visual representations.","sentences":["Infographics are visual representations designed for efficient and effective communication of data and knowledge.","One crucial aspect of infographic design is the interplay between text and visual elements, particularly in circular visualizations where the textual descriptions can either be embedded within the graphics or placed adjacent to the visual representation.","While several studies have examined text layout design in visualizations in general, the text-visual interplay in infographics and its subsequent perceptual effects remain underexplored.","To address this, our study investigates how varying text placement and descriptiveness impact pleasantness, comprehension and overall memorability in the infographics viewing experience.","We recruited 30 participants and presented them with a collection of 15 infographics across a diverse set of topics, including media and public events, health and nutrition, science and research, and sustainability.","The text placement (embed, side-to-side) and descriptiveness (simplistic, normal, descriptive) were systematically manipulated, resulting in a total of six experimental conditions.","Our key findings indicate that text placement can significantly influence the memorability of infographics, whereas descriptiveness can significantly impact the pleasantness of the viewing experience.","Embedding text placement and simplistic text can potentially contribute to more effective infographic designs.","These results offer valuable insights for infographic designers, contributing to the creation of more effective and memorable visual representations."],"url":"http://arxiv.org/abs/2402.05798v1"}
{"created":"2024-02-08 16:37:04","title":"TaE: Task-aware Expandable Representation for Long Tail Class Incremental Learning","abstract":"Class-incremental learning (CIL) aims to train classifiers that learn new classes without forgetting old ones. Most CIL methods focus on balanced data distribution for each task, overlooking real-world long-tailed distributions. Therefore, Long-Tailed Class-Incremental Learning (LT-CIL) has been introduced, which trains on data where head classes have more samples than tail classes. Existing methods mainly focus on preserving representative samples from previous classes to combat catastrophic forgetting. Recently, dynamic network algorithms frozen old network structures and expanded new ones, achieving significant performance. However, with the introduction of the long-tail problem, merely extending task-specific parameters can lead to miscalibrated predictions, while expanding the entire model results in an explosion of memory size. To address these issues, we introduce a novel Task-aware Expandable (TaE) framework, dynamically allocating and updating task-specific trainable parameters to learn diverse representations from each incremental task, while resisting forgetting through the majority of frozen model parameters. To further encourage the class-specific feature representation, we develop a Centroid-Enhanced (CEd) method to guide the update of these task-aware parameters. This approach is designed to adaptively minimize the distances between intra-class features while simultaneously maximizing the distances between inter-class features across all seen classes. The utility of this centroid-enhanced method extends to all \"training from scratch\" CIL algorithms. Extensive experiments were conducted on CIFAR-100 and ImageNet100 under different settings, which demonstrates that TaE achieves state-of-the-art performance.","sentences":["Class-incremental learning (CIL) aims to train classifiers that learn new classes without forgetting old ones.","Most CIL methods focus on balanced data distribution for each task, overlooking real-world long-tailed distributions.","Therefore, Long-Tailed Class-Incremental Learning (LT-CIL) has been introduced, which trains on data where head classes have more samples than tail classes.","Existing methods mainly focus on preserving representative samples from previous classes to combat catastrophic forgetting.","Recently, dynamic network algorithms frozen old network structures and expanded new ones, achieving significant performance.","However, with the introduction of the long-tail problem, merely extending task-specific parameters can lead to miscalibrated predictions, while expanding the entire model results in an explosion of memory size.","To address these issues, we introduce a novel Task-aware Expandable (TaE) framework, dynamically allocating and updating task-specific trainable parameters to learn diverse representations from each incremental task, while resisting forgetting through the majority of frozen model parameters.","To further encourage the class-specific feature representation, we develop a Centroid-Enhanced (CEd) method to guide the update of these task-aware parameters.","This approach is designed to adaptively minimize the distances between intra-class features while simultaneously maximizing the distances between inter-class features across all seen classes.","The utility of this centroid-enhanced method extends to all \"training from scratch\" CIL algorithms.","Extensive experiments were conducted on CIFAR-100 and ImageNet100 under different settings, which demonstrates that TaE achieves state-of-the-art performance."],"url":"http://arxiv.org/abs/2402.05797v1"}
{"created":"2024-02-08 16:36:11","title":"Phonetically rich corpus construction for a low-resourced language","abstract":"Speech technologies rely on capturing a speaker's voice variability while obtaining comprehensive language information. Textual prompts and sentence selection methods have been proposed in the literature to comprise such adequate phonetic data, referred to as a phonetically rich \\textit{corpus}. However, they are still insufficient for acoustic modeling, especially critical for languages with limited resources. Hence, this paper proposes a novel approach and outlines the methodological aspects required to create a \\textit{corpus} with broad phonetic coverage for a low-resourced language, Brazilian Portuguese. Our methodology includes text dataset collection up to a sentence selection algorithm based on triphone distribution. Furthermore, we propose a new phonemic classification according to acoustic-articulatory speech features since the absolute number of distinct triphones, or low-probability triphones, does not guarantee an adequate representation of every possible combination. Using our algorithm, we achieve a 55.8\\% higher percentage of distinct triphones -- for samples of similar size -- while the currently available phonetic-rich corpus, CETUC and TTS-Portuguese, 12.6\\% and 12.3\\% in comparison to a non-phonetically rich dataset.","sentences":["Speech technologies rely on capturing a speaker's voice variability while obtaining comprehensive language information.","Textual prompts and sentence selection methods have been proposed in the literature to comprise such adequate phonetic data, referred to as a phonetically rich \\textit{corpus}.","However, they are still insufficient for acoustic modeling, especially critical for languages with limited resources.","Hence, this paper proposes a novel approach and outlines the methodological aspects required to create a \\textit{corpus} with broad phonetic coverage for a low-resourced language, Brazilian Portuguese.","Our methodology includes text dataset collection up to a sentence selection algorithm based on triphone distribution.","Furthermore, we propose a new phonemic classification according to acoustic-articulatory speech features since the absolute number of distinct triphones, or low-probability triphones, does not guarantee an adequate representation of every possible combination.","Using our algorithm, we achieve a 55.8\\% higher percentage of distinct triphones -- for samples of similar size -- while the currently available phonetic-rich corpus, CETUC and TTS-Portuguese, 12.6\\% and 12.3\\% in comparison to a non-phonetically rich dataset."],"url":"http://arxiv.org/abs/2402.05794v1"}
{"created":"2024-02-08 16:23:29","title":"Limits of Transformer Language Models on Algorithmic Learning","abstract":"We analyze the capabilities of Transformer language models on learning discrete algorithms. To this end, we introduce two new tasks demanding the composition of several discrete sub-tasks. On both training LLaMA models from scratch and prompting on GPT-4 and Gemini we measure learning compositions of learned primitives. We observe that the compositional capabilities of state-of-the-art Transformer language models are very limited and sample-wise scale worse than relearning all sub-tasks for a new algorithmic composition. We also present a theorem in complexity theory, showing that gradient descent on memorizing feedforward models can be exponentially data inefficient.","sentences":["We analyze the capabilities of Transformer language models on learning discrete algorithms.","To this end, we introduce two new tasks demanding the composition of several discrete sub-tasks.","On both training LLaMA models from scratch and prompting on GPT-4 and Gemini we measure learning compositions of learned primitives.","We observe that the compositional capabilities of state-of-the-art Transformer language models are very limited and sample-wise scale worse than relearning all sub-tasks for a new algorithmic composition.","We also present a theorem in complexity theory, showing that gradient descent on memorizing feedforward models can be exponentially data inefficient."],"url":"http://arxiv.org/abs/2402.05785v1"}
{"created":"2024-02-08 16:01:24","title":"Stable Autonomous Flow Matching","abstract":"In contexts where data samples represent a physically stable state, it is often assumed that the data points represent the local minima of an energy landscape. In control theory, it is well-known that energy can serve as an effective Lyapunov function. Despite this, connections between control theory and generative models in the literature are sparse, even though there are several machine learning applications with physically stable data points. In this paper, we focus on such data and a recent class of deep generative models called flow matching. We apply tools of stochastic stability for time-independent systems to flow matching models. In doing so, we characterize the space of flow matching models that are amenable to this treatment, as well as draw connections to other control theory principles. We demonstrate our theoretical results on two examples.","sentences":["In contexts where data samples represent a physically stable state, it is often assumed that the data points represent the local minima of an energy landscape.","In control theory, it is well-known that energy can serve as an effective Lyapunov function.","Despite this, connections between control theory and generative models in the literature are sparse, even though there are several machine learning applications with physically stable data points.","In this paper, we focus on such data and a recent class of deep generative models called flow matching.","We apply tools of stochastic stability for time-independent systems to flow matching models.","In doing so, we characterize the space of flow matching models that are amenable to this treatment, as well as draw connections to other control theory principles.","We demonstrate our theoretical results on two examples."],"url":"http://arxiv.org/abs/2402.05774v1"}
{"created":"2024-02-08 15:41:48","title":"Latent variable model for high-dimensional point process with structured missingness","abstract":"Longitudinal data are important in numerous fields, such as healthcare, sociology and seismology, but real-world datasets present notable challenges for practitioners because they can be high-dimensional, contain structured missingness patterns, and measurement time points can be governed by an unknown stochastic process. While various solutions have been suggested, the majority of them have been designed to account for only one of these challenges. In this work, we propose a flexible and efficient latent-variable model that is capable of addressing all these limitations. Our approach utilizes Gaussian processes to capture temporal correlations between samples and their associated missingness masks as well as to model the underlying point process. We construct our model as a variational autoencoder together with deep neural network parameterised encoder and decoder models, and develop a scalable amortised variational inference approach for efficient model training. We demonstrate competitive performance using both simulated and real datasets.","sentences":["Longitudinal data are important in numerous fields, such as healthcare, sociology and seismology, but real-world datasets present notable challenges for practitioners because they can be high-dimensional, contain structured missingness patterns, and measurement time points can be governed by an unknown stochastic process.","While various solutions have been suggested, the majority of them have been designed to account for only one of these challenges.","In this work, we propose a flexible and efficient latent-variable model that is capable of addressing all these limitations.","Our approach utilizes Gaussian processes to capture temporal correlations between samples and their associated missingness masks as well as to model the underlying point process.","We construct our model as a variational autoencoder together with deep neural network parameterised encoder and decoder models, and develop a scalable amortised variational inference approach for efficient model training.","We demonstrate competitive performance using both simulated and real datasets."],"url":"http://arxiv.org/abs/2402.05758v1"}
{"created":"2024-02-08 15:33:09","title":"Generalized Preference Optimization: A Unified Approach to Offline Alignment","abstract":"Offline preference optimization allows fine-tuning large models directly from offline data, and has proved effective in recent alignment practices. We propose generalized preference optimization (GPO), a family of offline losses parameterized by a general class of convex functions. GPO enables a unified view over preference optimization, encompassing existing algorithms such as DPO, IPO and SLiC as special cases, while naturally introducing new variants. The GPO framework also sheds light on how offline algorithms enforce regularization, through the design of the convex function that defines the loss. Our analysis and experiments reveal the connections and subtle differences between the offline regularization and the KL divergence regularization intended by the canonical RLHF formulation. In all, our results present new algorithmic toolkits and empirical insights to alignment practitioners.","sentences":["Offline preference optimization allows fine-tuning large models directly from offline data, and has proved effective in recent alignment practices.","We propose generalized preference optimization (GPO), a family of offline losses parameterized by a general class of convex functions.","GPO enables a unified view over preference optimization, encompassing existing algorithms such as DPO, IPO and SLiC as special cases, while naturally introducing new variants.","The GPO framework also sheds light on how offline algorithms enforce regularization, through the design of the convex function that defines the loss.","Our analysis and experiments reveal the connections and subtle differences between the offline regularization and the KL divergence regularization intended by the canonical RLHF formulation.","In all, our results present new algorithmic toolkits and empirical insights to alignment practitioners."],"url":"http://arxiv.org/abs/2402.05749v1"}
{"created":"2024-02-08 15:32:22","title":"Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method","abstract":"In the context of rapid advancements in industrial automation, vision-based robotic grasping plays an increasingly crucial role. In order to enhance visual recognition accuracy, the utilization of large-scale datasets is imperative for training models to acquire implicit knowledge related to the handling of various objects. Creating datasets from scratch is a time and labor-intensive process. Moreover, existing datasets often contain errors due to automated annotations aimed at expediency, making the improvement of these datasets a substantial research challenge. Consequently, several issues have been identified in the annotation of grasp bounding boxes within the popular Jacquard Grasp. We propose utilizing a Human-In-The-Loop(HIL) method to enhance dataset quality. This approach relies on backbone deep learning networks to predict object positions and orientations for robotic grasping. Predictions with Intersection over Union (IOU) values below 0.2 undergo an assessment by human operators. After their evaluation, the data is categorized into False Negatives(FN) and True Negatives(TN). FN are then subcategorized into either missing annotations or catastrophic labeling errors. Images lacking labels are augmented with valid grasp bounding box information, whereas images afflicted by catastrophic labeling errors are completely removed. The open-source tool Labelbee was employed for 53,026 iterations of HIL dataset enhancement, leading to the removal of 2,884 images and the incorporation of ground truth information for 30,292 images. The enhanced dataset, named the Jacquard V2 Grasping Dataset, served as the training data for a range of neural networks.","sentences":["In the context of rapid advancements in industrial automation, vision-based robotic grasping plays an increasingly crucial role.","In order to enhance visual recognition accuracy, the utilization of large-scale datasets is imperative for training models to acquire implicit knowledge related to the handling of various objects.","Creating datasets from scratch is a time and labor-intensive process.","Moreover, existing datasets often contain errors due to automated annotations aimed at expediency, making the improvement of these datasets a substantial research challenge.","Consequently, several issues have been identified in the annotation of grasp bounding boxes within the popular Jacquard Grasp.","We propose utilizing a Human-In-The-Loop(HIL) method to enhance dataset quality.","This approach relies on backbone deep learning networks to predict object positions and orientations for robotic grasping.","Predictions with Intersection over Union (IOU) values below 0.2 undergo an assessment by human operators.","After their evaluation, the data is categorized into False Negatives(FN) and True Negatives(TN).","FN are then subcategorized into either missing annotations or catastrophic labeling errors.","Images lacking labels are augmented with valid grasp bounding box information, whereas images afflicted by catastrophic labeling errors are completely removed.","The open-source tool Labelbee was employed for 53,026 iterations of HIL dataset enhancement, leading to the removal of 2,884 images and the incorporation of ground truth information for 30,292 images.","The enhanced dataset, named the Jacquard V2 Grasping Dataset, served as the training data for a range of neural networks."],"url":"http://arxiv.org/abs/2402.05747v1"}
{"created":"2024-02-08 15:26:28","title":"Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents","abstract":"Scene simulation in autonomous driving has gained significant attention because of its huge potential for generating customized data. However, existing editable scene simulation approaches face limitations in terms of user interaction efficiency, multi-camera photo-realistic rendering and external digital assets integration. To address these challenges, this paper introduces ChatSim, the first system that enables editable photo-realistic 3D driving scene simulations via natural language commands with external digital assets. To enable editing with high command flexibility,~ChatSim leverages a large language model (LLM) agent collaboration framework. To generate photo-realistic outcomes, ChatSim employs a novel multi-camera neural radiance field method. Furthermore, to unleash the potential of extensive high-quality digital assets, ChatSim employs a novel multi-camera lighting estimation method to achieve scene-consistent assets' rendering. Our experiments on Waymo Open Dataset demonstrate that ChatSim can handle complex language commands and generate corresponding photo-realistic scene videos.","sentences":["Scene simulation in autonomous driving has gained significant attention because of its huge potential for generating customized data.","However, existing editable scene simulation approaches face limitations in terms of user interaction efficiency, multi-camera photo-realistic rendering and external digital assets integration.","To address these challenges, this paper introduces ChatSim, the first system that enables editable photo-realistic 3D driving scene simulations via natural language commands with external digital assets.","To enable editing with high command flexibility,~ChatSim leverages a large language model (LLM) agent collaboration framework.","To generate photo-realistic outcomes, ChatSim employs a novel multi-camera neural radiance field method.","Furthermore, to unleash the potential of extensive high-quality digital assets, ChatSim employs a novel multi-camera lighting estimation method to achieve scene-consistent assets' rendering.","Our experiments on Waymo Open Dataset demonstrate that ChatSim can handle complex language commands and generate corresponding photo-realistic scene videos."],"url":"http://arxiv.org/abs/2402.05746v1"}
{"created":"2024-02-08 15:19:50","title":"Real-World Robot Applications of Foundation Models: A Review","abstract":"Recent developments in foundation models, like Large Language Models (LLMs) and Vision-Language Models (VLMs), trained on extensive data, facilitate flexible application across different tasks and modalities. Their impact spans various fields, including healthcare, education, and robotics. This paper provides an overview of the practical application of foundation models in real-world robotics, with a primary emphasis on the replacement of specific components within existing robot systems. The summary encompasses the perspective of input-output relationships in foundation models, as well as their role in perception, motion planning, and control within the field of robotics. This paper concludes with a discussion of future challenges and implications for practical robot applications.","sentences":["Recent developments in foundation models, like Large Language Models (LLMs) and Vision-Language Models (VLMs), trained on extensive data, facilitate flexible application across different tasks and modalities.","Their impact spans various fields, including healthcare, education, and robotics.","This paper provides an overview of the practical application of foundation models in real-world robotics, with a primary emphasis on the replacement of specific components within existing robot systems.","The summary encompasses the perspective of input-output relationships in foundation models, as well as their role in perception, motion planning, and control within the field of robotics.","This paper concludes with a discussion of future challenges and implications for practical robot applications."],"url":"http://arxiv.org/abs/2402.05741v1"}
{"created":"2024-02-08 15:18:54","title":"CounterCLR: Counterfactual Contrastive Learning with Non-random Missing Data in Recommendation","abstract":"Recommender systems are designed to learn user preferences from observed feedback and comprise many fundamental tasks, such as rating prediction and post-click conversion rate (pCVR) prediction. However, the observed feedback usually suffer from two issues: selection bias and data sparsity, where biased and insufficient feedback seriously degrade the performance of recommender systems in terms of accuracy and ranking. Existing solutions for handling the issues, such as data imputation and inverse propensity score, are highly susceptible to additional trained imputation or propensity models. In this work, we propose a novel counterfactual contrastive learning framework for recommendation, named CounterCLR, to tackle the problem of non-random missing data by exploiting the advances in contrast learning. Specifically, the proposed CounterCLR employs a deep representation network, called CauNet, to infer non-random missing data in recommendations and perform user preference modeling by further introducing a self-supervised contrastive learning task. Our CounterCLR mitigates the selection bias problem without the need for additional models or estimators, while also enhancing the generalization ability in cases of sparse data. Experiments on real-world datasets demonstrate the effectiveness and superiority of our method.","sentences":["Recommender systems are designed to learn user preferences from observed feedback and comprise many fundamental tasks, such as rating prediction and post-click conversion rate (pCVR) prediction.","However, the observed feedback usually suffer from two issues: selection bias and data sparsity, where biased and insufficient feedback seriously degrade the performance of recommender systems in terms of accuracy and ranking.","Existing solutions for handling the issues, such as data imputation and inverse propensity score, are highly susceptible to additional trained imputation or propensity models.","In this work, we propose a novel counterfactual contrastive learning framework for recommendation, named CounterCLR, to tackle the problem of non-random missing data by exploiting the advances in contrast learning.","Specifically, the proposed CounterCLR employs a deep representation network, called CauNet, to infer non-random missing data in recommendations and perform user preference modeling by further introducing a self-supervised contrastive learning task.","Our CounterCLR mitigates the selection bias problem without the need for additional models or estimators, while also enhancing the generalization ability in cases of sparse data.","Experiments on real-world datasets demonstrate the effectiveness and superiority of our method."],"url":"http://arxiv.org/abs/2402.05740v1"}
{"created":"2024-02-08 15:15:09","title":"Implicit Bias and Fast Convergence Rates for Self-attention","abstract":"Self-attention, the core mechanism of transformers, distinguishes them from traditional neural networks and drives their outstanding performance. Towards developing the fundamental optimization principles of self-attention, we investigate the implicit bias of gradient descent (GD) in training a self-attention layer with fixed linear decoder in binary classification. Drawing inspiration from the study of GD in linear logistic regression over separable data, recent work demonstrates that as the number of iterations $t$ approaches infinity, the key-query matrix $W_t$ converges locally (with respect to the initialization direction) to a hard-margin SVM solution $W_{mm}$. Our work enhances this result in four aspects. Firstly, we identify non-trivial data settings for which convergence is provably global, thus shedding light on the optimization landscape. Secondly, we provide the first finite-time convergence rate for $W_t$ to $W_{mm}$, along with quantifying the rate of sparsification in the attention map. Thirdly, through an analysis of normalized GD and Polyak step-size, we demonstrate analytically that adaptive step-size rules can accelerate the convergence of self-attention. Additionally, we remove the restriction of prior work on a fixed linear decoder. Our results reinforce the implicit-bias perspective of self-attention and strengthen its connections to implicit-bias in linear logistic regression, despite the intricate non-convex nature of the former.","sentences":["Self-attention, the core mechanism of transformers, distinguishes them from traditional neural networks and drives their outstanding performance.","Towards developing the fundamental optimization principles of self-attention, we investigate the implicit bias of gradient descent (GD) in training a self-attention layer with fixed linear decoder in binary classification.","Drawing inspiration from the study of GD in linear logistic regression over separable data, recent work demonstrates that as the number of iterations $t$ approaches infinity, the key-query matrix $W_t$ converges locally (with respect to the initialization direction) to a hard-margin SVM solution $W_{mm}$. Our work enhances this result in four aspects.","Firstly, we identify non-trivial data settings for which convergence is provably global, thus shedding light on the optimization landscape.","Secondly, we provide the first finite-time convergence rate for $W_t$ to $W_{mm}$, along with quantifying the rate of sparsification in the attention map.","Thirdly, through an analysis of normalized GD and Polyak step-size, we demonstrate analytically that adaptive step-size rules can accelerate the convergence of self-attention.","Additionally, we remove the restriction of prior work on a fixed linear decoder.","Our results reinforce the implicit-bias perspective of self-attention and strengthen its connections to implicit-bias in linear logistic regression, despite the intricate non-convex nature of the former."],"url":"http://arxiv.org/abs/2402.05738v1"}
{"created":"2024-02-08 15:14:39","title":"Blockchain Based Residential Smart Rent","abstract":"The real estate market includes complex and inefficient mediation processes. Renting a property envolves multiple entities with different responsibilities and interests. Therefore it is imperative to establish a trustful relationship between parties through intermediaries such as notaries, banks or real estate agencies to avoid eventual disputes. Although an intermediary ensures trust, the current process still has some drawbacks concerning efficiency, costs, transparency, bureaucracy and data security. The blockchain technology aims to reduce this issues by providing transparent and secure real estate transactions. We propose a GDPR compliant blockchain-based residential smart rental platform, designed to allow both landlords and tenants to establish rental contracts and make rental payments securely.","sentences":["The real estate market includes complex and inefficient mediation processes.","Renting a property envolves multiple entities with different responsibilities and interests.","Therefore it is imperative to establish a trustful relationship between parties through intermediaries such as notaries, banks or real estate agencies to avoid eventual disputes.","Although an intermediary ensures trust, the current process still has some drawbacks concerning efficiency, costs, transparency, bureaucracy and data security.","The blockchain technology aims to reduce this issues by providing transparent and secure real estate transactions.","We propose a GDPR compliant blockchain-based residential smart rental platform, designed to allow both landlords and tenants to establish rental contracts and make rental payments securely."],"url":"http://arxiv.org/abs/2402.05737v1"}
{"created":"2024-02-08 14:40:32","title":"Hidden in Plain Sight: Undetectable Adversarial Bias Attacks on Vulnerable Patient Populations","abstract":"The proliferation of artificial intelligence (AI) in radiology has shed light on the risk of deep learning (DL) models exacerbating clinical biases towards vulnerable patient populations. While prior literature has focused on quantifying biases exhibited by trained DL models, demographically targeted adversarial bias attacks on DL models and its implication in the clinical environment remains an underexplored field of research in medical imaging. In this work, we demonstrate that demographically targeted label poisoning attacks can introduce adversarial underdiagnosis bias in DL models and degrade performance on underrepresented groups without impacting overall model performance. Moreover, our results across multiple performance metrics and demographic groups like sex, age, and their intersectional subgroups indicate that a group's vulnerability to undetectable adversarial bias attacks is directly correlated with its representation in the model's training data.","sentences":["The proliferation of artificial intelligence (AI) in radiology has shed light on the risk of deep learning (DL) models exacerbating clinical biases towards vulnerable patient populations.","While prior literature has focused on quantifying biases exhibited by trained DL models, demographically targeted adversarial bias attacks on DL models and its implication in the clinical environment remains an underexplored field of research in medical imaging.","In this work, we demonstrate that demographically targeted label poisoning attacks can introduce adversarial underdiagnosis bias in DL models and degrade performance on underrepresented groups without impacting overall model performance.","Moreover, our results across multiple performance metrics and demographic groups like sex, age, and their intersectional subgroups indicate that a group's vulnerability to undetectable adversarial bias attacks is directly correlated with its representation in the model's training data."],"url":"http://arxiv.org/abs/2402.05713v1"}
{"created":"2024-02-08 14:39:16","title":"DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer","abstract":"Speech-driven 3D facial animation is important for many multimedia applications. Recent work has shown promise in using either Diffusion models or Transformer architectures for this task. However, their mere aggregation does not lead to improved performance. We suspect this is due to a shortage of paired audio-4D data, which is crucial for the Transformer to effectively perform as a denoiser within the Diffusion framework. To tackle this issue, we present DiffSpeaker, a Transformer-based network equipped with novel biased conditional attention modules. These modules serve as substitutes for the traditional self/cross-attention in standard Transformers, incorporating thoughtfully designed biases that steer the attention mechanisms to concentrate on both the relevant task-specific and diffusion-related conditions. We also explore the trade-off between accurate lip synchronization and non-verbal facial expressions within the Diffusion paradigm. Experiments show our model not only achieves state-of-the-art performance on existing benchmarks, but also fast inference speed owing to its ability to generate facial motions in parallel.","sentences":["Speech-driven 3D facial animation is important for many multimedia applications.","Recent work has shown promise in using either Diffusion models or Transformer architectures for this task.","However, their mere aggregation does not lead to improved performance.","We suspect this is due to a shortage of paired audio-4D data, which is crucial for the Transformer to effectively perform as a denoiser within the Diffusion framework.","To tackle this issue, we present DiffSpeaker, a Transformer-based network equipped with novel biased conditional attention modules.","These modules serve as substitutes for the traditional self/cross-attention in standard Transformers, incorporating thoughtfully designed biases that steer the attention mechanisms to concentrate on both the relevant task-specific and diffusion-related conditions.","We also explore the trade-off between accurate lip synchronization and non-verbal facial expressions within the Diffusion paradigm.","Experiments show our model not only achieves state-of-the-art performance on existing benchmarks, but also fast inference speed owing to its ability to generate facial motions in parallel."],"url":"http://arxiv.org/abs/2402.05712v1"}
{"created":"2024-02-08 14:38:29","title":"Using Changeset Descriptions as a Data Source to Assist Feature Location","abstract":"Feature location attempts to assist developers in discovering functionality in source code. Many textual feature location techniques utilize information retrieval and rely on comments and identifiers of source code to describe software entities. An interesting alternative would be to employ the changeset descriptions of the code altered in that changeset as a data source to describe such software entities. To investigate this we implement a technique utilizing changeset descriptions and conduct an empirical study to observe this technique's overall performance. Moreover, we study how the granularity (i.e. file or method level of software entities) and changeset range inclusion (i.e. most recent or all historical changesets) affect such an approach. The results of a preliminary study with Rhino and Mylyn.Tasks systems suggest that the approach could lead to a potentially efficient feature location technique. They also suggest that it is advantageous in terms of the effort to configure the technique at method level granularity and that older changesets from older systems may reduce the effectiveness of the technique.","sentences":["Feature location attempts to assist developers in discovering functionality in source code.","Many textual feature location techniques utilize information retrieval and rely on comments and identifiers of source code to describe software entities.","An interesting alternative would be to employ the changeset descriptions of the code altered in that changeset as a data source to describe such software entities.","To investigate this we implement a technique utilizing changeset descriptions and conduct an empirical study to observe this technique's overall performance.","Moreover, we study how the granularity (i.e. file or method level of software entities) and changeset range inclusion (i.e. most recent or all historical changesets) affect such an approach.","The results of a preliminary study with Rhino and Mylyn.","Tasks systems suggest that the approach could lead to a potentially efficient feature location technique.","They also suggest that it is advantageous in terms of the effort to configure the technique at method level granularity and that older changesets from older systems may reduce the effectiveness of the technique."],"url":"http://arxiv.org/abs/2402.05711v1"}
{"created":"2024-02-08 14:37:58","title":"Exploring the Nostr Ecosystem: A Study of Decentralization and Resilience","abstract":"Nostr is an open decentralized social network launched in 2022. From a user's perspective, it is similar to a micro-blogging service like Twitter. However, the underlying infrastructure is very different, and Nostr boasts a range of unique features that set it apart. Nostr introduces the concept of relays, which act as open storage servers that receive, store, and distribute user posts. Each user is uniquely identified by a public key, ensuring authenticity of posts through digital signatures. Consequently, users are able to securely send and receive posts through various relays, which frees them from single-server reliance and enhances post availability (e.g., making it more censorship resistant). The Nostr ecosystem has garnered significant attention, boasting 4 million users and 60 million posts in just 2 years. To understand its characteristics and challenges, we conduct the first large-scale measurement of the Nostr ecosystem, spanning from July 1, 2023, to December 31, 2023. Our study focuses on two key aspects: Nostr relays and post replication strategies. We find that Nostr achieves superior decentralization compared to traditional Fediverse applications. However, relay availability remains a challenge, where financial sustainability (particularly for free-to-use relays) emerges as a contributing factor. We also find that the replication of posts across relays enhances post availability but introduces significant overhead. To address this, we propose two design innovations. One to control the number of post replications, and another to reduce the overhead during post retrieval. Via data-driven evaluations, we demonstrate their effectiveness without negatively impacting the system.","sentences":["Nostr is an open decentralized social network launched in 2022.","From a user's perspective, it is similar to a micro-blogging service like Twitter.","However, the underlying infrastructure is very different, and Nostr boasts a range of unique features that set it apart.","Nostr introduces the concept of relays, which act as open storage servers that receive, store, and distribute user posts.","Each user is uniquely identified by a public key, ensuring authenticity of posts through digital signatures.","Consequently, users are able to securely send and receive posts through various relays, which frees them from single-server reliance and enhances post availability (e.g., making it more censorship resistant).","The Nostr ecosystem has garnered significant attention, boasting 4 million users and 60 million posts in just 2 years.","To understand its characteristics and challenges, we conduct the first large-scale measurement of the Nostr ecosystem, spanning from July 1, 2023, to December 31, 2023.","Our study focuses on two key aspects: Nostr relays and post replication strategies.","We find that Nostr achieves superior decentralization compared to traditional Fediverse applications.","However, relay availability remains a challenge, where financial sustainability (particularly for free-to-use relays) emerges as a contributing factor.","We also find that the replication of posts across relays enhances post availability but introduces significant overhead.","To address this, we propose two design innovations.","One to control the number of post replications, and another to reduce the overhead during post retrieval.","Via data-driven evaluations, we demonstrate their effectiveness without negatively impacting the system."],"url":"http://arxiv.org/abs/2402.05709v1"}
{"created":"2024-02-08 14:27:34","title":"Offline Risk-sensitive RL with Partial Observability to Enhance Performance in Human-Robot Teaming","abstract":"The integration of physiological computing into mixed-initiative human-robot interaction systems offers valuable advantages in autonomous task allocation by incorporating real-time features as human state observations into the decision-making system. This approach may alleviate the cognitive load on human operators by intelligently allocating mission tasks between agents. Nevertheless, accommodating a diverse pool of human participants with varying physiological and behavioral measurements presents a substantial challenge. To address this, resorting to a probabilistic framework becomes necessary, given the inherent uncertainty and partial observability on the human's state. Recent research suggests to learn a Partially Observable Markov Decision Process (POMDP) model from a data set of previously collected experiences that can be solved using Offline Reinforcement Learning (ORL) methods. In the present work, we not only highlight the potential of partially observable representations and physiological measurements to improve human operator state estimation and performance, but also enhance the overall mission effectiveness of a human-robot team. Importantly, as the fixed data set may not contain enough information to fully represent complex stochastic processes, we propose a method to incorporate model uncertainty, thus enabling risk-sensitive sequential decision-making. Experiments were conducted with a group of twenty-six human participants within a simulated robot teleoperation environment, yielding empirical evidence of the method's efficacy. The obtained adaptive task allocation policy led to statistically significant higher scores than the one that was used to collect the data set, allowing for generalization across diverse participants also taking into account risk-sensitive metrics.","sentences":["The integration of physiological computing into mixed-initiative human-robot interaction systems offers valuable advantages in autonomous task allocation by incorporating real-time features as human state observations into the decision-making system.","This approach may alleviate the cognitive load on human operators by intelligently allocating mission tasks between agents.","Nevertheless, accommodating a diverse pool of human participants with varying physiological and behavioral measurements presents a substantial challenge.","To address this, resorting to a probabilistic framework becomes necessary, given the inherent uncertainty and partial observability on the human's state.","Recent research suggests to learn a Partially Observable Markov Decision Process (POMDP) model from a data set of previously collected experiences that can be solved using Offline Reinforcement Learning (ORL) methods.","In the present work, we not only highlight the potential of partially observable representations and physiological measurements to improve human operator state estimation and performance, but also enhance the overall mission effectiveness of a human-robot team.","Importantly, as the fixed data set may not contain enough information to fully represent complex stochastic processes, we propose a method to incorporate model uncertainty, thus enabling risk-sensitive sequential decision-making.","Experiments were conducted with a group of twenty-six human participants within a simulated robot teleoperation environment, yielding empirical evidence of the method's efficacy.","The obtained adaptive task allocation policy led to statistically significant higher scores than the one that was used to collect the data set, allowing for generalization across diverse participants also taking into account risk-sensitive metrics."],"url":"http://arxiv.org/abs/2402.05703v1"}
{"created":"2024-02-08 14:21:03","title":"Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation","abstract":"Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that our method outperforms over 10 baselines across 4 benchmarks. As evidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning with human values. Code is available at https://github.com/pangxianghe/MATRIX.","sentences":["Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse.","Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation.","To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding.","MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself.","To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed.","We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions.","Finally, extensive experiments validate that our method outperforms over 10 baselines across 4 benchmarks.","As evidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning with human values.","Code is available at https://github.com/pangxianghe/MATRIX."],"url":"http://arxiv.org/abs/2402.05699v1"}
{"created":"2024-02-08 14:19:47","title":"Evolving AI for Wellness: Dynamic and Personalized Real-time Loneliness Detection Using Passive Sensing","abstract":"Loneliness is a growing health concern as it can lead to depression and other associated mental health problems for people who experience feelings of loneliness over prolonged periods of time. Utilizing passive sensing methods that use smartphone and wearable sensor data to capture daily behavioural patterns offers a promising approach for the early detection of loneliness. Given the subjective nature of loneliness and people's varying daily routines, past detection approaches using machine learning models often face challenges with effectively detecting loneliness. This paper proposes a methodologically novel approach, particularly developing a loneliness detection system that evolves over time, adapts to new data, and provides real-time detection. Our study utilized the Globem dataset, a comprehensive collection of passive sensing data acquired over 10 weeks from university students. The base of our approach is the continuous identification and refinement of similar behavioural groups among students using an incremental clustering method. As we add new data, the model improves based on changing behavioural patterns. Parallel to this, we create and update classification models to detect loneliness among the evolving behavioural groups of students. When unique behavioural patterns are observed among student data, specialized classification models have been created. For predictions of loneliness, a collaborative effort between the generalized and specialized models is employed, treating each prediction as a vote. This study's findings reveal that group-based loneliness detection models exhibit superior performance compared to generic models, underscoring the necessity for more personalized approaches tailored to specific behavioural patterns. These results pave the way for future research, emphasizing the development of finely-tuned, individualized mental health interventions.","sentences":["Loneliness is a growing health concern as it can lead to depression and other associated mental health problems for people who experience feelings of loneliness over prolonged periods of time.","Utilizing passive sensing methods that use smartphone and wearable sensor data to capture daily behavioural patterns offers a promising approach for the early detection of loneliness.","Given the subjective nature of loneliness and people's varying daily routines, past detection approaches using machine learning models often face challenges with effectively detecting loneliness.","This paper proposes a methodologically novel approach, particularly developing a loneliness detection system that evolves over time, adapts to new data, and provides real-time detection.","Our study utilized the Globem dataset, a comprehensive collection of passive sensing data acquired over 10 weeks from university students.","The base of our approach is the continuous identification and refinement of similar behavioural groups among students using an incremental clustering method.","As we add new data, the model improves based on changing behavioural patterns.","Parallel to this, we create and update classification models to detect loneliness among the evolving behavioural groups of students.","When unique behavioural patterns are observed among student data, specialized classification models have been created.","For predictions of loneliness, a collaborative effort between the generalized and specialized models is employed, treating each prediction as a vote.","This study's findings reveal that group-based loneliness detection models exhibit superior performance compared to generic models, underscoring the necessity for more personalized approaches tailored to specific behavioural patterns.","These results pave the way for future research, emphasizing the development of finely-tuned, individualized mental health interventions."],"url":"http://arxiv.org/abs/2402.05698v1"}
{"created":"2024-02-08 13:58:16","title":"Interpretable classifiers for tabular data via discretization and feature selection","abstract":"We introduce a method for computing immediately human interpretable yet accurate classifiers from tabular data. The classifiers obtained are short DNF-formulas, computed via first discretizing the original data to Boolean form and then using feature selection coupled with a very fast algorithm for producing the best possible Boolean classifier for the setting. We demonstrate the approach via 14 experiments, obtaining results with accuracies mainly similar to ones obtained via random forests, XGBoost, and existing results for the same datasets in the literature. In several cases, our approach in fact outperforms the reference results in relation to accuracy, even though the main objective of our study is the immediate interpretability of our classifiers. We also prove a new result on the probability that the classifier we obtain from real-life data corresponds to the ideally best classifier with respect to the background distribution the data comes from.","sentences":["We introduce a method for computing immediately human interpretable yet accurate classifiers from tabular data.","The classifiers obtained are short DNF-formulas, computed via first discretizing the original data to Boolean form and then using feature selection coupled with a very fast algorithm for producing the best possible Boolean classifier for the setting.","We demonstrate the approach via 14 experiments, obtaining results with accuracies mainly similar to ones obtained via random forests, XGBoost, and existing results for the same datasets in the literature.","In several cases, our approach in fact outperforms the reference results in relation to accuracy, even though the main objective of our study is the immediate interpretability of our classifiers.","We also prove a new result on the probability that the classifier we obtain from real-life data corresponds to the ideally best classifier with respect to the background distribution the data comes from."],"url":"http://arxiv.org/abs/2402.05680v1"}
{"created":"2024-02-08 13:53:11","title":"Is Adversarial Training with Compressed Datasets Effective?","abstract":"Dataset Condensation (DC) refers to the recent class of dataset compression methods that generate a smaller, synthetic, dataset from a larger dataset. This synthetic dataset retains the essential information of the original dataset, enabling models trained on it to achieve performance levels comparable to those trained on the full dataset. Most current DC methods have mainly concerned with achieving high test performance with limited data budget, and have not directly addressed the question of adversarial robustness. In this work, we investigate the impact of adversarial robustness on models trained with compressed datasets. We show that the compressed datasets obtained from DC methods are not effective in transferring adversarial robustness to models. As a solution to improve dataset compression efficiency and adversarial robustness simultaneously, we propose a novel robustness-aware dataset compression method based on finding the Minimal Finite Covering (MFC) of the dataset. The proposed method is (1) obtained by one-time computation and is applicable for any model, (2) more effective than DC methods when applying adversarial training over MFC, (3) provably robust by minimizing the generalized adversarial loss. Additionally, empirical evaluation on three datasets shows that the proposed method is able to achieve better robustness and performance trade-off compared to DC methods such as distribution matching.","sentences":["Dataset Condensation (DC) refers to the recent class of dataset compression methods that generate a smaller, synthetic, dataset from a larger dataset.","This synthetic dataset retains the essential information of the original dataset, enabling models trained on it to achieve performance levels comparable to those trained on the full dataset.","Most current DC methods have mainly concerned with achieving high test performance with limited data budget, and have not directly addressed the question of adversarial robustness.","In this work, we investigate the impact of adversarial robustness on models trained with compressed datasets.","We show that the compressed datasets obtained from DC methods are not effective in transferring adversarial robustness to models.","As a solution to improve dataset compression efficiency and adversarial robustness simultaneously, we propose a novel robustness-aware dataset compression method based on finding the Minimal Finite Covering (MFC) of the dataset.","The proposed method is (1) obtained by one-time computation and is applicable for any model, (2) more effective than DC methods when applying adversarial training over MFC, (3) provably robust by minimizing the generalized adversarial loss.","Additionally, empirical evaluation on three datasets shows that the proposed method is able to achieve better robustness and performance trade-off compared to DC methods such as distribution matching."],"url":"http://arxiv.org/abs/2402.05675v1"}
{"created":"2024-02-08 13:38:23","title":"S$\u03a9$I: Score-based O-INFORMATION Estimation","abstract":"The analysis of scientific data and complex multivariate systems requires information quantities that capture relationships among multiple random variables. Recently, new information-theoretic measures have been developed to overcome the shortcomings of classical ones, such as mutual information, that are restricted to considering pairwise interactions. Among them, the concept of information synergy and redundancy is crucial for understanding the high-order dependencies between variables. One of the most prominent and versatile measures based on this concept is O-information, which provides a clear and scalable way to quantify the synergy-redundancy balance in multivariate systems. However, its practical application is limited to simplified cases. In this work, we introduce S$\\Omega$I, which allows for the first time to compute O-information without restrictive assumptions about the system. Our experiments validate our approach on synthetic data, and demonstrate the effectiveness of S$\\Omega$I in the context of a real-world use case.","sentences":["The analysis of scientific data and complex multivariate systems requires information quantities that capture relationships among multiple random variables.","Recently, new information-theoretic measures have been developed to overcome the shortcomings of classical ones, such as mutual information, that are restricted to considering pairwise interactions.","Among them, the concept of information synergy and redundancy is crucial for understanding the high-order dependencies between variables.","One of the most prominent and versatile measures based on this concept is O-information, which provides a clear and scalable way to quantify the synergy-redundancy balance in multivariate systems.","However, its practical application is limited to simplified cases.","In this work, we introduce S$\\Omega$I, which allows for the first time to compute O-information without restrictive assumptions about the system.","Our experiments validate our approach on synthetic data, and demonstrate the effectiveness of S$\\Omega$I in the context of a real-world use case."],"url":"http://arxiv.org/abs/2402.05667v1"}
{"created":"2024-02-08 13:27:10","title":"Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction","abstract":"Accurate real-time traffic state forecasting plays a pivotal role in traffic control research. In particular, the CIRCLES consortium project necessitates predictive techniques to mitigate the impact of data source delays. After the success of the MegaVanderTest experiment, this paper aims at overcoming the current system limitations and develop a more suited approach to improve the real-time traffic state estimation for the next iterations of the experiment. In this paper, we introduce the SA-LSTM, a deep forecasting method integrating Self-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM) yielding state-of-the-art results in real-time mesoscale traffic forecasting. We extend this approach to multi-step forecasting with the n-step SA-LSTM, which outperforms traditional multi-step forecasting methods in the trade-off between short-term and long-term predictions, all while operating in real-time.","sentences":["Accurate real-time traffic state forecasting plays a pivotal role in traffic control research.","In particular, the CIRCLES consortium project necessitates predictive techniques to mitigate the impact of data source delays.","After the success of the MegaVanderTest experiment, this paper aims at overcoming the current system limitations and develop a more suited approach to improve the real-time traffic state estimation for the next iterations of the experiment.","In this paper, we introduce the SA-LSTM, a deep forecasting method integrating Self-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM) yielding state-of-the-art results in real-time mesoscale traffic forecasting.","We extend this approach to multi-step forecasting with the n-step SA-LSTM, which outperforms traditional multi-step forecasting methods in the trade-off between short-term and long-term predictions, all while operating in real-time."],"url":"http://arxiv.org/abs/2402.05663v1"}
{"created":"2024-02-08 13:24:57","title":"Rethinking Propagation for Unsupervised Graph Domain Adaptation","abstract":"Unsupervised Graph Domain Adaptation (UGDA) aims to transfer knowledge from a labelled source graph to an unlabelled target graph in order to address the distribution shifts between graph domains. Previous works have primarily focused on aligning data from the source and target graph in the representation space learned by graph neural networks (GNNs). However, the inherent generalization capability of GNNs has been largely overlooked. Motivated by our empirical analysis, we reevaluate the role of GNNs in graph domain adaptation and uncover the pivotal role of the propagation process in GNNs for adapting to different graph domains. We provide a comprehensive theoretical analysis of UGDA and derive a generalization bound for multi-layer GNNs. By formulating GNN Lipschitz for k-layer GNNs, we show that the target risk bound can be tighter by removing propagation layers in source graph and stacking multiple propagation layers in target graph. Based on the empirical and theoretical analysis mentioned above, we propose a simple yet effective approach called A2GNN for graph domain adaptation. Through extensive experiments on real-world datasets, we demonstrate the effectiveness of our proposed A2GNN framework.","sentences":["Unsupervised Graph Domain Adaptation (UGDA) aims to transfer knowledge from a labelled source graph to an unlabelled target graph in order to address the distribution shifts between graph domains.","Previous works have primarily focused on aligning data from the source and target graph in the representation space learned by graph neural networks (GNNs).","However, the inherent generalization capability of GNNs has been largely overlooked.","Motivated by our empirical analysis, we reevaluate the role of GNNs in graph domain adaptation and uncover the pivotal role of the propagation process in GNNs for adapting to different graph domains.","We provide a comprehensive theoretical analysis of UGDA and derive a generalization bound for multi-layer GNNs.","By formulating GNN Lipschitz for k-layer GNNs, we show that the target risk bound can be tighter by removing propagation layers in source graph and stacking multiple propagation layers in target graph.","Based on the empirical and theoretical analysis mentioned above, we propose a simple yet effective approach called A2GNN for graph domain adaptation.","Through extensive experiments on real-world datasets, we demonstrate the effectiveness of our proposed A2GNN framework."],"url":"http://arxiv.org/abs/2402.05660v1"}
{"created":"2024-02-08 13:00:18","title":"Investigating Reproducibility in Deep Learning-Based Software Fault Prediction","abstract":"Over the past few years, deep learning methods have been applied for a wide range of Software Engineering (SE) tasks, including in particular for the important task of automatically predicting and localizing faults in software. With the rapid adoption of increasingly complex machine learning models, it however becomes more and more difficult for scholars to reproduce the results that are reported in the literature. This is in particular the case when the applied deep learning models and the evaluation methodology are not properly documented and when code and data are not shared. Given some recent -- and very worrying -- findings regarding reproducibility and progress in other areas of applied machine learning, the goal of this work is to analyze to what extent the field of software engineering, in particular in the area of software fault prediction, is plagued by similar problems. We have therefore conducted a systematic review of the current literature and examined the level of reproducibility of 56 research articles that were published between 2019 and 2022 in top-tier software engineering conferences. Our analysis revealed that scholars are apparently largely aware of the reproducibility problem, and about two thirds of the papers provide code for their proposed deep learning models. However, it turned out that in the vast majority of cases, crucial elements for reproducibility are missing, such as the code of the compared baselines, code for data pre-processing or code for hyperparameter tuning. In these cases, it therefore remains challenging to exactly reproduce the results in the current research literature. Overall, our meta-analysis therefore calls for improved research practices to ensure the reproducibility of machine-learning based research.","sentences":["Over the past few years, deep learning methods have been applied for a wide range of Software Engineering (SE) tasks, including in particular for the important task of automatically predicting and localizing faults in software.","With the rapid adoption of increasingly complex machine learning models, it however becomes more and more difficult for scholars to reproduce the results that are reported in the literature.","This is in particular the case when the applied deep learning models and the evaluation methodology are not properly documented and when code and data are not shared.","Given some recent -- and very worrying -- findings regarding reproducibility and progress in other areas of applied machine learning, the goal of this work is to analyze to what extent the field of software engineering, in particular in the area of software fault prediction, is plagued by similar problems.","We have therefore conducted a systematic review of the current literature and examined the level of reproducibility of 56 research articles that were published between 2019 and 2022 in top-tier software engineering conferences.","Our analysis revealed that scholars are apparently largely aware of the reproducibility problem, and about two thirds of the papers provide code for their proposed deep learning models.","However, it turned out that in the vast majority of cases, crucial elements for reproducibility are missing, such as the code of the compared baselines, code for data pre-processing or code for hyperparameter tuning.","In these cases, it therefore remains challenging to exactly reproduce the results in the current research literature.","Overall, our meta-analysis therefore calls for improved research practices to ensure the reproducibility of machine-learning based research."],"url":"http://arxiv.org/abs/2402.05645v1"}
{"created":"2024-02-08 12:47:57","title":"The Impact of AI Tool on Engineering at ANZ Bank An Emperical Study on GitHub Copilot within Coporate Environment","abstract":"The increasing popularity of AI, particularly Large Language Models (LLMs), has significantly impacted various domains, including Software Engineering. This study explores the integration of AI tools in software engineering practices within a large organization. We focus on ANZ Bank, which employs over 5000 engineers covering all aspects of the software development life cycle. This paper details an experiment conducted using GitHub Copilot, a notable AI tool, within a controlled environment to evaluate its effectiveness in real-world engineering tasks. Additionally, this paper shares initial findings on the productivity improvements observed after GitHub Copilot was adopted on a large scale, with about 1000 engineers using it. ANZ Bank's six-week experiment with GitHub Copilot included two weeks of preparation and four weeks of active testing. The study evaluated participant sentiment and the tool's impact on productivity, code quality, and security. Initially, participants used GitHub Copilot for proposed use-cases, with their feedback gathered through regular surveys. In the second phase, they were divided into Control and Copilot groups, each tackling the same Python challenges, and their experiences were again surveyed. Results showed a notable boost in productivity and code quality with GitHub Copilot, though its impact on code security remained inconclusive. Participant responses were overall positive, confirming GitHub Copilot's effectiveness in large-scale software engineering environments. Early data from 1000 engineers also indicated a significant increase in productivity and job satisfaction.","sentences":["The increasing popularity of AI, particularly Large Language Models (LLMs), has significantly impacted various domains, including Software Engineering.","This study explores the integration of AI tools in software engineering practices within a large organization.","We focus on ANZ Bank, which employs over 5000 engineers covering all aspects of the software development life cycle.","This paper details an experiment conducted using GitHub Copilot, a notable AI tool, within a controlled environment to evaluate its effectiveness in real-world engineering tasks.","Additionally, this paper shares initial findings on the productivity improvements observed after GitHub Copilot was adopted on a large scale, with about 1000 engineers using it.","ANZ Bank's six-week experiment with GitHub Copilot included two weeks of preparation and four weeks of active testing.","The study evaluated participant sentiment and the tool's impact on productivity, code quality, and security.","Initially, participants used GitHub Copilot for proposed use-cases, with their feedback gathered through regular surveys.","In the second phase, they were divided into Control and Copilot groups, each tackling the same Python challenges, and their experiences were again surveyed.","Results showed a notable boost in productivity and code quality with GitHub Copilot, though its impact on code security remained inconclusive.","Participant responses were overall positive, confirming GitHub Copilot's effectiveness in large-scale software engineering environments.","Early data from 1000 engineers also indicated a significant increase in productivity and job satisfaction."],"url":"http://arxiv.org/abs/2402.05636v1"}
{"created":"2024-02-08 12:38:12","title":"ShiftDTW: adapting the DTW metric for cyclic time series clustering","abstract":"The elasticity of the DTW metric provides a more flexible comparison between time series and is used in numerous machine learning domains such as classification or clustering. However, it does not align the measurements at the beginning and end of time series if they have a shift occurring right at the start of one series, with the omitted part appearing at the end of that series. Due to the cyclicity of such series - which lack a definite beginning or end - we rely on the Cyclic DTW approach to propose a less computationally expensive approximation of this calculation method. This approximation will then be employed in conjunction with the K-Means clustering method.","sentences":["The elasticity of the DTW metric provides a more flexible comparison between time series and is used in numerous machine learning domains such as classification or clustering.","However, it does not align the measurements at the beginning and end of time series if they have a shift occurring right at the start of one series, with the omitted part appearing at the end of that series.","Due to the cyclicity of such series - which lack a definite beginning or end - we rely on the Cyclic DTW approach to propose a less computationally expensive approximation of this calculation method.","This approximation will then be employed in conjunction with the K-Means clustering method."],"url":"http://arxiv.org/abs/2402.05631v1"}
{"created":"2024-02-08 12:28:18","title":"Efficient Models for the Detection of Hate, Abuse and Profanity","abstract":"Large Language Models (LLMs) are the cornerstone for many Natural Language Processing (NLP) tasks like sentiment analysis, document classification, named entity recognition, question answering, summarization, etc. LLMs are often trained on data which originates from the web. This data is prone to having content with Hate, Abuse and Profanity (HAP). For a detailed definition of HAP, please refer to the Appendix. Due to the LLMs being exposed to HAP content during training, the models learn it and may then generate hateful or profane content. For example, when the open-source RoBERTa model (specifically, the RoBERTA base model) from the HuggingFace (HF) Transformers library is prompted to replace the mask token in `I do not know that Persian people are that MASK` it returns the word `stupid` with the highest score. This is unacceptable in civil discourse.The detection of Hate, Abuse and Profanity in text is a vital component of creating civil and unbiased LLMs, which is needed not only for English, but for all languages. In this article, we briefly describe the creation of HAP detectors and various ways of using them to make models civil and acceptable in the output they generate.","sentences":["Large Language Models (LLMs) are the cornerstone for many Natural Language Processing (NLP) tasks like sentiment analysis, document classification, named entity recognition, question answering, summarization, etc. LLMs are often trained on data which originates from the web.","This data is prone to having content with Hate, Abuse and Profanity (HAP).","For a detailed definition of HAP, please refer to the Appendix.","Due to the LLMs being exposed to HAP content during training, the models learn it and may then generate hateful or profane content.","For example, when the open-source RoBERTa model (specifically, the RoBERTA base model) from the HuggingFace (HF) Transformers library is prompted to replace the mask token in `I do not know that Persian people are that MASK` it returns the word `stupid` with the highest score.","This is unacceptable in civil discourse.","The detection of Hate, Abuse and Profanity in text is a vital component of creating civil and unbiased LLMs, which is needed not only for English, but for all languages.","In this article, we briefly describe the creation of HAP detectors and various ways of using them to make models civil and acceptable in the output they generate."],"url":"http://arxiv.org/abs/2402.05624v1"}
{"created":"2024-02-08 12:19:32","title":"Pretrained Generative Language Models as General Learning Frameworks for Sequence-Based Tasks","abstract":"We propose that small pretrained foundational generative language models with millions of parameters can be utilized as a general learning framework for sequence-based tasks. Our proposal overcomes the computational resource, skill set, and timeline challenges associated with training neural networks and language models from scratch. Further, our approach focuses on creating small and highly specialized models that can accurately execute a challenging task of which the base model is incapable of performing. We demonstrate that 125M, 350M, and 1.3B parameter pretrained foundational language models can be instruction fine-tuned with 10,000-to-1,000,000 instruction examples to achieve near state-of-the-art results on challenging cheminformatics tasks. We also demonstrate the role of successive language model fine-tuning epochs on improved outcomes, as well as the importance of both data formatting and pretrained foundational language model selection for instruction fine-tuning success.","sentences":["We propose that small pretrained foundational generative language models with millions of parameters can be utilized as a general learning framework for sequence-based tasks.","Our proposal overcomes the computational resource, skill set, and timeline challenges associated with training neural networks and language models from scratch.","Further, our approach focuses on creating small and highly specialized models that can accurately execute a challenging task of which the base model is incapable of performing.","We demonstrate that 125M, 350M, and 1.3B parameter pretrained foundational language models can be instruction fine-tuned with 10,000-to-1,000,000 instruction examples to achieve near state-of-the-art results on challenging cheminformatics tasks.","We also demonstrate the role of successive language model fine-tuning epochs on improved outcomes, as well as the importance of both data formatting and pretrained foundational language model selection for instruction fine-tuning success."],"url":"http://arxiv.org/abs/2402.05616v1"}
{"created":"2024-02-08 12:18:39","title":"DAPlankton: Benchmark Dataset for Multi-instrument Plankton Recognition via Fine-grained Domain Adaptation","abstract":"Plankton recognition provides novel possibilities to study various environmental aspects and an interesting real-world context to develop domain adaptation (DA) methods. Different imaging instruments cause domain shift between datasets hampering the development of general plankton recognition methods. A promising remedy for this is DA allowing to adapt a model trained on one instrument to other instruments. In this paper, we present a new DA dataset called DAPlankton which consists of phytoplankton images obtained with different instruments. Phytoplankton provides a challenging DA problem due to the fine-grained nature of the task and high class imbalance in real-world datasets. DAPlankton consists of two subsets. DAPlankton_LAB contains images of cultured phytoplankton providing a balanced dataset with minimal label uncertainty. DAPlankton_SEA consists of images collected from the Baltic Sea providing challenging real-world data with large intra-class variance and class imbalance. We further present a benchmark comparison of three widely used DA methods.","sentences":["Plankton recognition provides novel possibilities to study various environmental aspects and an interesting real-world context to develop domain adaptation (DA) methods.","Different imaging instruments cause domain shift between datasets hampering the development of general plankton recognition methods.","A promising remedy for this is DA allowing to adapt a model trained on one instrument to other instruments.","In this paper, we present a new DA dataset called DAPlankton which consists of phytoplankton images obtained with different instruments.","Phytoplankton provides a challenging DA problem due to the fine-grained nature of the task and high class imbalance in real-world datasets.","DAPlankton consists of two subsets.","DAPlankton_LAB contains images of cultured phytoplankton providing a balanced dataset with minimal label uncertainty.","DAPlankton_SEA consists of images collected from the Baltic Sea providing challenging real-world data with large intra-class variance and class imbalance.","We further present a benchmark comparison of three widely used DA methods."],"url":"http://arxiv.org/abs/2402.05615v1"}
{"created":"2024-02-08 12:11:24","title":"An Implementation for Dynamic Application Allocation in Shared Sensor Networks","abstract":"We present a system architecture implementation to perform dynamic application allocation in shared sensor networks, where highly integrated wireless sensor systems are used to support multiple applications. The architecture is based on a central controller that collects the received data from the sensor nodes, dynamically decides which applications must be simultaneously deployed in each node and, accordingly, over-the-air reprograms the sensor nodes. Waspmote devices are used as sensor nodes that communicate with the controller using ZigBee protocol. Experimental results show the viability of the proposal.","sentences":["We present a system architecture implementation to perform dynamic application allocation in shared sensor networks, where highly integrated wireless sensor systems are used to support multiple applications.","The architecture is based on a central controller that collects the received data from the sensor nodes, dynamically decides which applications must be simultaneously deployed in each node and, accordingly, over-the-air reprograms the sensor nodes.","Waspmote devices are used as sensor nodes that communicate with the controller using ZigBee protocol.","Experimental results show the viability of the proposal."],"url":"http://arxiv.org/abs/2402.05611v1"}
{"created":"2024-02-08 12:08:42","title":"Scalable Diffusion Models with State Space Backbone","abstract":"This paper presents a new exploration into a category of diffusion models built upon state space architecture. We endeavor to train diffusion models for image data, wherein the traditional U-Net backbone is supplanted by a state space backbone, functioning on raw patches or latent space. Given its notable efficacy in accommodating long-range dependencies, Diffusion State Space Models (DiS) are distinguished by treating all inputs including time, condition, and noisy image patches as tokens. Our assessment of DiS encompasses both unconditional and class-conditional image generation scenarios, revealing that DiS exhibits comparable, if not superior, performance to CNN-based or Transformer-based U-Net architectures of commensurate size. Furthermore, we analyze the scalability of DiS, gauged by the forward pass complexity quantified in Gflops. DiS models with higher Gflops, achieved through augmentation of depth/width or augmentation of input tokens, consistently demonstrate lower FID. In addition to demonstrating commendable scalability characteristics, DiS-H/2 models in latent space achieve performance levels akin to prior diffusion models on class-conditional ImageNet benchmarks at the resolution of 256$\\times$256 and 512$\\times$512, while significantly reducing the computational burden. The code and models are available at: https://github.com/feizc/DiS.","sentences":["This paper presents a new exploration into a category of diffusion models built upon state space architecture.","We endeavor to train diffusion models for image data, wherein the traditional U-Net backbone is supplanted by a state space backbone, functioning on raw patches or latent space.","Given its notable efficacy in accommodating long-range dependencies, Diffusion State Space Models (DiS) are distinguished by treating all inputs including time, condition, and noisy image patches as tokens.","Our assessment of DiS encompasses both unconditional and class-conditional image generation scenarios, revealing that DiS exhibits comparable, if not superior, performance to CNN-based or Transformer-based U-Net architectures of commensurate size.","Furthermore, we analyze the scalability of DiS, gauged by the forward pass complexity quantified in Gflops.","DiS models with higher Gflops, achieved through augmentation of depth/width or augmentation of input tokens, consistently demonstrate lower FID.","In addition to demonstrating commendable scalability characteristics, DiS-H/2 models in latent space achieve performance levels akin to prior diffusion models on class-conditional ImageNet benchmarks at the resolution of 256$\\times$256 and 512$\\times$512, while significantly reducing the computational burden.","The code and models are available at: https://github.com/feizc/DiS."],"url":"http://arxiv.org/abs/2402.05608v1"}
{"created":"2024-02-08 11:46:26","title":"A Concept for Reconstructing Stucco Statues from historic Sketches using synthetic Data only","abstract":"In medieval times, stuccoworkers used a red color, called sinopia, to first create a sketch of the to-be-made statue on the wall. Today, many of these statues are destroyed, but using the original drawings, deriving from the red color also called sinopia, we can reconstruct how the final statue might have looked.We propose a fully-automated approach to reconstruct a point cloud and show preliminary results by generating a color-image, a depth-map, as well as surface normals requiring only a single sketch, and without requiring a collection of other, similar samples. Our proposed solution allows real-time reconstruction on-site, for instance, within an exhibition, or to generate a useful starting point for an expert, trying to manually reconstruct the statue, all while using only synthetic data for training.","sentences":["In medieval times, stuccoworkers used a red color, called sinopia, to first create a sketch of the to-be-made statue on the wall.","Today, many of these statues are destroyed, but using the original drawings, deriving from the red color also called sinopia, we can reconstruct how the final statue might have looked.","We propose a fully-automated approach to reconstruct a point cloud and show preliminary results by generating a color-image, a depth-map, as well as surface normals requiring only a single sketch, and without requiring a collection of other, similar samples.","Our proposed solution allows real-time reconstruction on-site, for instance, within an exhibition, or to generate a useful starting point for an expert, trying to manually reconstruct the statue, all while using only synthetic data for training."],"url":"http://arxiv.org/abs/2402.05593v1"}
{"created":"2024-02-08 11:44:25","title":"SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels","abstract":"Rule-based text data augmentation is widely used for NLP tasks due to its simplicity. However, this method can potentially damage the original meaning of the text, ultimately hurting the performance of the model. To overcome this limitation, we propose a straightforward technique for applying soft labels to augmented data. We conducted experiments across seven different classification tasks and empirically demonstrated the effectiveness of our proposed approach. We have publicly opened our source code for reproducibility.","sentences":["Rule-based text data augmentation is widely used for NLP tasks due to its simplicity.","However, this method can potentially damage the original meaning of the text, ultimately hurting the performance of the model.","To overcome this limitation, we propose a straightforward technique for applying soft labels to augmented data.","We conducted experiments across seven different classification tasks and empirically demonstrated the effectiveness of our proposed approach.","We have publicly opened our source code for reproducibility."],"url":"http://arxiv.org/abs/2402.05591v1"}
{"created":"2024-02-08 11:40:50","title":"RESMatch: Referring Expression Segmentation in a Semi-Supervised Manner","abstract":"Referring expression segmentation (RES), a task that involves localizing specific instance-level objects based on free-form linguistic descriptions, has emerged as a crucial frontier in human-AI interaction. It demands an intricate understanding of both visual and textual contexts and often requires extensive training data. This paper introduces RESMatch, the first semi-supervised learning (SSL) approach for RES, aimed at reducing reliance on exhaustive data annotation. Extensive validation on multiple RES datasets demonstrates that RESMatch significantly outperforms baseline approaches, establishing a new state-of-the-art. Although existing SSL techniques are effective in image segmentation, we find that they fall short in RES. Facing the challenges including the comprehension of free-form linguistic descriptions and the variability in object attributes, RESMatch introduces a trifecta of adaptations: revised strong perturbation, text augmentation, and adjustments for pseudo-label quality and strong-weak supervision. This pioneering work lays the groundwork for future research in semi-supervised learning for referring expression segmentation.","sentences":["Referring expression segmentation (RES), a task that involves localizing specific instance-level objects based on free-form linguistic descriptions, has emerged as a crucial frontier in human-AI interaction.","It demands an intricate understanding of both visual and textual contexts and often requires extensive training data.","This paper introduces RESMatch, the first semi-supervised learning (SSL) approach for RES, aimed at reducing reliance on exhaustive data annotation.","Extensive validation on multiple RES datasets demonstrates that RESMatch significantly outperforms baseline approaches, establishing a new state-of-the-art.","Although existing SSL techniques are effective in image segmentation, we find that they fall short in RES.","Facing the challenges including the comprehension of free-form linguistic descriptions and the variability in object attributes, RESMatch introduces a trifecta of adaptations: revised strong perturbation, text augmentation, and adjustments for pseudo-label quality and strong-weak supervision.","This pioneering work lays the groundwork for future research in semi-supervised learning for referring expression segmentation."],"url":"http://arxiv.org/abs/2402.05589v1"}
{"created":"2024-02-08 11:36:23","title":"AutoAugment Is What You Need: Enhancing Rule-based Augmentation Methods in Low-resource Regimes","abstract":"Text data augmentation is a complex problem due to the discrete nature of sentences. Although rule-based augmentation methods are widely adopted in real-world applications because of their simplicity, they suffer from potential semantic damage. Previous researchers have suggested easy data augmentation with soft labels (softEDA), employing label smoothing to mitigate this problem. However, finding the best factor for each model and dataset is challenging; therefore, using softEDA in real-world applications is still difficult. In this paper, we propose adapting AutoAugment to solve this problem. The experimental results suggest that the proposed method can boost existing augmentation methods and that rule-based methods can enhance cutting-edge pre-trained language models. We offer the source code.","sentences":["Text data augmentation is a complex problem due to the discrete nature of sentences.","Although rule-based augmentation methods are widely adopted in real-world applications because of their simplicity, they suffer from potential semantic damage.","Previous researchers have suggested easy data augmentation with soft labels (softEDA), employing label smoothing to mitigate this problem.","However, finding the best factor for each model and dataset is challenging; therefore, using softEDA in real-world applications is still difficult.","In this paper, we propose adapting AutoAugment to solve this problem.","The experimental results suggest that the proposed method can boost existing augmentation methods and that rule-based methods can enhance cutting-edge pre-trained language models.","We offer the source code."],"url":"http://arxiv.org/abs/2402.05584v1"}
{"created":"2024-02-08 11:10:39","title":"Hypergraph Node Classification With Graph Neural Networks","abstract":"Hypergraphs, with hyperedges connecting more than two nodes, are key for modelling higher-order interactions in real-world data. The success of graph neural networks (GNNs) reveals the capability of neural networks to process data with pairwise interactions. This inspires the usage of neural networks for data with higher-order interactions, thereby leading to the development of hypergraph neural networks (HyperGNNs). GNNs and HyperGNNs are typically considered distinct since they are designed for data on different geometric topologies. However, in this paper, we theoretically demonstrate that, in the context of node classification, most HyperGNNs can be approximated using a GNN with a weighted clique expansion of the hypergraph. This leads to WCE-GNN, a simple and efficient framework comprising a GNN and a weighted clique expansion (WCE), for hypergraph node classification. Experiments on nine real-world hypergraph node classification benchmarks showcase that WCE-GNN demonstrates not only higher classification accuracy compared to state-of-the-art HyperGNNs, but also superior memory and runtime efficiency.","sentences":["Hypergraphs, with hyperedges connecting more than two nodes, are key for modelling higher-order interactions in real-world data.","The success of graph neural networks (GNNs) reveals the capability of neural networks to process data with pairwise interactions.","This inspires the usage of neural networks for data with higher-order interactions, thereby leading to the development of hypergraph neural networks (HyperGNNs).","GNNs and HyperGNNs are typically considered distinct since they are designed for data on different geometric topologies.","However, in this paper, we theoretically demonstrate that, in the context of node classification, most HyperGNNs can be approximated using a GNN with a weighted clique expansion of the hypergraph.","This leads to WCE-GNN, a simple and efficient framework comprising a GNN and a weighted clique expansion (WCE), for hypergraph node classification.","Experiments on nine real-world hypergraph node classification benchmarks showcase that WCE-GNN demonstrates not only higher classification accuracy compared to state-of-the-art HyperGNNs, but also superior memory and runtime efficiency."],"url":"http://arxiv.org/abs/2402.05569v1"}
{"created":"2024-02-08 11:05:49","title":"Listening Between the Lines: Synthetic Speech Detection Disregarding Verbal Content","abstract":"Recent advancements in synthetic speech generation have led to the creation of forged audio data that are almost indistinguishable from real speech. This phenomenon poses a new challenge for the multimedia forensics community, as the misuse of synthetic media can potentially cause adverse consequences. Several methods have been proposed in the literature to mitigate potential risks and detect synthetic speech, mainly focusing on the analysis of the speech itself. However, recent studies have revealed that the most crucial frequency bands for detection lie in the highest ranges (above 6000 Hz), which do not include any speech content. In this work, we extensively explore this aspect and investigate whether synthetic speech detection can be performed by focusing only on the background component of the signal while disregarding its verbal content. Our findings indicate that the speech component is not the predominant factor in performing synthetic speech detection. These insights provide valuable guidance for the development of new synthetic speech detectors and their interpretability, together with some considerations on the existing work in the audio forensics field.","sentences":["Recent advancements in synthetic speech generation have led to the creation of forged audio data that are almost indistinguishable from real speech.","This phenomenon poses a new challenge for the multimedia forensics community, as the misuse of synthetic media can potentially cause adverse consequences.","Several methods have been proposed in the literature to mitigate potential risks and detect synthetic speech, mainly focusing on the analysis of the speech itself.","However, recent studies have revealed that the most crucial frequency bands for detection lie in the highest ranges (above 6000 Hz), which do not include any speech content.","In this work, we extensively explore this aspect and investigate whether synthetic speech detection can be performed by focusing only on the background component of the signal while disregarding its verbal content.","Our findings indicate that the speech component is not the predominant factor in performing synthetic speech detection.","These insights provide valuable guidance for the development of new synthetic speech detectors and their interpretability, together with some considerations on the existing work in the audio forensics field."],"url":"http://arxiv.org/abs/2402.05567v1"}
{"created":"2024-02-08 11:04:11","title":"Succint Interaction-Aware Explanations","abstract":"SHAP is a popular approach to explain black-box models by revealing the importance of individual features. As it ignores feature interactions, SHAP explanations can be confusing up to misleading. NSHAP, on the other hand, reports the additive importance for all subsets of features. While this does include all interacting sets of features, it also leads to an exponentially sized, difficult to interpret explanation. In this paper, we propose to combine the best of these two worlds, by partitioning the features into parts that significantly interact, and use these parts to compose a succinct, interpretable, additive explanation. We derive a criterion by which to measure the representativeness of such a partition for a models behavior, traded off against the complexity of the resulting explanation. To efficiently find the best partition out of super-exponentially many, we show how to prune sub-optimal solutions using a statistical test, which not only improves runtime but also helps to detect spurious interactions. Experiments on synthetic and real world data show that our explanations are both more accurate resp. more easily interpretable than those of SHAP and NSHAP.","sentences":["SHAP is a popular approach to explain black-box models by revealing the importance of individual features.","As it ignores feature interactions, SHAP explanations can be confusing up to misleading.","NSHAP, on the other hand, reports the additive importance for all subsets of features.","While this does include all interacting sets of features, it also leads to an exponentially sized, difficult to interpret explanation.","In this paper, we propose to combine the best of these two worlds, by partitioning the features into parts that significantly interact, and use these parts to compose a succinct, interpretable, additive explanation.","We derive a criterion by which to measure the representativeness of such a partition for a models behavior, traded off against the complexity of the resulting explanation.","To efficiently find the best partition out of super-exponentially many, we show how to prune sub-optimal solutions using a statistical test, which not only improves runtime but also helps to detect spurious interactions.","Experiments on synthetic and real world data show that our explanations are both more accurate resp.","more easily interpretable than those of SHAP and NSHAP."],"url":"http://arxiv.org/abs/2402.05566v1"}
{"created":"2024-02-08 10:57:36","title":"Tight Approximation Bounds on a Simple Algorithm for Minimum Average Search Time in Trees","abstract":"The graph invariant EPT-sum has cropped up in several unrelated fields in later years: As an objective function for hierarchical clustering, as a more fine-grained version of the classical edge ranking problem, and, specifically when the input is a vertex-weighted tree, as a measure of average/expected search length in a partially ordered set. The EPT-sum of a graph $G$ is defined as the minimum sum of the depth of every leaf in an edge partition tree (EPT), a rooted tree where leaves correspond to vertices in $G$ and internal nodes correspond to edges in $G$.   A simple algorithm that approximates EPT-sum on trees is given by recursively choosing the most balanced edge in the input tree $G$ to build an EPT of $G$. Due to its fast runtime, this balanced cut algorithm is used in practice. In this paper, we show that the balanced cut algorithm gives a 1.5-approximation of EPT-sum on trees, which amounts to a tight analysis and answers a question posed by Cicalese et al. in 2014.","sentences":["The graph invariant EPT-sum has cropped up in several unrelated fields in later years: As an objective function for hierarchical clustering, as a more fine-grained version of the classical edge ranking problem, and, specifically when the input is a vertex-weighted tree, as a measure of average/expected search length in a partially ordered set.","The EPT-sum of a graph $G$ is defined as the minimum sum of the depth of every leaf in an edge partition tree (EPT), a rooted tree where leaves correspond to vertices in $G$ and internal nodes correspond to edges in $G$.   A simple algorithm that approximates EPT-sum on trees is given by recursively choosing the most balanced edge in the input tree $G$ to build an EPT of $G$. Due to its fast runtime, this balanced cut algorithm is used in practice.","In this paper, we show that the balanced cut algorithm gives a 1.5-approximation of EPT-sum on trees, which amounts to a tight analysis and answers a question posed by Cicalese et al. in 2014."],"url":"http://arxiv.org/abs/2402.05560v1"}
{"created":"2024-02-08 10:52:37","title":"Flashback: Understanding and Mitigating Forgetting in Federated Learning","abstract":"In Federated Learning (FL), forgetting, or the loss of knowledge across rounds, hampers algorithm convergence, particularly in the presence of severe data heterogeneity among clients. This study explores the nuances of this issue, emphasizing the critical role of forgetting in FL's inefficient learning within heterogeneous data contexts. Knowledge loss occurs in both client-local updates and server-side aggregation steps; addressing one without the other fails to mitigate forgetting. We introduce a metric to measure forgetting granularly, ensuring distinct recognition amid new knowledge acquisition. Leveraging these insights, we propose Flashback, an FL algorithm with a dynamic distillation approach that is used to regularize the local models, and effectively aggregate their knowledge. Across different benchmarks, Flashback outperforms other methods, mitigates forgetting, and achieves faster round-to-target-accuracy, by converging in 6 to 16 rounds.","sentences":["In Federated Learning (FL), forgetting, or the loss of knowledge across rounds, hampers algorithm convergence, particularly in the presence of severe data heterogeneity among clients.","This study explores the nuances of this issue, emphasizing the critical role of forgetting in FL's inefficient learning within heterogeneous data contexts.","Knowledge loss occurs in both client-local updates and server-side aggregation steps; addressing one without the other fails to mitigate forgetting.","We introduce a metric to measure forgetting granularly, ensuring distinct recognition amid new knowledge acquisition.","Leveraging these insights, we propose Flashback, an FL algorithm with a dynamic distillation approach that is used to regularize the local models, and effectively aggregate their knowledge.","Across different benchmarks, Flashback outperforms other methods, mitigates forgetting, and achieves faster round-to-target-accuracy, by converging in 6 to 16 rounds."],"url":"http://arxiv.org/abs/2402.05558v1"}
{"created":"2024-02-08 10:50:12","title":"On Convolutional Vision Transformers for Yield Prediction","abstract":"While a variety of methods offer good yield prediction on histogrammed remote sensing data, vision Transformers are only sparsely represented in the literature. The Convolution vision Transformer (CvT) is being tested to evaluate vision Transformers that are currently achieving state-of-the-art results in many other vision tasks. CvT combines some of the advantages of convolution with the advantages of dynamic attention and global context fusion of Transformers. It performs worse than widely tested methods such as XGBoost and CNNs, but shows that Transformers have potential to improve yield prediction.","sentences":["While a variety of methods offer good yield prediction on histogrammed remote sensing data, vision Transformers are only sparsely represented in the literature.","The Convolution vision Transformer (CvT) is being tested to evaluate vision Transformers that are currently achieving state-of-the-art results in many other vision tasks.","CvT combines some of the advantages of convolution with the advantages of dynamic attention and global context fusion of Transformers.","It performs worse than widely tested methods such as XGBoost and CNNs, but shows that Transformers have potential to improve yield prediction."],"url":"http://arxiv.org/abs/2402.05557v1"}
{"created":"2024-02-08 10:29:46","title":"Offline Actor-Critic Reinforcement Learning Scales to Large Models","abstract":"We show that offline actor-critic reinforcement learning can scale to large models - such as transformers - and follows similar scaling laws as supervised learning. We find that offline actor-critic algorithms can outperform strong, supervised, behavioral cloning baselines for multi-task training on a large dataset containing both sub-optimal and expert behavior on 132 continuous control tasks. We introduce a Perceiver-based actor-critic model and elucidate the key model features needed to make offline RL work with self- and cross-attention modules. Overall, we find that: i) simple offline actor critic algorithms are a natural choice for gradually moving away from the currently predominant paradigm of behavioral cloning, and ii) via offline RL it is possible to learn multi-task policies that master many domains simultaneously, including real robotics tasks, from sub-optimal demonstrations or self-generated data.","sentences":["We show that offline actor-critic reinforcement learning can scale to large models - such as transformers - and follows similar scaling laws as supervised learning.","We find that offline actor-critic algorithms can outperform strong, supervised, behavioral cloning baselines for multi-task training on a large dataset containing both sub-optimal and expert behavior on 132 continuous control tasks.","We introduce a Perceiver-based actor-critic model and elucidate the key model features needed to make offline RL work with self- and cross-attention modules.","Overall, we find that: i) simple offline actor critic algorithms are a natural choice for gradually moving away from the currently predominant paradigm of behavioral cloning, and ii) via offline RL it is possible to learn multi-task policies that master many domains simultaneously, including real robotics tasks, from sub-optimal demonstrations or self-generated data."],"url":"http://arxiv.org/abs/2402.05546v1"}
{"created":"2024-02-08 10:29:11","title":"Named Entity Recognition for Address Extraction in Speech-to-Text Transcriptions Using Synthetic Data","abstract":"This paper introduces an approach for building a Named Entity Recognition (NER) model built upon a Bidirectional Encoder Representations from Transformers (BERT) architecture, specifically utilizing the SlovakBERT model. This NER model extracts address parts from data acquired from speech-to-text transcriptions. Due to scarcity of real data, a synthetic dataset using GPT API was generated. The importance of mimicking spoken language variability in this artificial data is emphasized. The performance of our NER model, trained solely on synthetic data, is evaluated using small real test dataset.","sentences":["This paper introduces an approach for building a Named Entity Recognition (NER) model built upon a Bidirectional Encoder Representations from Transformers (BERT) architecture, specifically utilizing the SlovakBERT model.","This NER model extracts address parts from data acquired from speech-to-text transcriptions.","Due to scarcity of real data, a synthetic dataset using GPT API was generated.","The importance of mimicking spoken language variability in this artificial data is emphasized.","The performance of our NER model, trained solely on synthetic data, is evaluated using small real test dataset."],"url":"http://arxiv.org/abs/2402.05545v1"}
{"created":"2024-02-08 10:22:12","title":"Reinforcement Learning as a Catalyst for Robust and Fair Federated Learning: Deciphering the Dynamics of Client Contributions","abstract":"Recent advancements in federated learning (FL) have produced models that retain user privacy by training across multiple decentralized devices or systems holding local data samples. However, these strategies often neglect the inherent challenges of statistical heterogeneity and vulnerability to adversarial attacks, which can degrade model robustness and fairness. Personalized FL strategies offer some respite by adjusting models to fit individual client profiles, yet they tend to neglect server-side aggregation vulnerabilities. To address these issues, we propose Reinforcement Federated Learning (RFL), a novel framework that leverages deep reinforcement learning to adaptively optimize client contribution during aggregation, thereby enhancing both model robustness against malicious clients and fairness across participants under non-identically distributed settings. To achieve this goal, we propose a meticulous approach involving a Deep Deterministic Policy Gradient-based algorithm for continuous control of aggregation weights, an innovative client selection method based on model parameter distances, and a reward mechanism guided by validation set performance. Empirically, extensive experiments demonstrate that, in terms of robustness, RFL outperforms the state-of-the-art methods, while maintaining comparable levels of fairness, offering a promising solution to build resilient and fair federated systems.","sentences":["Recent advancements in federated learning (FL) have produced models that retain user privacy by training across multiple decentralized devices or systems holding local data samples.","However, these strategies often neglect the inherent challenges of statistical heterogeneity and vulnerability to adversarial attacks, which can degrade model robustness and fairness.","Personalized FL strategies offer some respite by adjusting models to fit individual client profiles, yet they tend to neglect server-side aggregation vulnerabilities.","To address these issues, we propose Reinforcement Federated Learning (RFL), a novel framework that leverages deep reinforcement learning to adaptively optimize client contribution during aggregation, thereby enhancing both model robustness against malicious clients and fairness across participants under non-identically distributed settings.","To achieve this goal, we propose a meticulous approach involving a Deep Deterministic Policy Gradient-based algorithm for continuous control of aggregation weights, an innovative client selection method based on model parameter distances, and a reward mechanism guided by validation set performance.","Empirically, extensive experiments demonstrate that, in terms of robustness, RFL outperforms the state-of-the-art methods, while maintaining comparable levels of fairness, offering a promising solution to build resilient and fair federated systems."],"url":"http://arxiv.org/abs/2402.05541v1"}
{"created":"2024-02-08 10:21:51","title":"Tightly Coupled Range Inertial Localization on a 3D Prior Map Based on Sliding Window Factor Graph Optimization","abstract":"This paper presents a range inertial localization algorithm for a 3D prior map. The proposed algorithm tightly couples scan-to-scan and scan-to-map point cloud registration factors along with IMU factors on a sliding window factor graph. The tight coupling of the scan-to-scan and scan-to-map registration factors enables a smooth fusion of sensor ego-motion estimation and map-based trajectory correction that results in robust tracking of the sensor pose under severe point cloud degeneration and defective regions in a map. We also propose an initial sensor state estimation algorithm that robustly estimates the gravity direction and IMU state and helps perform global localization in 3- or 4-DoF for system initialization without prior position information. Experimental results show that the proposed method outperforms existing state-of-the-art methods in extremely severe situations where the point cloud data becomes degenerate, there are momentary sensor interruptions, or the sensor moves along the map boundary or into unmapped regions.","sentences":["This paper presents a range inertial localization algorithm for a 3D prior map.","The proposed algorithm tightly couples scan-to-scan and scan-to-map point cloud registration factors along with IMU factors on a sliding window factor graph.","The tight coupling of the scan-to-scan and scan-to-map registration factors enables a smooth fusion of sensor ego-motion estimation and map-based trajectory correction that results in robust tracking of the sensor pose under severe point cloud degeneration and defective regions in a map.","We also propose an initial sensor state estimation algorithm that robustly estimates the gravity direction and IMU state and helps perform global localization in 3- or 4-DoF for system initialization without prior position information.","Experimental results show that the proposed method outperforms existing state-of-the-art methods in extremely severe situations where the point cloud data becomes degenerate, there are momentary sensor interruptions, or the sensor moves along the map boundary or into unmapped regions."],"url":"http://arxiv.org/abs/2402.05540v1"}
{"created":"2024-02-08 10:13:35","title":"Robust Parameter Fitting to Realistic Network Models via Iterative Stochastic Approximation","abstract":"Random graph models are widely used to understand network properties and graph algorithms. Key to such analyses are the different parameters of each model, which affect various network features, such as its size, clustering, or degree distribution. The exact effect of the parameters on these features is not well understood, mainly because we lack tools to thoroughly investigate this relation. Moreover, the parameters cannot be considered in isolation, as changing one affects multiple features. Existing approaches for finding the best model parameters of desired features, such as a grid search or estimating the parameter-feature relations, are not well suited, as they are inaccurate or computationally expensive.   We introduce an efficient iterative fitting method, named ParFit, that finds parameters using only a few network samples, based on the Robbins-Monro algorithm. We test ParFit on three well-known graph models, namely Erd\\H{o}s-R\\'enyi, Chung-Lu, and geometric inhomogeneous random graphs, as well as on real-world networks, including web networks. We find that ParFit performs well in terms of quality and running time across most parameter configurations.","sentences":["Random graph models are widely used to understand network properties and graph algorithms.","Key to such analyses are the different parameters of each model, which affect various network features, such as its size, clustering, or degree distribution.","The exact effect of the parameters on these features is not well understood, mainly because we lack tools to thoroughly investigate this relation.","Moreover, the parameters cannot be considered in isolation, as changing one affects multiple features.","Existing approaches for finding the best model parameters of desired features, such as a grid search or estimating the parameter-feature relations, are not well suited, as they are inaccurate or computationally expensive.   ","We introduce an efficient iterative fitting method, named ParFit, that finds parameters using only a few network samples, based on the Robbins-Monro algorithm.","We test ParFit on three well-known graph models, namely Erd\\H{o}s-R\\'enyi, Chung-Lu, and geometric inhomogeneous random graphs, as well as on real-world networks, including web networks.","We find that ParFit performs well in terms of quality and running time across most parameter configurations."],"url":"http://arxiv.org/abs/2402.05534v1"}
{"created":"2024-02-08 10:05:11","title":"Differentially Private Model-Based Offline Reinforcement Learning","abstract":"We address offline reinforcement learning with privacy guarantees, where the goal is to train a policy that is differentially private with respect to individual trajectories in the dataset. To achieve this, we introduce DP-MORL, an MBRL algorithm coming with differential privacy guarantees. A private model of the environment is first learned from offline data using DP-FedAvg, a training method for neural networks that provides differential privacy guarantees at the trajectory level. Then, we use model-based policy optimization to derive a policy from the (penalized) private model, without any further interaction with the system or access to the input data. We empirically show that DP-MORL enables the training of private RL agents from offline data and we furthermore outline the price of privacy in this setting.","sentences":["We address offline reinforcement learning with privacy guarantees, where the goal is to train a policy that is differentially private with respect to individual trajectories in the dataset.","To achieve this, we introduce DP-MORL, an MBRL algorithm coming with differential privacy guarantees.","A private model of the environment is first learned from offline data using DP-FedAvg, a training method for neural networks that provides differential privacy guarantees at the trajectory level.","Then, we use model-based policy optimization to derive a policy from the (penalized) private model, without any further interaction with the system or access to the input data.","We empirically show that DP-MORL enables the training of private RL agents from offline data and we furthermore outline the price of privacy in this setting."],"url":"http://arxiv.org/abs/2402.05525v1"}
{"created":"2024-02-08 10:01:29","title":"Linearizing Models for Efficient yet Robust Private Inference","abstract":"The growing concern about data privacy has led to the development of private inference (PI) frameworks in client-server applications which protects both data privacy and model IP. However, the cryptographic primitives required yield significant latency overhead which limits its wide-spread application. At the same time, changing environments demand the PI service to be robust against various naturally occurring and gradient-based perturbations. Despite several works focused on the development of latency-efficient models suitable for PI, the impact of these models on robustness has remained unexplored. Towards this goal, this paper presents RLNet, a class of robust linearized networks that can yield latency improvement via reduction of high-latency ReLU operations while improving the model performance on both clean and corrupted images. In particular, RLNet models provide a \"triple win ticket\" of improved classification accuracy on clean, naturally perturbed, and gradient-based perturbed images using a shared-mask shared-weight architecture with over an order of magnitude fewer ReLUs than baseline models. To demonstrate the efficacy of RLNet, we perform extensive experiments with ResNet and WRN model variants on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets. Our experimental evaluations show that RLNet can yield models with up to 11.14x fewer ReLUs, with accuracy close to the all-ReLU models, on clean, naturally perturbed, and gradient-based perturbed images. Compared with the SoTA non-robust linearized models at similar ReLU budgets, RLNet achieves an improvement in adversarial accuracy of up to ~47%, naturally perturbed accuracy up to ~16.4%, while improving clean image accuracy up to ~1.5%.","sentences":["The growing concern about data privacy has led to the development of private inference (PI) frameworks in client-server applications which protects both data privacy and model IP.","However, the cryptographic primitives required yield significant latency overhead which limits its wide-spread application.","At the same time, changing environments demand the PI service to be robust against various naturally occurring and gradient-based perturbations.","Despite several works focused on the development of latency-efficient models suitable for PI, the impact of these models on robustness has remained unexplored.","Towards this goal, this paper presents RLNet, a class of robust linearized networks that can yield latency improvement via reduction of high-latency ReLU operations while improving the model performance on both clean and corrupted images.","In particular, RLNet models provide a \"triple win ticket\" of improved classification accuracy on clean, naturally perturbed, and gradient-based perturbed images using a shared-mask shared-weight architecture with over an order of magnitude fewer ReLUs than baseline models.","To demonstrate the efficacy of RLNet, we perform extensive experiments with ResNet and WRN model variants on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets.","Our experimental evaluations show that RLNet can yield models with up to 11.14x fewer ReLUs, with accuracy close to the all-ReLU models, on clean, naturally perturbed, and gradient-based perturbed images.","Compared with the SoTA non-robust linearized models at similar ReLU budgets, RLNet achieves an improvement in adversarial accuracy of up to ~47%, naturally perturbed accuracy up to ~16.4%, while improving clean image accuracy up to ~1.5%."],"url":"http://arxiv.org/abs/2402.05521v1"}
{"created":"2024-02-08 10:00:40","title":"Can ChatGPT evaluate research quality?","abstract":"Purpose: Assess whether ChatGPT 4.0 is accurate enough to perform research evaluations on journal articles to automate this time-consuming task. Design/methodology/approach: Test the extent to which ChatGPT-4 can assess the quality of journal articles using a case study of the published scoring guidelines of the UK Research Excellence Framework (REF) 2021 to create a research evaluation ChatGPT. This was applied to 51 of my own articles and compared against my own quality judgements. Findings: ChatGPT-4 can produce plausible document summaries and quality evaluation rationales that match the REF criteria. Its overall scores have weak correlations with my self-evaluation scores of the same documents (averaging r=0.281 over 15 iterations, with 8 being statistically significantly different from 0). In contrast, the average scores from the 15 iterations produced a statistically significant positive correlation of 0.509. Thus, averaging scores from multiple ChatGPT-4 rounds seems more effective than individual scores. The positive correlation may be due to ChatGPT being able to extract the author's significance, rigour, and originality claims from inside each paper. If my weakest articles are removed, then the correlation with average scores (r=0.200) falls below statistical significance, suggesting that ChatGPT struggles to make fine-grained evaluations. Research limitations: The data is self-evaluations of a convenience sample of articles from one academic in one field. Practical implications: Overall, ChatGPT does not yet seem to be accurate enough to be trusted for any formal or informal research quality evaluation tasks. Research evaluators, including journal editors, should therefore take steps to control its use. Originality/value: This is the first published attempt at post-publication expert review accuracy testing for ChatGPT.","sentences":["Purpose: Assess whether ChatGPT 4.0 is accurate enough to perform research evaluations on journal articles to automate this time-consuming task.","Design/methodology/approach: Test the extent to which ChatGPT-4 can assess the quality of journal articles using a case study of the published scoring guidelines of the UK Research Excellence Framework (REF) 2021 to create a research evaluation ChatGPT.","This was applied to 51 of my own articles and compared against my own quality judgements.","Findings: ChatGPT-4 can produce plausible document summaries and quality evaluation rationales that match the REF criteria.","Its overall scores have weak correlations with my self-evaluation scores of the same documents (averaging r=0.281 over 15 iterations, with 8 being statistically significantly different from 0).","In contrast, the average scores from the 15 iterations produced a statistically significant positive correlation of 0.509.","Thus, averaging scores from multiple ChatGPT-4 rounds seems more effective than individual scores.","The positive correlation may be due to ChatGPT being able to extract the author's significance, rigour, and originality claims from inside each paper.","If my weakest articles are removed, then the correlation with average scores (r=0.200) falls below statistical significance, suggesting that ChatGPT struggles to make fine-grained evaluations.","Research limitations: The data is self-evaluations of a convenience sample of articles from one academic in one field.","Practical implications: Overall, ChatGPT does not yet seem to be accurate enough to be trusted for any formal or informal research quality evaluation tasks.","Research evaluators, including journal editors, should therefore take steps to control its use.","Originality/value: This is the first published attempt at post-publication expert review accuracy testing for ChatGPT."],"url":"http://arxiv.org/abs/2402.05519v1"}
{"created":"2024-02-08 09:44:02","title":"GPTs Are Multilingual Annotators for Sequence Generation Tasks","abstract":"Data annotation is an essential step for constructing new datasets. However, the conventional approach of data annotation through crowdsourcing is both time-consuming and expensive. In addition, the complexity of this process increases when dealing with low-resource languages owing to the difference in the language pool of crowdworkers. To address these issues, this study proposes an autonomous annotation method by utilizing large language models, which have been recently demonstrated to exhibit remarkable performance. Through our experiments, we demonstrate that the proposed method is not just cost-efficient but also applicable for low-resource language annotation. Additionally, we constructed an image captioning dataset using our approach and are committed to open this dataset for future study. We have opened our source code for further study and reproducibility.","sentences":["Data annotation is an essential step for constructing new datasets.","However, the conventional approach of data annotation through crowdsourcing is both time-consuming and expensive.","In addition, the complexity of this process increases when dealing with low-resource languages owing to the difference in the language pool of crowdworkers.","To address these issues, this study proposes an autonomous annotation method by utilizing large language models, which have been recently demonstrated to exhibit remarkable performance.","Through our experiments, we demonstrate that the proposed method is not just cost-efficient but also applicable for low-resource language annotation.","Additionally, we constructed an image captioning dataset using our approach and are committed to open this dataset for future study.","We have opened our source code for further study and reproducibility."],"url":"http://arxiv.org/abs/2402.05512v1"}
{"created":"2024-02-08 09:09:03","title":"A Solution for Commercializing, Decentralizing and Storing Electronic Medical Records by Integrating Proxy Re-Encryption, IPFS, and Blockchain","abstract":"The rapid expansion of user medical records across global systems presents not only opportunities but also new challenges in maintaining effective application models that ensure user privacy, controllability, and the ability to commercialize patient medical records. Moreover, the proliferation of data analysis models in healthcare institutions necessitates the decentralization and restorability of medical record data. It is imperative that user medical data collected from these systems can be easily analyzed and utilized even years after collection, without the risk of data loss due to numerous factors. Additionally, medical information must be authorized by the data owner, granting patients the right to accept or decline data usage requests from medical research agencies. In response, we propose an innovative solution for implementing a decentralized system utilizing an EVM-compatible blockchain and IPFS for decentralized storage. To ensure privacy and control, we employ Proxy Re-Encryption (PRE), a cryptographic authorized method, within the medical data marketplace. Our proposed architecture significantly reduces costs associated with granting read access to healthcare research agencies by minimizing the encryption and decryption time of stored records. Furthermore, it empowers users with enhanced control over their health data through tamperproof blockchain smart contracts and IPFS, safeguarding the integrity and privacy of their medical records.","sentences":["The rapid expansion of user medical records across global systems presents not only opportunities but also new challenges in maintaining effective application models that ensure user privacy, controllability, and the ability to commercialize patient medical records.","Moreover, the proliferation of data analysis models in healthcare institutions necessitates the decentralization and restorability of medical record data.","It is imperative that user medical data collected from these systems can be easily analyzed and utilized even years after collection, without the risk of data loss due to numerous factors.","Additionally, medical information must be authorized by the data owner, granting patients the right to accept or decline data usage requests from medical research agencies.","In response, we propose an innovative solution for implementing a decentralized system utilizing an EVM-compatible blockchain and IPFS for decentralized storage.","To ensure privacy and control, we employ Proxy Re-Encryption (PRE), a cryptographic authorized method, within the medical data marketplace.","Our proposed architecture significantly reduces costs associated with granting read access to healthcare research agencies by minimizing the encryption and decryption time of stored records.","Furthermore, it empowers users with enhanced control over their health data through tamperproof blockchain smart contracts and IPFS, safeguarding the integrity and privacy of their medical records."],"url":"http://arxiv.org/abs/2402.05498v1"}
{"created":"2024-02-08 08:55:34","title":"Determining the severity of Parkinson's disease in patients using a multi task neural network","abstract":"Parkinson's disease is easy to diagnose when it is advanced, but it is very difficult to diagnose in its early stages. Early diagnosis is essential to be able to treat the symptoms. It impacts on daily activities and reduces the quality of life of both the patients and their families and it is also the second most prevalent neurodegenerative disorder after Alzheimer in people over the age of 60. Most current studies on the prediction of Parkinson's severity are carried out in advanced stages of the disease. In this work, the study analyzes a set of variables that can be easily extracted from voice analysis, making it a very non-intrusive technique. In this paper, a method based on different deep learning techniques is proposed with two purposes. On the one hand, to find out if a person has severe or non-severe Parkinson's disease, and on the other hand, to determine by means of regression techniques the degree of evolution of the disease in a given patient. The UPDRS (Unified Parkinson's Disease Rating Scale) has been used by taking into account both the motor and total labels, and the best results have been obtained using a mixed multi-layer perceptron (MLP) that classifies and regresses at the same time and the most important features of the data obtained are taken as input, using an autoencoder. A success rate of 99.15% has been achieved in the problem of predicting whether a person suffers from severe Parkinson's disease or non-severe Parkinson's disease. In the degree of disease involvement prediction problem case, a MSE (Mean Squared Error) of 0.15 has been obtained. Using a full deep learning pipeline for data preprocessing and classification has proven to be very promising in the field Parkinson's outperforming the state-of-the-art proposals.","sentences":["Parkinson's disease is easy to diagnose when it is advanced, but it is very difficult to diagnose in its early stages.","Early diagnosis is essential to be able to treat the symptoms.","It impacts on daily activities and reduces the quality of life of both the patients and their families and it is also the second most prevalent neurodegenerative disorder after Alzheimer in people over the age of 60.","Most current studies on the prediction of Parkinson's severity are carried out in advanced stages of the disease.","In this work, the study analyzes a set of variables that can be easily extracted from voice analysis, making it a very non-intrusive technique.","In this paper, a method based on different deep learning techniques is proposed with two purposes.","On the one hand, to find out if a person has severe or non-severe Parkinson's disease, and on the other hand, to determine by means of regression techniques the degree of evolution of the disease in a given patient.","The UPDRS (Unified Parkinson's Disease Rating Scale) has been used by taking into account both the motor and total labels, and the best results have been obtained using a mixed multi-layer perceptron (MLP) that classifies and regresses at the same time and the most important features of the data obtained are taken as input, using an autoencoder.","A success rate of 99.15% has been achieved in the problem of predicting whether a person suffers from severe Parkinson's disease or non-severe Parkinson's disease.","In the degree of disease involvement prediction problem case, a MSE (Mean Squared Error) of 0.15 has been obtained.","Using a full deep learning pipeline for data preprocessing and classification has proven to be very promising in the field Parkinson's outperforming the state-of-the-art proposals."],"url":"http://arxiv.org/abs/2402.05491v1"}
{"created":"2024-02-08 08:12:42","title":"Kontextbasierte Aktivit\u00e4tserkennung -- Synergie von Mensch und Technik in der Social Networked Industry","abstract":"In a social networked industry, the focus is on collaboration between humans and technology. Communication is the basic prerequisite for synergetic collaboration between all players. It includes non-verbal as well as verbal interactions. To enable non-verbal interaction, machines must be able to detect and understand human movements. This article presents the ongoing fundamental research on the analysis of human movements using sensor-based activity recognition and identifies potential for a transfer to industrial applications. The focus is on the practical feasibility of activity recognition by adding further data streams such as the position data of logistical objects and tools, meaning the context in which a certain activity is carried out.   --   In der Social Networked Industry steht die Zusammenarbeit von Mensch und Technik im Vordergrund. Grundvoraussetzung f\\\"ur eine synergetische Zusammenarbeit aller Akteure ist die Kommunikation, welche neben verbalen auch nonverbale Interaktionen umfasst. Um eine nonverbale Interaktion zu erm\\\"oglichen, m\\\"ussen Maschinen in der Lage sein, menschliche Bewegungen zu erfassen und zu verstehen. Dieser Beitrag stellt die laufende Grundlagenforschung zur Analyse menschlicher Bewegungen mittels sensorgest\\\"utzter Aktivit\\\"atserkennung vor und zeigt Ankn\\\"upfungspunkte f\\\"ur einen Transfer in industrielle Anwendungen. Im Fokus steht die Praxistauglichkeit der Aktivit\\\"atserkennung durch die Hinzunahme weiterer Datenstr\\\"ome wie beispielsweise den Positionsdaten logistischer Objekte und Hilfsmitteln, d. h. dem Kontext, in dem eine gewisse Aktivit\\\"at ausgef\\\"uhrt wird.","sentences":["In a social networked industry, the focus is on collaboration between humans and technology.","Communication is the basic prerequisite for synergetic collaboration between all players.","It includes non-verbal as well as verbal interactions.","To enable non-verbal interaction, machines must be able to detect and understand human movements.","This article presents the ongoing fundamental research on the analysis of human movements using sensor-based activity recognition and identifies potential for a transfer to industrial applications.","The focus is on the practical feasibility of activity recognition by adding further data streams such as the position data of logistical objects and tools, meaning the context in which a certain activity is carried out.   ","--   In der Social Networked Industry steht die Zusammenarbeit von Mensch und","Technik im Vordergrund.","Grundvoraussetzung f\\\"ur eine synergetische Zusammenarbeit aller Akteure ist die Kommunikation, welche neben verbalen auch nonverbale Interaktionen umfasst.","Um eine nonverbale Interaktion zu erm\\\"oglichen, m\\\"ussen Maschinen in der Lage sein, menschliche Bewegungen zu erfassen und zu verstehen.","Dieser Beitrag stellt die laufende","Grundlagenforschung zur Analyse menschlicher Bewegungen mittels sensorgest\\\"utzter Aktivit\\\"atserkennung vor und zeigt Ankn\\\"upfungspunkte f\\\"ur einen Transfer in industrielle Anwendungen.","Im Fokus steht die Praxistauglichkeit der Aktivit\\\"atserkennung durch die Hinzunahme weiterer Datenstr\\\"ome","wie beispielsweise den Positionsdaten logistischer Objekte und Hilfsmitteln, d. h.","dem Kontext, in dem eine gewisse Aktivit\\\"at ausgef\\\"uhrt wird."],"url":"http://arxiv.org/abs/2402.05480v1"}
{"created":"2024-02-08 07:41:20","title":"I-FENN with Temporal Convolutional Networks: expediting the load-history analysis of non-local gradient damage propagation","abstract":"In this paper, we demonstrate for the first time how the Integrated Finite Element Neural Network (I-FENN) framework, previously proposed by the authors, can efficiently simulate the entire loading history of non-local gradient damage propagation. To achieve this goal, we first adopt a Temporal Convolutional Network (TCN) as the neural network of choice to capture the history-dependent evolution of the non-local strain in a coarsely meshed domain. The quality of the network predictions governs the computational performance of I-FENN, and therefore we perform an extended investigation aimed at enhancing them. We explore a data-driven vs. physics-informed TCN setup to arrive at an optimum network training, evaluating the network based on a coherent set of relevant performance metrics. We address the crucial issue of training a physics-informed network with input data that span vastly different length scales by proposing a systematic way of input normalization and output un-normalization. We then integrate the trained TCN within the nonlinear iterative FEM solver and apply I-FENN to simulate the damage propagation analysis. I-FENN is always applied in mesh idealizations different from the one used for the TCN training, showcasing the framework's ability to be used at progressively refined mesh resolutions. We illustrate several cases that I-FENN completes the simulation using either a modified or a full Newton-Raphson scheme, and we showcase its computational savings compared to both the classical monolithic and staggered FEM solvers. We underline that we satisfy very strict convergence criteria for every increment across the entire simulation, providing clear evidence of the robustness and accuracy of I-FENN. All the code and data used in this work will be made publicly available upon publication of the article.","sentences":["In this paper, we demonstrate for the first time how the Integrated Finite Element Neural Network (I-FENN) framework, previously proposed by the authors, can efficiently simulate the entire loading history of non-local gradient damage propagation.","To achieve this goal, we first adopt a Temporal Convolutional Network (TCN) as the neural network of choice to capture the history-dependent evolution of the non-local strain in a coarsely meshed domain.","The quality of the network predictions governs the computational performance of I-FENN, and therefore we perform an extended investigation aimed at enhancing them.","We explore a data-driven vs. physics-informed TCN setup to arrive at an optimum network training, evaluating the network based on a coherent set of relevant performance metrics.","We address the crucial issue of training a physics-informed network with input data that span vastly different length scales by proposing a systematic way of input normalization and output un-normalization.","We then integrate the trained TCN within the nonlinear iterative FEM solver and apply I-FENN to simulate the damage propagation analysis.","I-FENN is always applied in mesh idealizations different from the one used for the TCN training, showcasing the framework's ability to be used at progressively refined mesh resolutions.","We illustrate several cases that I-FENN completes the simulation using either a modified or a full Newton-Raphson scheme, and we showcase its computational savings compared to both the classical monolithic and staggered FEM solvers.","We underline that we satisfy very strict convergence criteria for every increment across the entire simulation, providing clear evidence of the robustness and accuracy of I-FENN.","All the code and data used in this work will be made publicly available upon publication of the article."],"url":"http://arxiv.org/abs/2402.05460v1"}
{"created":"2024-02-08 07:21:45","title":"It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition","abstract":"Recent studies have successfully shown that large language models (LLMs) can be successfully used for generative error correction (GER) on top of the automatic speech recognition (ASR) output. Specifically, an LLM is utilized to carry out a direct mapping from the N-best hypotheses list generated by an ASR system to the predicted output transcription. However, despite its effectiveness, GER introduces extra data uncertainty since the LLM is trained without taking into account acoustic information available in the speech signal. In this work, we aim to overcome such a limitation by infusing acoustic information before generating the predicted transcription through a novel late fusion solution termed Uncertainty-Aware Dynamic Fusion (UADF). UADF is a multimodal fusion approach implemented into an auto-regressive decoding process and works in two stages: (i) It first analyzes and calibrates the token-level LLM decision, and (ii) it then dynamically assimilates the information from the acoustic modality. Experimental evidence collected from various ASR tasks shows that UADF surpasses existing fusion mechanisms in several ways. It yields significant improvements in word error rate (WER) while mitigating data uncertainty issues in LLM and addressing the poor generalization relied with sole modality during fusion. We also demonstrate that UADF seamlessly adapts to audio-visual speech recognition.","sentences":["Recent studies have successfully shown that large language models (LLMs) can be successfully used for generative error correction (GER) on top of the automatic speech recognition (ASR) output.","Specifically, an LLM is utilized to carry out a direct mapping from the N-best hypotheses list generated by an ASR system to the predicted output transcription.","However, despite its effectiveness, GER introduces extra data uncertainty since the LLM is trained without taking into account acoustic information available in the speech signal.","In this work, we aim to overcome such a limitation by infusing acoustic information before generating the predicted transcription through a novel late fusion solution termed Uncertainty-Aware Dynamic Fusion (UADF).","UADF is a multimodal fusion approach implemented into an auto-regressive decoding process and works in two stages: (i) It first analyzes and calibrates the token-level LLM decision, and (ii) it then dynamically assimilates the information from the acoustic modality.","Experimental evidence collected from various ASR tasks shows that UADF surpasses existing fusion mechanisms in several ways.","It yields significant improvements in word error rate (WER) while mitigating data uncertainty issues in LLM and addressing the poor generalization relied with sole modality during fusion.","We also demonstrate that UADF seamlessly adapts to audio-visual speech recognition."],"url":"http://arxiv.org/abs/2402.05457v1"}
{"created":"2024-02-08 07:14:17","title":"Mitigating Privacy Risk in Membership Inference by Convex-Concave Loss","abstract":"Machine learning models are susceptible to membership inference attacks (MIAs), which aim to infer whether a sample is in the training set. Existing work utilizes gradient ascent to enlarge the loss variance of training data, alleviating the privacy risk. However, optimizing toward a reverse direction may cause the model parameters to oscillate near local minima, leading to instability and suboptimal performance. In this work, we propose a novel method -- Convex-Concave Loss, which enables a high variance of training loss distribution by gradient descent. Our method is motivated by the theoretical analysis that convex losses tend to decrease the loss variance during training. Thus, our key idea behind CCL is to reduce the convexity of loss functions with a concave term. Trained with CCL, neural networks produce losses with high variance for training data, reinforcing the defense against MIAs. Extensive experiments demonstrate the superiority of CCL, achieving state-of-the-art balance in the privacy-utility trade-off.","sentences":["Machine learning models are susceptible to membership inference attacks (MIAs), which aim to infer whether a sample is in the training set.","Existing work utilizes gradient ascent to enlarge the loss variance of training data, alleviating the privacy risk.","However, optimizing toward a reverse direction may cause the model parameters to oscillate near local minima, leading to instability and suboptimal performance.","In this work, we propose a novel method -- Convex-Concave Loss, which enables a high variance of training loss distribution by gradient descent.","Our method is motivated by the theoretical analysis that convex losses tend to decrease the loss variance during training.","Thus, our key idea behind CCL is to reduce the convexity of loss functions with a concave term.","Trained with CCL, neural networks produce losses with high variance for training data, reinforcing the defense against MIAs.","Extensive experiments demonstrate the superiority of CCL, achieving state-of-the-art balance in the privacy-utility trade-off."],"url":"http://arxiv.org/abs/2402.05453v1"}
{"created":"2024-02-08 07:08:55","title":"Low-degree phase transitions for detecting a planted clique in sublinear time","abstract":"We consider the problem of detecting a planted clique of size $k$ in a random graph on $n$ vertices. When the size of the clique exceeds $\\Theta(\\sqrt{n})$, polynomial-time algorithms for detection proliferate. We study faster -- namely, sublinear time -- algorithms in the high-signal regime when $k = \\Theta(n^{1/2 + \\delta})$, for some $\\delta > 0$. To this end, we consider algorithms that non-adaptively query a subset $M$ of entries of the adjacency matrix and then compute a low-degree polynomial function of the revealed entries. We prove a computational phase transition for this class of non-adaptive low-degree algorithms: under the scaling $\\lvert M \\rvert = \\Theta(n^{\\gamma})$, the clique can be detected when $\\gamma > 3(1/2 - \\delta)$ but not when $\\gamma < 3(1/2 - \\delta)$. As a result, the best known runtime for detecting a planted clique, $\\widetilde{O}(n^{3(1/2-\\delta)})$, cannot be improved without looking beyond the non-adaptive low-degree class.   Our proof of the lower bound -- based on bounding the conditional low-degree likelihood ratio -- reveals further structure in non-adaptive detection of a planted clique. Using (a bound on) the conditional low-degree likelihood ratio as a potential function, we show that for every non-adaptive query pattern, there is a highly structured query pattern of the same size that is at least as effective.","sentences":["We consider the problem of detecting a planted clique of size $k$ in a random graph on $n$ vertices.","When the size of the clique exceeds $\\Theta(\\sqrt{n})$, polynomial-time algorithms for detection proliferate.","We study faster -- namely, sublinear time -- algorithms in the high-signal regime when $k = \\Theta(n^{1/2 + \\delta})$, for some $\\delta > 0$.","To this end, we consider algorithms that non-adaptively query a subset $M$ of entries of the adjacency matrix and then compute a low-degree polynomial function of the revealed entries.","We prove a computational phase transition for this class of non-adaptive low-degree algorithms: under the scaling $\\lvert M \\rvert = \\Theta(n^{\\gamma})$, the clique can be detected when $\\gamma > 3(1/2 - \\delta)$ but not when $\\gamma < 3(1/2 - \\delta)$. As a result, the best known runtime for detecting a planted clique, $\\widetilde{O}(n^{3(1/2-\\delta)})$, cannot be improved without looking beyond the non-adaptive low-degree class.   ","Our proof of the lower bound -- based on bounding the conditional low-degree likelihood ratio -- reveals further structure in non-adaptive detection of a planted clique.","Using (a bound on) the conditional low-degree likelihood ratio as a potential function, we show that for every non-adaptive query pattern, there is a highly structured query pattern of the same size that is at least as effective."],"url":"http://arxiv.org/abs/2402.05451v1"}
{"created":"2024-02-08 06:35:06","title":"Spiking Neural Network Enhanced Hand Gesture Recognition Using Low-Cost Single-photon Avalanche Diode Array","abstract":"We present a compact spiking convolutional neural network (SCNN) and spiking multilayer perceptron (SMLP) to recognize ten different gestures in dark and bright light environments, using a $9.6 single-photon avalanche diode (SPAD) array. In our hand gesture recognition (HGR) system, photon intensity data was leveraged to train and test the network. A vanilla convolutional neural network (CNN) was also implemented to compare the performance of SCNN with the same network topologies and training strategies. Our SCNN was trained from scratch instead of being converted from the CNN. We tested the three models in dark and ambient light (AL)-corrupted environments. The results indicate that SCNN achieves comparable accuracy (90.8%) to CNN (92.9%) and exhibits lower floating operations with only 8 timesteps. SMLP also presents a trade-off between computational workload and accuracy. The code and collected datasets of this work are available at https://github.com/zzy666666zzy/TinyLiDAR_NET_SNN.","sentences":["We present a compact spiking convolutional neural network (SCNN) and spiking multilayer perceptron (SMLP) to recognize ten different gestures in dark and bright light environments, using a $9.6 single-photon avalanche diode (SPAD) array.","In our hand gesture recognition (HGR) system, photon intensity data was leveraged to train and test the network.","A vanilla convolutional neural network (CNN) was also implemented to compare the performance of SCNN with the same network topologies and training strategies.","Our SCNN was trained from scratch instead of being converted from the CNN.","We tested the three models in dark and ambient light (AL)-corrupted environments.","The results indicate that SCNN achieves comparable accuracy (90.8%) to CNN (92.9%) and exhibits lower floating operations with only 8 timesteps.","SMLP also presents a trade-off between computational workload and accuracy.","The code and collected datasets of this work are available at https://github.com/zzy666666zzy/TinyLiDAR_NET_SNN."],"url":"http://arxiv.org/abs/2402.05441v1"}
{"created":"2024-02-08 05:54:08","title":"Mixture Density Networks for Classification with an Application to Product Bundling","abstract":"While mixture density networks (MDNs) have been extensively used for regression tasks, they have not been used much for classification tasks. One reason for this is that the usability of MDNs for classification is not clear and straightforward. In this paper, we propose two MDN-based models for classification tasks. Both models fit mixtures of Gaussians to the the data and use the fitted distributions to classify a given sample by evaluating the learnt cumulative distribution function for the given input features. While the proposed MDN-based models perform slightly better than, or on par with, five baseline classification models on three publicly available datasets, the real utility of our models comes out through a real-world product bundling application. Specifically, we use our MDN-based models to learn the willingness-to-pay (WTP) distributions for two products from synthetic sales data of the individual products. The Gaussian mixture representation of the learnt WTP distributions is then exploited to obtain the WTP distribution of the bundle consisting of both the products. The proposed MDN-based models are able to approximate the true WTP distributions of both products and the bundle well.","sentences":["While mixture density networks (MDNs) have been extensively used for regression tasks, they have not been used much for classification tasks.","One reason for this is that the usability of MDNs for classification is not clear and straightforward.","In this paper, we propose two MDN-based models for classification tasks.","Both models fit mixtures of Gaussians to the the data and use the fitted distributions to classify a given sample by evaluating the learnt cumulative distribution function for the given input features.","While the proposed MDN-based models perform slightly better than, or on par with, five baseline classification models on three publicly available datasets, the real utility of our models comes out through a real-world product bundling application.","Specifically, we use our MDN-based models to learn the willingness-to-pay (WTP) distributions for two products from synthetic sales data of the individual products.","The Gaussian mixture representation of the learnt WTP distributions is then exploited to obtain the WTP distribution of the bundle consisting of both the products.","The proposed MDN-based models are able to approximate the true WTP distributions of both products and the bundle well."],"url":"http://arxiv.org/abs/2402.05428v1"}
{"created":"2024-02-08 05:42:13","title":"Neural Circuit Diagrams: Robust Diagrams for the Communication, Implementation, and Analysis of Deep Learning Architectures","abstract":"Diagrams matter. Unfortunately, the deep learning community has no standard method for diagramming architectures. The current combination of linear algebra notation and ad-hoc diagrams fails to offer the necessary precision to understand architectures in all their detail. However, this detail is critical for faithful implementation, mathematical analysis, further innovation, and ethical assurances. I present neural circuit diagrams, a graphical language tailored to the needs of communicating deep learning architectures. Neural circuit diagrams naturally keep track of the changing arrangement of data, precisely show how operations are broadcast over axes, and display the critical parallel behavior of linear operations. A lingering issue with existing diagramming methods is the inability to simultaneously express the detail of axes and the free arrangement of data, which neural circuit diagrams solve. Their compositional structure is analogous to code, creating a close correspondence between diagrams and implementation.   In this work, I introduce neural circuit diagrams for an audience of machine learning researchers. After introducing neural circuit diagrams, I cover a host of architectures to show their utility and breed familiarity. This includes the transformer architecture, convolution (and its difficult-to-explain extensions), residual networks, the U-Net, and the vision transformer. I include a Jupyter notebook that provides evidence for the close correspondence between diagrams and code. Finally, I examine backpropagation using neural circuit diagrams. I show their utility in providing mathematical insight and analyzing algorithms' time and space complexities.","sentences":["Diagrams matter.","Unfortunately, the deep learning community has no standard method for diagramming architectures.","The current combination of linear algebra notation and ad-hoc diagrams fails to offer the necessary precision to understand architectures in all their detail.","However, this detail is critical for faithful implementation, mathematical analysis, further innovation, and ethical assurances.","I present neural circuit diagrams, a graphical language tailored to the needs of communicating deep learning architectures.","Neural circuit diagrams naturally keep track of the changing arrangement of data, precisely show how operations are broadcast over axes, and display the critical parallel behavior of linear operations.","A lingering issue with existing diagramming methods is the inability to simultaneously express the detail of axes and the free arrangement of data, which neural circuit diagrams solve.","Their compositional structure is analogous to code, creating a close correspondence between diagrams and implementation.   ","In this work, I introduce neural circuit diagrams for an audience of machine learning researchers.","After introducing neural circuit diagrams, I cover a host of architectures to show their utility and breed familiarity.","This includes the transformer architecture, convolution (and its difficult-to-explain extensions), residual networks, the U-Net, and the vision transformer.","I include a Jupyter notebook that provides evidence for the close correspondence between diagrams and code.","Finally, I examine backpropagation using neural circuit diagrams.","I show their utility in providing mathematical insight and analyzing algorithms' time and space complexities."],"url":"http://arxiv.org/abs/2402.05424v1"}
{"created":"2024-02-08 05:39:11","title":"MTSA-SNN: A Multi-modal Time Series Analysis Model Based on Spiking Neural Network","abstract":"Time series analysis and modelling constitute a crucial research area. Traditional artificial neural networks struggle with complex, non-stationary time series data due to high computational complexity, limited ability to capture temporal information, and difficulty in handling event-driven data. To address these challenges, we propose a Multi-modal Time Series Analysis Model Based on Spiking Neural Network (MTSA-SNN). The Pulse Encoder unifies the encoding of temporal images and sequential information in a common pulse-based representation. The Joint Learning Module employs a joint learning function and weight allocation mechanism to fuse information from multi-modal pulse signals complementary. Additionally, we incorporate wavelet transform operations to enhance the model's ability to analyze and evaluate temporal information. Experimental results demonstrate that our method achieved superior performance on three complex time-series tasks. This work provides an effective event-driven approach to overcome the challenges associated with analyzing intricate temporal information. Access to the source code is available at https://github.com/Chenngzz/MTSA-SNN}{https://github.com/Chenngzz/MTSA-SNN","sentences":["Time series analysis and modelling constitute a crucial research area.","Traditional artificial neural networks struggle with complex, non-stationary time series data due to high computational complexity, limited ability to capture temporal information, and difficulty in handling event-driven data.","To address these challenges, we propose a Multi-modal Time Series Analysis Model Based on Spiking Neural Network (MTSA-SNN).","The Pulse Encoder unifies the encoding of temporal images and sequential information in a common pulse-based representation.","The Joint Learning Module employs a joint learning function and weight allocation mechanism to fuse information from multi-modal pulse signals complementary.","Additionally, we incorporate wavelet transform operations to enhance the model's ability to analyze and evaluate temporal information.","Experimental results demonstrate that our method achieved superior performance on three complex time-series tasks.","This work provides an effective event-driven approach to overcome the challenges associated with analyzing intricate temporal information.","Access to the source code is available at https://github.com/Chenngzz/MTSA-SNN}{https://github.com/Chenngzz/MTSA-SNN"],"url":"http://arxiv.org/abs/2402.05423v1"}
{"created":"2024-02-08 04:48:51","title":"Version age-based client scheduling policy for federated learning","abstract":"Federated Learning (FL) has emerged as a privacy-preserving machine learning paradigm facilitating collaborative training across multiple clients without sharing local data. Despite advancements in edge device capabilities, communication bottlenecks present challenges in aggregating a large number of clients; only a portion of the clients can update their parameters upon each global aggregation. This phenomenon introduces the critical challenge of stragglers in FL and the profound impact of client scheduling policies on global model convergence and stability. Existing scheduling strategies address staleness but predominantly focus on either timeliness or content. Motivated by this, we introduce the novel concept of Version Age of Information (VAoI) to FL. Unlike traditional Age of Information metrics, VAoI considers both timeliness and content staleness. Each client's version age is updated discretely, indicating the freshness of information. VAoI is incorporated into the client scheduling policy to minimize the average VAoI, mitigating the impact of outdated local updates and enhancing the stability of FL systems.","sentences":["Federated Learning (FL) has emerged as a privacy-preserving machine learning paradigm facilitating collaborative training across multiple clients without sharing local data.","Despite advancements in edge device capabilities, communication bottlenecks present challenges in aggregating a large number of clients; only a portion of the clients can update their parameters upon each global aggregation.","This phenomenon introduces the critical challenge of stragglers in FL and the profound impact of client scheduling policies on global model convergence and stability.","Existing scheduling strategies address staleness but predominantly focus on either timeliness or content.","Motivated by this, we introduce the novel concept of Version Age of Information (VAoI) to FL.","Unlike traditional Age of Information metrics, VAoI considers both timeliness and content staleness.","Each client's version age is updated discretely, indicating the freshness of information.","VAoI is incorporated into the client scheduling policy to minimize the average VAoI, mitigating the impact of outdated local updates and enhancing the stability of FL systems."],"url":"http://arxiv.org/abs/2402.05407v1"}
{"created":"2024-02-08 04:35:09","title":"Adaptive Activation Functions for Predictive Modeling with Sparse Experimental Data","abstract":"A pivotal aspect in the design of neural networks lies in selecting activation functions, crucial for introducing nonlinear structures that capture intricate input-output patterns. While the effectiveness of adaptive or trainable activation functions has been studied in domains with ample data, like image classification problems, significant gaps persist in understanding their influence on classification accuracy and predictive uncertainty in settings characterized by limited data availability. This research aims to address these gaps by investigating the use of two types of adaptive activation functions. These functions incorporate shared and individual trainable parameters per hidden layer and are examined in three testbeds derived from additive manufacturing problems containing fewer than one hundred training instances. Our investigation reveals that adaptive activation functions, such as Exponential Linear Unit (ELU) and Softplus, with individual trainable parameters, result in accurate and confident prediction models that outperform fixed-shape activation functions and the less flexible method of using identical trainable activation functions in a hidden layer. Therefore, this work presents an elegant way of facilitating the design of adaptive neural networks in scientific and engineering problems.","sentences":["A pivotal aspect in the design of neural networks lies in selecting activation functions, crucial for introducing nonlinear structures that capture intricate input-output patterns.","While the effectiveness of adaptive or trainable activation functions has been studied in domains with ample data, like image classification problems, significant gaps persist in understanding their influence on classification accuracy and predictive uncertainty in settings characterized by limited data availability.","This research aims to address these gaps by investigating the use of two types of adaptive activation functions.","These functions incorporate shared and individual trainable parameters per hidden layer and are examined in three testbeds derived from additive manufacturing problems containing fewer than one hundred training instances.","Our investigation reveals that adaptive activation functions, such as Exponential Linear Unit (ELU) and Softplus, with individual trainable parameters, result in accurate and confident prediction models that outperform fixed-shape activation functions and the less flexible method of using identical trainable activation functions in a hidden layer.","Therefore, this work presents an elegant way of facilitating the design of adaptive neural networks in scientific and engineering problems."],"url":"http://arxiv.org/abs/2402.05401v1"}
{"created":"2024-02-08 04:31:21","title":"Optimizing for ROC Curves on Class-Imbalanced Data by Training over a Family of Loss Functions","abstract":"Although binary classification is a well-studied problem in computer vision, training reliable classifiers under severe class imbalance remains a challenging problem. Recent work has proposed techniques that mitigate the effects of training under imbalance by modifying the loss functions or optimization methods. While this work has led to significant improvements in the overall accuracy in the multi-class case, we observe that slight changes in hyperparameter values of these methods can result in highly variable performance in terms of Receiver Operating Characteristic (ROC) curves on binary problems with severe imbalance. To reduce the sensitivity to hyperparameter choices and train more general models, we propose training over a family of loss functions, instead of a single loss function. We develop a method for applying Loss Conditional Training (LCT) to an imbalanced classification problem. Extensive experiment results, on both CIFAR and Kaggle competition datasets, show that our method improves model performance and is more robust to hyperparameter choices. Code will be made available at: https://github.com/klieberman/roc_lct.","sentences":["Although binary classification is a well-studied problem in computer vision, training reliable classifiers under severe class imbalance remains a challenging problem.","Recent work has proposed techniques that mitigate the effects of training under imbalance by modifying the loss functions or optimization methods.","While this work has led to significant improvements in the overall accuracy in the multi-class case, we observe that slight changes in hyperparameter values of these methods can result in highly variable performance in terms of Receiver Operating Characteristic (ROC) curves on binary problems with severe imbalance.","To reduce the sensitivity to hyperparameter choices and train more general models, we propose training over a family of loss functions, instead of a single loss function.","We develop a method for applying Loss Conditional Training (LCT) to an imbalanced classification problem.","Extensive experiment results, on both CIFAR and Kaggle competition datasets, show that our method improves model performance and is more robust to hyperparameter choices.","Code will be made available at: https://github.com/klieberman/roc_lct."],"url":"http://arxiv.org/abs/2402.05400v1"}
{"created":"2024-02-08 04:27:14","title":"CURE: Simulation-Augmented Auto-Tuning in Robotics","abstract":"Robotic systems are typically composed of various subsystems, such as localization and navigation, each encompassing numerous configurable components (e.g., selecting different planning algorithms). Once an algorithm has been selected for a component, its associated configuration options must be set to the appropriate values. Configuration options across the system stack interact non-trivially. Finding optimal configurations for highly configurable robots to achieve desired performance poses a significant challenge due to the interactions between configuration options across software and hardware that result in an exponentially large and complex configuration space. These challenges are further compounded by the need for transferability between different environments and robotic platforms. Data efficient optimization algorithms (e.g., Bayesian optimization) have been increasingly employed to automate the tuning of configurable parameters in cyber-physical systems. However, such optimization algorithms converge at later stages, often after exhausting the allocated budget (e.g., optimization steps, allotted time) and lacking transferability. This paper proposes CURE -- a method that identifies causally relevant configuration options, enabling the optimization process to operate in a reduced search space, thereby enabling faster optimization of robot performance. CURE abstracts the causal relationships between various configuration options and robot performance objectives by learning a causal model in the source (a low-cost environment such as the Gazebo simulator) and applying the learned knowledge to perform optimization in the target (e.g., Turtlebot 3 physical robot). We demonstrate the effectiveness and transferability of CURE by conducting experiments that involve varying degrees of deployment changes in both physical robots and simulation.","sentences":["Robotic systems are typically composed of various subsystems, such as localization and navigation, each encompassing numerous configurable components (e.g., selecting different planning algorithms).","Once an algorithm has been selected for a component, its associated configuration options must be set to the appropriate values.","Configuration options across the system stack interact non","-trivially.","Finding optimal configurations for highly configurable robots to achieve desired performance poses a significant challenge due to the interactions between configuration options across software and hardware that result in an exponentially large and complex configuration space.","These challenges are further compounded by the need for transferability between different environments and robotic platforms.","Data efficient optimization algorithms (e.g., Bayesian optimization) have been increasingly employed to automate the tuning of configurable parameters in cyber-physical systems.","However, such optimization algorithms converge at later stages, often after exhausting the allocated budget (e.g., optimization steps, allotted time) and lacking transferability.","This paper proposes CURE -- a method that identifies causally relevant configuration options, enabling the optimization process to operate in a reduced search space, thereby enabling faster optimization of robot performance.","CURE abstracts the causal relationships between various configuration options and robot performance objectives by learning a causal model in the source (a low-cost environment such as the Gazebo simulator) and applying the learned knowledge to perform optimization in the target (e.g., Turtlebot 3 physical robot).","We demonstrate the effectiveness and transferability of CURE by conducting experiments that involve varying degrees of deployment changes in both physical robots and simulation."],"url":"http://arxiv.org/abs/2402.05399v1"}
{"created":"2024-02-08 03:46:32","title":"Task-customized Masked AutoEncoder via Mixture of Cluster-conditional Experts","abstract":"Masked Autoencoder~(MAE) is a prevailing self-supervised learning method that achieves promising results in model pre-training. However, when the various downstream tasks have data distributions different from the pre-training data, the semantically irrelevant pre-training information might result in negative transfer, impeding MAE's scalability. To address this issue, we propose a novel MAE-based pre-training paradigm, Mixture of Cluster-conditional Experts (MoCE), which can be trained once but provides customized pre-training models for diverse downstream tasks. Different from the mixture of experts (MoE), our MoCE trains each expert only with semantically relevant images by using cluster-conditional gates. Thus, each downstream task can be allocated to its customized model pre-trained with data most similar to the downstream data. Experiments on a collection of 11 downstream tasks show that MoCE outperforms the vanilla MAE by 2.45\\% on average. It also obtains new state-of-the-art self-supervised learning results on detection and segmentation.","sentences":["Masked Autoencoder~(MAE) is a prevailing self-supervised learning method that achieves promising results in model pre-training.","However, when the various downstream tasks have data distributions different from the pre-training data, the semantically irrelevant pre-training information might result in negative transfer, impeding MAE's scalability.","To address this issue, we propose a novel MAE-based pre-training paradigm, Mixture of Cluster-conditional Experts (MoCE), which can be trained once but provides customized pre-training models for diverse downstream tasks.","Different from the mixture of experts (MoE), our MoCE trains each expert only with semantically relevant images by using cluster-conditional gates.","Thus, each downstream task can be allocated to its customized model pre-trained with data most similar to the downstream data.","Experiments on a collection of 11 downstream tasks show that MoCE outperforms the vanilla MAE by 2.45\\% on average.","It also obtains new state-of-the-art self-supervised learning results on detection and segmentation."],"url":"http://arxiv.org/abs/2402.05382v1"}
{"created":"2024-02-08 03:00:50","title":"Attention as Robust Representation for Time Series Forecasting","abstract":"Time series forecasting is essential for many practical applications, with the adoption of transformer-based models on the rise due to their impressive performance in NLP and CV. Transformers' key feature, the attention mechanism, dynamically fusing embeddings to enhance data representation, often relegating attention weights to a byproduct role. Yet, time series data, characterized by noise and non-stationarity, poses significant forecasting challenges. Our approach elevates attention weights as the primary representation for time series, capitalizing on the temporal relationships among data points to improve forecasting accuracy. Our study shows that an attention map, structured using global landmarks and local windows, acts as a robust kernel representation for data points, withstanding noise and shifts in distribution. Our method outperforms state-of-the-art models, reducing mean squared error (MSE) in multivariate time series forecasting by a notable 3.6% without altering the core neural network architecture. It serves as a versatile component that can readily replace recent patching based embedding schemes in transformer-based models, boosting their performance.","sentences":["Time series forecasting is essential for many practical applications, with the adoption of transformer-based models on the rise due to their impressive performance in NLP and CV.","Transformers' key feature, the attention mechanism, dynamically fusing embeddings to enhance data representation, often relegating attention weights to a byproduct role.","Yet, time series data, characterized by noise and non-stationarity, poses significant forecasting challenges.","Our approach elevates attention weights as the primary representation for time series, capitalizing on the temporal relationships among data points to improve forecasting accuracy.","Our study shows that an attention map, structured using global landmarks and local windows, acts as a robust kernel representation for data points, withstanding noise and shifts in distribution.","Our method outperforms state-of-the-art models, reducing mean squared error (MSE) in multivariate time series forecasting by a notable 3.6% without altering the core neural network architecture.","It serves as a versatile component that can readily replace recent patching based embedding schemes in transformer-based models, boosting their performance."],"url":"http://arxiv.org/abs/2402.05370v1"}
{"created":"2024-02-08 02:58:47","title":"Noise Contrastive Alignment of Language Models with Explicit Rewards","abstract":"User intentions are typically formalized as evaluation rewards to be maximized when fine-tuning language models (LMs). Existing alignment methods, such as Direct Preference Optimization (DPO), are mainly tailored for pairwise preference data where rewards are implicitly defined rather than explicitly given. In this paper, we introduce a general framework for LM alignment, leveraging Noise Contrastive Estimation (NCE) to bridge the gap in handling reward datasets explicitly annotated with scalar evaluations. Our framework comprises two parallel algorithms, NCA and InfoNCA, both enabling the direct extraction of an LM policy from reward data as well as preference data. Notably, we show that the DPO loss is a special case of our proposed InfoNCA objective under pairwise preference settings, thereby integrating and extending current alignment theories. By contrasting NCA and InfoNCA, we show that InfoNCA and DPO adjust relative likelihood across different responses to a single instruction, while NCA optimizes absolute likelihood for each response. We apply our methods to align a 7B language model with a GPT-4 annotated reward dataset. Experimental results suggest that InfoNCA surpasses the DPO baseline in GPT-4 evaluations, while NCA enjoys better training stability with competitive performance.","sentences":["User intentions are typically formalized as evaluation rewards to be maximized when fine-tuning language models (LMs).","Existing alignment methods, such as Direct Preference Optimization (DPO), are mainly tailored for pairwise preference data where rewards are implicitly defined rather than explicitly given.","In this paper, we introduce a general framework for LM alignment, leveraging Noise Contrastive Estimation (NCE) to bridge the gap in handling reward datasets explicitly annotated with scalar evaluations.","Our framework comprises two parallel algorithms, NCA and InfoNCA, both enabling the direct extraction of an LM policy from reward data as well as preference data.","Notably, we show that the DPO loss is a special case of our proposed InfoNCA objective under pairwise preference settings, thereby integrating and extending current alignment theories.","By contrasting NCA and InfoNCA, we show that InfoNCA and DPO adjust relative likelihood across different responses to a single instruction, while NCA optimizes absolute likelihood for each response.","We apply our methods to align a 7B language model with a GPT-4 annotated reward dataset.","Experimental results suggest that InfoNCA surpasses the DPO baseline in GPT-4 evaluations, while NCA enjoys better training stability with competitive performance."],"url":"http://arxiv.org/abs/2402.05369v1"}
{"created":"2024-02-08 02:30:44","title":"Dynamic Geometric Connectivity in the Plane with Constant Query Time","abstract":"We present the first fully dynamic connectivity data structures for geometric intersection graphs achieving constant query time and sublinear amortized update time for most types of geometric objects in 2D. Our data structures can answer connectivity queries between two objects, as well as \"global\" connectivity queries (e.g., deciding whether the entire graph is connected). Previously, the data structure by Afshani and Chan (ESA'06) achieved such bounds only in the special case of axis-aligned line segments or rectangles but did not work for arbitrary line segments or disks, whereas the data structures by Chan, P\\u{a}tra\\c{s}cu and Roditty (FOCS'08) worked for more general classes of geometric objects but required $n^{\\Omega(1)}$ query time and could not handle global connectivity queries.   Specifically, we obtain new data structures with $O(1)$ query time and amortized update time near $n^{4/5}$, $n^{7/8}$, and $n^{20/21}$ for axis-aligned line segments, disks, and arbitrary line segments respectively. Besides greatly reducing the query time, our data structures also improve the previous update times for axis-aligned line segments by Afshani and Chan (from near $n^{10/11}$ to $n^{4/5}$) and for disks by Chan, P\\u{a}tra\\c{s}cu, and Roditty (from near $n^{20/21}$ to $n^{7/8}$).","sentences":["We present the first fully dynamic connectivity data structures for geometric intersection graphs achieving constant query time and sublinear amortized update time for most types of geometric objects in 2D. Our data structures can answer connectivity queries between two objects, as well as \"global\" connectivity queries (e.g., deciding whether the entire graph is connected).","Previously, the data structure by Afshani and Chan (ESA'06) achieved such bounds only in the special case of axis-aligned line segments or rectangles but did not work for arbitrary line segments or disks, whereas the data structures by Chan, P\\u{a}tra\\c{s}cu and Roditty (FOCS'08) worked for more general classes of geometric objects but required $n^{\\Omega(1)}$ query time and could not handle global connectivity queries.   ","Specifically, we obtain new data structures with $O(1)$ query time and amortized update time near $n^{4/5}$, $n^{7/8}$, and $n^{20/21}$ for axis-aligned line segments, disks, and arbitrary line segments respectively.","Besides greatly reducing the query time, our data structures also improve the previous update times for axis-aligned line segments by Afshani and Chan (from near $n^{10/11}$ to $n^{4/5}$) and for disks by Chan, P\\u{a}tra\\c{s}cu, and Roditty (from near $n^{20/21}$ to $n^{7/8}$)."],"url":"http://arxiv.org/abs/2402.05357v1"}
{"created":"2024-02-08 02:29:33","title":"Exploring Learning Complexity for Downstream Data Pruning","abstract":"The over-parameterized pre-trained models pose a great challenge to fine-tuning with limited computation resources. An intuitive solution is to prune the less informative samples from the fine-tuning dataset. A series of training-based scoring functions are proposed to quantify the informativeness of the data subset but the pruning cost becomes non-negligible due to the heavy parameter updating. For efficient pruning, it is viable to adapt the similarity scoring function of geometric-based methods from training-based to training-free. However, we empirically show that such adaption distorts the original pruning and results in inferior performance on the downstream tasks. In this paper, we propose to treat the learning complexity (LC) as the scoring function for classification and regression tasks. Specifically, the learning complexity is defined as the average predicted confidence of subnets with different capacities, which encapsulates data processing within a converged model. Then we preserve the diverse and easy samples for fine-tuning. Extensive experiments with vision datasets demonstrate the effectiveness and efficiency of the proposed scoring function for classification tasks. For the instruction fine-tuning of large language models, our method achieves state-of-the-art performance with stable convergence, outperforming the full training with only 10\\% of the instruction dataset.","sentences":["The over-parameterized pre-trained models pose a great challenge to fine-tuning with limited computation resources.","An intuitive solution is to prune the less informative samples from the fine-tuning dataset.","A series of training-based scoring functions are proposed to quantify the informativeness of the data subset but the pruning cost becomes non-negligible due to the heavy parameter updating.","For efficient pruning, it is viable to adapt the similarity scoring function of geometric-based methods from training-based to training-free.","However, we empirically show that such adaption distorts the original pruning and results in inferior performance on the downstream tasks.","In this paper, we propose to treat the learning complexity (LC) as the scoring function for classification and regression tasks.","Specifically, the learning complexity is defined as the average predicted confidence of subnets with different capacities, which encapsulates data processing within a converged model.","Then we preserve the diverse and easy samples for fine-tuning.","Extensive experiments with vision datasets demonstrate the effectiveness and efficiency of the proposed scoring function for classification tasks.","For the instruction fine-tuning of large language models, our method achieves state-of-the-art performance with stable convergence, outperforming the full training with only 10\\% of the instruction dataset."],"url":"http://arxiv.org/abs/2402.05356v1"}
{"created":"2024-02-08 02:21:33","title":"Revisiting Early-Learning Regularization When Federated Learning Meets Noisy Labels","abstract":"In the evolving landscape of federated learning (FL), addressing label noise presents unique challenges due to the decentralized and diverse nature of data collection across clients. Traditional centralized learning approaches to mitigate label noise are constrained in FL by privacy concerns and the heterogeneity of client data. This paper revisits early-learning regularization, introducing an innovative strategy, Federated Label-mixture Regularization (FLR). FLR adeptly adapts to FL's complexities by generating new pseudo labels, blending local and global model predictions. This method not only enhances the accuracy of the global model in both i.i.d. and non-i.i.d. settings but also effectively counters the memorization of noisy labels. Demonstrating compatibility with existing label noise and FL techniques, FLR paves the way for improved generalization in FL environments fraught with label inaccuracies.","sentences":["In the evolving landscape of federated learning (FL), addressing label noise presents unique challenges due to the decentralized and diverse nature of data collection across clients.","Traditional centralized learning approaches to mitigate label noise are constrained in FL by privacy concerns and the heterogeneity of client data.","This paper revisits early-learning regularization, introducing an innovative strategy, Federated Label-mixture Regularization (FLR).","FLR adeptly adapts to FL's complexities by generating new pseudo labels, blending local and global model predictions.","This method not only enhances the accuracy of the global model in both i.i.d. and non-i.i.d. settings but also effectively counters the memorization of noisy labels.","Demonstrating compatibility with existing label noise and FL techniques, FLR paves the way for improved generalization in FL environments fraught with label inaccuracies."],"url":"http://arxiv.org/abs/2402.05353v1"}
{"created":"2024-02-08 02:11:52","title":"Descanning: From Scanned to the Original Images with a Color Correction Diffusion Model","abstract":"A significant volume of analog information, i.e., documents and images, have been digitized in the form of scanned copies for storing, sharing, and/or analyzing in the digital world. However, the quality of such contents is severely degraded by various distortions caused by printing, storing, and scanning processes in the physical world. Although restoring high-quality content from scanned copies has become an indispensable task for many products, it has not been systematically explored, and to the best of our knowledge, no public datasets are available. In this paper, we define this problem as Descanning and introduce a new high-quality and large-scale dataset named DESCAN-18K. It contains 18K pairs of original and scanned images collected in the wild containing multiple complex degradations. In order to eliminate such complex degradations, we propose a new image restoration model called DescanDiffusion consisting of a color encoder that corrects the global color degradation and a conditional denoising diffusion probabilistic model (DDPM) that removes local degradations. To further improve the generalization ability of DescanDiffusion, we also design a synthetic data generation scheme by reproducing prominent degradations in scanned images. We demonstrate that our DescanDiffusion outperforms other baselines including commercial restoration products, objectively and subjectively, via comprehensive experiments and analyses.","sentences":["A significant volume of analog information, i.e., documents and images, have been digitized in the form of scanned copies for storing, sharing, and/or analyzing in the digital world.","However, the quality of such contents is severely degraded by various distortions caused by printing, storing, and scanning processes in the physical world.","Although restoring high-quality content from scanned copies has become an indispensable task for many products, it has not been systematically explored, and to the best of our knowledge, no public datasets are available.","In this paper, we define this problem as Descanning and introduce a new high-quality and large-scale dataset named DESCAN-18K. It contains 18K pairs of original and scanned images collected in the wild containing multiple complex degradations.","In order to eliminate such complex degradations, we propose a new image restoration model called DescanDiffusion consisting of a color encoder that corrects the global color degradation and a conditional denoising diffusion probabilistic model (DDPM) that removes local degradations.","To further improve the generalization ability of DescanDiffusion, we also design a synthetic data generation scheme by reproducing prominent degradations in scanned images.","We demonstrate that our DescanDiffusion outperforms other baselines including commercial restoration products, objectively and subjectively, via comprehensive experiments and analyses."],"url":"http://arxiv.org/abs/2402.05350v1"}
{"created":"2024-02-08 02:01:36","title":"Scrapping The Web For Early Wildfire Detection","abstract":"Early wildfire detection is of the utmost importance to enable rapid response efforts, and thus minimize the negative impacts of wildfire spreads. To this end, we present \\Pyro, a web-scraping-based dataset composed of videos of wildfires from a network of cameras that were enhanced with manual bounding-box-level annotations. Our dataset was filtered based on a strategy to improve the quality and diversity of the data, reducing the final data to a set of 10,000 images. We ran experiments using a state-of-the-art object detection model and found out that the proposed dataset is challenging and its use in concordance with other public dataset helps to reach higher results overall. We will make our code and data publicly available.","sentences":["Early wildfire detection is of the utmost importance to enable rapid response efforts, and thus minimize the negative impacts of wildfire spreads.","To this end, we present \\Pyro, a web-scraping-based dataset composed of videos of wildfires from a network of cameras that were enhanced with manual bounding-box-level annotations.","Our dataset was filtered based on a strategy to improve the quality and diversity of the data, reducing the final data to a set of 10,000 images.","We ran experiments using a state-of-the-art object detection model and found out that the proposed dataset is challenging and its use in concordance with other public dataset helps to reach higher results overall.","We will make our code and data publicly available."],"url":"http://arxiv.org/abs/2402.05349v1"}
{"created":"2024-02-08 01:50:59","title":"Are We Asking the Right Questions?: Designing for Community Stakeholders' Interactions with AI in Policing","abstract":"Research into recidivism risk prediction in the criminal legal system has garnered significant attention from HCI, critical algorithm studies, and the emerging field of human-AI decision-making. This study focuses on algorithmic crime mapping, a prevalent yet underexplored form of algorithmic decision support (ADS) in this context. We conducted experiments and follow-up interviews with 60 participants, including community members, technical experts, and law enforcement agents (LEAs), to explore how lived experiences, technical knowledge, and domain expertise shape interactions with the ADS, impacting human-AI decision-making. Surprisingly, we found that domain experts (LEAs) often exhibited anchoring bias, readily accepting and engaging with the first crime map presented to them. Conversely, community members and technical experts were more inclined to engage with the tool, adjust controls, and generate different maps. Our findings highlight that all three stakeholders were able to provide critical feedback regarding AI design and use - community members questioned the core motivation of the tool, technical experts drew attention to the elastic nature of data science practice, and LEAs suggested redesign pathways such that the tool could complement their domain expertise.","sentences":["Research into recidivism risk prediction in the criminal legal system has garnered significant attention from HCI, critical algorithm studies, and the emerging field of human-AI decision-making.","This study focuses on algorithmic crime mapping, a prevalent yet underexplored form of algorithmic decision support (ADS) in this context.","We conducted experiments and follow-up interviews with 60 participants, including community members, technical experts, and law enforcement agents (LEAs), to explore how lived experiences, technical knowledge, and domain expertise shape interactions with the ADS, impacting human-AI decision-making.","Surprisingly, we found that domain experts (LEAs) often exhibited anchoring bias, readily accepting and engaging with the first crime map presented to them.","Conversely, community members and technical experts were more inclined to engage with the tool, adjust controls, and generate different maps.","Our findings highlight that all three stakeholders were able to provide critical feedback regarding AI design and use - community members questioned the core motivation of the tool, technical experts drew attention to the elastic nature of data science practice, and LEAs suggested redesign pathways such that the tool could complement their domain expertise."],"url":"http://arxiv.org/abs/2402.05348v1"}
{"created":"2024-02-08 00:44:45","title":"Investigating the Impact of SOLID Design Principles on Machine Learning Code Understanding","abstract":"[Context] Applying design principles has long been acknowledged as beneficial for understanding and maintainability in traditional software projects. These benefits may similarly hold for Machine Learning (ML) projects, which involve iterative experimentation with data, models, and algorithms. However, ML components are often developed by data scientists with diverse educational backgrounds, potentially resulting in code that doesn't adhere to software design best practices. [Goal] In order to better understand this phenomenon, we investigated the impact of the SOLID design principles on ML code understanding. [Method] We conducted a controlled experiment with three independent trials involving 100 data scientists. We restructured real industrial ML code that did not use SOLID principles. Within each trial, one group was presented with the original ML code, while the other was presented with ML code incorporating SOLID principles. Participants of both groups were asked to analyze the code and fill out a questionnaire that included both open-ended and closed-ended questions on their understanding. [Results] The study results provide statistically significant evidence that the adoption of the SOLID design principles can improve code understanding within the realm of ML projects. [Conclusion] We put forward that software engineering design principles should be spread within the data science community and considered for enhancing the maintainability of ML code.","sentences":["[Context] Applying design principles has long been acknowledged as beneficial for understanding and maintainability in traditional software projects.","These benefits may similarly hold for Machine Learning (ML) projects, which involve iterative experimentation with data, models, and algorithms.","However, ML components are often developed by data scientists with diverse educational backgrounds, potentially resulting in code that doesn't adhere to software design best practices.","[Goal] In order to better understand this phenomenon, we investigated the impact of the SOLID design principles on ML code understanding.","[Method] We conducted a controlled experiment with three independent trials involving 100 data scientists.","We restructured real industrial ML code that did not use SOLID principles.","Within each trial, one group was presented with the original ML code, while the other was presented with ML code incorporating SOLID principles.","Participants of both groups were asked to analyze the code and fill out a questionnaire that included both open-ended and closed-ended questions on their understanding.","[Results]","The study results provide statistically significant evidence that the adoption of the SOLID design principles can improve code understanding within the realm of ML projects.","[Conclusion] We put forward that software engineering design principles should be spread within the data science community and considered for enhancing the maintainability of ML code."],"url":"http://arxiv.org/abs/2402.05337v1"}
{"created":"2024-02-08 00:27:56","title":"On the Interaction between Software Engineers and Data Scientists when building Machine Learning-Enabled Systems","abstract":"In recent years, Machine Learning (ML) components have been increasingly integrated into the core systems of organizations. Engineering such systems presents various challenges from both a theoretical and practical perspective. One of the key challenges is the effective interaction between actors with different backgrounds who need to work closely together, such as software engineers and data scientists. This paper presents an exploratory case study to understand the current interaction and collaboration dynamics between these roles in ML projects. We conducted semi-structured interviews with four practitioners with experience in software engineering and data science of a large ML-enabled system project and analyzed the data using reflexive thematic analysis. Our findings reveal several challenges that can hinder collaboration between software engineers and data scientists, including differences in technical expertise, unclear definitions of each role's duties, and the lack of documents that support the specification of the ML-enabled system. We also indicate potential solutions to address these challenges, such as fostering a collaborative culture, encouraging team communication, and producing concise system documentation. This study contributes to understanding the complex dynamics between software engineers and data scientists in ML projects and provides insights for improving collaboration and communication in this context. We encourage future studies investigating this interaction in other projects.","sentences":["In recent years, Machine Learning (ML) components have been increasingly integrated into the core systems of organizations.","Engineering such systems presents various challenges from both a theoretical and practical perspective.","One of the key challenges is the effective interaction between actors with different backgrounds who need to work closely together, such as software engineers and data scientists.","This paper presents an exploratory case study to understand the current interaction and collaboration dynamics between these roles in ML projects.","We conducted semi-structured interviews with four practitioners with experience in software engineering and data science of a large ML-enabled system project and analyzed the data using reflexive thematic analysis.","Our findings reveal several challenges that can hinder collaboration between software engineers and data scientists, including differences in technical expertise, unclear definitions of each role's duties, and the lack of documents that support the specification of the ML-enabled system.","We also indicate potential solutions to address these challenges, such as fostering a collaborative culture, encouraging team communication, and producing concise system documentation.","This study contributes to understanding the complex dynamics between software engineers and data scientists in ML projects and provides insights for improving collaboration and communication in this context.","We encourage future studies investigating this interaction in other projects."],"url":"http://arxiv.org/abs/2402.05334v1"}
{"created":"2024-02-08 00:23:42","title":"Domain-Agnostic Hardware Fingerprinting-Based Device Identifier for Zero-Trust IoT Security","abstract":"Next-generation networks aim for comprehensive connectivity, interconnecting humans, machines, devices, and systems seamlessly. This interconnectivity raises concerns about privacy and security, given the potential network-wide impact of a single compromise. To address this challenge, the Zero Trust (ZT) paradigm emerges as a key method for safeguarding network integrity and data confidentiality. This work introduces EPS-CNN, a novel deep-learning-based wireless device identification framework designed to serve as the device authentication layer within the ZT architecture, with a focus on resource-constrained IoT devices. At the core of EPS-CNN, a Convolutional Neural Network (CNN) is utilized to generate the device identity from a unique RF signal representation, known as the Double-Sided Envelope Power Spectrum (EPS), which effectively captures the device-specific hardware characteristics while ignoring device-unrelated information. Experimental evaluations show that the proposed framework achieves over 99%, 93%, and 95% testing accuracy when tested in same-domain (day, location, and channel), cross-day, and cross-location scenarios, respectively. Our findings demonstrate the superiority of the proposed framework in enhancing the accuracy, robustness, and adaptability of deep learning-based methods, thus offering a pioneering solution for enabling ZT IoT device identification.","sentences":["Next-generation networks aim for comprehensive connectivity, interconnecting humans, machines, devices, and systems seamlessly.","This interconnectivity raises concerns about privacy and security, given the potential network-wide impact of a single compromise.","To address this challenge, the Zero Trust (ZT) paradigm emerges as a key method for safeguarding network integrity and data confidentiality.","This work introduces EPS-CNN, a novel deep-learning-based wireless device identification framework designed to serve as the device authentication layer within the ZT architecture, with a focus on resource-constrained IoT devices.","At the core of EPS-CNN, a Convolutional Neural Network (CNN) is utilized to generate the device identity from a unique RF signal representation, known as the Double-Sided Envelope Power Spectrum (EPS), which effectively captures the device-specific hardware characteristics while ignoring device-unrelated information.","Experimental evaluations show that the proposed framework achieves over 99%, 93%, and 95% testing accuracy when tested in same-domain (day, location, and channel), cross-day, and cross-location scenarios, respectively.","Our findings demonstrate the superiority of the proposed framework in enhancing the accuracy, robustness, and adaptability of deep learning-based methods, thus offering a pioneering solution for enabling ZT IoT device identification."],"url":"http://arxiv.org/abs/2402.05332v1"}
{"created":"2024-02-07 23:50:00","title":"Learning on Multimodal Graphs: A Survey","abstract":"Multimodal data pervades various domains, including healthcare, social media, and transportation, where multimodal graphs play a pivotal role. Machine learning on multimodal graphs, referred to as multimodal graph learning (MGL), is essential for successful artificial intelligence (AI) applications. The burgeoning research in this field encompasses diverse graph data types and modalities, learning techniques, and application scenarios. This survey paper conducts a comparative analysis of existing works in multimodal graph learning, elucidating how multimodal learning is achieved across different graph types and exploring the characteristics of prevalent learning techniques. Additionally, we delineate significant applications of multimodal graph learning and offer insights into future directions in this domain. Consequently, this paper serves as a foundational resource for researchers seeking to comprehend existing MGL techniques and their applicability across diverse scenarios.","sentences":["Multimodal data pervades various domains, including healthcare, social media, and transportation, where multimodal graphs play a pivotal role.","Machine learning on multimodal graphs, referred to as multimodal graph learning (MGL), is essential for successful artificial intelligence (AI) applications.","The burgeoning research in this field encompasses diverse graph data types and modalities, learning techniques, and application scenarios.","This survey paper conducts a comparative analysis of existing works in multimodal graph learning, elucidating how multimodal learning is achieved across different graph types and exploring the characteristics of prevalent learning techniques.","Additionally, we delineate significant applications of multimodal graph learning and offer insights into future directions in this domain.","Consequently, this paper serves as a foundational resource for researchers seeking to comprehend existing MGL techniques and their applicability across diverse scenarios."],"url":"http://arxiv.org/abs/2402.05322v1"}
{"created":"2024-02-07 23:05:30","title":"Dual-disentangled Deep Multiple Clustering","abstract":"Multiple clustering has gathered significant attention in recent years due to its potential to reveal multiple hidden structures of the data from different perspectives. Most of multiple clustering methods first derive feature representations by controlling the dissimilarity among them, subsequently employing traditional clustering methods (e.g., k-means) to achieve the final multiple clustering outcomes. However, the learned feature representations can exhibit a weak relevance to the ultimate goal of distinct clustering. Moreover, these features are often not explicitly learned for the purpose of clustering. Therefore, in this paper, we propose a novel Dual-Disentangled deep Multiple Clustering method named DDMC by learning disentangled representations. Specifically, DDMC is achieved by a variational Expectation-Maximization (EM) framework. In the E-step, the disentanglement learning module employs coarse-grained and fine-grained disentangled representations to obtain a more diverse set of latent factors from the data. In the M-step, the cluster assignment module utilizes a cluster objective function to augment the effectiveness of the cluster output. Our extensive experiments demonstrate that DDMC consistently outperforms state-of-the-art methods across seven commonly used tasks. Our code is available at https://github.com/Alexander-Yao/DDMC.","sentences":["Multiple clustering has gathered significant attention in recent years due to its potential to reveal multiple hidden structures of the data from different perspectives.","Most of multiple clustering methods first derive feature representations by controlling the dissimilarity among them, subsequently employing traditional clustering methods (e.g., k-means) to achieve the final multiple clustering outcomes.","However, the learned feature representations can exhibit a weak relevance to the ultimate goal of distinct clustering.","Moreover, these features are often not explicitly learned for the purpose of clustering.","Therefore, in this paper, we propose a novel Dual-Disentangled deep Multiple Clustering method named DDMC by learning disentangled representations.","Specifically, DDMC is achieved by a variational Expectation-Maximization (EM) framework.","In the E-step, the disentanglement learning module employs coarse-grained and fine-grained disentangled representations to obtain a more diverse set of latent factors from the data.","In the M-step, the cluster assignment module utilizes a cluster objective function to augment the effectiveness of the cluster output.","Our extensive experiments demonstrate that DDMC consistently outperforms state-of-the-art methods across seven commonly used tasks.","Our code is available at https://github.com/Alexander-Yao/DDMC."],"url":"http://arxiv.org/abs/2402.05310v1"}
{"created":"2024-02-07 23:00:24","title":"Three Pathways to Neurosymbolic Reinforcement Learning with Interpretable Model and Policy Networks","abstract":"Neurosymbolic AI combines the interpretability, parsimony, and explicit reasoning of classical symbolic approaches with the statistical learning of data-driven neural approaches. Models and policies that are simultaneously differentiable and interpretable may be key enablers of this marriage. This paper demonstrates three pathways to implementing such models and policies in a real-world reinforcement learning setting. Specifically, we study a broad class of neural networks that build interpretable semantics directly into their architecture. We reveal and highlight both the potential and the essential difficulties of combining logic, simulation, and learning. One lesson is that learning benefits from continuity and differentiability, but classical logic is discrete and non-differentiable. The relaxation to real-valued, differentiable representations presents a trade-off; the more learnable, the less interpretable. Another lesson is that using logic in the context of a numerical simulation involves a non-trivial mapping from raw (e.g., real-valued time series) simulation data to logical predicates. Some open questions this note exposes include: What are the limits of rule-based controllers, and how learnable are they? Do the differentiable interpretable approaches discussed here scale to large, complex, uncertain systems? Can we truly achieve interpretability? We highlight these and other themes across the three approaches.","sentences":["Neurosymbolic AI combines the interpretability, parsimony, and explicit reasoning of classical symbolic approaches with the statistical learning of data-driven neural approaches.","Models and policies that are simultaneously differentiable and interpretable may be key enablers of this marriage.","This paper demonstrates three pathways to implementing such models and policies in a real-world reinforcement learning setting.","Specifically, we study a broad class of neural networks that build interpretable semantics directly into their architecture.","We reveal and highlight both the potential and the essential difficulties of combining logic, simulation, and learning.","One lesson is that learning benefits from continuity and differentiability, but classical logic is discrete and non-differentiable.","The relaxation to real-valued, differentiable representations presents a trade-off; the more learnable, the less interpretable.","Another lesson is that using logic in the context of a numerical simulation involves a non-trivial mapping from raw (e.g., real-valued time series) simulation data to logical predicates.","Some open questions this note exposes include: What are the limits of rule-based controllers, and how learnable are they?","Do the differentiable interpretable approaches discussed here scale to large, complex, uncertain systems?","Can we truly achieve interpretability?","We highlight these and other themes across the three approaches."],"url":"http://arxiv.org/abs/2402.05307v1"}
{"created":"2024-02-07 22:53:54","title":"Sym-Q: Adaptive Symbolic Regression via Sequential Decision-Making","abstract":"Symbolic regression holds great potential for uncovering underlying mathematical and physical relationships from empirical data. While existing transformer-based models have recently achieved significant success in this domain, they face challenges in terms of generalizability and adaptability. Typically, in cases where the output expressions do not adequately fit experimental data, the models lack efficient mechanisms to adapt or modify the expression. This inflexibility hinders their application in real-world scenarios, particularly in discovering unknown physical or biological relationships. Inspired by how human experts refine and adapt expressions, we introduce Symbolic Q-network (Sym-Q), a novel reinforcement learning-based model that redefines symbolic regression as a sequential decision-making task. Sym-Q leverages supervised demonstrations and refines expressions based on reward signals indicating the quality of fitting precision. Its distinctive ability to manage the complexity of expression trees and perform precise step-wise updates significantly enhances flexibility and efficiency. Our results demonstrate that Sym-Q excels not only in recovering underlying mathematical structures but also uniquely learns to efficiently refine the output expression based on reward signals, thereby discovering underlying expressions. Sym-Q paves the way for more intuitive and impactful discoveries in physical science, marking a substantial advancement in the field of symbolic regression.","sentences":["Symbolic regression holds great potential for uncovering underlying mathematical and physical relationships from empirical data.","While existing transformer-based models have recently achieved significant success in this domain, they face challenges in terms of generalizability and adaptability.","Typically, in cases where the output expressions do not adequately fit experimental data, the models lack efficient mechanisms to adapt or modify the expression.","This inflexibility hinders their application in real-world scenarios, particularly in discovering unknown physical or biological relationships.","Inspired by how human experts refine and adapt expressions, we introduce Symbolic Q-network (Sym-Q), a novel reinforcement learning-based model that redefines symbolic regression as a sequential decision-making task.","Sym-Q leverages supervised demonstrations and refines expressions based on reward signals indicating the quality of fitting precision.","Its distinctive ability to manage the complexity of expression trees and perform precise step-wise updates significantly enhances flexibility and efficiency.","Our results demonstrate that Sym-Q excels not only in recovering underlying mathematical structures but also uniquely learns to efficiently refine the output expression based on reward signals, thereby discovering underlying expressions.","Sym-Q paves the way for more intuitive and impactful discoveries in physical science, marking a substantial advancement in the field of symbolic regression."],"url":"http://arxiv.org/abs/2402.05306v1"}
{"created":"2024-02-07 22:50:47","title":"Knowledge Distillation for Road Detection based on cross-model Semi-Supervised Learning","abstract":"The advancement of knowledge distillation has played a crucial role in enabling the transfer of knowledge from larger teacher models to smaller and more efficient student models, and is particularly beneficial for online and resource-constrained applications. The effectiveness of the student model heavily relies on the quality of the distilled knowledge received from the teacher. Given the accessibility of unlabelled remote sensing data, semi-supervised learning has become a prevalent strategy for enhancing model performance. However, relying solely on semi-supervised learning with smaller models may be insufficient due to their limited capacity for feature extraction. This limitation restricts their ability to exploit training data. To address this issue, we propose an integrated approach that combines knowledge distillation and semi-supervised learning methods. This hybrid approach leverages the robust capabilities of large models to effectively utilise large unlabelled data whilst subsequently providing the small student model with rich and informative features for enhancement. The proposed semi-supervised learning-based knowledge distillation (SSLKD) approach demonstrates a notable improvement in the performance of the student model, in the application of road segmentation, surpassing the effectiveness of traditional semi-supervised learning methods.","sentences":["The advancement of knowledge distillation has played a crucial role in enabling the transfer of knowledge from larger teacher models to smaller and more efficient student models, and is particularly beneficial for online and resource-constrained applications.","The effectiveness of the student model heavily relies on the quality of the distilled knowledge received from the teacher.","Given the accessibility of unlabelled remote sensing data, semi-supervised learning has become a prevalent strategy for enhancing model performance.","However, relying solely on semi-supervised learning with smaller models may be insufficient due to their limited capacity for feature extraction.","This limitation restricts their ability to exploit training data.","To address this issue, we propose an integrated approach that combines knowledge distillation and semi-supervised learning methods.","This hybrid approach leverages the robust capabilities of large models to effectively utilise large unlabelled data whilst subsequently providing the small student model with rich and informative features for enhancement.","The proposed semi-supervised learning-based knowledge distillation (SSLKD) approach demonstrates a notable improvement in the performance of the student model, in the application of road segmentation, surpassing the effectiveness of traditional semi-supervised learning methods."],"url":"http://arxiv.org/abs/2402.05305v1"}
{"created":"2024-02-07 22:39:34","title":"Training DNN Models over Heterogeneous Clusters with Optimal Performance","abstract":"Adjusting batch sizes and adaptively tuning other hyperparameters can significantly speed up deep neural network (DNN) training. Despite the ubiquity of heterogeneous clusters, existing adaptive DNN training techniques solely consider homogeneous environments. Optimizing distributed DNN training over heterogeneous clusters is technically challenging, and directly adapting existing techniques results in low utilization and poor performance. To solve this problem, we introduce Cannikin -- a novel data-parallel distributed training system. Cannikin achieves efficient and near-optimal performance by accurately modeling the optimal system performance and predicting adaptive batch size training metrics for DNNs in heterogeneous clusters. We implemented Cannikin in PyTorch and conducted experiments over 16 GPUs in Chameleon. Empirical results show that Cannikin reduces DNN training in heterogeneous clusters by up to $52\\%$ compared to the state-of-the-art adaptive training system and up to $85\\%$ compared to native PyTorch DistributedDataParallel.","sentences":["Adjusting batch sizes and adaptively tuning other hyperparameters can significantly speed up deep neural network (DNN) training.","Despite the ubiquity of heterogeneous clusters, existing adaptive DNN training techniques solely consider homogeneous environments.","Optimizing distributed DNN training over heterogeneous clusters is technically challenging, and directly adapting existing techniques results in low utilization and poor performance.","To solve this problem, we introduce Cannikin -- a novel data-parallel distributed training system.","Cannikin achieves efficient and near-optimal performance by accurately modeling the optimal system performance and predicting adaptive batch size training metrics for DNNs in heterogeneous clusters.","We implemented Cannikin in PyTorch and conducted experiments over 16 GPUs in Chameleon.","Empirical results show that Cannikin reduces DNN training in heterogeneous clusters by up to $52\\%$ compared to the state-of-the-art adaptive training system and up to $85\\%$ compared to native PyTorch DistributedDataParallel."],"url":"http://arxiv.org/abs/2402.05302v1"}
{"created":"2024-02-07 22:17:37","title":"An information theoretic approach to quantify the stability of feature selection and ranking algorithms","abstract":"Feature selection is a key step when dealing with high dimensional data. In particular, these techniques simplify the process of knowledge discovery from the data by selecting the most relevant features out of the noisy, redundant and irrelevant features. A problem that arises in many of these practical applications is that the outcome of the feature selection algorithm is not stable. Thus, small variations in the data may yield very different feature rankings. Assessing the stability of these methods becomes an important issue in the previously mentioned situations. We propose an information theoretic approach based on the Jensen Shannon divergence to quantify this robustness. Unlike other stability measures, this metric is suitable for different algorithm outcomes: full ranked lists, feature subsets as well as the lesser studied partial ranked lists. This generalized metric quantifies the difference among a whole set of lists with the same size, following a probabilistic approach and being able to give more importance to the disagreements that appear at the top of the list. Moreover, it possesses desirable properties including correction for change, upper lower bounds and conditions for a deterministic selection. We illustrate the use of this stability metric with data generated in a fully controlled way and compare it with popular metrics including the Spearmans rank correlation and the Kunchevas index on feature ranking and selection outcomes, respectively. Additionally, experimental validation of the proposed approach is carried out on a real-world problem of food quality assessment showing its potential to quantify stability from different perspectives.","sentences":["Feature selection is a key step when dealing with high dimensional data.","In particular, these techniques simplify the process of knowledge discovery from the data by selecting the most relevant features out of the noisy, redundant and irrelevant features.","A problem that arises in many of these practical applications is that the outcome of the feature selection algorithm is not stable.","Thus, small variations in the data may yield very different feature rankings.","Assessing the stability of these methods becomes an important issue in the previously mentioned situations.","We propose an information theoretic approach based on the Jensen Shannon divergence to quantify this robustness.","Unlike other stability measures, this metric is suitable for different algorithm outcomes: full ranked lists, feature subsets as well as the lesser studied partial ranked lists.","This generalized metric quantifies the difference among a whole set of lists with the same size, following a probabilistic approach and being able to give more importance to the disagreements that appear at the top of the list.","Moreover, it possesses desirable properties including correction for change, upper lower bounds and conditions for a deterministic selection.","We illustrate the use of this stability metric with data generated in a fully controlled way and compare it with popular metrics including the Spearmans rank correlation and the Kunchevas index on feature ranking and selection outcomes, respectively.","Additionally, experimental validation of the proposed approach is carried out on a real-world problem of food quality assessment showing its potential to quantify stability from different perspectives."],"url":"http://arxiv.org/abs/2402.05295v1"}
{"created":"2024-02-07 22:16:53","title":"Examining Modality Incongruity in Multimodal Federated Learning for Medical Vision and Language-based Disease Detection","abstract":"Multimodal Federated Learning (MMFL) utilizes multiple modalities in each client to build a more powerful Federated Learning (FL) model than its unimodal counterpart. However, the impact of missing modality in different clients, also called modality incongruity, has been greatly overlooked. This paper, for the first time, analyses the impact of modality incongruity and reveals its connection with data heterogeneity across participating clients. We particularly inspect whether incongruent MMFL with unimodal and multimodal clients is more beneficial than unimodal FL. Furthermore, we examine three potential routes of addressing this issue. Firstly, we study the effectiveness of various self-attention mechanisms towards incongruity-agnostic information fusion in MMFL. Secondly, we introduce a modality imputation network (MIN) pre-trained in a multimodal client for modality translation in unimodal clients and investigate its potential towards mitigating the missing modality problem. Thirdly, we assess the capability of client-level and server-level regularization techniques towards mitigating modality incongruity effects. Experiments are conducted under several MMFL settings on two publicly available real-world datasets, MIMIC-CXR and Open-I, with Chest X-Ray and radiology reports.","sentences":["Multimodal Federated Learning (MMFL) utilizes multiple modalities in each client to build a more powerful Federated Learning (FL) model than its unimodal counterpart.","However, the impact of missing modality in different clients, also called modality incongruity, has been greatly overlooked.","This paper, for the first time, analyses the impact of modality incongruity and reveals its connection with data heterogeneity across participating clients.","We particularly inspect whether incongruent MMFL with unimodal and multimodal clients is more beneficial than unimodal FL.","Furthermore, we examine three potential routes of addressing this issue.","Firstly, we study the effectiveness of various self-attention mechanisms towards incongruity-agnostic information fusion in MMFL.","Secondly, we introduce a modality imputation network (MIN) pre-trained in a multimodal client for modality translation in unimodal clients and investigate its potential towards mitigating the missing modality problem.","Thirdly, we assess the capability of client-level and server-level regularization techniques towards mitigating modality incongruity effects.","Experiments are conducted under several MMFL settings on two publicly available real-world datasets, MIMIC-CXR and Open-I, with Chest X-Ray and radiology reports."],"url":"http://arxiv.org/abs/2402.05294v1"}
{"created":"2024-02-07 21:53:28","title":"Physics Informed and Data Driven Simulation of Underwater Images via Residual Learning","abstract":"In general, underwater images suffer from color distortion and low contrast, because light is attenuated and backscattered as it propagates through water (differently depending on wavelength and on the properties of the water body). An existing simple degradation model (similar to atmospheric image \"hazing\" effects), though helpful, is not sufficient to properly represent the underwater image degradation because there are unaccounted for and non-measurable factors e.g. scattering of light due to turbidity of water, reflective characteristics of turbid medium etc. We propose a deep learning-based architecture to automatically simulate the underwater effects where only a dehazing-like image formation equation is known to the network, and the additional degradation due to the other unknown factors if inferred in a data-driven way. We only use RGB images (because in real-time scenario depth image is not available) to estimate the depth image. For testing, we have proposed (due to the lack of real underwater image datasets) a complex image formation model/equation to manually generate images that resemble real underwater images (used as ground truth). However, only the classical image formation equation (the one used for image dehazing) is informed to the network. This mimics the fact that in a real scenario, the physics are never completely known and only simplified models are known. Thanks to the ground truth, generated by a complex image formation equation, we could successfully perform a qualitative and quantitative evaluation of proposed technique, compared to other purely data driven approaches","sentences":["In general, underwater images suffer from color distortion and low contrast, because light is attenuated and backscattered as it propagates through water (differently depending on wavelength and on the properties of the water body).","An existing simple degradation model (similar to atmospheric image \"hazing\" effects), though helpful, is not sufficient to properly represent the underwater image degradation because there are unaccounted for and non-measurable factors e.g. scattering of light due to turbidity of water, reflective characteristics of turbid medium etc.","We propose a deep learning-based architecture to automatically simulate the underwater effects where only a dehazing-like image formation equation is known to the network, and the additional degradation due to the other unknown factors if inferred in a data-driven way.","We only use RGB images (because in real-time scenario depth image is not available) to estimate the depth image.","For testing, we have proposed (due to the lack of real underwater image datasets) a complex image formation model/equation to manually generate images that resemble real underwater images (used as ground truth).","However, only the classical image formation equation (the one used for image dehazing) is informed to the network.","This mimics the fact that in a real scenario, the physics are never completely known and only simplified models are known.","Thanks to the ground truth, generated by a complex image formation equation, we could successfully perform a qualitative and quantitative evaluation of proposed technique, compared to other purely data driven approaches"],"url":"http://arxiv.org/abs/2402.05281v1"}
{"created":"2024-02-07 21:53:01","title":"No Dimensional Sampling Coresets for Classification","abstract":"We refine and generalize what is known about coresets for classification problems via the sensitivity sampling framework. Such coresets seek the smallest possible subsets of input data, so one can optimize a loss function on the coreset and ensure approximation guarantees with respect to the original data. Our analysis provides the first no dimensional coresets, so the size does not depend on the dimension. Moreover, our results are general, apply for distributional input and can use iid samples, so provide sample complexity bounds, and work for a variety of loss functions. A key tool we develop is a Radamacher complexity version of the main sensitivity sampling approach, which can be of independent interest.","sentences":["We refine and generalize what is known about coresets for classification problems via the sensitivity sampling framework.","Such coresets seek the smallest possible subsets of input data, so one can optimize a loss function on the coreset and ensure approximation guarantees with respect to the original data.","Our analysis provides the first no dimensional coresets, so the size does not depend on the dimension.","Moreover, our results are general, apply for distributional input and can use iid samples, so provide sample complexity bounds, and work for a variety of loss functions.","A key tool we develop is a Radamacher complexity version of the main sensitivity sampling approach, which can be of independent interest."],"url":"http://arxiv.org/abs/2402.05280v1"}
{"created":"2024-02-07 21:46:26","title":"Exploring Hierarchical Classification Performance for Time Series Data: Dissimilarity Measures and Classifier Comparisons","abstract":"The comparative performance of hierarchical classification (HC) and flat classification (FC) methodologies in the realm of time series data analysis is investigated in this study. Dissimilarity measures, including Jensen-Shannon Distance (JSD), Task Similarity Distance (TSD), and Classifier Based Distance (CBD), are leveraged alongside various classifiers such as MINIROCKET, STSF, and SVM. A subset of datasets from the UCR archive, focusing on multi-class cases comprising more than two classes, is employed for analysis. A significant trend is observed wherein HC demonstrates significant superiority over FC when paired with MINIROCKET utilizing TSD, diverging from conventional understandings. Conversely, FC exhibits consistent dominance across all configurations when employing alternative classifiers such as STSF and SVM. Moreover, TSD is found to consistently outperform both CBD and JSD across nearly all scenarios, except in instances involving the STSF classifier where CBD showcases superior performance. This discrepancy underscores the nuanced nature of dissimilarity measures and emphasizes the importance of their tailored selection based on the dataset and classifier employed. Valuable insights into the dynamic interplay between classification methodologies and dissimilarity measures in the realm of time series data analysis are provided by these findings. By elucidating the performance variations across different configurations, a foundation is laid for refining classification methodologies and dissimilarity measures to optimize performance in diverse analytical scenarios. Furthermore, the need for continued research aimed at elucidating the underlying mechanisms driving classification performance in time series data analysis is underscored, with implications for enhancing predictive modeling and decision-making in various domains.","sentences":["The comparative performance of hierarchical classification (HC) and flat classification (FC) methodologies in the realm of time series data analysis is investigated in this study.","Dissimilarity measures, including Jensen-Shannon Distance (JSD), Task Similarity Distance (TSD), and Classifier Based Distance (CBD), are leveraged alongside various classifiers such as MINIROCKET, STSF, and SVM.","A subset of datasets from the UCR archive, focusing on multi-class cases comprising more than two classes, is employed for analysis.","A significant trend is observed wherein HC demonstrates significant superiority over FC when paired with MINIROCKET utilizing TSD, diverging from conventional understandings.","Conversely, FC exhibits consistent dominance across all configurations when employing alternative classifiers such as STSF and SVM.","Moreover, TSD is found to consistently outperform both CBD and JSD across nearly all scenarios, except in instances involving the STSF classifier where CBD showcases superior performance.","This discrepancy underscores the nuanced nature of dissimilarity measures and emphasizes the importance of their tailored selection based on the dataset and classifier employed.","Valuable insights into the dynamic interplay between classification methodologies and dissimilarity measures in the realm of time series data analysis are provided by these findings.","By elucidating the performance variations across different configurations, a foundation is laid for refining classification methodologies and dissimilarity measures to optimize performance in diverse analytical scenarios.","Furthermore, the need for continued research aimed at elucidating the underlying mechanisms driving classification performance in time series data analysis is underscored, with implications for enhancing predictive modeling and decision-making in various domains."],"url":"http://arxiv.org/abs/2402.05275v1"}
{"created":"2024-02-07 21:00:59","title":"An Overview of Machine Learning-Enabled Network Softwarization for the Internet of Things","abstract":"The Internet of Things (IoT) has evolved from a novel technology to an integral part of our everyday lives. It encompasses a multitude of heterogeneous devices that collect valuable data through various sensors. The sheer volume of these interconnected devices poses significant challenges as IoT provides complex network services with diverse requirements on a shared infrastructure. Network softwarization could help address these issues as it has emerged as a paradigm that enhances traditional networking by decoupling hardware from software and leveraging enabling technologies such as Software Defined Networking (SDN) and Network Function Virtualization (NFV). In networking, Machine Learning (ML) has demonstrated impressive results across multiple domains. By smoothly integrating with network softwarization, ML plays a pivotal role in building efficient and intelligent IoT networks. This paper explores the fundamentals of IoT, network softwarization, and ML, while reviewing the latest advances in ML-enabled network softwarization for IoT.","sentences":["The Internet of Things (IoT) has evolved from a novel technology to an integral part of our everyday lives.","It encompasses a multitude of heterogeneous devices that collect valuable data through various sensors.","The sheer volume of these interconnected devices poses significant challenges as IoT provides complex network services with diverse requirements on a shared infrastructure.","Network softwarization could help address these issues as it has emerged as a paradigm that enhances traditional networking by decoupling hardware from software and leveraging enabling technologies such as Software Defined Networking (SDN) and Network Function Virtualization (NFV).","In networking, Machine Learning (ML) has demonstrated impressive results across multiple domains.","By smoothly integrating with network softwarization, ML plays a pivotal role in building efficient and intelligent IoT networks.","This paper explores the fundamentals of IoT, network softwarization, and ML, while reviewing the latest advances in ML-enabled network softwarization for IoT."],"url":"http://arxiv.org/abs/2402.05255v1"}
{"created":"2024-02-07 20:31:07","title":"Automated Data-Driven Discovery of Material Models Based on Symbolic Regression: A Case Study on Human Brain Cortex","abstract":"We introduce a data-driven framework to automatically identify interpretable and physically meaningful hyperelastic constitutive models from sparse data. Leveraging symbolic regression, an algorithm based on genetic programming, our approach generates elegant hyperelastic models that achieve accurate data fitting through parsimonious mathematic formulae, while strictly adhering to hyperelasticity constraints such as polyconvexity. Our investigation spans three distinct hyperelastic models -- invariant-based, principal stretch-based, and normal strain-based -- and highlights the versatility of symbolic regression. We validate our new approach using synthetic data from five classic hyperelastic models and experimental data from the human brain to demonstrate algorithmic efficacy. Our results suggest that our symbolic regression robustly discovers accurate models with succinct mathematic expressions in invariant-based, stretch-based, and strain-based scenarios. Strikingly, the strain-based model exhibits superior accuracy, while both stretch- and strain-based models effectively capture the nonlinearity and tension-compression asymmetry inherent to human brain tissue. Polyconvexity examinations affirm the rigor of convexity within the training regime and demonstrate excellent extrapolation capabilities beyond this regime for all three models. However, the stretch-based models raise concerns regarding potential convexity loss under large deformations. Finally, robustness tests on noise-embedded data underscore the reliability of our symbolic regression algorithms. Our study confirms the applicability and accuracy of symbolic regression in the automated discovery of hyperelastic models for the human brain and gives rise to a wide variety of applications in other soft matter systems.","sentences":["We introduce a data-driven framework to automatically identify interpretable and physically meaningful hyperelastic constitutive models from sparse data.","Leveraging symbolic regression, an algorithm based on genetic programming, our approach generates elegant hyperelastic models that achieve accurate data fitting through parsimonious mathematic formulae, while strictly adhering to hyperelasticity constraints such as polyconvexity.","Our investigation spans three distinct hyperelastic models -- invariant-based, principal stretch-based, and normal strain-based -- and highlights the versatility of symbolic regression.","We validate our new approach using synthetic data from five classic hyperelastic models and experimental data from the human brain to demonstrate algorithmic efficacy.","Our results suggest that our symbolic regression robustly discovers accurate models with succinct mathematic expressions in invariant-based, stretch-based, and strain-based scenarios.","Strikingly, the strain-based model exhibits superior accuracy, while both stretch- and strain-based models effectively capture the nonlinearity and tension-compression asymmetry inherent to human brain tissue.","Polyconvexity examinations affirm the rigor of convexity within the training regime and demonstrate excellent extrapolation capabilities beyond this regime for all three models.","However, the stretch-based models raise concerns regarding potential convexity loss under large deformations.","Finally, robustness tests on noise-embedded data underscore the reliability of our symbolic regression algorithms.","Our study confirms the applicability and accuracy of symbolic regression in the automated discovery of hyperelastic models for the human brain and gives rise to a wide variety of applications in other soft matter systems."],"url":"http://arxiv.org/abs/2402.05238v1"}
{"created":"2024-02-07 20:18:15","title":"Real-Time Line-Based Room Segmentation and Continuous Euclidean Distance Fields","abstract":"Continuous maps representations, as opposed to traditional discrete ones such as grid maps, have been gaining traction in the research community. However, current approaches still suffer from high computation costs, making them unable to be used in large environments without sacrificing precision. In this paper, a scalable method building upon Gaussian Process-based Euclidean Distance Fields (GP-EDFs) is proposed. By leveraging structure inherent to indoor environments, namely walls and rooms, we achieve an accurate continuous map representation that is fast enough to be updated and used in real-time. This is possible thanks to a novel line-based room segmentation algorithm, enabling the creation of smaller local GP-EDFs for each room, which in turn also use line segments as its shape priors, thus representing the map more efficiently with fewer data points. We evaluate this method in simulation experiments, and make the code available open-source.","sentences":["Continuous maps representations, as opposed to traditional discrete ones such as grid maps, have been gaining traction in the research community.","However, current approaches still suffer from high computation costs, making them unable to be used in large environments without sacrificing precision.","In this paper, a scalable method building upon Gaussian Process-based Euclidean Distance Fields (GP-EDFs) is proposed.","By leveraging structure inherent to indoor environments, namely walls and rooms, we achieve an accurate continuous map representation that is fast enough to be updated and used in real-time.","This is possible thanks to a novel line-based room segmentation algorithm, enabling the creation of smaller local GP-EDFs for each room, which in turn also use line segments as its shape priors, thus representing the map more efficiently with fewer data points.","We evaluate this method in simulation experiments, and make the code available open-source."],"url":"http://arxiv.org/abs/2402.05236v1"}
{"created":"2024-02-07 19:36:36","title":"A Maturity Model for Urban Dataset Meta-data","abstract":"In the current environment of data generation and publication, there is an ever-growing number of datasets available for download. This growth precipitates an existing challenge: sourcing and integrating relevant datasets for analysis is becoming more complex. Despite efforts by open data platforms, obstacles remain, predominantly rooted in inadequate metadata, unsuitable data presentation, complications in pinpointing desired data, and data integration. This paper delves into the intricacies of dataset retrieval, emphasizing the pivotal role of metadata in aligning datasets with user queries. Through an exploration of existing literature, it underscores prevailing issues such as the identification of valuable metadata and the development of tools to maintain and annotate them effectively. The central contribution of this research is the proposition of a dataset metadata maturity model. Deriving inspiration from software engineering maturity models, this framework delineates a progression from rudimentary metadata documentation to advanced levels, aiding dataset creators in their documentation efforts. The model encompasses seven pivotal dimensions, spanning content to quality information, each stratified across six maturity levels to guide the optimal documentation of datasets, ensuring ease of discovery, relevance assessment, and comprehensive dataset understanding. This paper also incorporates the maturity model into a data cataloguing tool called CKAN through a custom plugin, CKANext-udc. The plugin introduces custom fields based on different maturity levels, allows for user interface customisation, and integrates with a graph database, converting catalogue data into a knowledge graph based on the Maturity Model ontology.","sentences":["In the current environment of data generation and publication, there is an ever-growing number of datasets available for download.","This growth precipitates an existing challenge: sourcing and integrating relevant datasets for analysis is becoming more complex.","Despite efforts by open data platforms, obstacles remain, predominantly rooted in inadequate metadata, unsuitable data presentation, complications in pinpointing desired data, and data integration.","This paper delves into the intricacies of dataset retrieval, emphasizing the pivotal role of metadata in aligning datasets with user queries.","Through an exploration of existing literature, it underscores prevailing issues such as the identification of valuable metadata and the development of tools to maintain and annotate them effectively.","The central contribution of this research is the proposition of a dataset metadata maturity model.","Deriving inspiration from software engineering maturity models, this framework delineates a progression from rudimentary metadata documentation to advanced levels, aiding dataset creators in their documentation efforts.","The model encompasses seven pivotal dimensions, spanning content to quality information, each stratified across six maturity levels to guide the optimal documentation of datasets, ensuring ease of discovery, relevance assessment, and comprehensive dataset understanding.","This paper also incorporates the maturity model into a data cataloguing tool called CKAN through a custom plugin, CKANext-udc.","The plugin introduces custom fields based on different maturity levels, allows for user interface customisation, and integrates with a graph database, converting catalogue data into a knowledge graph based on the Maturity Model ontology."],"url":"http://arxiv.org/abs/2402.05211v1"}
{"created":"2024-02-07 19:11:23","title":"The Effect of Sampling Temperature on Problem Solving in Large Language Models","abstract":"In this research study, we empirically investigate the effect of sampling temperature on the performance of Large Language Models (LLMs) on various problem-solving tasks. We created a multiple-choice question-and-answer (MCQA) exam by randomly sampling problems from standard LLM benchmarks. Then, we used four popular LLMs with five prompt-engineering techniques to solve the MCQA problems while increasing the sampling temperature from 0.0 to 1.0. Despite anecdotal reports to the contrary, our empirical results indicate that changes in temperature in the range 0.0 to 1.0 do not have a statistically significant impact on LLM performance for problem-solving tasks. In addition, these results appear to hold regardless of the LLM, the prompt-engineering technique, or the problem domain. All code, data, and supplemental materials are available on GitHub at: https://github.com/matthewrenze/jhu-llm-temperature.","sentences":["In this research study, we empirically investigate the effect of sampling temperature on the performance of Large Language Models (LLMs) on various problem-solving tasks.","We created a multiple-choice question-and-answer (MCQA) exam by randomly sampling problems from standard LLM benchmarks.","Then, we used four popular LLMs with five prompt-engineering techniques to solve the MCQA problems while increasing the sampling temperature from 0.0 to 1.0.","Despite anecdotal reports to the contrary, our empirical results indicate that changes in temperature in the range 0.0 to 1.0 do not have a statistically significant impact on LLM performance for problem-solving tasks.","In addition, these results appear to hold regardless of the LLM, the prompt-engineering technique, or the problem domain.","All code, data, and supplemental materials are available on GitHub at: https://github.com/matthewrenze/jhu-llm-temperature."],"url":"http://arxiv.org/abs/2402.05201v1"}
{"created":"2024-02-07 19:07:10","title":"$\u03bb$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space","abstract":"Despite the recent advances in personalized text-to-image (P-T2I) generative models, subject-driven T2I remains challenging. The primary bottlenecks include 1) Intensive training resource requirements, 2) Hyper-parameter sensitivity leading to inconsistent outputs, and 3) Balancing the intricacies of novel visual concept and composition alignment. We start by re-iterating the core philosophy of T2I diffusion models to address the above limitations. Predominantly, contemporary subject-driven T2I approaches hinge on Latent Diffusion Models (LDMs), which facilitate T2I mapping through cross-attention layers. While LDMs offer distinct advantages, P-T2I methods' reliance on the latent space of these diffusion models significantly escalates resource demands, leading to inconsistent results and necessitating numerous iterations for a single desired image. Recently, ECLIPSE has demonstrated a more resource-efficient pathway for training UnCLIP-based T2I models, circumventing the need for diffusion text-to-image priors. Building on this, we introduce $\\lambda$-ECLIPSE. Our method illustrates that effective P-T2I does not necessarily depend on the latent space of diffusion models. $\\lambda$-ECLIPSE achieves single, multi-subject, and edge-guided T2I personalization with just 34M parameters and is trained on a mere 74 GPU hours using 1.6M image-text interleaved data. Through extensive experiments, we also establish that $\\lambda$-ECLIPSE surpasses existing baselines in composition alignment while preserving concept alignment performance, even with significantly lower resource utilization.","sentences":["Despite the recent advances in personalized text-to-image (P-T2I) generative models, subject-driven T2I remains challenging.","The primary bottlenecks include 1) Intensive training resource requirements, 2) Hyper-parameter sensitivity leading to inconsistent outputs, and 3)","Balancing the intricacies of novel visual concept and composition alignment.","We start by re-iterating the core philosophy of T2I diffusion models to address the above limitations.","Predominantly, contemporary subject-driven T2I approaches hinge on Latent Diffusion Models (LDMs), which facilitate T2I mapping through cross-attention layers.","While LDMs offer distinct advantages, P-T2I methods' reliance on the latent space of these diffusion models significantly escalates resource demands, leading to inconsistent results and necessitating numerous iterations for a single desired image.","Recently, ECLIPSE has demonstrated a more resource-efficient pathway for training UnCLIP-based T2I models, circumventing the need for diffusion text-to-image priors.","Building on this, we introduce $\\lambda$-ECLIPSE.","Our method illustrates that effective P-T2I does not necessarily depend on the latent space of diffusion models.","$\\lambda$-ECLIPSE achieves single, multi-subject, and edge-guided T2I personalization with just 34M parameters and is trained on a mere 74 GPU hours using 1.6M image-text interleaved data.","Through extensive experiments, we also establish that $\\lambda$-ECLIPSE surpasses existing baselines in composition alignment while preserving concept alignment performance, even with significantly lower resource utilization."],"url":"http://arxiv.org/abs/2402.05195v1"}
