{"created":"2024-01-16 14:07:48","title":"KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation","abstract":"Commit messages are natural language descriptions of code changes, which are important for software evolution such as code understanding and maintenance. However, previous methods are trained on the entire dataset without considering the fact that a portion of commit messages adhere to good practice (i.e., good-practice commits), while the rest do not. On the basis of our empirical study, we discover that training on good-practice commits significantly contributes to the commit message generation. Motivated by this finding, we propose a novel knowledge-aware denoising learning method called KADEL. Considering that good-practice commits constitute only a small proportion of the dataset, we align the remaining training samples with these good-practice commits. To achieve this, we propose a model that learns the commit knowledge by training on good-practice commits. This knowledge model enables supplementing more information for training samples that do not conform to good practice. However, since the supplementary information may contain noise or prediction errors, we propose a dynamic denoising training method. This method composes a distribution-aware confidence function and a dynamic distribution list, which enhances the effectiveness of the training process. Experimental results on the whole MCMD dataset demonstrate that our method overall achieves state-of-the-art performance compared with previous methods. Our source code and data are available at https://github.com/DeepSoftwareAnalytics/KADEL","sentences":["Commit messages are natural language descriptions of code changes, which are important for software evolution such as code understanding and maintenance.","However, previous methods are trained on the entire dataset without considering the fact that a portion of commit messages adhere to good practice (i.e., good-practice commits), while the rest do not.","On the basis of our empirical study, we discover that training on good-practice commits significantly contributes to the commit message generation.","Motivated by this finding, we propose a novel knowledge-aware denoising learning method called KADEL.","Considering that good-practice commits constitute only a small proportion of the dataset, we align the remaining training samples with these good-practice commits.","To achieve this, we propose a model that learns the commit knowledge by training on good-practice commits.","This knowledge model enables supplementing more information for training samples that do not conform to good practice.","However, since the supplementary information may contain noise or prediction errors, we propose a dynamic denoising training method.","This method composes a distribution-aware confidence function and a dynamic distribution list, which enhances the effectiveness of the training process.","Experimental results on the whole MCMD dataset demonstrate that our method overall achieves state-of-the-art performance compared with previous methods.","Our source code and data are available at https://github.com/DeepSoftwareAnalytics/KADEL"],"url":"http://arxiv.org/abs/2401.08376v1"}
{"created":"2024-01-16 13:48:35","title":"On the formalization of the notion of an algorithm","abstract":"The starting point of this paper is a collection of properties of an algorithm that have been distilled from the informal descriptions of what an algorithm is that are given in standard works from the mathematical and computer science literature. Based on that, the notion of a proto-algorithm is introduced. The thought is that algorithms are equivalence classes of proto-algorithms under some equivalence relation. Three equivalence relations are defined. Two of them give bounds between which an appropriate equivalence relation must lie. The third lies in between these two and is likely an appropriate equivalence relation. A sound method is presented to prove, using an imperative process algebra based on ACP, that this equivalence relation holds between two proto-algorithms.","sentences":["The starting point of this paper is a collection of properties of an algorithm that have been distilled from the informal descriptions of what an algorithm is that are given in standard works from the mathematical and computer science literature.","Based on that, the notion of a proto-algorithm is introduced.","The thought is that algorithms are equivalence classes of proto-algorithms under some equivalence relation.","Three equivalence relations are defined.","Two of them give bounds between which an appropriate equivalence relation must lie.","The third lies in between these two and is likely an appropriate equivalence relation.","A sound method is presented to prove, using an imperative process algebra based on ACP, that this equivalence relation holds between two proto-algorithms."],"url":"http://arxiv.org/abs/2401.08366v1"}
{"created":"2024-01-16 13:46:10","title":"Weighted Spectral Filters for Kernel Interpolation on Spheres: Estimates of Prediction Accuracy for Noisy Data","abstract":"Spherical radial-basis-based kernel interpolation abounds in image sciences including geophysical image reconstruction, climate trends description and image rendering due to its excellent spatial localization property and perfect approximation performance. However, in dealing with noisy data, kernel interpolation frequently behaves not so well due to the large condition number of the kernel matrix and instability of the interpolation process. In this paper, we introduce a weighted spectral filter approach to reduce the condition number of the kernel matrix and then stabilize kernel interpolation. The main building blocks of the proposed method are the well developed spherical positive quadrature rules and high-pass spectral filters. Using a recently developed integral operator approach for spherical data analysis, we theoretically demonstrate that the proposed weighted spectral filter approach succeeds in breaking through the bottleneck of kernel interpolation, especially in fitting noisy data. We provide optimal approximation rates of the new method to show that our approach does not compromise the predicting accuracy. Furthermore, we conduct both toy simulations and two real-world data experiments with synthetically added noise in geophysical image reconstruction and climate image processing to verify our theoretical assertions and show the feasibility of the weighted spectral filter approach.","sentences":["Spherical radial-basis-based kernel interpolation abounds in image sciences including geophysical image reconstruction, climate trends description and image rendering due to its excellent spatial localization property and perfect approximation performance.","However, in dealing with noisy data, kernel interpolation frequently behaves not so well due to the large condition number of the kernel matrix and instability of the interpolation process.","In this paper, we introduce a weighted spectral filter approach to reduce the condition number of the kernel matrix and then stabilize kernel interpolation.","The main building blocks of the proposed method are the well developed spherical positive quadrature rules and high-pass spectral filters.","Using a recently developed integral operator approach for spherical data analysis, we theoretically demonstrate that the proposed weighted spectral filter approach succeeds in breaking through the bottleneck of kernel interpolation, especially in fitting noisy data.","We provide optimal approximation rates of the new method to show that our approach does not compromise the predicting accuracy.","Furthermore, we conduct both toy simulations and two real-world data experiments with synthetically added noise in geophysical image reconstruction and climate image processing to verify our theoretical assertions and show the feasibility of the weighted spectral filter approach."],"url":"http://arxiv.org/abs/2401.08364v1"}
{"created":"2024-01-16 13:37:45","title":"AdaSem: Adaptive Goal-Oriented Semantic Communications for End-to-End Camera Relocalization","abstract":"Recently, deep autoencoders have gained traction as a powerful method for implementing goal-oriented semantic communications systems. The idea is to train a mapping from the source domain directly to channel symbols, and vice versa. However, prior studies often focused on rate-distortion tradeoff and transmission delay, at the cost of increasing end-to-end complexity and thus latency. Moreover, the datasets used are often not reflective of real-world environments, and the results were not validated against real-world baseline systems, leading to an unfair comparison. In this paper, we study the problem of remote camera pose estimation and propose AdaSem, an adaptive semantic communications approach that optimizes the tradeoff between inference accuracy and end-to-end latency. We develop an adaptive semantic codec model, which encodes the source data into a dynamic number of symbols, based on the latent space distribution and the channel state feedback. We utilize a lightweight model for both transmitter and receiver to ensure comparable complexity to the baseline implemented in a real-world system. Extensive experiments on real-environment data show the effectiveness of our approach. When compared to a real implementation of a client-server camera relocalization service, AdaSem outperforms the baseline by reducing the end-to-end delay and estimation error by over 75% and 63%, respectively.","sentences":["Recently, deep autoencoders have gained traction as a powerful method for implementing goal-oriented semantic communications systems.","The idea is to train a mapping from the source domain directly to channel symbols, and vice versa.","However, prior studies often focused on rate-distortion tradeoff and transmission delay, at the cost of increasing end-to-end complexity and thus latency.","Moreover, the datasets used are often not reflective of real-world environments, and the results were not validated against real-world baseline systems, leading to an unfair comparison.","In this paper, we study the problem of remote camera pose estimation and propose AdaSem, an adaptive semantic communications approach that optimizes the tradeoff between inference accuracy and end-to-end latency.","We develop an adaptive semantic codec model, which encodes the source data into a dynamic number of symbols, based on the latent space distribution and the channel state feedback.","We utilize a lightweight model for both transmitter and receiver to ensure comparable complexity to the baseline implemented in a real-world system.","Extensive experiments on real-environment data show the effectiveness of our approach.","When compared to a real implementation of a client-server camera relocalization service, AdaSem outperforms the baseline by reducing the end-to-end delay and estimation error by over 75% and 63%, respectively."],"url":"http://arxiv.org/abs/2401.08360v1"}
{"created":"2024-01-16 13:30:37","title":"Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian Approach","abstract":"Federated learning aims to infer a shared model from private and decentralized data stored locally by multiple clients. Personalized federated learning (PFL) goes one step further by adapting the global model to each client, enhancing the model's fit for different clients. A significant level of personalization is required for highly heterogeneous clients, but can be challenging to achieve especially when they have small datasets. To address this problem, we propose a PFL algorithm named PAC-PFL for learning probabilistic models within a PAC-Bayesian framework that utilizes differential privacy to handle data-dependent priors. Our algorithm collaboratively learns a shared hyper-posterior and regards each client's posterior inference as the personalization step. By establishing and minimizing a generalization bound on the average true risk of clients, PAC-PFL effectively combats over-fitting. PACPFL achieves accurate and well-calibrated predictions, supported by experiments on a dataset of photovoltaic panel power generation, FEMNIST dataset (Caldas et al., 2019), and Dirichlet-partitioned EMNIST dataset (Cohen et al., 2017).","sentences":["Federated learning aims to infer a shared model from private and decentralized data stored locally by multiple clients.","Personalized federated learning (PFL) goes one step further by adapting the global model to each client, enhancing the model's fit for different clients.","A significant level of personalization is required for highly heterogeneous clients, but can be challenging to achieve especially when they have small datasets.","To address this problem, we propose a PFL algorithm named PAC-PFL for learning probabilistic models within a PAC-Bayesian framework that utilizes differential privacy to handle data-dependent priors.","Our algorithm collaboratively learns a shared hyper-posterior and regards each client's posterior inference as the personalization step.","By establishing and minimizing a generalization bound on the average true risk of clients, PAC-PFL effectively combats over-fitting.","PACPFL achieves accurate and well-calibrated predictions, supported by experiments on a dataset of photovoltaic panel power generation, FEMNIST dataset (Caldas et al., 2019), and Dirichlet-partitioned EMNIST dataset (Cohen et al., 2017)."],"url":"http://arxiv.org/abs/2401.08351v1"}
{"created":"2024-01-16 13:30:09","title":"Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models","abstract":"The evolution of Neural Machine Translation (NMT) has been significantly influenced by six core challenges (Koehn and Knowles, 2017), which have acted as benchmarks for progress in this field. This study revisits these challenges, offering insights into their ongoing relevance in the context of advanced Large Language Models (LLMs): domain mismatch, amount of parallel data, rare word prediction, translation of long sentences, attention model as word alignment, and sub-optimal beam search. Our empirical findings indicate that LLMs effectively lessen the reliance on parallel data for major languages in the pretraining phase. Additionally, the LLM-based translation system significantly enhances the translation of long sentences that contain approximately 80 words and shows the capability to translate documents of up to 512 words. However, despite these significant improvements, the challenges of domain mismatch and prediction of rare words persist. While the challenges of word alignment and beam search, specifically associated with NMT, may not apply to LLMs, we identify three new challenges for LLMs in translation tasks: inference efficiency, translation of low-resource languages in the pretraining phase, and human-aligned evaluation. The datasets and models are released at https://github.com/pangjh3/LLM4MT.","sentences":["The evolution of Neural Machine Translation (NMT) has been significantly influenced by six core challenges (Koehn and Knowles, 2017), which have acted as benchmarks for progress in this field.","This study revisits these challenges, offering insights into their ongoing relevance in the context of advanced Large Language Models (LLMs): domain mismatch, amount of parallel data, rare word prediction, translation of long sentences, attention model as word alignment, and sub-optimal beam search.","Our empirical findings indicate that LLMs effectively lessen the reliance on parallel data for major languages in the pretraining phase.","Additionally, the LLM-based translation system significantly enhances the translation of long sentences that contain approximately 80 words and shows the capability to translate documents of up to 512 words.","However, despite these significant improvements, the challenges of domain mismatch and prediction of rare words persist.","While the challenges of word alignment and beam search, specifically associated with NMT, may not apply to LLMs, we identify three new challenges for LLMs in translation tasks: inference efficiency, translation of low-resource languages in the pretraining phase, and human-aligned evaluation.","The datasets and models are released at https://github.com/pangjh3/LLM4MT."],"url":"http://arxiv.org/abs/2401.08350v1"}
{"created":"2024-01-16 13:29:30","title":"We don't need no labels: Estimating post-deployment model performance under covariate shift without ground truth","abstract":"The performance of machine learning models often degrades after deployment due to data distribution shifts. In many use cases, it is impossible to calculate the post-deployment performance because labels are unavailable or significantly delayed. Proxy methods for evaluating model performance stability, like drift detection techniques, do not properly quantify data distribution shift impact. As a solution, we propose a robust and accurate performance estimation method for evaluating ML classification models on unlabeled data that accurately quantifies the impact of covariate shift on model performance. We call it multi-calibrated confidence-based performance estimation (M-CBPE). It is model and data-type agnostic and works for any performance metric. It does not require access to the monitored model - it uses the model predictions and probability estimates. M-CBPE does not need user input on the nature of the covariate shift as it fully learns from the data. We evaluate it with over 600 dataset-model pairs from US census data and compare it with multiple benchmarks using several evaluation metrics. Results show that M-CBPE is the best method to estimate the performance of classification models in any evaluation context.","sentences":["The performance of machine learning models often degrades after deployment due to data distribution shifts.","In many use cases, it is impossible to calculate the post-deployment performance because labels are unavailable or significantly delayed.","Proxy methods for evaluating model performance stability, like drift detection techniques, do not properly quantify data distribution shift impact.","As a solution, we propose a robust and accurate performance estimation method for evaluating ML classification models on unlabeled data that accurately quantifies the impact of covariate shift on model performance.","We call it multi-calibrated confidence-based performance estimation (M-CBPE).","It is model and data-type agnostic and works for any performance metric.","It does not require access to the monitored model - it uses the model predictions and probability estimates.","M-CBPE does not need user input on the nature of the covariate shift as it fully learns from the data.","We evaluate it with over 600 dataset-model pairs from US census data and compare it with multiple benchmarks using several evaluation metrics.","Results show that M-CBPE is the best method to estimate the performance of classification models in any evaluation context."],"url":"http://arxiv.org/abs/2401.08348v1"}
{"created":"2024-01-16 12:57:35","title":"dabih -- encrypted data storage and sharing platform","abstract":"Background: The secure management of sensitive clinical data, particularly human genomics data, has become a critical requirement in modern biomedical research. Although the necessary software and algorithms are readily available, their use by non-IT experts poses significant challenges.   Methods: We developed dabih, an open-source web application specifically designed to facilitate user-friendly encrypted data management. dabih enables web-based uploading, storing, sharing, and downloading of sensitive data in any format. Its approach to data security involves a two-stage envelope encryption process. We combine symmetric-key encryption for data and public-key encryption as key encapsulation mechanism. The private key necessary for decrypting the data remains exclusively on the owner's device. Thus, accessing data is impossible without explicit permission from the keyholder.   Results: dabih is available open-source on GitHub https://github.com/spang-lab/dabih, as ready to use containers on docker hub and includes a command line interface and a graphical bulk upload tool as pre-built binaries. Documentation is available as part of the web application.   Conclusions: dabih enables everyone to use strong cryptography for their data, while being just as simple to use as other, non-encrypted, data storage solutions. All the cryptography occurs seamlessly in the background as users interact with a secure web portal, simply by dragging and dropping files.","sentences":["Background: The secure management of sensitive clinical data, particularly human genomics data, has become a critical requirement in modern biomedical research.","Although the necessary software and algorithms are readily available, their use by non-IT experts poses significant challenges.   ","Methods: We developed dabih, an open-source web application specifically designed to facilitate user-friendly encrypted data management.","dabih enables web-based uploading, storing, sharing, and downloading of sensitive data in any format.","Its approach to data security involves a two-stage envelope encryption process.","We combine symmetric-key encryption for data and public-key encryption as key encapsulation mechanism.","The private key necessary for decrypting the data remains exclusively on the owner's device.","Thus, accessing data is impossible without explicit permission from the keyholder.   ","Results: dabih is available open-source on GitHub https://github.com/spang-lab/dabih, as ready to use containers on docker hub and includes a command line interface and a graphical bulk upload tool as pre-built binaries.","Documentation is available as part of the web application.   ","Conclusions: dabih enables everyone to use strong cryptography for their data, while being just as simple to use as other, non-encrypted, data storage solutions.","All the cryptography occurs seamlessly in the background as users interact with a secure web portal, simply by dragging and dropping files."],"url":"http://arxiv.org/abs/2401.08333v1"}
{"created":"2024-01-16 12:48:52","title":"Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation","abstract":"In an era where test-time adaptation methods increasingly rely on the nuanced manipulation of batch normalization (BN) parameters, one critical assumption often goes overlooked: that of independently and identically distributed (i.i.d.) test batches with respect to unknown labels. This assumption culminates in biased estimates of BN statistics and jeopardizes system stability under non-i.i.d. conditions. This paper pioneers a departure from the i.i.d. paradigm by introducing a groundbreaking strategy termed \"Un-Mixing Test-Time Normalization Statistics\" (UnMix-TNS). UnMix-TNS re-calibrates the instance-wise statistics used to normalize each instance in a batch by mixing it with multiple unmixed statistics components, thus inherently simulating the i.i.d. environment. The key lies in our innovative online unmixing procedure, which persistently refines these statistics components by drawing upon the closest instances from an incoming test batch. Remarkably generic in its design, UnMix-TNS seamlessly integrates with an array of state-of-the-art test-time adaptation methods and pre-trained architectures equipped with BN layers. Empirical evaluations corroborate the robustness of UnMix-TNS under varied scenarios ranging from single to continual and mixed domain shifts. UnMix-TNS stands out when handling test data streams with temporal correlation, including those with corrupted real-world non-i.i.d. streams, sustaining its efficacy even with minimal batch sizes and individual samples. Our results set a new standard for test-time adaptation, demonstrating significant improvements in both stability and performance across multiple benchmarks.","sentences":["In an era where test-time adaptation methods increasingly rely on the nuanced manipulation of batch normalization (BN) parameters, one critical assumption often goes overlooked: that of independently and identically distributed (i.i.d.)","test batches with respect to unknown labels.","This assumption culminates in biased estimates of BN statistics and jeopardizes system stability under non-i.i.d. conditions.","This paper pioneers a departure from the i.i.d. paradigm by introducing a groundbreaking strategy termed \"Un-Mixing Test-Time Normalization Statistics\" (UnMix-TNS).","UnMix-TNS re-calibrates the instance-wise statistics used to normalize each instance in a batch by mixing it with multiple unmixed statistics components, thus inherently simulating the i.i.d. environment.","The key lies in our innovative online unmixing procedure, which persistently refines these statistics components by drawing upon the closest instances from an incoming test batch.","Remarkably generic in its design, UnMix-TNS seamlessly integrates with an array of state-of-the-art test-time adaptation methods and pre-trained architectures equipped with BN layers.","Empirical evaluations corroborate the robustness of UnMix-TNS under varied scenarios ranging from single to continual and mixed domain shifts.","UnMix-TNS stands out when handling test data streams with temporal correlation, including those with corrupted real-world non-i.i.d. streams, sustaining its efficacy even with minimal batch sizes and individual samples.","Our results set a new standard for test-time adaptation, demonstrating significant improvements in both stability and performance across multiple benchmarks."],"url":"http://arxiv.org/abs/2401.08328v1"}
{"created":"2024-01-16 12:45:15","title":"RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning","abstract":"Tool learning has generated widespread interest as a vital means of interaction between Large Language Models (LLMs) and the physical world. Current research predominantly emphasizes LLMs' capacity to utilize tools in well-structured environments while overlooking their stability when confronted with the inevitable noise of the real world. To bridge this gap, we introduce RoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool learning. Specifically, we establish five external environments, each featuring varying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union), providing an in-depth analysis of the model's resilience across three critical phases: tool selection, parameter identification, and content filling. Experiments involving six widely-used models underscore the urgent necessity for enhancing the robustness of LLMs in tool learning. For instance, the performance of GPT-4 even drops significantly from 80.00 to 58.10 when there is no substantial change in manual accuracy. More surprisingly, the noise correction capability inherent in the GPT family paradoxically impedes its adaptability in the face of mild noise. In light of these findings, we propose RoTTuning, a strategy that enriches the diversity of training environments to bolster the robustness of LLMs in tool learning. The code and data are available at https://github.com/Junjie-Ye/RoTBench.","sentences":["Tool learning has generated widespread interest as a vital means of interaction between Large Language Models (LLMs) and the physical world.","Current research predominantly emphasizes LLMs' capacity to utilize tools in well-structured environments while overlooking their stability when confronted with the inevitable noise of the real world.","To bridge this gap, we introduce RoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool learning.","Specifically, we establish five external environments, each featuring varying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union), providing an in-depth analysis of the model's resilience across three critical phases: tool selection, parameter identification, and content filling.","Experiments involving six widely-used models underscore the urgent necessity for enhancing the robustness of LLMs in tool learning.","For instance, the performance of GPT-4 even drops significantly from 80.00 to 58.10 when there is no substantial change in manual accuracy.","More surprisingly, the noise correction capability inherent in the GPT family paradoxically impedes its adaptability in the face of mild noise.","In light of these findings, we propose RoTTuning, a strategy that enriches the diversity of training environments to bolster the robustness of LLMs in tool learning.","The code and data are available at https://github.com/Junjie-Ye/RoTBench."],"url":"http://arxiv.org/abs/2401.08326v1"}
{"created":"2024-01-16 12:45:15","title":"Learn What You Need in Personalized Federated Learning","abstract":"Personalized federated learning aims to address data heterogeneity across local clients in federated learning. However, current methods blindly incorporate either full model parameters or predefined partial parameters in personalized federated learning. They fail to customize the collaboration manner according to each local client's data characteristics, causing unpleasant aggregation results. To address this essential issue, we propose $\\textit{Learn2pFed}$, a novel algorithm-unrolling-based personalized federated learning framework, enabling each client to adaptively select which part of its local model parameters should participate in collaborative training. The key novelty of the proposed $\\textit{Learn2pFed}$ is to optimize each local model parameter's degree of participant in collaboration as learnable parameters via algorithm unrolling methods. This approach brings two benefits: 1) mathmatically determining the participation degree of local model parameters in the federated collaboration, and 2) obtaining more stable and improved solutions. Extensive experiments on various tasks, including regression, forecasting, and image classification, demonstrate that $\\textit{Learn2pFed}$ significantly outperforms previous personalized federated learning methods.","sentences":["Personalized federated learning aims to address data heterogeneity across local clients in federated learning.","However, current methods blindly incorporate either full model parameters or predefined partial parameters in personalized federated learning.","They fail to customize the collaboration manner according to each local client's data characteristics, causing unpleasant aggregation results.","To address this essential issue, we propose $\\textit{Learn2pFed}$, a novel algorithm-unrolling-based personalized federated learning framework, enabling each client to adaptively select which part of its local model parameters should participate in collaborative training.","The key novelty of the proposed $\\textit{Learn2pFed}$ is to optimize each local model parameter's degree of participant in collaboration as learnable parameters via algorithm unrolling methods.","This approach brings two benefits: 1) mathmatically determining the participation degree of local model parameters in the federated collaboration, and 2) obtaining more stable and improved solutions.","Extensive experiments on various tasks, including regression, forecasting, and image classification, demonstrate that $\\textit{Learn2pFed}$ significantly outperforms previous personalized federated learning methods."],"url":"http://arxiv.org/abs/2401.08327v1"}
{"created":"2024-01-16 12:10:49","title":"Anchor function: a type of benchmark functions for studying language models","abstract":"Understanding transformer-based language models is becoming increasingly crucial, particularly as they play pivotal roles in advancing towards artificial general intelligence. However, language model research faces significant challenges, especially for academic research groups with constrained resources. These challenges include complex data structures, unknown target functions, high computational costs and memory requirements, and a lack of interpretability in the inference process, etc. Drawing a parallel to the use of simple models in scientific research, we propose the concept of an anchor function. This is a type of benchmark function designed for studying language models in learning tasks that follow an \"anchor-key\" pattern. By utilizing the concept of an anchor function, we can construct a series of functions to simulate various language tasks. The anchor function plays a role analogous to that of mice in diabetes research, particularly suitable for academic research. We demonstrate the utility of the anchor function with an example, revealing two basic operations by attention structures in language models: shifting tokens and broadcasting one token from one position to many positions. These operations are also commonly observed in large language models. The anchor function framework, therefore, opens up a series of valuable and accessible research questions for further exploration, especially for theoretical study.","sentences":["Understanding transformer-based language models is becoming increasingly crucial, particularly as they play pivotal roles in advancing towards artificial general intelligence.","However, language model research faces significant challenges, especially for academic research groups with constrained resources.","These challenges include complex data structures, unknown target functions, high computational costs and memory requirements, and a lack of interpretability in the inference process, etc.","Drawing a parallel to the use of simple models in scientific research, we propose the concept of an anchor function.","This is a type of benchmark function designed for studying language models in learning tasks that follow an \"anchor-key\" pattern.","By utilizing the concept of an anchor function, we can construct a series of functions to simulate various language tasks.","The anchor function plays a role analogous to that of mice in diabetes research, particularly suitable for academic research.","We demonstrate the utility of the anchor function with an example, revealing two basic operations by attention structures in language models: shifting tokens and broadcasting one token from one position to many positions.","These operations are also commonly observed in large language models.","The anchor function framework, therefore, opens up a series of valuable and accessible research questions for further exploration, especially for theoretical study."],"url":"http://arxiv.org/abs/2401.08309v1"}
{"created":"2024-01-16 11:50:54","title":"Evaluating online elasticity estimation of soft objects using standard robot grippers","abstract":"Standard robot grippers are not designed for elasticity estimation. In this work, a professional biaxial compression device was used as a control setup to study the accuracy with which material properties can be estimated by two standard parallel jaw grippers and a force/torque sensor mounted at the robot wrist. Using three sets of deformable objects, different parameters were varied to observe their effect on measuring material characteristics: (1) repeated compression cycles, (2) compression speed, and (3) the surface area of the gripper jaws. Gripper effort versus position curves were obtained and transformed into stress/strain curves. The modulus of elasticity was estimated at different strain points. Viscoelasticity was assessed using the energy absorbed in a compression/decompression cycle, the Kelvin-Voigt, and Hunt-Crossley models. Our results can be summarized as follows: (1) better results were obtained with slower compression speeds, while additional compression cycles or surface area did not improve estimation; (2) the robot grippers, even after calibration, were found to have a limited capability of delivering accurate estimates of absolute values of Young's modulus and viscoelasticity; (3) relative ordering of material characteristics was largely consistent across different grippers; (4) despite the nonlinear characteristics of deformable objects, fitting linear stress/strain approximations led to more stable results than local estimates of Young's modulus; (5) to assess viscoelasticity, the Hunt-Crossley model worked best. Finally, we show that a two-dimensional space representing elasticity and viscoelasticity estimates is advantageous for the discrimination of deformable objects. A single-grasp, online, classification and sorting of such objects is thus possible. An additional contribution is the dataset and data processing codes that we make publicly available.","sentences":["Standard robot grippers are not designed for elasticity estimation.","In this work, a professional biaxial compression device was used as a control setup to study the accuracy with which material properties can be estimated by two standard parallel jaw grippers and a force/torque sensor mounted at the robot wrist.","Using three sets of deformable objects, different parameters were varied to observe their effect on measuring material characteristics: (1) repeated compression cycles, (2) compression speed, and (3) the surface area of the gripper jaws.","Gripper effort versus position curves were obtained and transformed into stress/strain curves.","The modulus of elasticity was estimated at different strain points.","Viscoelasticity was assessed using the energy absorbed in a compression/decompression cycle, the Kelvin-Voigt, and Hunt-Crossley models.","Our results can be summarized as follows: (1) better results were obtained with slower compression speeds, while additional compression cycles or surface area did not improve estimation; (2) the robot grippers, even after calibration, were found to have a limited capability of delivering accurate estimates of absolute values of Young's modulus and viscoelasticity; (3) relative ordering of material characteristics was largely consistent across different grippers; (4) despite the nonlinear characteristics of deformable objects, fitting linear stress/strain approximations led to more stable results than local estimates of Young's modulus; (5) to assess viscoelasticity, the Hunt-Crossley model worked best.","Finally, we show that a two-dimensional space representing elasticity and viscoelasticity estimates is advantageous for the discrimination of deformable objects.","A single-grasp, online, classification and sorting of such objects is thus possible.","An additional contribution is the dataset and data processing codes that we make publicly available."],"url":"http://arxiv.org/abs/2401.08298v1"}
{"created":"2024-01-16 10:58:07","title":"AesBench: An Expert Benchmark for Multimodal Large Language Models on Image Aesthetics Perception","abstract":"With collective endeavors, multimodal large language models (MLLMs) are undergoing a flourishing development. However, their performances on image aesthetics perception remain indeterminate, which is highly desired in real-world applications. An obvious obstacle lies in the absence of a specific benchmark to evaluate the effectiveness of MLLMs on aesthetic perception. This blind groping may impede the further development of more advanced MLLMs with aesthetic perception capacity. To address this dilemma, we propose AesBench, an expert benchmark aiming to comprehensively evaluate the aesthetic perception capacities of MLLMs through elaborate design across dual facets. (1) We construct an Expert-labeled Aesthetics Perception Database (EAPD), which features diversified image contents and high-quality annotations provided by professional aesthetic experts. (2) We propose a set of integrative criteria to measure the aesthetic perception abilities of MLLMs from four perspectives, including Perception (AesP), Empathy (AesE), Assessment (AesA) and Interpretation (AesI). Extensive experimental results underscore that the current MLLMs only possess rudimentary aesthetic perception ability, and there is still a significant gap between MLLMs and humans. We hope this work can inspire the community to engage in deeper explorations on the aesthetic potentials of MLLMs. Source data will be available at https://github.com/yipoh/AesBench.","sentences":["With collective endeavors, multimodal large language models (MLLMs) are undergoing a flourishing development.","However, their performances on image aesthetics perception remain indeterminate, which is highly desired in real-world applications.","An obvious obstacle lies in the absence of a specific benchmark to evaluate the effectiveness of MLLMs on aesthetic perception.","This blind groping may impede the further development of more advanced MLLMs with aesthetic perception capacity.","To address this dilemma, we propose AesBench, an expert benchmark aiming to comprehensively evaluate the aesthetic perception capacities of MLLMs through elaborate design across dual facets.","(1) We construct an Expert-labeled Aesthetics Perception Database (EAPD), which features diversified image contents and high-quality annotations provided by professional aesthetic experts.","(2) We propose a set of integrative criteria to measure the aesthetic perception abilities of MLLMs from four perspectives, including Perception (AesP), Empathy (AesE), Assessment (AesA) and Interpretation (AesI).","Extensive experimental results underscore that the current MLLMs only possess rudimentary aesthetic perception ability, and there is still a significant gap between MLLMs and humans.","We hope this work can inspire the community to engage in deeper explorations on the aesthetic potentials of MLLMs.","Source data will be available at https://github.com/yipoh/AesBench."],"url":"http://arxiv.org/abs/2401.08276v1"}
{"created":"2024-01-16 10:54:37","title":"Modeling Spoof Noise by De-spoofing Diffusion and its Application in Face Anti-spoofing","abstract":"Face anti-spoofing is crucial for ensuring the security and reliability of face recognition systems. Several existing face anti-spoofing methods utilize GAN-like networks to detect presentation attacks by estimating the noise pattern of a spoof image and recovering the corresponding genuine image. But GAN's limited face appearance space results in the denoised faces cannot cover the full data distribution of genuine faces, thereby undermining the generalization performance of such methods. In this work, we present a pioneering attempt to employ diffusion models to denoise a spoof image and restore the genuine image. The difference between these two images is considered as the spoof noise, which can serve as a discriminative cue for face anti-spoofing. We evaluate our proposed method on several intra-testing and inter-testing protocols, where the experimental results showcase the effectiveness of our method in achieving competitive performance in terms of both accuracy and generalization.","sentences":["Face anti-spoofing is crucial for ensuring the security and reliability of face recognition systems.","Several existing face anti-spoofing methods utilize GAN-like networks to detect presentation attacks by estimating the noise pattern of a spoof image and recovering the corresponding genuine image.","But GAN's limited face appearance space results in the denoised faces cannot cover the full data distribution of genuine faces, thereby undermining the generalization performance of such methods.","In this work, we present a pioneering attempt to employ diffusion models to denoise a spoof image and restore the genuine image.","The difference between these two images is considered as the spoof noise, which can serve as a discriminative cue for face anti-spoofing.","We evaluate our proposed method on several intra-testing and inter-testing protocols, where the experimental results showcase the effectiveness of our method in achieving competitive performance in terms of both accuracy and generalization."],"url":"http://arxiv.org/abs/2401.08275v1"}
{"created":"2024-01-16 10:51:55","title":"Siamese Content-based Search Engine for a More Transparent Skin and Breast Cancer Diagnosis through Histological Imaging","abstract":"Computer Aid Diagnosis (CAD) has developed digital pathology with Deep Learning (DL)-based tools to assist pathologists in decision-making. Content-Based Histopathological Image Retrieval (CBHIR) is a novel tool to seek highly correlated patches in terms of similarity in histopathological features. In this work, we proposed two CBHIR approaches on breast (Breast-twins) and skin cancer (Skin-twins) data sets for robust and accurate patch-level retrieval, integrating a custom-built Siamese network as a feature extractor. The proposed Siamese network is able to generalize for unseen images by focusing on the similar histopathological features of the input pairs. The proposed CBHIR approaches are evaluated on the Breast (public) and Skin (private) data sets with top K accuracy. Finding the optimum amount of K is challenging, but also, as much as K increases, the dissimilarity between the query and the returned images increases which might mislead the pathologists. To the best of the author's belief, this paper is tackling this issue for the first time on histopathological images by evaluating the top first retrieved images. The Breast-twins model achieves 70% of the F1score at the top first, which exceeds the other state-of-the-art methods at a higher amount of K such as 5 and 400. Skin-twins overpasses the recently proposed Convolutional Auto Encoder (CAE) by 67%, increasing the precision. Besides, the Skin-twins model tackles the challenges of Spitzoid Tumors of Uncertain Malignant Potential (STUMP) to assist pathologists with retrieving top K images and their corresponding labels. So, this approach can offer a more explainable CAD tool to pathologists in terms of transparency, trustworthiness, or reliability among other characteristics.","sentences":["Computer Aid Diagnosis (CAD) has developed digital pathology with Deep Learning (DL)-based tools to assist pathologists in decision-making.","Content-Based Histopathological Image Retrieval (CBHIR) is a novel tool to seek highly correlated patches in terms of similarity in histopathological features.","In this work, we proposed two CBHIR approaches on breast (Breast-twins) and skin cancer (Skin-twins) data sets for robust and accurate patch-level retrieval, integrating a custom-built Siamese network as a feature extractor.","The proposed Siamese network is able to generalize for unseen images by focusing on the similar histopathological features of the input pairs.","The proposed CBHIR approaches are evaluated on the Breast (public) and Skin (private) data sets with top K accuracy.","Finding the optimum amount of K is challenging, but also, as much as K increases, the dissimilarity between the query and the returned images increases which might mislead the pathologists.","To the best of the author's belief, this paper is tackling this issue for the first time on histopathological images by evaluating the top first retrieved images.","The Breast-twins model achieves 70% of the F1score at the top first, which exceeds the other state-of-the-art methods at a higher amount of K such as 5 and 400.","Skin-twins overpasses the recently proposed Convolutional Auto Encoder (CAE) by 67%, increasing the precision.","Besides, the Skin-twins model tackles the challenges of Spitzoid Tumors of Uncertain Malignant Potential (STUMP) to assist pathologists with retrieving top K images and their corresponding labels.","So, this approach can offer a more explainable CAD tool to pathologists in terms of transparency, trustworthiness, or reliability among other characteristics."],"url":"http://arxiv.org/abs/2401.08272v1"}
{"created":"2024-01-16 10:35:01","title":"Multi-Technique Sequential Information Consistency For Dynamic Visual Place Recognition In Changing Environments","abstract":"Visual place recognition (VPR) is an essential component of robot navigation and localization systems that allows them to identify a place using only image data. VPR is challenging due to the significant changes in a place's appearance driven by different daily illumination, seasonal weather variations and diverse viewpoints. Currently, no single VPR technique excels in every environmental condition, each exhibiting unique benefits and shortcomings, and therefore combining multiple techniques can achieve more reliable VPR performance. Present multi-method approaches either rely on online ground-truth information, which is often not available, or on brute-force technique combination, potentially lowering performance with high variance technique sets. Addressing these shortcomings, we propose a VPR system dubbed Multi-Sequential Information Consistency (MuSIC) which leverages sequential information to select the most cohesive technique on an online per-frame basis. For each technique in a set, MuSIC computes their respective sequential consistencies by analysing the frame-to-frame continuity of their top match candidates, which are then directly compared to select the optimal technique for the current query image. The use of sequential information to select between VPR methods results in an overall VPR performance increase across different benchmark datasets, while avoiding the need for extra ground-truth of the runtime environment.","sentences":["Visual place recognition (VPR) is an essential component of robot navigation and localization systems that allows them to identify a place using only image data.","VPR is challenging due to the significant changes in a place's appearance driven by different daily illumination, seasonal weather variations and diverse viewpoints.","Currently, no single VPR technique excels in every environmental condition, each exhibiting unique benefits and shortcomings, and therefore combining multiple techniques can achieve more reliable VPR performance.","Present multi-method approaches either rely on online ground-truth information, which is often not available, or on brute-force technique combination, potentially lowering performance with high variance technique sets.","Addressing these shortcomings, we propose a VPR system dubbed Multi-Sequential Information Consistency (MuSIC) which leverages sequential information to select the most cohesive technique on an online per-frame basis.","For each technique in a set, MuSIC computes their respective sequential consistencies by analysing the frame-to-frame continuity of their top match candidates, which are then directly compared to select the optimal technique for the current query image.","The use of sequential information to select between VPR methods results in an overall VPR performance increase across different benchmark datasets, while avoiding the need for extra ground-truth of the runtime environment."],"url":"http://arxiv.org/abs/2401.08263v1"}
{"created":"2024-01-16 10:18:57","title":"Multitask Learning in Minimally Invasive Surgical Vision: A Review","abstract":"Minimally invasive surgery (MIS) has revolutionized many procedures and led to reduced recovery time and risk of patient injury. However, MIS poses additional complexity and burden on surgical teams. Data-driven surgical vision algorithms are thought to be key building blocks in the development of future MIS systems with improved autonomy. Recent advancements in machine learning and computer vision have led to successful applications in analyzing videos obtained from MIS with the promise of alleviating challenges in MIS videos. Surgical scene and action understanding encompasses multiple related tasks that, when solved individually, can be memory-intensive, inefficient, and fail to capture task relationships. Multitask learning (MTL), a learning paradigm that leverages information from multiple related tasks to improve performance and aid generalization, is wellsuited for fine-grained and high-level understanding of MIS data. This review provides an overview of the current state-of-the-art MTL systems that leverage videos obtained from MIS. Beyond listing published approaches, we discuss the benefits and limitations of these MTL systems. Moreover, this manuscript presents an analysis of the literature for various application fields of MTL in MIS, including those with large models, highlighting notable trends, new directions of research, and developments.","sentences":["Minimally invasive surgery (MIS) has revolutionized many procedures and led to reduced recovery time and risk of patient injury.","However, MIS poses additional complexity and burden on surgical teams.","Data-driven surgical vision algorithms are thought to be key building blocks in the development of future MIS systems with improved autonomy.","Recent advancements in machine learning and computer vision have led to successful applications in analyzing videos obtained from MIS with the promise of alleviating challenges in MIS videos.","Surgical scene and action understanding encompasses multiple related tasks that, when solved individually, can be memory-intensive, inefficient, and fail to capture task relationships.","Multitask learning (MTL), a learning paradigm that leverages information from multiple related tasks to improve performance and aid generalization, is wellsuited for fine-grained and high-level understanding of MIS data.","This review provides an overview of the current state-of-the-art MTL systems that leverage videos obtained from MIS.","Beyond listing published approaches, we discuss the benefits and limitations of these MTL systems.","Moreover, this manuscript presents an analysis of the literature for various application fields of MTL in MIS, including those with large models, highlighting notable trends, new directions of research, and developments."],"url":"http://arxiv.org/abs/2401.08256v1"}
{"created":"2024-01-16 09:34:17","title":"Enhancing Wind Speed and Wind Power Forecasting Using Shape-Wise Feature Engineering: A Novel Approach for Improved Accuracy and Robustness","abstract":"Accurate prediction of wind speed and power is vital for enhancing the efficiency of wind energy systems. Numerous solutions have been implemented to date, demonstrating their potential to improve forecasting. Among these, deep learning is perceived as a revolutionary approach in the field. However, despite their effectiveness, the noise present in the collected data remains a significant challenge. This noise has the potential to diminish the performance of these algorithms, leading to inaccurate predictions. In response to this, this study explores a novel feature engineering approach. This approach involves altering the data input shape in both Convolutional Neural Network-Long Short-Term Memory (CNN-LSTM) and Autoregressive models for various forecasting horizons. The results reveal substantial enhancements in model resilience against noise resulting from step increases in data. The approach could achieve an impressive 83% accuracy in predicting unseen data up to the 24th steps. Furthermore, this method consistently provides high accuracy for short, mid, and long-term forecasts, outperforming the performance of individual models. These findings pave the way for further research on noise reduction strategies at different forecasting horizons through shape-wise feature engineering.","sentences":["Accurate prediction of wind speed and power is vital for enhancing the efficiency of wind energy systems.","Numerous solutions have been implemented to date, demonstrating their potential to improve forecasting.","Among these, deep learning is perceived as a revolutionary approach in the field.","However, despite their effectiveness, the noise present in the collected data remains a significant challenge.","This noise has the potential to diminish the performance of these algorithms, leading to inaccurate predictions.","In response to this, this study explores a novel feature engineering approach.","This approach involves altering the data input shape in both Convolutional Neural Network-Long Short-Term Memory (CNN-LSTM) and Autoregressive models for various forecasting horizons.","The results reveal substantial enhancements in model resilience against noise resulting from step increases in data.","The approach could achieve an impressive 83% accuracy in predicting unseen data up to the 24th steps.","Furthermore, this method consistently provides high accuracy for short, mid, and long-term forecasts, outperforming the performance of individual models.","These findings pave the way for further research on noise reduction strategies at different forecasting horizons through shape-wise feature engineering."],"url":"http://arxiv.org/abs/2401.08233v1"}
{"created":"2024-01-16 09:33:29","title":"Multi-scale 2D Temporal Map Diffusion Models for Natural Language Video Localization","abstract":"Natural Language Video Localization (NLVL), grounding phrases from natural language descriptions to corresponding video segments, is a complex yet critical task in video understanding. Despite ongoing advancements, many existing solutions lack the capability to globally capture temporal dynamics of the video data. In this study, we present a novel approach to NLVL that aims to address this issue. Our method involves the direct generation of a global 2D temporal map via a conditional denoising diffusion process, based on the input video and language query. The main challenges are the inherent sparsity and discontinuity of a 2D temporal map in devising the diffusion decoder. To address these challenges, we introduce a multi-scale technique and develop an innovative diffusion decoder. Our approach effectively encapsulates the interaction between the query and video data across various time scales. Experiments on the Charades and DiDeMo datasets underscore the potency of our design.","sentences":["Natural Language Video Localization (NLVL), grounding phrases from natural language descriptions to corresponding video segments, is a complex yet critical task in video understanding.","Despite ongoing advancements, many existing solutions lack the capability to globally capture temporal dynamics of the video data.","In this study, we present a novel approach to NLVL that aims to address this issue.","Our method involves the direct generation of a global 2D temporal map via a conditional denoising diffusion process, based on the input video and language query.","The main challenges are the inherent sparsity and discontinuity of a 2D temporal map in devising the diffusion decoder.","To address these challenges, we introduce a multi-scale technique and develop an innovative diffusion decoder.","Our approach effectively encapsulates the interaction between the query and video data across various time scales.","Experiments on the Charades and DiDeMo datasets underscore the potency of our design."],"url":"http://arxiv.org/abs/2401.08232v1"}
{"created":"2024-01-16 09:15:43","title":"Towards Causal Relationship in Indefinite Data: Baseline Model and New Datasets","abstract":"Integrating deep learning and causal discovery has encouraged us to spot that learning causal structures and representations in dialogue and video is full of challenges. We defined These data forms as \"Indefinite Data\", characterized by multi-structure data and multi-value representations. Unlike existing adaptable data forms, Indefinite Data still faces gaps in datasets and methods. To address the dataset gap, we release two high-quality datasets - Causalogue and Causaction, containing text dialogue samples and video action samples with causal annotations respectively. Moreover, the method gap arises from the coexistence of multi-structure data and multi-value representations, breaking the assumptions of all current methods and rendering them infeasible on Indefinite Data. To this end, we propose a probabilistic framework as a baseline, incorporating three designed highlights for this gap: 1) establishing Causation Condition of representations using the independence of noise terms under non-fixed causal structures, 2) treating causal strength as a latent variable and measuring the reconstruction loss in the correlation space, and 3) estimating the effects of latent confounders. These highpoints make the probabilistic model capable of overcoming challenges brought by the coexistence of multi-structure data and multi-value representations and pave the way for the extension of latent confounders. Comprehensive experiments have evaluated baseline results of causal structures, causal representations, and confounding disentanglement.","sentences":["Integrating deep learning and causal discovery has encouraged us to spot that learning causal structures and representations in dialogue and video is full of challenges.","We defined These data forms as \"Indefinite Data\", characterized by multi-structure data and multi-value representations.","Unlike existing adaptable data forms, Indefinite Data still faces gaps in datasets and methods.","To address the dataset gap, we release two high-quality datasets - Causalogue and Causaction, containing text dialogue samples and video action samples with causal annotations respectively.","Moreover, the method gap arises from the coexistence of multi-structure data and multi-value representations, breaking the assumptions of all current methods and rendering them infeasible on Indefinite Data.","To this end, we propose a probabilistic framework as a baseline, incorporating three designed highlights for this gap: 1) establishing Causation Condition of representations using the independence of noise terms under non-fixed causal structures, 2) treating causal strength as a latent variable and measuring the reconstruction loss in the correlation space, and 3) estimating the effects of latent confounders.","These highpoints make the probabilistic model capable of overcoming challenges brought by the coexistence of multi-structure data and multi-value representations and pave the way for the extension of latent confounders.","Comprehensive experiments have evaluated baseline results of causal structures, causal representations, and confounding disentanglement."],"url":"http://arxiv.org/abs/2401.08221v1"}
{"created":"2024-01-16 08:50:44","title":"Transcending the Limit of Local Window: Advanced Super-Resolution Transformer with Adaptive Token Dictionary","abstract":"Single Image Super-Resolution is a classic computer vision problem that involves estimating high-resolution (HR) images from low-resolution (LR) ones. Although deep neural networks (DNNs), especially Transformers for super-resolution, have seen significant advancements in recent years, challenges still remain, particularly in limited receptive field caused by window-based self-attention. To address these issues, we introduce a group of auxiliary Adapeive Token Dictionary to SR Transformer and establish an ATD-SR method. The introduced token dictionary could learn prior information from training data and adapt the learned prior to specific testing image through an adaptive refinement step. The refinement strategy could not only provide global information to all input tokens but also group image tokens into categories. Based on category partitions, we further propose a category-based self-attention mechanism designed to leverage distant but similar tokens for enhancing input features. The experimental results show that our method achieves the best performance on various single image super-resolution benchmarks.","sentences":["Single Image Super-Resolution is a classic computer vision problem that involves estimating high-resolution (HR) images from low-resolution (LR) ones.","Although deep neural networks (DNNs), especially Transformers for super-resolution, have seen significant advancements in recent years, challenges still remain, particularly in limited receptive field caused by window-based self-attention.","To address these issues, we introduce a group of auxiliary Adapeive Token Dictionary to SR Transformer and establish an ATD-SR method.","The introduced token dictionary could learn prior information from training data and adapt the learned prior to specific testing image through an adaptive refinement step.","The refinement strategy could not only provide global information to all input tokens but also group image tokens into categories.","Based on category partitions, we further propose a category-based self-attention mechanism designed to leverage distant but similar tokens for enhancing input features.","The experimental results show that our method achieves the best performance on various single image super-resolution benchmarks."],"url":"http://arxiv.org/abs/2401.08209v1"}
{"created":"2024-01-16 08:44:29","title":"Generative Multi-Modal Knowledge Retrieval with Large Language Models","abstract":"Knowledge retrieval with multi-modal queries plays a crucial role in supporting knowledge-intensive multi-modal applications. However, existing methods face challenges in terms of their effectiveness and training efficiency, especially when it comes to training and integrating multiple retrievers to handle multi-modal queries. In this paper, we propose an innovative end-to-end generative framework for multi-modal knowledge retrieval. Our framework takes advantage of the fact that large language models (LLMs) can effectively serve as virtual knowledge bases, even when trained with limited data. We retrieve knowledge via a two-step process: 1) generating knowledge clues related to the queries, and 2) obtaining the relevant document by searching databases using the knowledge clue. In particular, we first introduce an object-aware prefix-tuning technique to guide multi-grained visual learning. Then, we align multi-grained visual features into the textual feature space of the LLM, employing the LLM to capture cross-modal interactions. Subsequently, we construct instruction data with a unified format for model training. Finally, we propose the knowledge-guided generation strategy to impose prior constraints in the decoding steps, thereby promoting the generation of distinctive knowledge clues. Through experiments conducted on three benchmarks, we demonstrate significant improvements ranging from 3.0% to 14.6% across all evaluation metrics when compared to strong baselines.","sentences":["Knowledge retrieval with multi-modal queries plays a crucial role in supporting knowledge-intensive multi-modal applications.","However, existing methods face challenges in terms of their effectiveness and training efficiency, especially when it comes to training and integrating multiple retrievers to handle multi-modal queries.","In this paper, we propose an innovative end-to-end generative framework for multi-modal knowledge retrieval.","Our framework takes advantage of the fact that large language models (LLMs) can effectively serve as virtual knowledge bases, even when trained with limited data.","We retrieve knowledge via a two-step process: 1) generating knowledge clues related to the queries, and 2) obtaining the relevant document by searching databases using the knowledge clue.","In particular, we first introduce an object-aware prefix-tuning technique to guide multi-grained visual learning.","Then, we align multi-grained visual features into the textual feature space of the LLM, employing the LLM to capture cross-modal interactions.","Subsequently, we construct instruction data with a unified format for model training.","Finally, we propose the knowledge-guided generation strategy to impose prior constraints in the decoding steps, thereby promoting the generation of distinctive knowledge clues.","Through experiments conducted on three benchmarks, we demonstrate significant improvements ranging from 3.0% to 14.6% across all evaluation metrics when compared to strong baselines."],"url":"http://arxiv.org/abs/2401.08206v1"}
{"created":"2024-01-16 08:30:41","title":"IsamasRed: A Public Dataset Tracking Reddit Discussions on Israel-Hamas Conflict","abstract":"The conflict between Israel and Palestinians significantly escalated after the October 7, 2023 Hamas attack, capturing global attention. To understand the public discourse on this conflict, we present a meticulously compiled dataset--IsamasRed--comprising nearly 400,000 conversations and over 8 million comments from Reddit, spanning from August 2023 to November 2023. We introduce an innovative keyword extraction framework leveraging a large language model to effectively identify pertinent keywords, ensuring a comprehensive data collection. Our initial analysis on the dataset, examining topics, controversy, emotional and moral language trends over time, highlights the emotionally charged and complex nature of the discourse. This dataset aims to enrich the understanding of online discussions, shedding light on the complex interplay between ideology, sentiment, and community engagement in digital spaces.","sentences":["The conflict between Israel and Palestinians significantly escalated after the October 7, 2023 Hamas attack, capturing global attention.","To understand the public discourse on this conflict, we present a meticulously compiled dataset--IsamasRed--comprising nearly 400,000 conversations and over 8 million comments from Reddit, spanning from August 2023 to November 2023.","We introduce an innovative keyword extraction framework leveraging a large language model to effectively identify pertinent keywords, ensuring a comprehensive data collection.","Our initial analysis on the dataset, examining topics, controversy, emotional and moral language trends over time, highlights the emotionally charged and complex nature of the discourse.","This dataset aims to enrich the understanding of online discussions, shedding light on the complex interplay between ideology, sentiment, and community engagement in digital spaces."],"url":"http://arxiv.org/abs/2401.08202v1"}
{"created":"2024-01-16 08:08:01","title":"MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline","abstract":"Large language models (LLMs) have seen considerable advancements in natural language understanding tasks, yet there remains a gap to bridge before attaining true artificial general intelligence, especially concerning shortcomings in mathematical reasoning capabilities. We postulate that the inherent nature of LLM training, which focuses on predicting probabilities of next token, presents challenges in effectively modeling mathematical reasoning that demands exact calculations, both from data-driven and theoretical standpoints. In this paper, we address this challenge by enriching the data landscape and introducing a novel math dataset, enhanced with a capability to utilize a Python code interpreter. This dataset is derived from GSM8K and MATH and has been further refined through a combination of GPT-4 annotations, human review, and self-training processes, where the errors in the original GSM8K training set have been fixed. Additionally, we propose a tentative, easily replicable protocol for the fine-tuning of math-specific LLMs, which has led to a significant improvement in the performance of a 7B-parameter LLM on the GSM8K and MATH datasets. We are committed to advancing the field of mathematical reasoning in LLMs and, to that end, we have made the model checkpoints and will make the dataset publicly available. We hope this will facilitate further research and development within the community.","sentences":["Large language models (LLMs) have seen considerable advancements in natural language understanding tasks, yet there remains a gap to bridge before attaining true artificial general intelligence, especially concerning shortcomings in mathematical reasoning capabilities.","We postulate that the inherent nature of LLM training, which focuses on predicting probabilities of next token, presents challenges in effectively modeling mathematical reasoning that demands exact calculations, both from data-driven and theoretical standpoints.","In this paper, we address this challenge by enriching the data landscape and introducing a novel math dataset, enhanced with a capability to utilize a Python code interpreter.","This dataset is derived from GSM8K and MATH and has been further refined through a combination of GPT-4 annotations, human review, and self-training processes, where the errors in the original GSM8K training set have been fixed.","Additionally, we propose a tentative, easily replicable protocol for the fine-tuning of math-specific LLMs, which has led to a significant improvement in the performance of a 7B-parameter LLM on the GSM8K and MATH datasets.","We are committed to advancing the field of mathematical reasoning in LLMs and, to that end, we have made the model checkpoints and will make the dataset publicly available.","We hope this will facilitate further research and development within the community."],"url":"http://arxiv.org/abs/2401.08190v1"}
{"created":"2024-01-16 07:26:26","title":"Deep Linear Array Pushbroom Image Restoration: A Degradation Pipeline and Jitter-Aware Restoration Network","abstract":"Linear Array Pushbroom (LAP) imaging technology is widely used in the realm of remote sensing. However, images acquired through LAP always suffer from distortion and blur because of camera jitter. Traditional methods for restoring LAP images, such as algorithms estimating the point spread function (PSF), exhibit limited performance. To tackle this issue, we propose a Jitter-Aware Restoration Network (JARNet), to remove the distortion and blur in two stages. In the first stage, we formulate an Optical Flow Correction (OFC) block to refine the optical flow of the degraded LAP images, resulting in pre-corrected images where most of the distortions are alleviated. In the second stage, for further enhancement of the pre-corrected images, we integrate two jitter-aware techniques within the Spatial and Frequency Residual (SFRes) block: 1) introducing Coordinate Attention (CoA) to the SFRes block in order to capture the jitter state in orthogonal direction; 2) manipulating image features in both spatial and frequency domains to leverage local and global priors. Additionally, we develop a data synthesis pipeline, which applies Continue Dynamic Shooting Model (CDSM) to simulate realistic degradation in LAP images. Both the proposed JARNet and LAP image synthesis pipeline establish a foundation for addressing this intricate challenge. Extensive experiments demonstrate that the proposed two-stage method outperforms state-of-the-art image restoration models. Code is available at https://github.com/JHW2000/JARNet.","sentences":["Linear Array Pushbroom (LAP) imaging technology is widely used in the realm of remote sensing.","However, images acquired through LAP always suffer from distortion and blur because of camera jitter.","Traditional methods for restoring LAP images, such as algorithms estimating the point spread function (PSF), exhibit limited performance.","To tackle this issue, we propose a Jitter-Aware Restoration Network (JARNet), to remove the distortion and blur in two stages.","In the first stage, we formulate an Optical Flow Correction (OFC) block to refine the optical flow of the degraded LAP images, resulting in pre-corrected images where most of the distortions are alleviated.","In the second stage, for further enhancement of the pre-corrected images, we integrate two jitter-aware techniques within the Spatial and Frequency Residual (SFRes) block: 1) introducing Coordinate Attention (CoA) to the SFRes block in order to capture the jitter state in orthogonal direction; 2) manipulating image features in both spatial and frequency domains to leverage local and global priors.","Additionally, we develop a data synthesis pipeline, which applies Continue Dynamic Shooting Model (CDSM) to simulate realistic degradation in LAP images.","Both the proposed JARNet and LAP image synthesis pipeline establish a foundation for addressing this intricate challenge.","Extensive experiments demonstrate that the proposed two-stage method outperforms state-of-the-art image restoration models.","Code is available at https://github.com/JHW2000/JARNet."],"url":"http://arxiv.org/abs/2401.08171v1"}
{"created":"2024-01-16 07:11:14","title":"EEG-based Cognitive Load Estimation of Acoustic Parameters for Data Sonification","abstract":"Sonification is a data visualization technique which expresses data attributes via psychoacoustic parameters, which are non-speech audio signals used to convey information. This paper investigates the binary estimation of cognitive load induced by psychoacoustic parameters conveying the focus level of an astronomical image via Electroencephalogram (EEG) embeddings. Employing machine learning and deep learning methodologies, we demonstrate that EEG signals are reliable for (a) binary estimation of cognitive load, (b) isolating easy vs difficult visual-to-auditory perceptual mappings, and (c) capturing perceptual similarities among psychoacoustic parameters. Our key findings reveal that (1) EEG embeddings can reliably measure cognitive load, achieving a peak F1-score of 0.98; (2) Extreme focus levels are easier to detect via auditory mappings than intermediate ones, and (3) psychoacoustic parameters inducing comparable cognitive load levels tend to generate similar EEG encodings.","sentences":["Sonification is a data visualization technique which expresses data attributes via psychoacoustic parameters, which are non-speech audio signals used to convey information.","This paper investigates the binary estimation of cognitive load induced by psychoacoustic parameters conveying the focus level of an astronomical image via Electroencephalogram (EEG) embeddings.","Employing machine learning and deep learning methodologies, we demonstrate that EEG signals are reliable for (a) binary estimation of cognitive load, (b) isolating easy vs difficult visual-to-auditory perceptual mappings, and (c) capturing perceptual similarities among psychoacoustic parameters.","Our key findings reveal that (1) EEG embeddings can reliably measure cognitive load, achieving a peak F1-score of 0.98; (2) Extreme focus levels are easier to detect via auditory mappings than intermediate ones, and (3) psychoacoustic parameters inducing comparable cognitive load levels tend to generate similar EEG encodings."],"url":"http://arxiv.org/abs/2401.08164v1"}
{"created":"2024-01-16 06:16:33","title":"LLMs for Test Input Generation for Semantic Caches","abstract":"Large language models (LLMs) enable state-of-the-art semantic capabilities to be added to software systems such as semantic search of unstructured documents and text generation. However, these models are computationally expensive. At scale, the cost of serving thousands of users increases massively affecting also user experience. To address this problem, semantic caches are used to check for answers to similar queries (that may have been phrased differently) without hitting the LLM service. Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system. Adopting semantic cache techniques usually requires testing the effectiveness of a semantic cache (accurate cache hits and misses) which requires a labelled test set of similar queries and responses which is often unavailable. In this paper, we present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents. Our novel approach uses the reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise subtle variations to queries, and 3) evaluate the synthesised test dataset. We evaluated our approach in the domain of a student question and answer system by qualitatively analysing 100 generated queries and result pairs, and conducting an empirical case study with an open source semantic cache. Our results show that query pairs satisfy human expectations of similarity and our generated data demonstrates failure cases of a semantic cache. Additionally, we also evaluate our approach on Qasper dataset. This work is an important first step into test input generation for semantic applications and presents considerations for practitioners when calibrating a semantic cache.","sentences":["Large language models (LLMs) enable state-of-the-art semantic capabilities to be added to software systems such as semantic search of unstructured documents and text generation.","However, these models are computationally expensive.","At scale, the cost of serving thousands of users increases massively affecting also user experience.","To address this problem, semantic caches are used to check for answers to similar queries (that may have been phrased differently) without hitting the LLM service.","Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system.","Adopting semantic cache techniques usually requires testing the effectiveness of a semantic cache (accurate cache hits and misses) which requires a labelled test set of similar queries and responses which is often unavailable.","In this paper, we present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents.","Our novel approach uses the reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise subtle variations to queries, and 3) evaluate the synthesised test dataset.","We evaluated our approach in the domain of a student question and answer system by qualitatively analysing 100 generated queries and result pairs, and conducting an empirical case study with an open source semantic cache.","Our results show that query pairs satisfy human expectations of similarity and our generated data demonstrates failure cases of a semantic cache.","Additionally, we also evaluate our approach on Qasper dataset.","This work is an important first step into test input generation for semantic applications and presents considerations for practitioners when calibrating a semantic cache."],"url":"http://arxiv.org/abs/2401.08138v1"}
{"created":"2024-01-16 06:01:02","title":"Machine Learning-Based Malicious Vehicle Detection for Security Threats and Attacks in Vehicle Ad-hoc Network (VANET) Communications","abstract":"With the rapid growth of Vehicle Ad-hoc Network (VANET) as a promising technology for efficient and reliable communication among vehicles and infrastructure, the security and integrity of VANET communications has become a critical concern. One of the significant threats to VANET is the presence of blackhole attacks, where malicious nodes disrupt the network's functionality and compromise data confidentiality, integrity, and availability. In this paper, we propose a machine learning-based approach for blackhole detection in VANET. To achieve this task, we first create a comprehensive dataset comprising normal and malicious traffic flows. Afterward, we study and define a promising set of features to discriminate the blackhole attacks. Finally, we evaluate various machine learning algorithms, including Gradient Boosting, Random Forest, Support Vector Machines, k-Nearest Neighbors, Gaussian Naive Bayes, and Logistic Regression. Experimental results demonstrate the effectiveness of these algorithms in distinguishing between normal and malicious nodes. Our findings also highlight the potential of machine learning based approach in enhancing the security of VANET by detecting and mitigating blackhole attacks.","sentences":["With the rapid growth of Vehicle Ad-hoc Network (VANET) as a promising technology for efficient and reliable communication among vehicles and infrastructure, the security and integrity of VANET communications has become a critical concern.","One of the significant threats to VANET is the presence of blackhole attacks, where malicious nodes disrupt the network's functionality and compromise data confidentiality, integrity, and availability.","In this paper, we propose a machine learning-based approach for blackhole detection in VANET.","To achieve this task, we first create a comprehensive dataset comprising normal and malicious traffic flows.","Afterward, we study and define a promising set of features to discriminate the blackhole attacks.","Finally, we evaluate various machine learning algorithms, including Gradient Boosting, Random Forest, Support Vector Machines, k-Nearest Neighbors, Gaussian Naive Bayes, and Logistic Regression.","Experimental results demonstrate the effectiveness of these algorithms in distinguishing between normal and malicious nodes.","Our findings also highlight the potential of machine learning based approach in enhancing the security of VANET by detecting and mitigating blackhole attacks."],"url":"http://arxiv.org/abs/2401.08135v1"}
{"created":"2024-01-16 05:28:12","title":"CycLight: learning traffic signal cooperation with a cycle-level strategy","abstract":"This study introduces CycLight, a novel cycle-level deep reinforcement learning (RL) approach for network-level adaptive traffic signal control (NATSC) systems. Unlike most traditional RL-based traffic controllers that focus on step-by-step decision making, CycLight adopts a cycle-level strategy, optimizing cycle length and splits simultaneously using Parameterized Deep Q-Networks (PDQN) algorithm. This cycle-level approach effectively reduces the computational burden associated with frequent data communication, meanwhile enhancing the practicality and safety of real-world applications. A decentralized framework is formulated for multi-agent cooperation, while attention mechanism is integrated to accurately assess the impact of the surroundings on the current intersection. CycLight is tested in a large synthetic traffic grid using the microscopic traffic simulation tool, SUMO. Experimental results not only demonstrate the superiority of CycLight over other state-of-the-art approaches but also showcase its robustness against information transmission delays.","sentences":["This study introduces CycLight, a novel cycle-level deep reinforcement learning (RL) approach for network-level adaptive traffic signal control (NATSC) systems.","Unlike most traditional RL-based traffic controllers that focus on step-by-step decision making, CycLight adopts a cycle-level strategy, optimizing cycle length and splits simultaneously using Parameterized Deep Q-Networks (PDQN) algorithm.","This cycle-level approach effectively reduces the computational burden associated with frequent data communication, meanwhile enhancing the practicality and safety of real-world applications.","A decentralized framework is formulated for multi-agent cooperation, while attention mechanism is integrated to accurately assess the impact of the surroundings on the current intersection.","CycLight is tested in a large synthetic traffic grid using the microscopic traffic simulation tool, SUMO.","Experimental results not only demonstrate the superiority of CycLight over other state-of-the-art approaches but also showcase its robustness against information transmission delays."],"url":"http://arxiv.org/abs/2401.08121v1"}
{"created":"2024-01-16 05:23:34","title":"SpecSTG: A Fast Spectral Diffusion Framework for Probabilistic Spatio-Temporal Traffic Forecasting","abstract":"Traffic forecasting, a crucial application of spatio-temporal graph (STG) learning, has traditionally relied on deterministic models for accurate point estimations. Yet, these models fall short of identifying latent risks of unexpected volatility in future observations. To address this gap, probabilistic methods, especially variants of diffusion models, have emerged as uncertainty-aware solutions. However, existing diffusion methods typically focus on generating separate future time series for individual sensors in the traffic network, resulting in insufficient involvement of spatial network characteristics in the probabilistic learning process. To better leverage spatial dependencies and systematic patterns inherent in traffic data, we propose SpecSTG, a novel spectral diffusion framework. Our method generates the Fourier representation of future time series, transforming the learning process into the spectral domain enriched with spatial information. Additionally, our approach incorporates a fast spectral graph convolution designed for Fourier input, alleviating the computational burden associated with existing models. Numerical experiments show that SpecSTG achieves outstanding performance with traffic flow and traffic speed datasets compared to state-of-the-art baselines. The source code for SpecSTG is available at https://anonymous.4open.science/r/SpecSTG.","sentences":["Traffic forecasting, a crucial application of spatio-temporal graph (STG) learning, has traditionally relied on deterministic models for accurate point estimations.","Yet, these models fall short of identifying latent risks of unexpected volatility in future observations.","To address this gap, probabilistic methods, especially variants of diffusion models, have emerged as uncertainty-aware solutions.","However, existing diffusion methods typically focus on generating separate future time series for individual sensors in the traffic network, resulting in insufficient involvement of spatial network characteristics in the probabilistic learning process.","To better leverage spatial dependencies and systematic patterns inherent in traffic data, we propose SpecSTG, a novel spectral diffusion framework.","Our method generates the Fourier representation of future time series, transforming the learning process into the spectral domain enriched with spatial information.","Additionally, our approach incorporates a fast spectral graph convolution designed for Fourier input, alleviating the computational burden associated with existing models.","Numerical experiments show that SpecSTG achieves outstanding performance with traffic flow and traffic speed datasets compared to state-of-the-art baselines.","The source code for SpecSTG is available at https://anonymous.4open.science/r/SpecSTG."],"url":"http://arxiv.org/abs/2401.08119v1"}
{"created":"2024-01-16 05:10:50","title":"E2HQV: High-Quality Video Generation from Event Camera via Theory-Inspired Model-Aided Deep Learning","abstract":"The bio-inspired event cameras or dynamic vision sensors are capable of asynchronously capturing per-pixel brightness changes (called event-streams) in high temporal resolution and high dynamic range. However, the non-structural spatial-temporal event-streams make it challenging for providing intuitive visualization with rich semantic information for human vision. It calls for events-to-video (E2V) solutions which take event-streams as input and generate high quality video frames for intuitive visualization. However, current solutions are predominantly data-driven without considering the prior knowledge of the underlying statistics relating event-streams and video frames. It highly relies on the non-linearity and generalization capability of the deep neural networks, thus, is struggling on reconstructing detailed textures when the scenes are complex. In this work, we propose \\textbf{E2HQV}, a novel E2V paradigm designed to produce high-quality video frames from events. This approach leverages a model-aided deep learning framework, underpinned by a theory-inspired E2V model, which is meticulously derived from the fundamental imaging principles of event cameras. To deal with the issue of state-reset in the recurrent components of E2HQV, we also design a temporal shift embedding module to further improve the quality of the video frames. Comprehensive evaluations on the real world event camera datasets validate our approach, with E2HQV, notably outperforming state-of-the-art approaches, e.g., surpassing the second best by over 40\\% for some evaluation metrics.","sentences":["The bio-inspired event cameras or dynamic vision sensors are capable of asynchronously capturing per-pixel brightness changes (called event-streams) in high temporal resolution and high dynamic range.","However, the non-structural spatial-temporal event-streams make it challenging for providing intuitive visualization with rich semantic information for human vision.","It calls for events-to-video (E2V) solutions which take event-streams as input and generate high quality video frames for intuitive visualization.","However, current solutions are predominantly data-driven without considering the prior knowledge of the underlying statistics relating event-streams and video frames.","It highly relies on the non-linearity and generalization capability of the deep neural networks, thus, is struggling on reconstructing detailed textures when the scenes are complex.","In this work, we propose \\textbf{E2HQV}, a novel E2V paradigm designed to produce high-quality video frames from events.","This approach leverages a model-aided deep learning framework, underpinned by a theory-inspired E2V model, which is meticulously derived from the fundamental imaging principles of event cameras.","To deal with the issue of state-reset in the recurrent components of E2HQV, we also design a temporal shift embedding module to further improve the quality of the video frames.","Comprehensive evaluations on the real world event camera datasets validate our approach, with E2HQV, notably outperforming state-of-the-art approaches, e.g., surpassing the second best by over 40\\% for some evaluation metrics."],"url":"http://arxiv.org/abs/2401.08117v1"}
{"created":"2024-01-16 04:28:09","title":"Deep Shape-Texture Statistics for Completely Blind Image Quality Evaluation","abstract":"Opinion-Unaware Blind Image Quality Assessment (OU-BIQA) models aim to predict image quality without training on reference images and subjective quality scores. Thereinto, image statistical comparison is a classic paradigm, while the performance is limited by the representation ability of visual descriptors. Deep features as visual descriptors have advanced IQA in recent research, but they are discovered to be highly texture-biased and lack of shape-bias. On this basis, we find out that image shape and texture cues respond differently towards distortions, and the absence of either one results in an incomplete image representation. Therefore, to formulate a well-round statistical description for images, we utilize the shapebiased and texture-biased deep features produced by Deep Neural Networks (DNNs) simultaneously. More specifically, we design a Shape-Texture Adaptive Fusion (STAF) module to merge shape and texture information, based on which we formulate qualityrelevant image statistics. The perceptual quality is quantified by the variant Mahalanobis Distance between the inner and outer Shape-Texture Statistics (DSTS), wherein the inner and outer statistics respectively describe the quality fingerprints of the distorted image and natural images. The proposed DSTS delicately utilizes shape-texture statistical relations between different data scales in the deep domain, and achieves state-of-the-art (SOTA) quality prediction performance on images with artificial and authentic distortions.","sentences":["Opinion-Unaware Blind Image Quality Assessment (OU-BIQA) models aim to predict image quality without training on reference images and subjective quality scores.","Thereinto, image statistical comparison is a classic paradigm, while the performance is limited by the representation ability of visual descriptors.","Deep features as visual descriptors have advanced IQA in recent research, but they are discovered to be highly texture-biased and lack of shape-bias.","On this basis, we find out that image shape and texture cues respond differently towards distortions, and the absence of either one results in an incomplete image representation.","Therefore, to formulate a well-round statistical description for images, we utilize the shapebiased and texture-biased deep features produced by Deep Neural Networks (DNNs) simultaneously.","More specifically, we design a Shape-Texture Adaptive Fusion (STAF) module to merge shape and texture information, based on which we formulate qualityrelevant image statistics.","The perceptual quality is quantified by the variant Mahalanobis Distance between the inner and outer Shape-Texture Statistics (DSTS), wherein the inner and outer statistics respectively describe the quality fingerprints of the distorted image and natural images.","The proposed DSTS delicately utilizes shape-texture statistical relations between different data scales in the deep domain, and achieves state-of-the-art (SOTA) quality prediction performance on images with artificial and authentic distortions."],"url":"http://arxiv.org/abs/2401.08107v1"}
{"created":"2024-01-16 03:59:07","title":"Inpainting Normal Maps for Lightstage data","abstract":"This study introduces a novel method for inpainting normal maps using a generative adversarial network (GAN). Normal maps, often derived from a lightstage, are crucial in performance capture but can have obscured areas due to movement (e.g., by arms, hair, or props). Inpainting fills these missing areas with plausible data. Our approach extends previous general image inpainting techniques, employing a bow tie-like generator network and a discriminator network, with alternating training phases. The generator aims to synthesize images aligning with the ground truth and deceive the discriminator, which differentiates between real and processed images. Periodically, the discriminator undergoes retraining to enhance its ability to identify processed images. Importantly, our method adapts to the unique characteristics of normal map data, necessitating modifications to the loss function. We utilize a cosine loss instead of mean squared error loss for generator training. Limited training data availability, even with synthetic datasets, demands significant augmentation, considering the specific nature of the input data. This includes appropriate image flipping and in-plane rotations to accurately alter normal vectors. Throughout training, we monitored key metrics such as average loss, Structural Similarity Index Measure (SSIM), and Peak Signal-to-Noise Ratio (PSNR) for the generator, along with average loss and accuracy for the discriminator. Our findings suggest that the proposed model effectively generates high-quality, realistic inpainted normal maps, suitable for performance capture applications. These results establish a foundation for future research, potentially involving more advanced networks and comparisons with inpainting of source images used to create the normal maps.","sentences":["This study introduces a novel method for inpainting normal maps using a generative adversarial network (GAN).","Normal maps, often derived from a lightstage, are crucial in performance capture but can have obscured areas due to movement (e.g., by arms, hair, or props).","Inpainting fills these missing areas with plausible data.","Our approach extends previous general image inpainting techniques, employing a bow tie-like generator network and a discriminator network, with alternating training phases.","The generator aims to synthesize images aligning with the ground truth and deceive the discriminator, which differentiates between real and processed images.","Periodically, the discriminator undergoes retraining to enhance its ability to identify processed images.","Importantly, our method adapts to the unique characteristics of normal map data, necessitating modifications to the loss function.","We utilize a cosine loss instead of mean squared error loss for generator training.","Limited training data availability, even with synthetic datasets, demands significant augmentation, considering the specific nature of the input data.","This includes appropriate image flipping and in-plane rotations to accurately alter normal vectors.","Throughout training, we monitored key metrics such as average loss, Structural Similarity Index Measure (SSIM), and Peak Signal-to-Noise Ratio (PSNR) for the generator, along with average loss and accuracy for the discriminator.","Our findings suggest that the proposed model effectively generates high-quality, realistic inpainted normal maps, suitable for performance capture applications.","These results establish a foundation for future research, potentially involving more advanced networks and comparisons with inpainting of source images used to create the normal maps."],"url":"http://arxiv.org/abs/2401.08099v1"}
{"created":"2024-01-16 03:28:29","title":"A Study on Training and Developing Large Language Models for Behavior Tree Generation","abstract":"This paper presents an innovative exploration of the application potential of large language models (LLM) in addressing the challenging task of automatically generating behavior trees (BTs) for complex tasks. The conventional manual BT generation method is inefficient and heavily reliant on domain expertise. On the other hand, existing automatic BT generation technologies encounter bottlenecks related to task complexity, model adaptability, and reliability. In order to overcome these challenges, we propose a novel methodology that leverages the robust representation and reasoning abilities of LLMs. The core contribution of this paper lies in the design of a BT generation framework based on LLM, which encompasses the entire process, from data synthesis and model training to application developing and data verification. Synthetic data is introduced to train the BT generation model (BTGen model), enhancing its understanding and adaptability to various complex tasks, thereby significantly improving its overall performance. In order to ensure the effectiveness and executability of the generated BTs, we emphasize the importance of data verification and introduce a multilevel verification strategy. Additionally, we explore a range of agent design and development schemes with LLM as the central element. We hope that the work in this paper may provide a reference for the researchers who are interested in BT generation based on LLMs.","sentences":["This paper presents an innovative exploration of the application potential of large language models (LLM) in addressing the challenging task of automatically generating behavior trees (BTs) for complex tasks.","The conventional manual BT generation method is inefficient and heavily reliant on domain expertise.","On the other hand, existing automatic BT generation technologies encounter bottlenecks related to task complexity, model adaptability, and reliability.","In order to overcome these challenges, we propose a novel methodology that leverages the robust representation and reasoning abilities of LLMs.","The core contribution of this paper lies in the design of a BT generation framework based on LLM, which encompasses the entire process, from data synthesis and model training to application developing and data verification.","Synthetic data is introduced to train the BT generation model (BTGen model), enhancing its understanding and adaptability to various complex tasks, thereby significantly improving its overall performance.","In order to ensure the effectiveness and executability of the generated BTs, we emphasize the importance of data verification and introduce a multilevel verification strategy.","Additionally, we explore a range of agent design and development schemes with LLM as the central element.","We hope that the work in this paper may provide a reference for the researchers who are interested in BT generation based on LLMs."],"url":"http://arxiv.org/abs/2401.08089v1"}
{"created":"2024-01-16 03:09:45","title":"Adversarial Masking Contrastive Learning for vein recognition","abstract":"Vein recognition has received increasing attention due to its high security and privacy. Recently, deep neural networks such as Convolutional neural networks (CNN) and Transformers have been introduced for vein recognition and achieved state-of-the-art performance. Despite the recent advances, however, existing solutions for finger-vein feature extraction are still not optimal due to scarce training image samples. To overcome this problem, in this paper, we propose an adversarial masking contrastive learning (AMCL) approach, that generates challenging samples to train a more robust contrastive learning model for the downstream palm-vein recognition task, by alternatively optimizing the encoder in the contrastive learning model and a set of latent variables. First, a huge number of masks are generated to train a robust generative adversarial network (GAN). The trained generator transforms a latent variable from the latent variable space into a mask space. Then, we combine the trained generator with a contrastive learning model to obtain our AMCL, where the generator produces challenging masking images to increase the contrastive loss and the contrastive learning model is trained based on the harder images to learn a more robust feature representation. After training, the trained encoder in the contrastive learning model is combined with a classification layer to build a classifier, which is further fine-tuned on labeled training data for vein recognition. The experimental results on three databases demonstrate that our approach outperforms existing contrastive learning approaches in terms of improving identification accuracy of vein classifiers and achieves state-of-the-art recognition results.","sentences":["Vein recognition has received increasing attention due to its high security and privacy.","Recently, deep neural networks such as Convolutional neural networks (CNN) and Transformers have been introduced for vein recognition and achieved state-of-the-art performance.","Despite the recent advances, however, existing solutions for finger-vein feature extraction are still not optimal due to scarce training image samples.","To overcome this problem, in this paper, we propose an adversarial masking contrastive learning (AMCL) approach, that generates challenging samples to train a more robust contrastive learning model for the downstream palm-vein recognition task, by alternatively optimizing the encoder in the contrastive learning model and a set of latent variables.","First, a huge number of masks are generated to train a robust generative adversarial network (GAN).","The trained generator transforms a latent variable from the latent variable space into a mask space.","Then, we combine the trained generator with a contrastive learning model to obtain our AMCL, where the generator produces challenging masking images to increase the contrastive loss and the contrastive learning model is trained based on the harder images to learn a more robust feature representation.","After training, the trained encoder in the contrastive learning model is combined with a classification layer to build a classifier, which is further fine-tuned on labeled training data for vein recognition.","The experimental results on three databases demonstrate that our approach outperforms existing contrastive learning approaches in terms of improving identification accuracy of vein classifiers and achieves state-of-the-art recognition results."],"url":"http://arxiv.org/abs/2401.08079v1"}
{"created":"2024-01-16 02:51:42","title":"TrajVis: a visual clinical decision support system to translate artificial intelligence trajectory models in the precision management of chronic kidney disease","abstract":"Objective: Our objective is to develop and validate TrajVis, an interactive tool that assists clinicians in using artificial intelligence (AI) models to leverage patients' longitudinal electronic medical records (EMR) for personalized precision management of chronic disease progression. Methods: We first perform requirement analysis with clinicians and data scientists to determine the visual analytics tasks of the TrajVis system as well as its design and functionalities. A graph AI model for chronic kidney disease (CKD) trajectory inference named DEPOT is used for system development and demonstration. TrajVis is implemented as a full-stack web application with synthetic EMR data derived from the Atrium Health Wake Forest Baptist Translational Data Warehouse and the Indiana Network for Patient Care research database. A case study with a nephrologist and a user experience survey of clinicians and data scientists are conducted to evaluate the TrajVis system. Results: The TrajVis clinical information system is composed of four panels: the Patient View for demographic and clinical information, the Trajectory View to visualize the DEPOT-derived CKD trajectories in latent space, the Clinical Indicator View to elucidate longitudinal patterns of clinical features and interpret DEPOT predictions, and the Analysis View to demonstrate personal CKD progression trajectories. System evaluations suggest that TrajVis supports clinicians in summarizing clinical data, identifying individualized risk predictors, and visualizing patient disease progression trajectories, overcoming the barriers of AI implementation in healthcare. Conclusion: TrajVis bridges the gap between the fast-growing AI/ML modeling and the clinical use of such models for personalized and precision management of chronic diseases.","sentences":["Objective: Our objective is to develop and validate TrajVis, an interactive tool that assists clinicians in using artificial intelligence (AI) models to leverage patients' longitudinal electronic medical records (EMR) for personalized precision management of chronic disease progression.","Methods: We first perform requirement analysis with clinicians and data scientists to determine the visual analytics tasks of the TrajVis system as well as its design and functionalities.","A graph AI model for chronic kidney disease (CKD) trajectory inference named DEPOT is used for system development and demonstration.","TrajVis is implemented as a full-stack web application with synthetic EMR data derived from the Atrium Health Wake Forest Baptist Translational Data Warehouse and the Indiana Network for Patient Care research database.","A case study with a nephrologist and a user experience survey of clinicians and data scientists are conducted to evaluate the TrajVis system.","Results:","The TrajVis clinical information system is composed of four panels: the Patient View for demographic and clinical information, the Trajectory View to visualize the DEPOT-derived CKD trajectories in latent space, the Clinical Indicator View to elucidate longitudinal patterns of clinical features and interpret DEPOT predictions, and the Analysis View to demonstrate personal CKD progression trajectories.","System evaluations suggest that TrajVis supports clinicians in summarizing clinical data, identifying individualized risk predictors, and visualizing patient disease progression trajectories, overcoming the barriers of AI implementation in healthcare.","Conclusion:","TrajVis bridges the gap between the fast-growing AI/ML modeling and the clinical use of such models for personalized and precision management of chronic diseases."],"url":"http://arxiv.org/abs/2401.08067v1"}
{"created":"2024-01-16 02:42:45","title":"Augmenting Ground-Level PM2.5 Prediction via Kriging-Based Pseudo-Label Generation","abstract":"Fusing abundant satellite data with sparse ground measurements constitutes a major challenge in climate modeling. To address this, we propose a strategy to augment the training dataset by introducing unlabeled satellite images paired with pseudo-labels generated through a spatial interpolation technique known as ordinary kriging, thereby making full use of the available satellite data resources. We show that the proposed data augmentation strategy helps enhance the performance of the state-of-the-art convolutional neural network-random forest (CNN-RF) model by a reasonable amount, resulting in a noteworthy improvement in spatial correlation and a reduction in prediction error.","sentences":["Fusing abundant satellite data with sparse ground measurements constitutes a major challenge in climate modeling.","To address this, we propose a strategy to augment the training dataset by introducing unlabeled satellite images paired with pseudo-labels generated through a spatial interpolation technique known as ordinary kriging, thereby making full use of the available satellite data resources.","We show that the proposed data augmentation strategy helps enhance the performance of the state-of-the-art convolutional neural network-random forest (CNN-RF) model by a reasonable amount, resulting in a noteworthy improvement in spatial correlation and a reduction in prediction error."],"url":"http://arxiv.org/abs/2401.08061v1"}
{"created":"2024-01-16 02:26:29","title":"Toward Clinically Trustworthy Deep Learning: Applying Conformal Prediction to Intracranial Hemorrhage Detection","abstract":"As deep learning (DL) continues to demonstrate its ability in radiological tasks, it is critical that we optimize clinical DL solutions to include safety. One of the principal concerns in the clinical adoption of DL tools is trust. This study aims to apply conformal prediction as a step toward trustworthiness for DL in radiology. This is a retrospective study of 491 non-contrast head CTs from the CQ500 dataset, in which three senior radiologists annotated slices containing intracranial hemorrhage (ICH). The dataset was split into definite and challenging subsets, where challenging images were defined to those in which there was disagreement among readers. A DL model was trained on 146 patients (10,815 slices) from the definite data (training dataset) to perform ICH localization and classification for five classes of ICH. To develop an uncertainty-aware DL model, 1,546 cases of the definite data (calibration dataset) was used for Mondrian conformal prediction (MCP). The uncertainty-aware DL model was tested on 8,401 definite and challenging cases to assess its ability to identify challenging cases. After the MCP procedure, the model achieved an F1 score of 0.920 for ICH classification on the test dataset. Additionally, it correctly identified 6,837 of the 6,856 total challenging cases as challenging (99.7% accuracy). It did not incorrectly label any definite cases as challenging. The uncertainty-aware ICH detector performs on par with state-of-the-art models. MCP's performance in detecting challenging cases demonstrates that it is useful in automated ICH detection and promising for trustworthiness in radiological DL.","sentences":["As deep learning (DL) continues to demonstrate its ability in radiological tasks, it is critical that we optimize clinical DL solutions to include safety.","One of the principal concerns in the clinical adoption of DL tools is trust.","This study aims to apply conformal prediction as a step toward trustworthiness for DL in radiology.","This is a retrospective study of 491 non-contrast head CTs from the CQ500 dataset, in which three senior radiologists annotated slices containing intracranial hemorrhage (ICH).","The dataset was split into definite and challenging subsets, where challenging images were defined to those in which there was disagreement among readers.","A DL model was trained on 146 patients (10,815 slices) from the definite data (training dataset) to perform ICH localization and classification for five classes of ICH.","To develop an uncertainty-aware DL model, 1,546 cases of the definite data (calibration dataset) was used for Mondrian conformal prediction (MCP).","The uncertainty-aware DL model was tested on 8,401 definite and challenging cases to assess its ability to identify challenging cases.","After the MCP procedure, the model achieved an F1 score of 0.920 for ICH classification on the test dataset.","Additionally, it correctly identified 6,837 of the 6,856 total challenging cases as challenging (99.7% accuracy).","It did not incorrectly label any definite cases as challenging.","The uncertainty-aware ICH detector performs on par with state-of-the-art models.","MCP's performance in detecting challenging cases demonstrates that it is useful in automated ICH detection and promising for trustworthiness in radiological DL."],"url":"http://arxiv.org/abs/2401.08058v1"}
{"created":"2024-01-16 02:10:13","title":"SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation","abstract":"Accurate representation in media is known to improve the well-being of the people who consume it. Generative image models trained on large web-crawled datasets such as LAION are known to produce images with harmful stereotypes and misrepresentations of cultures. We improve inclusive representation in generated images by (1) engaging with communities to collect a culturally representative dataset that we call the Cross-Cultural Understanding Benchmark (CCUB) and (2) proposing a novel Self-Contrastive Fine-Tuning (SCoFT) method that leverages the model's known biases to self-improve. SCoFT is designed to prevent overfitting on small datasets, encode only high-level information from the data, and shift the generated distribution away from misrepresentations encoded in a pretrained model. Our user study conducted on 51 participants from 5 different countries based on their self-selected national cultural affiliation shows that fine-tuning on CCUB consistently generates images with higher cultural relevance and fewer stereotypes when compared to the Stable Diffusion baseline, which is further improved with our SCoFT technique.","sentences":["Accurate representation in media is known to improve the well-being of the people who consume it.","Generative image models trained on large web-crawled datasets such as LAION are known to produce images with harmful stereotypes and misrepresentations of cultures.","We improve inclusive representation in generated images by (1) engaging with communities to collect a culturally representative dataset that we call the Cross-Cultural Understanding Benchmark (CCUB) and (2) proposing a novel Self-Contrastive Fine-Tuning (SCoFT) method that leverages the model's known biases to self-improve.","SCoFT is designed to prevent overfitting on small datasets, encode only high-level information from the data, and shift the generated distribution away from misrepresentations encoded in a pretrained model.","Our user study conducted on 51 participants from 5 different countries based on their self-selected national cultural affiliation shows that fine-tuning on CCUB consistently generates images with higher cultural relevance and fewer stereotypes when compared to the Stable Diffusion baseline, which is further improved with our SCoFT technique."],"url":"http://arxiv.org/abs/2401.08053v1"}
{"created":"2024-01-16 02:00:17","title":"Incremental Extractive Opinion Summarization Using Cover Trees","abstract":"Extractive opinion summarization involves automatically producing a summary of text about an entity (e.g., a product's reviews) by extracting representative sentences that capture prevalent opinions in the review set. Typically, in online marketplaces user reviews accrue over time, and opinion summaries need to be updated periodically to provide customers with up-to-date information. In this work, we study the task of extractive opinion summarization in an incremental setting, where the underlying review set evolves over time. Many of the state-of-the-art extractive opinion summarization approaches are centrality-based, such as CentroidRank. CentroidRank performs extractive summarization by selecting a subset of review sentences closest to the centroid in the representation space as the summary. However, these methods are not capable of operating efficiently in an incremental setting, where reviews arrive one at a time. In this paper, we present an efficient algorithm for accurately computing the CentroidRank summaries in an incremental setting. Our approach, CoverSumm, relies on indexing review representations in a cover tree and maintaining a reservoir of candidate summary review sentences. CoverSumm's efficacy is supported by a theoretical and empirical analysis of running time. Empirically, on a diverse collection of data (both real and synthetically created to illustrate scaling considerations), we demonstrate that CoverSumm is up to 25x faster than baseline methods, and capable of adapting to nuanced changes in data distribution. We also conduct human evaluations of the generated summaries and find that CoverSumm is capable of producing informative summaries consistent with the underlying review set.","sentences":["Extractive opinion summarization involves automatically producing a summary of text about an entity (e.g., a product's reviews) by extracting representative sentences that capture prevalent opinions in the review set.","Typically, in online marketplaces user reviews accrue over time, and opinion summaries need to be updated periodically to provide customers with up-to-date information.","In this work, we study the task of extractive opinion summarization in an incremental setting, where the underlying review set evolves over time.","Many of the state-of-the-art extractive opinion summarization approaches are centrality-based, such as CentroidRank.","CentroidRank performs extractive summarization by selecting a subset of review sentences closest to the centroid in the representation space as the summary.","However, these methods are not capable of operating efficiently in an incremental setting, where reviews arrive one at a time.","In this paper, we present an efficient algorithm for accurately computing the CentroidRank summaries in an incremental setting.","Our approach, CoverSumm, relies on indexing review representations in a cover tree and maintaining a reservoir of candidate summary review sentences.","CoverSumm's efficacy is supported by a theoretical and empirical analysis of running time.","Empirically, on a diverse collection of data (both real and synthetically created to illustrate scaling considerations), we demonstrate that CoverSumm is up to 25x faster than baseline methods, and capable of adapting to nuanced changes in data distribution.","We also conduct human evaluations of the generated summaries and find that CoverSumm is capable of producing informative summaries consistent with the underlying review set."],"url":"http://arxiv.org/abs/2401.08047v1"}
{"created":"2024-01-16 01:57:24","title":"Forging Vision Foundation Models for Autonomous Driving: Challenges, Methodologies, and Opportunities","abstract":"The rise of large foundation models, trained on extensive datasets, is revolutionizing the field of AI. Models such as SAM, DALL-E2, and GPT-4 showcase their adaptability by extracting intricate patterns and performing effectively across diverse tasks, thereby serving as potent building blocks for a wide range of AI applications. Autonomous driving, a vibrant front in AI applications, remains challenged by the lack of dedicated vision foundation models (VFMs). The scarcity of comprehensive training data, the need for multi-sensor integration, and the diverse task-specific architectures pose significant obstacles to the development of VFMs in this field. This paper delves into the critical challenge of forging VFMs tailored specifically for autonomous driving, while also outlining future directions. Through a systematic analysis of over 250 papers, we dissect essential techniques for VFM development, including data preparation, pre-training strategies, and downstream task adaptation. Moreover, we explore key advancements such as NeRF, diffusion models, 3D Gaussian Splatting, and world models, presenting a comprehensive roadmap for future research. To empower researchers, we have built and maintained https://github.com/zhanghm1995/Forge_VFM4AD, an open-access repository constantly updated with the latest advancements in forging VFMs for autonomous driving.","sentences":["The rise of large foundation models, trained on extensive datasets, is revolutionizing the field of AI.","Models such as SAM, DALL-E2, and GPT-4 showcase their adaptability by extracting intricate patterns and performing effectively across diverse tasks, thereby serving as potent building blocks for a wide range of AI applications.","Autonomous driving, a vibrant front in AI applications, remains challenged by the lack of dedicated vision foundation models (VFMs).","The scarcity of comprehensive training data, the need for multi-sensor integration, and the diverse task-specific architectures pose significant obstacles to the development of VFMs in this field.","This paper delves into the critical challenge of forging VFMs tailored specifically for autonomous driving, while also outlining future directions.","Through a systematic analysis of over 250 papers, we dissect essential techniques for VFM development, including data preparation, pre-training strategies, and downstream task adaptation.","Moreover, we explore key advancements such as NeRF, diffusion models, 3D Gaussian Splatting, and world models, presenting a comprehensive roadmap for future research.","To empower researchers, we have built and maintained https://github.com/zhanghm1995/Forge_VFM4AD, an open-access repository constantly updated with the latest advancements in forging VFMs for autonomous driving."],"url":"http://arxiv.org/abs/2401.08045v1"}
{"created":"2024-01-16 01:27:26","title":"Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with Crowdsourcing and Active Learning","abstract":"A significant challenge to training accurate deep learning models on privacy policies is the cost and difficulty of obtaining a large and comprehensive set of training data. To address these challenges, we present Calpric , which combines automatic text selection and segmentation, active learning and the use of crowdsourced annotators to generate a large, balanced training set for privacy policies at low cost. Automated text selection and segmentation simplifies the labeling task, enabling untrained annotators from crowdsourcing platforms, like Amazon's Mechanical Turk, to be competitive with trained annotators, such as law students, and also reduces inter-annotator agreement, which decreases labeling cost. Having reliable labels for training enables the use of active learning, which uses fewer training samples to efficiently cover the input space, further reducing cost and improving class and data category balance in the data set. The combination of these techniques allows Calpric to produce models that are accurate over a wider range of data categories, and provide more detailed, fine-grain labels than previous work. Our crowdsourcing process enables Calpric to attain reliable labeled data at a cost of roughly $0.92-$1.71 per labeled text segment. Calpric 's training process also generates a labeled data set of 16K privacy policy text segments across 9 Data categories with balanced positive and negative samples.","sentences":["A significant challenge to training accurate deep learning models on privacy policies is the cost and difficulty of obtaining a large and comprehensive set of training data.","To address these challenges, we present Calpric , which combines automatic text selection and segmentation, active learning and the use of crowdsourced annotators to generate a large, balanced training set for privacy policies at low cost.","Automated text selection and segmentation simplifies the labeling task, enabling untrained annotators from crowdsourcing platforms, like Amazon's Mechanical Turk, to be competitive with trained annotators, such as law students, and also reduces inter-annotator agreement, which decreases labeling cost.","Having reliable labels for training enables the use of active learning, which uses fewer training samples to efficiently cover the input space, further reducing cost and improving class and data category balance in the data set.","The combination of these techniques allows Calpric to produce models that are accurate over a wider range of data categories, and provide more detailed, fine-grain labels than previous work.","Our crowdsourcing process enables Calpric to attain reliable labeled data at a cost of roughly $0.92-$1.71 per labeled text segment.","Calpric 's training process also generates a labeled data set of 16K privacy policy text segments across 9 Data categories with balanced positive and negative samples."],"url":"http://arxiv.org/abs/2401.08038v1"}
{"created":"2024-01-16 01:13:14","title":"Understanding factors behind IoT privacy -- A user's perspective on RF sensors","abstract":"While IoT sensors in physical spaces have provided utility and comfort in our lives, their instrumentation in private and personal spaces has led to growing concerns regarding privacy. The existing notion behind IoT privacy is that the sensors whose data can easily be understood and interpreted by humans (such as cameras) are more privacy-invasive than sensors that are not human-understandable, such as RF (radio-frequency) sensors. However, given recent advancements in machine learning, we can not only make sensitive inferences on RF data but also translate between modalities. Thus, the existing notions of privacy for IoT sensors need to be revisited. In this paper, our goal is to understand what factors affect the privacy notions of a non-expert user (someone who is not well-versed in privacy concepts). To this regard, we conduct an online study of 162 participants from the USA to find out what factors affect the privacy perception of a user regarding an RF-based device or a sensor. Our findings show that a user's perception of privacy not only depends upon the data collected by the sensor but also on the inferences that can be made on that data, familiarity with the device and its form factor as well as the control a user has over the device design and its data policies. When the data collected by the sensor is not human-interpretable, it is the inferences that can be made on the data and not the data itself that users care about when making informed decisions regarding device privacy.","sentences":["While IoT sensors in physical spaces have provided utility and comfort in our lives, their instrumentation in private and personal spaces has led to growing concerns regarding privacy.","The existing notion behind IoT privacy is that the sensors whose data can easily be understood and interpreted by humans (such as cameras) are more privacy-invasive than sensors that are not human-understandable, such as RF (radio-frequency) sensors.","However, given recent advancements in machine learning, we can not only make sensitive inferences on RF data but also translate between modalities.","Thus, the existing notions of privacy for IoT sensors need to be revisited.","In this paper, our goal is to understand what factors affect the privacy notions of a non-expert user (someone who is not well-versed in privacy concepts).","To this regard, we conduct an online study of 162 participants from the USA to find out what factors affect the privacy perception of a user regarding an RF-based device or a sensor.","Our findings show that a user's perception of privacy not only depends upon the data collected by the sensor but also on the inferences that can be made on that data, familiarity with the device and its form factor as well as the control a user has over the device design and its data policies.","When the data collected by the sensor is not human-interpretable, it is the inferences that can be made on the data and not the data itself that users care about when making informed decisions regarding device privacy."],"url":"http://arxiv.org/abs/2401.08037v1"}
{"created":"2024-01-16 01:12:24","title":"3D Lane Detection from Front or Surround-View using Joint-Modeling & Matching","abstract":"3D lanes offer a more comprehensive understanding of the road surface geometry than 2D lanes, thereby providing crucial references for driving decisions and trajectory planning. While many efforts aim to improve prediction accuracy, we recognize that an efficient network can bring results closer to lane modeling. However, if the modeling data is imprecise, the results might not accurately capture the real-world scenario. Therefore, accurate lane modeling is essential to align prediction results closely with the environment. This study centers on efficient and accurate lane modeling, proposing a joint modeling approach that combines Bezier curves and interpolation methods. Furthermore, based on this lane modeling approach, we developed a Global2Local Lane Matching method with Bezier Control-Point and Key-Point, which serve as a comprehensive solution that leverages hierarchical features with two mathematical models to ensure a precise match. We also introduce a novel 3D Spatial Constructor, representing an exploration of 3D surround-view lane detection research. The framework is suitable for front-view or surround-view 3D lane detection. By directly outputting the key points of lanes in 3D space, it overcomes the limitations of anchor-based methods, enabling accurate prediction of closed-loop or U-shaped lanes and effective adaptation to complex road conditions. This innovative method establishes a new benchmark in front-view 3D lane detection on the Openlane dataset and achieves competitive performance in surround-view 2D lane detection on the Argoverse2 dataset.","sentences":["3D lanes offer a more comprehensive understanding of the road surface geometry than 2D lanes, thereby providing crucial references for driving decisions and trajectory planning.","While many efforts aim to improve prediction accuracy, we recognize that an efficient network can bring results closer to lane modeling.","However, if the modeling data is imprecise, the results might not accurately capture the real-world scenario.","Therefore, accurate lane modeling is essential to align prediction results closely with the environment.","This study centers on efficient and accurate lane modeling, proposing a joint modeling approach that combines Bezier curves and interpolation methods.","Furthermore, based on this lane modeling approach, we developed a Global2Local Lane Matching method with Bezier Control-Point and Key-Point, which serve as a comprehensive solution that leverages hierarchical features with two mathematical models to ensure a precise match.","We also introduce a novel 3D Spatial Constructor, representing an exploration of 3D surround-view lane detection research.","The framework is suitable for front-view or surround-view 3D lane detection.","By directly outputting the key points of lanes in 3D space, it overcomes the limitations of anchor-based methods, enabling accurate prediction of closed-loop or U-shaped lanes and effective adaptation to complex road conditions.","This innovative method establishes a new benchmark in front-view 3D lane detection on the Openlane dataset and achieves competitive performance in surround-view 2D lane detection on the Argoverse2 dataset."],"url":"http://arxiv.org/abs/2401.08036v1"}
{"created":"2024-01-16 00:46:29","title":"Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using Self-Imagination","abstract":"The potential of Vision-Language Models (\\textsc{vlm}s) often remains underutilized in handling complex text-based problems, particularly when these problems could benefit from visual representation. Resonating with humans' ability to solve complex text-based problems by (1) creating a visual diagram from the problem and (2) deducing what steps they need to take to solve it, we propose \\textsc{Self-Imagine}. We leverage a single Vision-Language Model (\\textsc{vlm}) to generate a structured representation of the question using HTML, then render the HTML as an image, and finally use the same \\vlm to answer the question using both the question and the image. Our approach does not require any additional training data or training. We evaluate our approach in three mathematics tasks and nine general-purpose reasoning tasks using state-of-the-art \\textsc{vlm}. Our approach boosts the performance of \\textsc{vlm} on all math tasks (\\gsm: +4.62\\%; \\asdiv: +4.49\\%; \\svamp: +9.30\\%) and the majority of the general-purpose reasoning tasks by 0.4\\% to 13.20\\% while achieving comparable performance in other tasks.   Code and data at https://github.com/snat1505027/self-imagine .","sentences":["The potential of Vision-Language Models (\\textsc{vlm}s) often remains underutilized in handling complex text-based problems, particularly when these problems could benefit from visual representation.","Resonating with humans' ability to solve complex text-based problems by (1) creating a visual diagram from the problem and (2) deducing what steps they need to take to solve it, we propose \\textsc{Self-Imagine}.","We leverage a single Vision-Language Model (\\textsc{vlm}) to generate a structured representation of the question using HTML, then render the HTML as an image, and finally use the same \\vlm to answer the question using both the question and the image.","Our approach does not require any additional training data or training.","We evaluate our approach in three mathematics tasks and nine general-purpose reasoning tasks using state-of-the-art \\textsc{vlm}.","Our approach boosts the performance of \\textsc{vlm} on all math tasks (\\gsm: +4.62\\%; \\asdiv: +4.49\\%; \\svamp: +9.30\\%) and the majority of the general-purpose reasoning tasks by 0.4\\% to 13.20\\% while achieving comparable performance in other tasks.   ","Code and data at https://github.com/snat1505027/self-imagine ."],"url":"http://arxiv.org/abs/2401.08025v1"}
{"created":"2024-01-16 00:17:57","title":"Belief Miner: A Methodology for Discovering Causal Beliefs and Causal Illusions from General Populations","abstract":"Causal belief is a cognitive practice that humans apply everyday to reason about cause and effect relations between factors, phenomena, or events. Like optical illusions, humans are prone to drawing causal relations between events that are only coincidental (i.e., causal illusions). Researchers in domains such as cognitive psychology and healthcare often use logistically expensive experiments to understand causal beliefs and illusions. In this paper, we propose Belief Miner, a crowdsourcing method for evaluating people's causal beliefs and illusions. Our method uses the (dis)similarities between the causal relations collected from the crowds and experts to surface the causal beliefs and illusions. Through an iterative design process, we developed a web-based interface for collecting causal relations from a target population. We then conducted a crowdsourced experiment with 101 workers on Amazon Mechanical Turk and Prolific using this interface and analyzed the collected data with Belief Miner. We discovered a variety of causal beliefs and potential illusions, and we report the design implications for future research.","sentences":["Causal belief is a cognitive practice that humans apply everyday to reason about cause and effect relations between factors, phenomena, or events.","Like optical illusions, humans are prone to drawing causal relations between events that are only coincidental (i.e., causal illusions).","Researchers in domains such as cognitive psychology and healthcare often use logistically expensive experiments to understand causal beliefs and illusions.","In this paper, we propose Belief Miner, a crowdsourcing method for evaluating people's causal beliefs and illusions.","Our method uses the (dis)similarities between the causal relations collected from the crowds and experts to surface the causal beliefs and illusions.","Through an iterative design process, we developed a web-based interface for collecting causal relations from a target population.","We then conducted a crowdsourced experiment with 101 workers on Amazon Mechanical Turk and Prolific using this interface and analyzed the collected data with Belief Miner.","We discovered a variety of causal beliefs and potential illusions, and we report the design implications for future research."],"url":"http://arxiv.org/abs/2401.08020v1"}
{"created":"2024-01-16 00:15:48","title":"A polynomial algorithm for the most degree-central shortest path problem","abstract":"The degree centrality of a node, defined to be the number of nodes adjacent to it, can be used as a measure of importance of a node to the structure of a network. This metric can be extended to paths in a network, where the degree centrality of a path is defined to be the number of nodes adjacent to it. In this paper, we reconsider the problem of finding the most degree-central shortest path in an unweighted network. We propose a polynomial algorithm with the worst-case running time of $O(|V|^3(\\Delta(G))^2)$, where $|V|$ is the number of vertices in the network and $\\Delta(G)$ is the maximum degree of the graph. We conduct a numerical study of our algorithm on synthetic and real-world networks and compare our results to the existing literature. In addition, we show that the same problem is NP-hard when a weighted graph is considered.","sentences":["The degree centrality of a node, defined to be the number of nodes adjacent to it, can be used as a measure of importance of a node to the structure of a network.","This metric can be extended to paths in a network, where the degree centrality of a path is defined to be the number of nodes adjacent to it.","In this paper, we reconsider the problem of finding the most degree-central shortest path in an unweighted network.","We propose a polynomial algorithm with the worst-case running time of $O(|V|^3(\\Delta(G))^2)$, where $|V|$ is the number of vertices in the network and $\\Delta(G)$ is the maximum degree of the graph.","We conduct a numerical study of our algorithm on synthetic and real-world networks and compare our results to the existing literature.","In addition, we show that the same problem is NP-hard when a weighted graph is considered."],"url":"http://arxiv.org/abs/2401.08019v1"}
{"created":"2024-01-16 00:09:45","title":"Effects of Virtual Hand Representation on the Typing Performance, Upper Extremity Angle, and Neck Muscle Activity during Virtual Reality Typing","abstract":"This study evaluated the effect of virtual hand representation on the typing performance, upper extremity angle, neck muscle activity, and usability during virtual reality (VR) typing. A total of 15 participants (7 females and 8 males) performed a typing task with and without virtual hand representations. The optical motion capture data was utilized to capture the upper extremity angles, and electromyography device was used to collect the neck muscle activities (left and right splenius capitis). The results showed that the typing performance, upper extremity angle, neck muscle activity, and usability were significantly different with and without virtual hand representations. With the virtual hand representation, net typing speed (WPM) and usability increased significantly by 171.4% and 25% compared to the without hand representation. Without the virtual hand representation, participants showed increased wrist extension, and decreased right shoulder abduction angles. The variability of the neck rotation was increased while typing without the virtual hand representation. The neck muscle activities were increased with the virtual hand representation. The results suggest that typing with the virtual hand representation could positively affect the typing performance and usability and reduce the risk of the musculoskeletal disorders of the upper extremity. Future study could explore the effect of the virtual hand representation for users with varying levels of typing skills.","sentences":["This study evaluated the effect of virtual hand representation on the typing performance, upper extremity angle, neck muscle activity, and usability during virtual reality (VR) typing.","A total of 15 participants (7 females and 8 males) performed a typing task with and without virtual hand representations.","The optical motion capture data was utilized to capture the upper extremity angles, and electromyography device was used to collect the neck muscle activities (left and right splenius capitis).","The results showed that the typing performance, upper extremity angle, neck muscle activity, and usability were significantly different with and without virtual hand representations.","With the virtual hand representation, net typing speed (WPM) and usability increased significantly by 171.4% and 25% compared to the without hand representation.","Without the virtual hand representation, participants showed increased wrist extension, and decreased right shoulder abduction angles.","The variability of the neck rotation was increased while typing without the virtual hand representation.","The neck muscle activities were increased with the virtual hand representation.","The results suggest that typing with the virtual hand representation could positively affect the typing performance and usability and reduce the risk of the musculoskeletal disorders of the upper extremity.","Future study could explore the effect of the virtual hand representation for users with varying levels of typing skills."],"url":"http://arxiv.org/abs/2401.08018v1"}
{"created":"2024-01-15 23:54:18","title":"Parallel $k$-Core Decomposition with Batched Updates and Asynchronous Reads","abstract":"Maintaining a dynamic $k$-core decomposition is an important problem that identifies dense subgraphs in dynamically changing graphs. Recent work by Liu et al. [SPAA 2022] presents a parallel batch-dynamic algorithm for maintaining an approximate $k$-core decomposition. In their solution, both reads and updates need to be batched, and therefore each type of operation can incur high latency waiting for the other type to finish. To tackle most real-world workloads, which are dominated by reads, this paper presents a novel hybrid concurrent-parallel dynamic $k$-core data structure where asynchronous reads can proceed concurrently with batches of updates, leading to significantly lower read latencies. Our approach is based on tracking causal dependencies between updates, so that causally related groups of updates appear atomic to concurrent readers. Our data structure guarantees linearizability and liveness for both reads and updates, and maintains the same approximation guarantees as prior work. Our experimental evaluation on a 30-core machine shows that our approach reduces read latency by orders of magnitude compared to the batch-dynamic algorithm, up to a $\\left(4.05 \\cdot 10^{5}\\right)$-factor. Compared to an unsynchronized (non-linearizable) baseline, our read latency overhead is only up to a $3.21$-factor greater, while improving accuracy of coreness estimates by up to a factor of $52.7$.","sentences":["Maintaining a dynamic $k$-core decomposition is an important problem that identifies dense subgraphs in dynamically changing graphs.","Recent work by Liu et al.","[SPAA 2022] presents a parallel batch-dynamic algorithm for maintaining an approximate $k$-core decomposition.","In their solution, both reads and updates need to be batched, and therefore each type of operation can incur high latency waiting for the other type to finish.","To tackle most real-world workloads, which are dominated by reads, this paper presents a novel hybrid concurrent-parallel dynamic $k$-core data structure where asynchronous reads can proceed concurrently with batches of updates, leading to significantly lower read latencies.","Our approach is based on tracking causal dependencies between updates, so that causally related groups of updates appear atomic to concurrent readers.","Our data structure guarantees linearizability and liveness for both reads and updates, and maintains the same approximation guarantees as prior work.","Our experimental evaluation on a 30-core machine shows that our approach reduces read latency by orders of magnitude compared to the batch-dynamic algorithm, up to a $\\left(4.05 \\cdot 10^{5}\\right)$-factor.","Compared to an unsynchronized (non-linearizable) baseline, our read latency overhead is only up to a $3.21$-factor greater, while improving accuracy of coreness estimates by up to a factor of $52.7$."],"url":"http://arxiv.org/abs/2401.08015v1"}
{"created":"2024-01-15 23:52:35","title":"Convolutional Neural Network Compression via Dynamic Parameter Rank Pruning","abstract":"While Convolutional Neural Networks (CNNs) excel at learning complex latent-space representations, their over-parameterization can lead to overfitting and reduced performance, particularly with limited data. This, alongside their high computational and memory demands, limits the applicability of CNNs for edge deployment. Low-rank matrix approximation has emerged as a promising approach to reduce CNN parameters, but its application presents challenges including rank selection and performance loss. To address these issues, we propose an efficient training method for CNN compression via dynamic parameter rank pruning. Our approach integrates efficient matrix factorization and novel regularization techniques, forming a robust framework for dynamic rank reduction and model compression. We use Singular Value Decomposition (SVD) to model low-rank convolutional filters and dense weight matrices and we achieve model compression by training the SVD factors with back-propagation in an end-to-end way. We evaluate our method on an array of modern CNNs, including ResNet-18, ResNet-20, and ResNet-32, and datasets like CIFAR-10, CIFAR-100, and ImageNet (2012), showcasing its applicability in computer vision. Our experiments show that the proposed method can yield substantial storage savings while maintaining or even enhancing classification performance.","sentences":["While Convolutional Neural Networks (CNNs) excel at learning complex latent-space representations, their over-parameterization can lead to overfitting and reduced performance, particularly with limited data.","This, alongside their high computational and memory demands, limits the applicability of CNNs for edge deployment.","Low-rank matrix approximation has emerged as a promising approach to reduce CNN parameters, but its application presents challenges including rank selection and performance loss.","To address these issues, we propose an efficient training method for CNN compression via dynamic parameter rank pruning.","Our approach integrates efficient matrix factorization and novel regularization techniques, forming a robust framework for dynamic rank reduction and model compression.","We use Singular Value Decomposition (SVD) to model low-rank convolutional filters and dense weight matrices and we achieve model compression by training the SVD factors with back-propagation in an end-to-end way.","We evaluate our method on an array of modern CNNs, including ResNet-18, ResNet-20, and ResNet-32, and datasets like CIFAR-10, CIFAR-100, and ImageNet (2012), showcasing its applicability in computer vision.","Our experiments show that the proposed method can yield substantial storage savings while maintaining or even enhancing classification performance."],"url":"http://arxiv.org/abs/2401.08014v1"}
{"created":"2024-01-15 23:28:55","title":"Analysing the Needs of Homeless People Using Feature Selection and Mining Association Rules","abstract":"Homelessness is a social and health problem with great repercussions in Europe. Many non-governmental organisations help homeless people by collecting and analysing large amounts of information about them. However, these tasks are not always easy to perform, and hinder other of the organisations duties. The SINTECH project was created to tackle this issue proposing two different tools: a mobile application to quickly and easily collect data; and a software based on artificial intelligence which obtains interesting information from the collected data. The first one has been distributed to some Spanish organisations which are using it to conduct surveys of homeless people. The second tool implements different feature selection and association rules mining methods. These artificial intelligence techniques have allowed us to identify the most relevant features and some interesting association rules from previously collected homeless data.","sentences":["Homelessness is a social and health problem with great repercussions in Europe.","Many non-governmental organisations help homeless people by collecting and analysing large amounts of information about them.","However, these tasks are not always easy to perform, and hinder other of the organisations duties.","The SINTECH project was created to tackle this issue proposing two different tools: a mobile application to quickly and easily collect data; and a software based on artificial intelligence which obtains interesting information from the collected data.","The first one has been distributed to some Spanish organisations which are using it to conduct surveys of homeless people.","The second tool implements different feature selection and association rules mining methods.","These artificial intelligence techniques have allowed us to identify the most relevant features and some interesting association rules from previously collected homeless data."],"url":"http://arxiv.org/abs/2401.08008v1"}
{"created":"2024-01-15 23:10:22","title":"Discovery of Generalizable TBI Phenotypes Using Multivariate Time-Series Clustering","abstract":"Traumatic Brain Injury (TBI) presents a broad spectrum of clinical presentations and outcomes due to its inherent heterogeneity, leading to diverse recovery trajectories and varied therapeutic responses. While many studies have delved into TBI phenotyping for distinct patient populations, identifying TBI phenotypes that consistently generalize across various settings and populations remains a critical research gap. Our research addresses this by employing multivariate time-series clustering to unveil TBI's dynamic intricates. Utilizing a self-supervised learning-based approach to clustering multivariate time-Series data with missing values (SLAC-Time), we analyzed both the research-centric TRACK-TBI and the real-world MIMIC-IV datasets. Remarkably, the optimal hyperparameters of SLAC-Time and the ideal number of clusters remained consistent across these datasets, underscoring SLAC-Time's stability across heterogeneous datasets. Our analysis revealed three generalizable TBI phenotypes ({\\alpha}, \\b{eta}, and {\\gamma}), each exhibiting distinct non-temporal features during emergency department visits, and temporal feature profiles throughout ICU stays. Specifically, phenotype {\\alpha} represents mild TBI with a remarkably consistent clinical presentation. In contrast, phenotype \\b{eta} signifies severe TBI with diverse clinical manifestations, and phenotype {\\gamma} represents a moderate TBI profile in terms of severity and clinical diversity. Age is a significant determinant of TBI outcomes, with older cohorts recording higher mortality rates. Importantly, while certain features varied by age, the core characteristics of TBI manifestations tied to each phenotype remain consistent across diverse populations.","sentences":["Traumatic Brain Injury (TBI) presents a broad spectrum of clinical presentations and outcomes due to its inherent heterogeneity, leading to diverse recovery trajectories and varied therapeutic responses.","While many studies have delved into TBI phenotyping for distinct patient populations, identifying TBI phenotypes that consistently generalize across various settings and populations remains a critical research gap.","Our research addresses this by employing multivariate time-series clustering to unveil TBI's dynamic intricates.","Utilizing a self-supervised learning-based approach to clustering multivariate time-Series data with missing values (SLAC-Time), we analyzed both the research-centric TRACK-TBI and the real-world MIMIC-IV datasets.","Remarkably, the optimal hyperparameters of SLAC-Time and the ideal number of clusters remained consistent across these datasets, underscoring SLAC-Time's stability across heterogeneous datasets.","Our analysis revealed three generalizable TBI phenotypes ({\\alpha}, \\b{eta}, and {\\gamma}), each exhibiting distinct non-temporal features during emergency department visits, and temporal feature profiles throughout ICU stays.","Specifically, phenotype {\\alpha} represents mild TBI with a remarkably consistent clinical presentation.","In contrast, phenotype \\b{eta} signifies severe TBI with diverse clinical manifestations, and phenotype {\\gamma} represents a moderate TBI profile in terms of severity and clinical diversity.","Age is a significant determinant of TBI outcomes, with older cohorts recording higher mortality rates.","Importantly, while certain features varied by age, the core characteristics of TBI manifestations tied to each phenotype remain consistent across diverse populations."],"url":"http://arxiv.org/abs/2401.08002v1"}
{"created":"2024-01-15 22:36:31","title":"A Novel Approach for Automatic Program Repair using Round-Trip Translation with Large Language Models","abstract":"Research shows that grammatical mistakes in a sentence can be corrected by translating it to another language and back using neural machine translation with language models. We investigate whether this correction capability of Large Language Models (LLMs) extends to Automatic Program Repair (APR). Current generative models for APR are pre-trained on source code and fine-tuned for repair. This paper proposes bypassing the fine-tuning step and using Round-Trip Translation (RTT): translation of code from one programming language to another programming or natural language, and back. We hypothesize that RTT with LLMs restores the most commonly seen patterns in code during pre-training, i.e., performs a regression toward the mean, which removes bugs as they are a form of noise w.r.t. the more frequent, natural, bug-free code in the training data. To test this hypothesis, we employ eight recent LLMs pre-trained on code, including the latest GPT versions, and four common program repair benchmarks in Java. We find that RTT with English as an intermediate language repaired 101 of 164 bugs with GPT-4 on the HumanEval-Java dataset. Moreover, 46 of these are unique bugs that are not repaired by other LLMs fine-tuned for APR. Our findings highlight the viability of round-trip translation with LLMs as a technique for automated program repair and its potential for research in software engineering.   Keywords: automated program repair, large language model, machine translation","sentences":["Research shows that grammatical mistakes in a sentence can be corrected by translating it to another language and back using neural machine translation with language models.","We investigate whether this correction capability of Large Language Models (LLMs) extends to Automatic Program Repair (APR).","Current generative models for APR are pre-trained on source code and fine-tuned for repair.","This paper proposes bypassing the fine-tuning step and using Round-Trip Translation (RTT): translation of code from one programming language to another programming or natural language, and back.","We hypothesize that RTT with LLMs restores the most commonly seen patterns in code during pre-training, i.e., performs a regression toward the mean, which removes bugs as they are a form of noise w.r.t.","the more frequent, natural, bug-free code in the training data.","To test this hypothesis, we employ eight recent LLMs pre-trained on code, including the latest GPT versions, and four common program repair benchmarks in Java.","We find that RTT with English as an intermediate language repaired 101 of 164 bugs with GPT-4 on the HumanEval-Java dataset.","Moreover, 46 of these are unique bugs that are not repaired by other LLMs fine-tuned for APR.","Our findings highlight the viability of round-trip translation with LLMs as a technique for automated program repair and its potential for research in software engineering.   ","Keywords: automated program repair, large language model, machine translation"],"url":"http://arxiv.org/abs/2401.07994v1"}
{"created":"2024-01-15 21:43:46","title":"Leveraging External Knowledge Resources to Enable Domain-Specific Comprehension","abstract":"Machine Reading Comprehension (MRC) has been a long-standing problem in NLP and, with the recent introduction of the BERT family of transformer based language models, it has come a long way to getting solved. Unfortunately, however, when BERT variants trained on general text corpora are applied to domain-specific text, their performance inevitably degrades on account of the domain shift i.e. genre/subject matter discrepancy between the training and downstream application data. Knowledge graphs act as reservoirs for either open or closed domain information and prior studies have shown that they can be used to improve the performance of general-purpose transformers in domain-specific applications. Building on existing work, we introduce a method using Multi-Layer Perceptrons (MLPs) for aligning and integrating embeddings extracted from knowledge graphs with the embeddings spaces of pre-trained language models (LMs). We fuse the aligned embeddings with open-domain LMs BERT and RoBERTa, and fine-tune them for two MRC tasks namely span detection (COVID-QA) and multiple-choice questions (PubMedQA). On the COVID-QA dataset, we see that our approach allows these models to perform similar to their domain-specific counterparts, Bio/Sci-BERT, as evidenced by the Exact Match (EM) metric. With regards to PubMedQA, we observe an overall improvement in accuracy while the F1 stays relatively the same over the domain-specific models.","sentences":["Machine Reading Comprehension (MRC) has been a long-standing problem in NLP and, with the recent introduction of the BERT family of transformer based language models, it has come a long way to getting solved.","Unfortunately, however, when BERT variants trained on general text corpora are applied to domain-specific text, their performance inevitably degrades on account of the domain shift i.e. genre/subject matter discrepancy between the training and downstream application data.","Knowledge graphs act as reservoirs for either open or closed domain information and prior studies have shown that they can be used to improve the performance of general-purpose transformers in domain-specific applications.","Building on existing work, we introduce a method using Multi-Layer Perceptrons (MLPs) for aligning and integrating embeddings extracted from knowledge graphs with the embeddings spaces of pre-trained language models (LMs).","We fuse the aligned embeddings with open-domain LMs BERT and RoBERTa, and fine-tune them for two MRC tasks namely span detection (COVID-QA) and multiple-choice questions (PubMedQA).","On the COVID-QA dataset, we see that our approach allows these models to perform similar to their domain-specific counterparts, Bio/Sci-BERT, as evidenced by the Exact Match (EM) metric.","With regards to PubMedQA, we observe an overall improvement in accuracy while the F1 stays relatively the same over the domain-specific models."],"url":"http://arxiv.org/abs/2401.07977v1"}
{"created":"2024-01-15 20:54:20","title":"GD-CAF: Graph Dual-stream Convolutional Attention Fusion for Precipitation Nowcasting","abstract":"Accurate precipitation nowcasting is essential for various purposes, including flood prediction, disaster management, optimizing agricultural activities, managing transportation routes and renewable energy. While several studies have addressed this challenging task from a sequence-to-sequence perspective, most of them have focused on a single area without considering the existing correlation between multiple disjoint regions. In this paper, we formulate precipitation nowcasting as a spatiotemporal graph sequence nowcasting problem. In particular, we introduce Graph Dual-stream Convolutional Attention Fusion (GD-CAF), a novel approach designed to learn from historical spatiotemporal graph of precipitation maps and nowcast future time step ahead precipitation at different spatial locations. GD-CAF consists of spatio-temporal convolutional attention as well as gated fusion modules which are equipped with depthwise-separable convolutional operations. This enhancement enables the model to directly process the high-dimensional spatiotemporal graph of precipitation maps and exploits higher-order correlations between the data dimensions. We evaluate our model on seven years of precipitation maps across Europe and its neighboring areas collected from the ERA5 dataset, provided by Copernicus. The model receives a fully connected graph in which each node represents historical observations from a specific region on the map. Consequently, each node contains a 3D tensor with time, height, and width dimensions. Experimental results demonstrate that the proposed GD-CAF model outperforms the other examined models. Furthermore, the averaged seasonal spatial and temporal attention scores over the test set are visualized to provide additional insights about the strongest connections between different regions or time steps. These visualizations shed light on the decision-making process of our model.","sentences":["Accurate precipitation nowcasting is essential for various purposes, including flood prediction, disaster management, optimizing agricultural activities, managing transportation routes and renewable energy.","While several studies have addressed this challenging task from a sequence-to-sequence perspective, most of them have focused on a single area without considering the existing correlation between multiple disjoint regions.","In this paper, we formulate precipitation nowcasting as a spatiotemporal graph sequence nowcasting problem.","In particular, we introduce Graph Dual-stream Convolutional Attention Fusion (GD-CAF), a novel approach designed to learn from historical spatiotemporal graph of precipitation maps and nowcast future time step ahead precipitation at different spatial locations.","GD-CAF consists of spatio-temporal convolutional attention as well as gated fusion modules which are equipped with depthwise-separable convolutional operations.","This enhancement enables the model to directly process the high-dimensional spatiotemporal graph of precipitation maps and exploits higher-order correlations between the data dimensions.","We evaluate our model on seven years of precipitation maps across Europe and its neighboring areas collected from the ERA5 dataset, provided by Copernicus.","The model receives a fully connected graph in which each node represents historical observations from a specific region on the map.","Consequently, each node contains a 3D tensor with time, height, and width dimensions.","Experimental results demonstrate that the proposed GD-CAF model outperforms the other examined models.","Furthermore, the averaged seasonal spatial and temporal attention scores over the test set are visualized to provide additional insights about the strongest connections between different regions or time steps.","These visualizations shed light on the decision-making process of our model."],"url":"http://arxiv.org/abs/2401.07958v1"}
{"created":"2024-01-15 20:23:05","title":"Image Similarity using An Ensemble of Context-Sensitive Models","abstract":"Image similarity has been extensively studied in computer vision. In recently years, machine-learned models have shown their ability to encode more semantics than traditional multivariate metrics. However, in labelling similarity, assigning a numerical score to a pair of images is less intuitive than determining if an image A is closer to a reference image R than another image B. In this work, we present a novel approach for building an image similarity model based on labelled data in the form of A:R vs B:R. We address the challenges of sparse sampling in the image space (R, A, B) and biases in the models trained with context-based data by using an ensemble model. In particular, we employed two ML techniques to construct such an ensemble model, namely dimensionality reduction and MLP regressors. Our testing results show that the ensemble model constructed performs ~5% better than the best individual context-sensitive models. They also performed better than the model trained with mixed imagery data as well as existing similarity models, e.g., CLIP and DINO. This work demonstrate that context-based labelling and model training can be effective when an appropriate ensemble approach is used to alleviate the limitation due to sparse sampling.","sentences":["Image similarity has been extensively studied in computer vision.","In recently years, machine-learned models have shown their ability to encode more semantics than traditional multivariate metrics.","However, in labelling similarity, assigning a numerical score to a pair of images is less intuitive than determining if an image A is closer to a reference image R than another image B.","In this work, we present a novel approach for building an image similarity model based on labelled data in the form of A:R vs B:R. We address the challenges of sparse sampling in the image space (R, A, B) and biases in the models trained with context-based data by using an ensemble model.","In particular, we employed two ML techniques to construct such an ensemble model, namely dimensionality reduction and MLP regressors.","Our testing results show that the ensemble model constructed performs ~5% better than the best individual context-sensitive models.","They also performed better than the model trained with mixed imagery data as well as existing similarity models, e.g., CLIP and DINO.","This work demonstrate that context-based labelling and model training can be effective when an appropriate ensemble approach is used to alleviate the limitation due to sparse sampling."],"url":"http://arxiv.org/abs/2401.07951v1"}
{"created":"2024-01-15 20:22:21","title":"SciGLM: Training Scientific Language Models with Self-Reflective Instruction Annotation and Tuning","abstract":"\\label{sec:abstract} Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving advanced numerical calculations. To bridge these gaps, we introduce SciGLM, a suite of scientific language models able to conduct college-level scientific reasoning. Central to our approach is a novel self-reflective instruction annotation framework to address the data scarcity challenge in the science domain. This framework leverages existing LLMs to generate step-by-step reasoning for unlabelled scientific questions, followed by a process of self-reflective critic-and-revise. Applying this framework, we curated SciInstruct, a diverse and high-quality dataset encompassing mathematics, physics, chemistry, and formal proofs. We fine-tuned the ChatGLM family of language models with SciInstruct, enhancing their capabilities in scientific and mathematical reasoning. Remarkably, SciGLM consistently improves both the base model (ChatGLM3-6B-Base) and larger-scale models (12B and 32B), without sacrificing the language understanding capabilities of the base model. This makes SciGLM a suitable foundational model to facilitate diverse scientific discovery tasks. For the benefit of the wider research community, we release SciInstruct, SciGLM, alongside a self-reflective framework and fine-tuning code at \\url{https://github.com/THUDM/SciGLM}.","sentences":["\\label{sec:abstract} Large Language Models (LLMs) have shown promise in assisting scientific discovery.","However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving advanced numerical calculations.","To bridge these gaps, we introduce SciGLM, a suite of scientific language models able to conduct college-level scientific reasoning.","Central to our approach is a novel self-reflective instruction annotation framework to address the data scarcity challenge in the science domain.","This framework leverages existing LLMs to generate step-by-step reasoning for unlabelled scientific questions, followed by a process of self-reflective critic-and-revise.","Applying this framework, we curated SciInstruct, a diverse and high-quality dataset encompassing mathematics, physics, chemistry, and formal proofs.","We fine-tuned the ChatGLM family of language models with SciInstruct, enhancing their capabilities in scientific and mathematical reasoning.","Remarkably, SciGLM consistently improves both the base model (ChatGLM3-6B-Base) and larger-scale models (12B and 32B), without sacrificing the language understanding capabilities of the base model.","This makes SciGLM a suitable foundational model to facilitate diverse scientific discovery tasks.","For the benefit of the wider research community, we release SciInstruct, SciGLM, alongside a self-reflective framework and fine-tuning code at \\url{https://github.com/THUDM/SciGLM}."],"url":"http://arxiv.org/abs/2401.07950v1"}
{"created":"2024-01-15 20:17:31","title":"SemEval-2017 Task 4: Sentiment Analysis in Twitter using BERT","abstract":"This paper uses the BERT model, which is a transformer-based architecture, to solve task 4A, English Language, Sentiment Analysis in Twitter of SemEval2017. BERT is a very powerful large language model for classification tasks when the amount of training data is small. For this experiment, we have used the BERT{\\textsubscript{\\tiny BASE}} model, which has 12 hidden layers. This model provides better accuracy, precision, recall, and f1 score than the Naive Bayes baseline model. It performs better in binary classification subtasks than the multi-class classification subtasks. We also considered all kinds of ethical issues during this experiment, as Twitter data contains personal and sensible information. The dataset and code used in our experiment can be found in this GitHub repository.","sentences":["This paper uses the BERT model, which is a transformer-based architecture, to solve task 4A, English Language, Sentiment Analysis in Twitter of SemEval2017.","BERT is a very powerful large language model for classification tasks when the amount of training data is small.","For this experiment, we have used the BERT{\\textsubscript{\\tiny BASE}} model, which has 12 hidden layers.","This model provides better accuracy, precision, recall, and f1 score than the Naive Bayes baseline model.","It performs better in binary classification subtasks than the multi-class classification subtasks.","We also considered all kinds of ethical issues during this experiment, as Twitter data contains personal and sensible information.","The dataset and code used in our experiment can be found in this GitHub repository."],"url":"http://arxiv.org/abs/2401.07944v1"}
{"created":"2024-01-15 19:52:38","title":"6-DoF Grasp Pose Evaluation and Optimization via Transfer Learning from NeRFs","abstract":"We address the problem of robotic grasping of known and unknown objects using implicit behavior cloning. We train a grasp evaluation model from a small number of demonstrations that outputs higher values for grasp candidates that are more likely to succeed in grasping. This evaluation model serves as an objective function, that we maximize to identify successful grasps. Key to our approach is the utilization of learned implicit representations of visual and geometric features derived from a pre-trained NeRF. Though trained exclusively in a simulated environment with simplified objects and 4-DoF top-down grasps, our evaluation model and optimization procedure demonstrate generalization to 6-DoF grasps and novel objects both in simulation and in real-world settings, without the need for additional data. Supplementary material is available at: https://gergely-soti.github.io/grasp","sentences":["We address the problem of robotic grasping of known and unknown objects using implicit behavior cloning.","We train a grasp evaluation model from a small number of demonstrations that outputs higher values for grasp candidates that are more likely to succeed in grasping.","This evaluation model serves as an objective function, that we maximize to identify successful grasps.","Key to our approach is the utilization of learned implicit representations of visual and geometric features derived from a pre-trained NeRF.","Though trained exclusively in a simulated environment with simplified objects and 4-DoF top-down grasps, our evaluation model and optimization procedure demonstrate generalization to 6-DoF grasps and novel objects both in simulation and in real-world settings, without the need for additional data.","Supplementary material is available at: https://gergely-soti.github.io/grasp"],"url":"http://arxiv.org/abs/2401.07935v1"}
{"created":"2024-01-15 19:47:14","title":"Vertical Federated Image Segmentation","abstract":"With the popularization of AI solutions for image based problems, there has been a growing concern for both data privacy and acquisition. In a large number of cases, information is located on separate data silos and it can be difficult for a developer to consolidate all of it in a fashion that is appropriate for machine learning model development. Alongside this, a portion of these localized data regions may not have access to a labelled ground truth. This indicates that they have the capacity to reach conclusions numerically, but are not able to assign classifications amid a lack of pertinent information. Such a determination is often negligible, especially when attempting to develop image based solutions that often necessitate this capability. With this being the case, we propose an innovative vertical federated learning (VFL) model architecture that can operate under this common set of conditions. This is the first (and currently the only) implementation of a system that can work under the constraints of a VFL environment and perform image segmentation while maintaining nominal accuracies. We achieved this by utilizing an FCN that boasts the ability to operate on federates that lack labelled data and privately share the respective weights with a central server, that of which hosts the necessary features for classification. Tests were conducted on the CamVid dataset in order to determine the impact of heavy feature compression required for the transfer of information between federates, as well as to reach nominal conclusions about the overall performance metrics when working under such constraints.","sentences":["With the popularization of AI solutions for image based problems, there has been a growing concern for both data privacy and acquisition.","In a large number of cases, information is located on separate data silos and it can be difficult for a developer to consolidate all of it in a fashion that is appropriate for machine learning model development.","Alongside this, a portion of these localized data regions may not have access to a labelled ground truth.","This indicates that they have the capacity to reach conclusions numerically, but are not able to assign classifications amid a lack of pertinent information.","Such a determination is often negligible, especially when attempting to develop image based solutions that often necessitate this capability.","With this being the case, we propose an innovative vertical federated learning (VFL) model architecture that can operate under this common set of conditions.","This is the first (and currently the only) implementation of a system that can work under the constraints of a VFL environment and perform image segmentation while maintaining nominal accuracies.","We achieved this by utilizing an FCN that boasts the ability to operate on federates that lack labelled data and privately share the respective weights with a central server, that of which hosts the necessary features for classification.","Tests were conducted on the CamVid dataset in order to determine the impact of heavy feature compression required for the transfer of information between federates, as well as to reach nominal conclusions about the overall performance metrics when working under such constraints."],"url":"http://arxiv.org/abs/2401.07931v1"}
{"created":"2024-01-15 19:46:40","title":"On Inter-dataset Code Duplication and Data Leakage in Large Language Models","abstract":"Motivation. Large language models (LLMs) have exhibited remarkable proficiency in diverse software engineering (SE) tasks. Handling such tasks typically involves acquiring foundational coding knowledge on large, general-purpose datasets during a pre-training phase, and subsequently refining on smaller, task-specific datasets as part of a fine-tuning phase.   Problem statement. Data leakage is a well-known issue in training of machine learning models. A manifestation of this issue is the intersection of the training and testing splits. While intra-dataset code duplication examines this intersection within a given dataset and has been addressed in prior research, inter-dataset code duplication, which gauges the overlap between different datasets, remains largely unexplored. If this phenomenon exists, it could compromise the integrity of LLM evaluations because of the inclusion of fine-tuning test samples that were already encountered during pre-training, resulting in inflated performance metrics.   Contribution. This paper explores the phenomenon of inter-dataset code duplication and its impact on evaluating LLMs across diverse SE tasks.   Study design. We conduct an empirical study using the CSN dataset, a widely adopted pre-training dataset, and five fine-tuning datasets used for various SE tasks. We first identify the intersection between the pre-training and fine-tuning datasets using a deduplication process. Then, we fine-tune four models pre-trained on CSN to evaluate their performance on samples encountered during pre-training and those unseen during that phase.   Results. Our findings reveal a potential threat to the evaluation of various LLMs across multiple SE tasks, stemming from the inter-dataset code duplication phenomenon. Moreover, we demonstrate that this threat is accentuated by factors like the LLM's size and the chosen fine-tuning technique.","sentences":["Motivation.","Large language models (LLMs) have exhibited remarkable proficiency in diverse software engineering (SE) tasks.","Handling such tasks typically involves acquiring foundational coding knowledge on large, general-purpose datasets during a pre-training phase, and subsequently refining on smaller, task-specific datasets as part of a fine-tuning phase.   ","Problem statement.","Data leakage is a well-known issue in training of machine learning models.","A manifestation of this issue is the intersection of the training and testing splits.","While intra-dataset code duplication examines this intersection within a given dataset and has been addressed in prior research, inter-dataset code duplication, which gauges the overlap between different datasets, remains largely unexplored.","If this phenomenon exists, it could compromise the integrity of LLM evaluations because of the inclusion of fine-tuning test samples that were already encountered during pre-training, resulting in inflated performance metrics.   Contribution.","This paper explores the phenomenon of inter-dataset code duplication and its impact on evaluating LLMs across diverse SE tasks.   ","Study design.","We conduct an empirical study using the CSN dataset, a widely adopted pre-training dataset, and five fine-tuning datasets used for various SE tasks.","We first identify the intersection between the pre-training and fine-tuning datasets using a deduplication process.","Then, we fine-tune four models pre-trained on CSN to evaluate their performance on samples encountered during pre-training and those unseen during that phase.   ","Results.","Our findings reveal a potential threat to the evaluation of various LLMs across multiple SE tasks, stemming from the inter-dataset code duplication phenomenon.","Moreover, we demonstrate that this threat is accentuated by factors like the LLM's size and the chosen fine-tuning technique."],"url":"http://arxiv.org/abs/2401.07930v1"}
{"created":"2024-01-15 19:07:37","title":"Survey of Learning Approaches for Robotic In-Hand Manipulation","abstract":"Human dexterity is an invaluable capability for precise manipulation of objects in complex tasks. The capability of robots to similarly grasp and perform in-hand manipulation of objects is critical for their use in the ever changing human environment, and for their ability to replace manpower. In recent decades, significant effort has been put in order to enable in-hand manipulation capabilities to robotic systems. Initial robotic manipulators followed carefully programmed paths, while later attempts provided a solution based on analytical modeling of motion and contact. However, these have failed to provide practical solutions due to inability to cope with complex environments and uncertainties. Therefore, the effort has shifted to learning-based approaches where data is collected from the real world or through a simulation, during repeated attempts to complete various tasks. The vast majority of learning approaches focused on learning data-based models that describe the system to some extent or Reinforcement Learning (RL). RL, in particular, has seen growing interest due to the remarkable ability to generate solutions to problems with minimal human guidance. In this survey paper, we track the developments of learning approaches for in-hand manipulations and, explore the challenges and opportunities. This survey is designed both as an introduction for novices in the field with a glossary of terms as well as a guide of novel advances for advanced practitioners.","sentences":["Human dexterity is an invaluable capability for precise manipulation of objects in complex tasks.","The capability of robots to similarly grasp and perform in-hand manipulation of objects is critical for their use in the ever changing human environment, and for their ability to replace manpower.","In recent decades, significant effort has been put in order to enable in-hand manipulation capabilities to robotic systems.","Initial robotic manipulators followed carefully programmed paths, while later attempts provided a solution based on analytical modeling of motion and contact.","However, these have failed to provide practical solutions due to inability to cope with complex environments and uncertainties.","Therefore, the effort has shifted to learning-based approaches where data is collected from the real world or through a simulation, during repeated attempts to complete various tasks.","The vast majority of learning approaches focused on learning data-based models that describe the system to some extent or Reinforcement Learning (RL).","RL, in particular, has seen growing interest due to the remarkable ability to generate solutions to problems with minimal human guidance.","In this survey paper, we track the developments of learning approaches for in-hand manipulations and, explore the challenges and opportunities.","This survey is designed both as an introduction for novices in the field with a glossary of terms as well as a guide of novel advances for advanced practitioners."],"url":"http://arxiv.org/abs/2401.07915v1"}
{"created":"2024-01-15 18:53:15","title":"The Pitfalls of Defining Hallucination","abstract":"Despite impressive advances in Natural Language Generation (NLG) and Large Language Models (LLMs), researchers are still unclear about important aspects of NLG evaluation. To substantiate this claim, I examine current classifications of hallucination and omission in Data-text NLG, and I propose a logic-based synthesis of these classfications. I conclude by highlighting some remaining limitations of all current thinking about hallucination and by discussing implications for LLMs.","sentences":["Despite impressive advances in Natural Language Generation (NLG) and Large Language Models (LLMs), researchers are still unclear about important aspects of NLG evaluation.","To substantiate this claim, I examine current classifications of hallucination and omission in Data-text NLG, and I propose a logic-based synthesis of these classfications.","I conclude by highlighting some remaining limitations of all current thinking about hallucination and by discussing implications for LLMs."],"url":"http://arxiv.org/abs/2401.07897v1"}
{"created":"2024-01-15 18:44:13","title":"Deep Fuzzy Framework for Emotion Recognition using EEG Signals and Emotion Representation in Type-2 Fuzzy VAD Space","abstract":"Recently, the representation of emotions in the Valence, Arousal and Dominance (VAD) space has drawn enough attention. However, the complex nature of emotions and the subjective biases in self-reported values of VAD make the emotion model too specific to a particular experiment. This study aims to develop a generic model representing emotions using a fuzzy VAD space and improve emotion recognition by utilizing this representation. We partitioned the crisp VAD space into a fuzzy VAD space using low, medium and high type-2 fuzzy dimensions to represent emotions. A framework that integrates fuzzy VAD space with EEG data has been developed to recognize emotions. The EEG features were extracted using spatial and temporal feature vectors from time-frequency spectrograms, while the subject-reported values of VAD were also considered. The study was conducted on the DENS dataset, which includes a wide range of twenty-four emotions, along with EEG data and subjective ratings. The study was validated using various deep fuzzy framework models based on type-2 fuzzy representation, cuboid probabilistic lattice representation and unsupervised fuzzy emotion clusters. These models resulted in emotion recognition accuracy of 96.09\\%, 95.75\\% and 95.31\\%, respectively, for the classes of 24 emotions. The study also included an ablation study, one with crisp VAD space and the other without VAD space. The result with crisp VAD space performed better, while the deep fuzzy framework outperformed both models. The model was extended to predict cross-subject cases of emotions, and the results with 78.37\\% accuracy are promising, proving the generality of our model. The generic nature of the developed model, along with its successful cross-subject predictions, gives direction for real-world applications in the areas such as affective computing, human-computer interaction, and mental health monitoring.","sentences":["Recently, the representation of emotions in the Valence, Arousal and Dominance (VAD) space has drawn enough attention.","However, the complex nature of emotions and the subjective biases in self-reported values of VAD make the emotion model too specific to a particular experiment.","This study aims to develop a generic model representing emotions using a fuzzy VAD space and improve emotion recognition by utilizing this representation.","We partitioned the crisp VAD space into a fuzzy VAD space using low, medium and high type-2 fuzzy dimensions to represent emotions.","A framework that integrates fuzzy VAD space with EEG data has been developed to recognize emotions.","The EEG features were extracted using spatial and temporal feature vectors from time-frequency spectrograms, while the subject-reported values of VAD were also considered.","The study was conducted on the DENS dataset, which includes a wide range of twenty-four emotions, along with EEG data and subjective ratings.","The study was validated using various deep fuzzy framework models based on type-2 fuzzy representation, cuboid probabilistic lattice representation and unsupervised fuzzy emotion clusters.","These models resulted in emotion recognition accuracy of 96.09\\%, 95.75\\% and 95.31\\%, respectively, for the classes of 24 emotions.","The study also included an ablation study, one with crisp VAD space and the other without VAD space.","The result with crisp VAD space performed better, while the deep fuzzy framework outperformed both models.","The model was extended to predict cross-subject cases of emotions, and the results with 78.37\\% accuracy are promising, proving the generality of our model.","The generic nature of the developed model, along with its successful cross-subject predictions, gives direction for real-world applications in the areas such as affective computing, human-computer interaction, and mental health monitoring."],"url":"http://arxiv.org/abs/2401.07892v1"}
{"created":"2024-01-15 18:39:13","title":"Machine Learning Techniques to Identify Hand Gestures amidst Forearm Muscle Signals","abstract":"This study investigated the use of forearm EMG data for distinguishing eight hand gestures, employing the Neural Network and Random Forest algorithms on data from ten participants. The Neural Network achieved 97 percent accuracy with 1000-millisecond windows, while the Random Forest achieved 85 percent accuracy with 200-millisecond windows. Larger window sizes improved gesture classification due to increased temporal resolution. The Random Forest exhibited faster processing at 92 milliseconds, compared to the Neural Network's 124 milliseconds. In conclusion, the study identified a Neural Network with a 1000-millisecond stream as the most accurate (97 percent), and a Random Forest with a 200-millisecond stream as the most efficient (85 percent). Future research should focus on increasing sample size, incorporating more hand gestures, and exploring different feature extraction methods and modeling algorithms to enhance system accuracy and efficiency.","sentences":["This study investigated the use of forearm EMG data for distinguishing eight hand gestures, employing the Neural Network and Random Forest algorithms on data from ten participants.","The Neural Network achieved 97 percent accuracy with 1000-millisecond windows, while the Random Forest achieved 85 percent accuracy with 200-millisecond windows.","Larger window sizes improved gesture classification due to increased temporal resolution.","The Random Forest exhibited faster processing at 92 milliseconds, compared to the Neural Network's 124 milliseconds.","In conclusion, the study identified a Neural Network with a 1000-millisecond stream as the most accurate (97 percent), and a Random Forest with a 200-millisecond stream as the most efficient (85 percent).","Future research should focus on increasing sample size, incorporating more hand gestures, and exploring different feature extraction methods and modeling algorithms to enhance system accuracy and efficiency."],"url":"http://arxiv.org/abs/2401.07889v1"}
{"created":"2024-01-15 18:25:18","title":"The Chronicles of RAG: The Retriever, the Chunk and the Generator","abstract":"Retrieval Augmented Generation (RAG) has become one of the most popular paradigms for enabling LLMs to access external data, and also as a mechanism for grounding to mitigate against hallucinations. When implementing RAG you can face several challenges like effective integration of retrieval models, efficient representation learning, data diversity, computational efficiency optimization, evaluation, and quality of text generation. Given all these challenges, every day a new technique to improve RAG appears, making it unfeasible to experiment with all combinations for your problem. In this context, this paper presents good practices to implement, optimize, and evaluate RAG for the Brazilian Portuguese language, focusing on the establishment of a simple pipeline for inference and experiments. We explored a diverse set of methods to answer questions about the first Harry Potter book. To generate the answers we used the OpenAI's gpt-4, gpt-4-1106-preview, gpt-3.5-turbo-1106, and Google's Gemini Pro. Focusing on the quality of the retriever, our approach achieved an improvement of MRR@10 by 35.4% compared to the baseline. When optimizing the input size in the application, we observed that it is possible to further enhance it by 2.4%. Finally, we present the complete architecture of the RAG with our recommendations. As result, we moved from a baseline of 57.88% to a maximum relative score of 98.61%.","sentences":["Retrieval Augmented Generation (RAG) has become one of the most popular paradigms for enabling LLMs to access external data, and also as a mechanism for grounding to mitigate against hallucinations.","When implementing RAG you can face several challenges like effective integration of retrieval models, efficient representation learning, data diversity, computational efficiency optimization, evaluation, and quality of text generation.","Given all these challenges, every day a new technique to improve RAG appears, making it unfeasible to experiment with all combinations for your problem.","In this context, this paper presents good practices to implement, optimize, and evaluate RAG for the Brazilian Portuguese language, focusing on the establishment of a simple pipeline for inference and experiments.","We explored a diverse set of methods to answer questions about the first Harry Potter book.","To generate the answers we used the OpenAI's gpt-4, gpt-4-1106-preview, gpt-3.5-turbo-1106, and Google's Gemini Pro.","Focusing on the quality of the retriever, our approach achieved an improvement of MRR@10 by 35.4% compared to the baseline.","When optimizing the input size in the application, we observed that it is possible to further enhance it by 2.4%.","Finally, we present the complete architecture of the RAG with our recommendations.","As result, we moved from a baseline of 57.88% to a maximum relative score of 98.61%."],"url":"http://arxiv.org/abs/2401.07883v1"}
{"created":"2024-01-15 18:12:01","title":"EMBRE: Entity-aware Masking for Biomedical Relation Extraction","abstract":"Information extraction techniques, including named entity recognition (NER) and relation extraction (RE), are crucial in many domains to support making sense of vast amounts of unstructured text data by identifying and connecting relevant information. Such techniques can assist researchers in extracting valuable insights. In this paper, we introduce the Entity-aware Masking for Biomedical Relation Extraction (EMBRE) method for biomedical relation extraction, as applied in the context of the BioRED challenge Task 1, in which human-annotated entities are provided as input. Specifically, we integrate entity knowledge into a deep neural network by pretraining the backbone model with an entity masking objective. We randomly mask named entities for each instance and let the model identify the masked entity along with its type. In this way, the model is capable of learning more specific knowledge and more robust representations. Then, we utilize the pre-trained model as our backbone to encode language representations and feed these representations into two multilayer perceptron (MLPs) to predict the logits for relation and novelty, respectively. The experimental results demonstrate that our proposed method can improve the performances of entity pair, relation and novelty extraction over our baseline.","sentences":["Information extraction techniques, including named entity recognition (NER) and relation extraction (RE), are crucial in many domains to support making sense of vast amounts of unstructured text data by identifying and connecting relevant information.","Such techniques can assist researchers in extracting valuable insights.","In this paper, we introduce the Entity-aware Masking for Biomedical Relation Extraction (EMBRE) method for biomedical relation extraction, as applied in the context of the BioRED challenge Task 1, in which human-annotated entities are provided as input.","Specifically, we integrate entity knowledge into a deep neural network by pretraining the backbone model with an entity masking objective.","We randomly mask named entities for each instance and let the model identify the masked entity along with its type.","In this way, the model is capable of learning more specific knowledge and more robust representations.","Then, we utilize the pre-trained model as our backbone to encode language representations and feed these representations into two multilayer perceptron (MLPs) to predict the logits for relation and novelty, respectively.","The experimental results demonstrate that our proposed method can improve the performances of entity pair, relation and novelty extraction over our baseline."],"url":"http://arxiv.org/abs/2401.07877v1"}
{"created":"2024-01-15 17:57:41","title":"Authorship Obfuscation in Multilingual Machine-Generated Text Detection","abstract":"High-quality text generation capability of latest Large Language Models (LLMs) causes concerns about their misuse (e.g., in massive generation/spread of disinformation). Machine-generated text (MGT) detection is important to cope with such threats. However, it is susceptible to authorship obfuscation (AO) methods, such as paraphrasing, which can cause MGTs to evade detection. So far, this was evaluated only in monolingual settings. Thus, the susceptibility of recently proposed multilingual detectors is still unknown. We fill this gap by comprehensively benchmarking the performance of 10 well-known AO methods, attacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10 $\\times$ 37 $\\times$ 11 = 4,070 combinations). We also evaluate the effect of data augmentation on adversarial robustness using obfuscated texts. The results indicate that all tested AO methods can cause detection evasion in all tested languages, where homoglyph attacks are especially successful.","sentences":["High-quality text generation capability of latest Large Language Models (LLMs) causes concerns about their misuse (e.g., in massive generation/spread of disinformation).","Machine-generated text (MGT) detection is important to cope with such threats.","However, it is susceptible to authorship obfuscation (AO) methods, such as paraphrasing, which can cause MGTs to evade detection.","So far, this was evaluated only in monolingual settings.","Thus, the susceptibility of recently proposed multilingual detectors is still unknown.","We fill this gap by comprehensively benchmarking the performance of 10 well-known AO methods, attacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10 $\\times$ 37 $\\times$ 11 = 4,070 combinations).","We also evaluate the effect of data augmentation on adversarial robustness using obfuscated texts.","The results indicate that all tested AO methods can cause detection evasion in all tested languages, where homoglyph attacks are especially successful."],"url":"http://arxiv.org/abs/2401.07867v1"}
{"created":"2024-01-15 17:28:58","title":"$M^{2}$Fusion: Bayesian-based Multimodal Multi-level Fusion on Colorectal Cancer Microsatellite Instability Prediction","abstract":"Colorectal cancer (CRC) micro-satellite instability (MSI) prediction on histopathology images is a challenging weakly supervised learning task that involves multi-instance learning on gigapixel images. To date, radiology images have proven to have CRC MSI information and efficient patient imaging techniques. Different data modalities integration offers the opportunity to increase the accuracy and robustness of MSI prediction. Despite the progress in representation learning from the whole slide images (WSI) and exploring the potential of making use of radiology data, CRC MSI prediction remains a challenge to fuse the information from multiple data modalities (e.g., pathology WSI and radiology CT image). In this paper, we propose $M^{2}$Fusion: a Bayesian-based multimodal multi-level fusion pipeline for CRC MSI. The proposed fusion model $M^{2}$Fusion is capable of discovering more novel patterns within and across modalities that are beneficial for predicting MSI than using a single modality alone, as well as other fusion methods. The contribution of the paper is three-fold: (1) $M^{2}$Fusion is the first pipeline of multi-level fusion on pathology WSI and 3D radiology CT image for MSI prediction; (2) CT images are the first time integrated into multimodal fusion for CRC MSI prediction; (3) feature-level fusion strategy is evaluated on both Transformer-based and CNN-based method. Our approach is validated on cross-validation of 352 cases and outperforms either feature-level (0.8177 vs. 0.7908) or decision-level fusion strategy (0.8177 vs. 0.7289) on AUC score.","sentences":["Colorectal cancer (CRC) micro-satellite instability (MSI) prediction on histopathology images is a challenging weakly supervised learning task that involves multi-instance learning on gigapixel images.","To date, radiology images have proven to have CRC MSI information and efficient patient imaging techniques.","Different data modalities integration offers the opportunity to increase the accuracy and robustness of MSI prediction.","Despite the progress in representation learning from the whole slide images (WSI) and exploring the potential of making use of radiology data, CRC MSI prediction remains a challenge to fuse the information from multiple data modalities (e.g., pathology WSI and radiology CT image).","In this paper, we propose $M^{2}$Fusion: a Bayesian-based multimodal multi-level fusion pipeline for CRC MSI.","The proposed fusion model $M^{2}$Fusion is capable of discovering more novel patterns within and across modalities that are beneficial for predicting MSI than using a single modality alone, as well as other fusion methods.","The contribution of the paper is three-fold: (1) $M^{2}$Fusion is the first pipeline of multi-level fusion on pathology WSI and 3D radiology CT image for MSI prediction; (2) CT images are the first time integrated into multimodal fusion for CRC MSI prediction; (3) feature-level fusion strategy is evaluated on both Transformer-based and CNN-based method.","Our approach is validated on cross-validation of 352 cases and outperforms either feature-level (0.8177 vs. 0.7908) or decision-level fusion strategy (0.8177 vs. 0.7289) on AUC score."],"url":"http://arxiv.org/abs/2401.07854v1"}
{"created":"2024-01-15 17:28:37","title":"VeCAF: VLM-empowered Collaborative Active Finetuning with Training Objective Awareness","abstract":"Finetuning a pretrained vision model (PVM) is a common technique for learning downstream vision tasks. The conventional finetuning process with the randomly sampled data points results in diminished training efficiency. To address this drawback, we propose a novel approach, VLM-empowered Collaborative Active Finetuning (VeCAF). VeCAF optimizes a parametric data selection model by incorporating the training objective of the model being tuned. Effectively, this guides the PVM towards the performance goal with improved data and computational efficiency. As vision-language models (VLMs) have achieved significant advancements by establishing a robust connection between image and language domains, we exploit the inherent semantic richness of the text embedding space and utilize text embedding of pretrained VLM models to augment PVM image features for better data selection and finetuning. Furthermore, the flexibility of text-domain augmentation gives VeCAF a unique ability to handle out-of-distribution scenarios without external augmented data. Extensive experiments show the leading performance and high efficiency of VeCAF that is superior to baselines in both in-distribution and out-of-distribution image classification tasks. On ImageNet, VeCAF needs up to 3.3x less training batches to reach the target performance compared to full finetuning and achieves 2.8% accuracy improvement over SOTA methods with the same number of batches.","sentences":["Finetuning a pretrained vision model (PVM) is a common technique for learning downstream vision tasks.","The conventional finetuning process with the randomly sampled data points results in diminished training efficiency.","To address this drawback, we propose a novel approach, VLM-empowered Collaborative Active Finetuning (VeCAF).","VeCAF optimizes a parametric data selection model by incorporating the training objective of the model being tuned.","Effectively, this guides the PVM towards the performance goal with improved data and computational efficiency.","As vision-language models (VLMs) have achieved significant advancements by establishing a robust connection between image and language domains, we exploit the inherent semantic richness of the text embedding space and utilize text embedding of pretrained VLM models to augment PVM image features for better data selection and finetuning.","Furthermore, the flexibility of text-domain augmentation gives VeCAF a unique ability to handle out-of-distribution scenarios without external augmented data.","Extensive experiments show the leading performance and high efficiency of VeCAF that is superior to baselines in both in-distribution and out-of-distribution image classification tasks.","On ImageNet, VeCAF needs up to 3.3x less training batches to reach the target performance compared to full finetuning and achieves 2.8% accuracy improvement over SOTA methods with the same number of batches."],"url":"http://arxiv.org/abs/2401.07853v1"}
{"created":"2024-01-15 16:53:20","title":"Phenotyping calcification in vascular tissues using artificial intelligence","abstract":"Vascular calcification is implicated as an important factor in major adverse cardiovascular events (MACE), including heart attack and stroke. A controversy remains over how to integrate the diverse forms of vascular calcification into clinical risk assessment tools. Even the commonly used calcium score for coronary arteries, which assumes risk scales positively with total calcification, has important inconsistencies. Fundamental studies are needed to determine how risk is influenced by the diverse calcification phenotypes. However, studies of these kinds are hindered by the lack of high-throughput, objective, and non-destructive tools for classifying calcification in imaging data sets. Here, we introduce a new classification system for phenotyping calcification along with a semi-automated, non-destructive pipeline that can distinguish these phenotypes in even atherosclerotic tissues. The pipeline includes a deep-learning-based framework for segmenting lipid pools in noisy micro-CT images and an unsupervised clustering framework for categorizing calcification based on size, clustering, and topology. This approach is illustrated for five vascular specimens, providing phenotyping for thousands of calcification particles across as many as 3200 images in less than seven hours. Average Dice Similarity Coefficients of 0.96 and 0.87 could be achieved for tissue and lipid pool, respectively, with training and validation needed on only 13 images despite the high heterogeneity in these tissues. By introducing an efficient and comprehensive approach to phenotyping calcification, this work enables large-scale studies to identify a more reliable indicator of the risk of cardiovascular events, a leading cause of global mortality and morbidity.","sentences":["Vascular calcification is implicated as an important factor in major adverse cardiovascular events (MACE), including heart attack and stroke.","A controversy remains over how to integrate the diverse forms of vascular calcification into clinical risk assessment tools.","Even the commonly used calcium score for coronary arteries, which assumes risk scales positively with total calcification, has important inconsistencies.","Fundamental studies are needed to determine how risk is influenced by the diverse calcification phenotypes.","However, studies of these kinds are hindered by the lack of high-throughput, objective, and non-destructive tools for classifying calcification in imaging data sets.","Here, we introduce a new classification system for phenotyping calcification along with a semi-automated, non-destructive pipeline that can distinguish these phenotypes in even atherosclerotic tissues.","The pipeline includes a deep-learning-based framework for segmenting lipid pools in noisy micro-CT images and an unsupervised clustering framework for categorizing calcification based on size, clustering, and topology.","This approach is illustrated for five vascular specimens, providing phenotyping for thousands of calcification particles across as many as 3200 images in less than seven hours.","Average Dice Similarity Coefficients of 0.96 and 0.87 could be achieved for tissue and lipid pool, respectively, with training and validation needed on only 13 images despite the high heterogeneity in these tissues.","By introducing an efficient and comprehensive approach to phenotyping calcification, this work enables large-scale studies to identify a more reliable indicator of the risk of cardiovascular events, a leading cause of global mortality and morbidity."],"url":"http://arxiv.org/abs/2401.07825v1"}
{"created":"2024-01-15 16:39:10","title":"Question Translation Training for Better Multilingual Reasoning","abstract":"Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English. This is unsurprising given that their training data largely consists of English text and instructions. A typical solution is to translate instruction data into all languages of interest, and then train on the resulting multilingual data, which is called translate-training. This approach not only incurs high cost, but also results in poorly translated data due to the non-standard formatting of chain-of-thought and mathematical reasoning instructions. In this paper, we explore the benefits of question alignment, where we train the model to translate reasoning questions into English by finetuning on X-English question data. In this way we perform targetted, in-domain language alignment which makes best use of English instruction data to unlock the LLMs' multilingual reasoning abilities. Experimental results on LLaMA2-13B show that question alignment leads to consistent improvements over the translate-training approach: an average improvement of 11.3\\% and 16.1\\% accuracy across ten languages on the MGSM and MSVAMP maths reasoning benchmarks (The project will be available at: https://github.com/NJUNLP/QAlign).","sentences":["Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English.","This is unsurprising given that their training data largely consists of English text and instructions.","A typical solution is to translate instruction data into all languages of interest, and then train on the resulting multilingual data, which is called translate-training.","This approach not only incurs high cost, but also results in poorly translated data due to the non-standard formatting of chain-of-thought and","mathematical reasoning instructions",".","In this paper, we explore the benefits of question alignment, where we train the model to translate reasoning questions into English by finetuning on X-English question data.","In this way we perform targetted, in-domain language alignment which makes best use of English instruction data to unlock the LLMs' multilingual reasoning abilities.","Experimental results on LLaMA2-13B show that question alignment leads to consistent improvements over the translate-training approach: an average improvement of 11.3\\% and 16.1\\% accuracy across ten languages on the MGSM and MSVAMP maths reasoning benchmarks (The project will be available at: https://github.com/NJUNLP/QAlign)."],"url":"http://arxiv.org/abs/2401.07817v1"}
{"created":"2024-01-15 16:35:52","title":"Wikidata as a seed for Web Extraction","abstract":"Wikidata has grown to a knowledge graph with an impressive size. To date, it contains more than 17 billion triples collecting information about people, places, films, stars, publications, proteins, and many more. On the other side, most of the information on the Web is not published in highly structured data repositories like Wikidata, but rather as unstructured and semi-structured content, more concretely in HTML pages containing text and tables. Finding, monitoring, and organizing this data in a knowledge graph is requiring considerable work from human editors. The volume and complexity of the data make this task difficult and time-consuming. In this work, we present a framework that is able to identify and extract new facts that are published under multiple Web domains so that they can be proposed for validation by Wikidata editors. The framework is relying on question-answering technologies. We take inspiration from ideas that are used to extract facts from textual collections and adapt them to extract facts from Web pages. For achieving this, we demonstrate that language models can be adapted to extract facts not only from textual collections but also from Web pages. By exploiting the information already contained in Wikidata the proposed framework can be trained without the need for any additional learning signals and can extract new facts for a wide range of properties and domains. Following this path, Wikidata can be used as a seed to extract facts on the Web. Our experiments show that we can achieve a mean performance of 84.07 at F1-score. Moreover, our estimations show that we can potentially extract millions of facts that can be proposed for human validation. The goal is to help editors in their daily tasks and contribute to the completion of the Wikidata knowledge graph.","sentences":["Wikidata has grown to a knowledge graph with an impressive size.","To date, it contains more than 17 billion triples collecting information about people, places, films, stars, publications, proteins, and many more.","On the other side, most of the information on the Web is not published in highly structured data repositories like Wikidata, but rather as unstructured and semi-structured content, more concretely in HTML pages containing text and tables.","Finding, monitoring, and organizing this data in a knowledge graph is requiring considerable work from human editors.","The volume and complexity of the data make this task difficult and time-consuming.","In this work, we present a framework that is able to identify and extract new facts that are published under multiple Web domains so that they can be proposed for validation by Wikidata editors.","The framework is relying on question-answering technologies.","We take inspiration from ideas that are used to extract facts from textual collections and adapt them to extract facts from Web pages.","For achieving this, we demonstrate that language models can be adapted to extract facts not only from textual collections but also from Web pages.","By exploiting the information already contained in Wikidata the proposed framework can be trained without the need for any additional learning signals and can extract new facts for a wide range of properties and domains.","Following this path, Wikidata can be used as a seed to extract facts on the Web.","Our experiments show that we can achieve a mean performance of 84.07 at F1-score.","Moreover, our estimations show that we can potentially extract millions of facts that can be proposed for human validation.","The goal is to help editors in their daily tasks and contribute to the completion of the Wikidata knowledge graph."],"url":"http://arxiv.org/abs/2401.07812v1"}
{"created":"2024-01-15 16:21:19","title":"Uncovering the Full Potential of Visual Grounding Methods in VQA","abstract":"Visual Grounding (VG) methods in Visual Question Answering (VQA) attempt to improve VQA performance by strengthening a model's reliance on question-relevant visual information. The presence of such relevant information in the visual input is typically assumed in training and testing. This assumption, however, is inherently flawed when dealing with imperfect image representations common in large-scale VQA, where the information carried by visual features frequently deviates from expected ground-truth contents. As a result, training and testing of VG-methods is performed with largely inaccurate data, which obstructs proper assessment of their potential benefits.   In this work, we demonstrate that current evaluation schemes for VG-methods are problematic due to the flawed assumption of availability of relevant visual information. Our experiments show that the potential benefits of these methods are severely underestimated as a result.","sentences":["Visual Grounding (VG) methods in Visual Question Answering (VQA) attempt to improve VQA performance by strengthening a model's reliance on question-relevant visual information.","The presence of such relevant information in the visual input is typically assumed in training and testing.","This assumption, however, is inherently flawed when dealing with imperfect image representations common in large-scale VQA, where the information carried by visual features frequently deviates from expected ground-truth contents.","As a result, training and testing of VG-methods is performed with largely inaccurate data, which obstructs proper assessment of their potential benefits.   ","In this work, we demonstrate that current evaluation schemes for VG-methods are problematic due to the flawed assumption of availability of relevant visual information.","Our experiments show that the potential benefits of these methods are severely underestimated as a result."],"url":"http://arxiv.org/abs/2401.07803v1"}
{"created":"2024-01-15 16:04:46","title":"Fusing Echocardiography Images and Medical Records for Continuous Patient Stratification","abstract":"Deep learning now enables automatic and robust extraction of cardiac function descriptors from echocardiographic sequences, such as ejection fraction or strain. These descriptors provide fine-grained information that physicians consider, in conjunction with more global variables from the clinical record, to assess patients' condition. Drawing on novel transformer models applied to tabular data (e.g., variables from electronic health records), we propose a method that considers all descriptors extracted from medical records and echocardiograms to learn the representation of a difficult-to-characterize cardiovascular pathology, namely hypertension. Our method first projects each variable into its own representation space using modality-specific approaches. These standardized representations of multimodal data are then fed to a transformer encoder, which learns to merge them into a comprehensive representation of the patient through a pretext task of predicting a clinical rating. This pretext task is formulated as an ordinal classification to enforce a pathological continuum in the representation space. We observe the major trends along this continuum for a cohort of 239 hypertensive patients to describe, with unprecedented gradation, the effect of hypertension on a number of cardiac function descriptors. Our analysis shows that i) pretrained weights from a foundation model allow to reach good performance (83% accuracy) even with limited data (less than 200 training samples), ii) trends across the population are reproducible between trainings, and iii) for descriptors whose interactions with hypertension are well documented, patterns are consistent with prior physiological knowledge.","sentences":["Deep learning now enables automatic and robust extraction of cardiac function descriptors from echocardiographic sequences, such as ejection fraction or strain.","These descriptors provide fine-grained information that physicians consider, in conjunction with more global variables from the clinical record, to assess patients' condition.","Drawing on novel transformer models applied to tabular data (e.g., variables from electronic health records), we propose a method that considers all descriptors extracted from medical records and echocardiograms to learn the representation of a difficult-to-characterize cardiovascular pathology, namely hypertension.","Our method first projects each variable into its own representation space using modality-specific approaches.","These standardized representations of multimodal data are then fed to a transformer encoder, which learns to merge them into a comprehensive representation of the patient through a pretext task of predicting a clinical rating.","This pretext task is formulated as an ordinal classification to enforce a pathological continuum in the representation space.","We observe the major trends along this continuum for a cohort of 239 hypertensive patients to describe, with unprecedented gradation, the effect of hypertension on a number of cardiac function descriptors.","Our analysis shows that i) pretrained weights from a foundation model allow to reach good performance (83% accuracy) even with limited data (less than 200 training samples), ii) trends across the population are reproducible between trainings, and iii) for descriptors whose interactions with hypertension are well documented, patterns are consistent with prior physiological knowledge."],"url":"http://arxiv.org/abs/2401.07796v1"}
{"created":"2024-01-15 15:53:13","title":"Improving OCR Quality in 19th Century Historical Documents Using a Combined Machine Learning Based Approach","abstract":"This paper addresses a major challenge to historical research on the 19th century. Large quantities of sources have become digitally available for the first time, while extraction techniques are lagging behind. Therefore, we researched machine learning (ML) models to recognise and extract complex data structures in a high-value historical primary source, the Schematismus. It records every single person in the Habsburg civil service above a certain hierarchical level between 1702 and 1918 and documents the genesis of the central administration over two centuries. Its complex and intricate structure as well as its enormous size have so far made any more comprehensive analysis of the administrative and social structure of the later Habsburg Empire on the basis of this source impossible. We pursued two central objectives: Primarily, the improvement of the OCR quality, for which we considered an improved structure recognition to be essential; in the further course, it turned out that this also made the extraction of the data structure possible. We chose Faster R-CNN as base for the ML architecture for structure recognition. In order to obtain the required amount of training data quickly and economically, we synthesised Hof- und Staatsschematismus-style data, which we used to train our model. The model was then fine-tuned with a smaller set of manually annotated historical source data. We then used Tesseract-OCR, which was further optimised for the style of our documents, to complete the combined structure extraction and OCR process. Results show a significant decrease in the two standard parameters of OCR-performance, WER and CER (where lower values are better). Combined structure detection and fine-tuned OCR improved CER and WER values by remarkable 71.98 percent (CER) respectively 52.49 percent (WER).","sentences":["This paper addresses a major challenge to historical research on the 19th century.","Large quantities of sources have become digitally available for the first time, while extraction techniques are lagging behind.","Therefore, we researched machine learning (ML) models to recognise and extract complex data structures in a high-value historical primary source, the Schematismus.","It records every single person in the Habsburg civil service above a certain hierarchical level between 1702 and 1918 and documents the genesis of the central administration over two centuries.","Its complex and intricate structure as well as its enormous size have so far made any more comprehensive analysis of the administrative and social structure of the later Habsburg Empire on the basis of this source impossible.","We pursued two central objectives: Primarily, the improvement of the OCR quality, for which we considered an improved structure recognition to be essential; in the further course, it turned out that this also made the extraction of the data structure possible.","We chose Faster R-CNN as base for the ML architecture for structure recognition.","In order to obtain the required amount of training data quickly and economically, we synthesised Hof- und Staatsschematismus-style data, which we used to train our model.","The model was then fine-tuned with a smaller set of manually annotated historical source data.","We then used Tesseract-OCR, which was further optimised for the style of our documents, to complete the combined structure extraction and OCR process.","Results show a significant decrease in the two standard parameters of OCR-performance, WER and CER (where lower values are better).","Combined structure detection and fine-tuned OCR improved CER and WER values by remarkable 71.98 percent (CER) respectively 52.49 percent (WER)."],"url":"http://arxiv.org/abs/2401.07787v1"}
{"created":"2024-01-15 15:28:30","title":"Seeing the Unseen: Visual Common Sense for Semantic Placement","abstract":"Computer vision tasks typically involve describing what is present in an image (e.g. classification, detection, segmentation, and captioning). We study a visual common sense task that requires understanding what is not present. Specifically, given an image (e.g. of a living room) and name of an object (\"cushion\"), a vision system is asked to predict semantically-meaningful regions (masks or bounding boxes) in the image where that object could be placed or is likely be placed by humans (e.g. on the sofa). We call this task: Semantic Placement (SP) and believe that such common-sense visual understanding is critical for assitive robots (tidying a house), and AR devices (automatically rendering an object in the user's space). Studying the invisible is hard. Datasets for image description are typically constructed by curating relevant images and asking humans to annotate the contents of the image; neither of those two steps are straightforward for objects not present in the image. We overcome this challenge by operating in the opposite direction: we start with an image of an object in context from web, and then remove that object from the image via inpainting. This automated pipeline converts unstructured web data into a dataset comprising pairs of images with/without the object. Using this, we collect a novel dataset, with ${\\sim}1.3$M images across $9$ object categories, and train a SP prediction model called CLIP-UNet. CLIP-UNet outperforms existing VLMs and baselines that combine semantic priors with object detectors on real-world and simulated images. In our user studies, we find that the SP masks predicted by CLIP-UNet are favored $43.7\\%$ and $31.3\\%$ times when comparing against the $4$ SP baselines on real and simulated images. In addition, we demonstrate leveraging SP mask predictions from CLIP-UNet enables downstream applications like building tidying robots in indoor environments.","sentences":["Computer vision tasks typically involve describing what is present in an image (e.g. classification, detection, segmentation, and captioning).","We study a visual common sense task that requires understanding what is not present.","Specifically, given an image (e.g. of a living room) and name of an object (\"cushion\"), a vision system is asked to predict semantically-meaningful regions (masks or bounding boxes) in the image where that object could be placed or is likely be placed by humans (e.g. on the sofa).","We call this task: Semantic Placement (SP) and believe that such common-sense visual understanding is critical for assitive robots (tidying a house), and AR devices (automatically rendering an object in the user's space).","Studying the invisible is hard.","Datasets for image description are typically constructed by curating relevant images and asking humans to annotate the contents of the image; neither of those two steps are straightforward for objects not present in the image.","We overcome this challenge by operating in the opposite direction: we start with an image of an object in context from web, and then remove that object from the image via inpainting.","This automated pipeline converts unstructured web data into a dataset comprising pairs of images with/without the object.","Using this, we collect a novel dataset, with ${\\sim}1.3$M images across $9$ object categories, and train a SP prediction model called CLIP-UNet.","CLIP-UNet outperforms existing VLMs and baselines that combine semantic priors with object detectors on real-world and simulated images.","In our user studies, we find that the SP masks predicted by CLIP-UNet are favored $43.7\\%$ and $31.3\\%$ times when comparing against the $4$ SP baselines on real and simulated images.","In addition, we demonstrate leveraging SP mask predictions from CLIP-UNet enables downstream applications like building tidying robots in indoor environments."],"url":"http://arxiv.org/abs/2401.07770v1"}
{"created":"2024-01-15 15:27:24","title":"Deep Evolutional Instant Interest Network for CTR Prediction in Trigger-Induced Recommendation","abstract":"The recommendation has been playing a key role in many industries, e.g., e-commerce, streaming media, social media, etc. Recently, a new recommendation scenario, called Trigger-Induced Recommendation (TIR), where users are able to explicitly express their instant interests via trigger items, is emerging as an essential role in many e-commerce platforms, e.g., Alibaba.com and Amazon. Without explicitly modeling the user's instant interest, traditional recommendation methods usually obtain sub-optimal results in TIR. Even though there are a few methods considering the trigger and target items simultaneously to solve this problem, they still haven't taken into account temporal information of user behaviors, the dynamic change of user instant interest when the user scrolls down and the interactions between the trigger and target items. To tackle these problems, we propose a novel method -- Deep Evolutional Instant Interest Network (DEI2N), for click-through rate prediction in TIR scenarios. Specifically, we design a User Instant Interest Modeling Layer to predict the dynamic change of the intensity of instant interest when the user scrolls down. Temporal information is utilized in user behavior modeling. Moreover, an Interaction Layer is introduced to learn better interactions between the trigger and target items. We evaluate our method on several offline and real-world industrial datasets. Experimental results show that our proposed DEI2N outperforms state-of-the-art baselines. In addition, online A/B testing demonstrates the superiority over the existing baseline in real-world production environments.","sentences":["The recommendation has been playing a key role in many industries, e.g., e-commerce, streaming media, social media, etc.","Recently, a new recommendation scenario, called Trigger-Induced Recommendation (TIR), where users are able to explicitly express their instant interests via trigger items, is emerging as an essential role in many e-commerce platforms, e.g., Alibaba.com and Amazon.","Without explicitly modeling the user's instant interest, traditional recommendation methods usually obtain sub-optimal results in TIR.","Even though there are a few methods considering the trigger and target items simultaneously to solve this problem, they still haven't taken into account temporal information of user behaviors, the dynamic change of user instant interest when the user scrolls down and the interactions between the trigger and target items.","To tackle these problems, we propose a novel method -- Deep Evolutional Instant Interest Network (DEI2N), for click-through rate prediction in TIR scenarios.","Specifically, we design a User Instant Interest Modeling Layer to predict the dynamic change of the intensity of instant interest when the user scrolls down.","Temporal information is utilized in user behavior modeling.","Moreover, an Interaction Layer is introduced to learn better interactions between the trigger and target items.","We evaluate our method on several offline and real-world industrial datasets.","Experimental results show that our proposed DEI2N outperforms state-of-the-art baselines.","In addition, online A/B testing demonstrates the superiority over the existing baseline in real-world production environments."],"url":"http://arxiv.org/abs/2401.07769v1"}
{"created":"2024-01-15 15:14:17","title":"Stable Matchings in Practice: A Constraint Programming Approach","abstract":"We study a practical two-sided matching problem of allocating children to daycare centers, which has significant social implications. We are cooperating with several municipalities in Japan and our goal is to devise a reliable and trustworthy clearing algorithm to deal with the problem. In this paper, we describe the design of our new algorithm that minimizes the number of unmatched children while ensuring stability. We evaluate our algorithm using real-life data sets, and experimental results demonstrate that our algorithm surpasses the commercial software that currently dominates the market in terms of both the number of matched children and the number of blocking coalitions (measuring stability). Our findings have been reported to local governments, and some are considering adopting our proposed algorithm in the near future, instead of the existing solution. Moreover, our model and algorithm have broader applicability to other important matching markets, such as hospital-doctor matching with couples and school choice with siblings.","sentences":["We study a practical two-sided matching problem of allocating children to daycare centers, which has significant social implications.","We are cooperating with several municipalities in Japan and our goal is to devise a reliable and trustworthy clearing algorithm to deal with the problem.","In this paper, we describe the design of our new algorithm that minimizes the number of unmatched children while ensuring stability.","We evaluate our algorithm using real-life data sets, and experimental results demonstrate that our algorithm surpasses the commercial software that currently dominates the market in terms of both the number of matched children and the number of blocking coalitions (measuring stability).","Our findings have been reported to local governments, and some are considering adopting our proposed algorithm in the near future, instead of the existing solution.","Moreover, our model and algorithm have broader applicability to other important matching markets, such as hospital-doctor matching with couples and school choice with siblings."],"url":"http://arxiv.org/abs/2401.07761v1"}
{"created":"2024-01-15 15:11:15","title":"On the importance of Data Scale in Pretraining Arabic Language Models","abstract":"Pretraining monolingual language models have been proven to be vital for performance in Arabic Natural Language Processing (NLP) tasks. In this paper, we conduct a comprehensive study on the role of data in Arabic Pretrained Language Models (PLMs). More precisely, we reassess the performance of a suite of state-of-the-art Arabic PLMs by retraining them on massive-scale, high-quality Arabic corpora. We have significantly improved the performance of the leading Arabic encoder-only BERT-base and encoder-decoder T5-base models on the ALUE and ORCA leaderboards, thereby reporting state-of-the-art results in their respective model categories. In addition, our analysis strongly suggests that pretraining data by far is the primary contributor to performance, surpassing other factors. Our models and source code are publicly available at https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/JABER-PyTorch.","sentences":["Pretraining monolingual language models have been proven to be vital for performance in Arabic Natural Language Processing (NLP) tasks.","In this paper, we conduct a comprehensive study on the role of data in Arabic Pretrained Language Models (PLMs).","More precisely, we reassess the performance of a suite of state-of-the-art Arabic PLMs by retraining them on massive-scale, high-quality Arabic corpora.","We have significantly improved the performance of the leading Arabic encoder-only BERT-base and encoder-decoder T5-base models on the ALUE and ORCA leaderboards, thereby reporting state-of-the-art results in their respective model categories.","In addition, our analysis strongly suggests that pretraining data by far is the primary contributor to performance, surpassing other factors.","Our models and source code are publicly available at https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/JABER-PyTorch."],"url":"http://arxiv.org/abs/2401.07760v1"}
{"created":"2024-01-15 14:56:15","title":"MaskClustering: View Consensus based Mask Graph Clustering for Open-Vocabulary 3D Instance Segmentation","abstract":"Open-vocabulary 3D instance segmentation has emerged as a frontier topic due to its capability to segment 3D instances beyond a predefined set of categories. However, compared to significant progress in the 2D domain, methods for 3D open-vocabulary instance segmentation are hindered by the limited scale of high-quality annotated 3D data. To harness the capabilities of 2D models, recent efforts have focused on merging 2D masks based on metrics such as geometric and semantic similarity to form 3D instances. In contrast to these local metrics, we propose a novel metric called view consensus to better exploit multi-view observation. The key insight is that two 2D masks should be considered as belonging to the same instance if a considerable number of other 2D masks from other views contain both these two masks. Based on this metric, we build a global mask graph and iteratively cluster masks, prioritizing mask pairs with solid view consensus. The corresponding 3D points cluster of these 2D mask clusters can be regarded as 3D instances, along with the fused open-vocabulary features from clustered 2D masks. Through this multi-view verification and fusion mechanism, our method effectively leverages the prior instance knowledge from massive 2D masks predicted by visual foundation models, eliminating the need for training on 3D data. Experiments on publicly available datasets, including ScanNet200 and MatterPort3D, demonstrate that our method achieves state-of-the-art performance in both open-vocabulary instance segmentation and class-agnostic mask generation. Our project page is at https://pku-epic.github.io/MaskClustering.","sentences":["Open-vocabulary 3D instance segmentation has emerged as a frontier topic due to its capability to segment 3D instances beyond a predefined set of categories.","However, compared to significant progress in the 2D domain, methods for 3D open-vocabulary instance segmentation are hindered by the limited scale of high-quality annotated 3D data.","To harness the capabilities of 2D models, recent efforts have focused on merging 2D masks based on metrics such as geometric and semantic similarity to form 3D instances.","In contrast to these local metrics, we propose a novel metric called view consensus to better exploit multi-view observation.","The key insight is that two 2D masks should be considered as belonging to the same instance if a considerable number of other 2D masks from other views contain both these two masks.","Based on this metric, we build a global mask graph and iteratively cluster masks, prioritizing mask pairs with solid view consensus.","The corresponding 3D points cluster of these 2D mask clusters can be regarded as 3D instances, along with the fused open-vocabulary features from clustered 2D masks.","Through this multi-view verification and fusion mechanism, our method effectively leverages the prior instance knowledge from massive 2D masks predicted by visual foundation models, eliminating the need for training on 3D data.","Experiments on publicly available datasets, including ScanNet200 and MatterPort3D, demonstrate that our method achieves state-of-the-art performance in both open-vocabulary instance segmentation and class-agnostic mask generation.","Our project page is at https://pku-epic.github.io/MaskClustering."],"url":"http://arxiv.org/abs/2401.07745v1"}
{"created":"2024-01-15 14:56:04","title":"Combining Machine Learning and Ontology: A Systematic Literature Review","abstract":"Motivated by the desire to explore the process of combining inductive and deductive reasoning, we conducted a systematic literature review of articles that investigate the integration of machine learning and ontologies. The objective was to identify diverse techniques that incorporate both inductive reasoning (performed by machine learning) and deductive reasoning (performed by ontologies) into artificial intelligence systems. Our review, which included the analysis of 128 studies, allowed us to identify three main categories of hybridization between machine learning and ontologies: learning-enhanced ontologies, semantic data mining, and learning and reasoning systems. We provide a comprehensive examination of all these categories, emphasizing the various machine learning algorithms utilized in the studies. Furthermore, we compared our classification with similar recent work in the field of hybrid AI and neuro-symbolic approaches.","sentences":["Motivated by the desire to explore the process of combining inductive and deductive reasoning, we conducted a systematic literature review of articles that investigate the integration of machine learning and ontologies.","The objective was to identify diverse techniques that incorporate both inductive reasoning (performed by machine learning) and deductive reasoning (performed by ontologies) into artificial intelligence systems.","Our review, which included the analysis of 128 studies, allowed us to identify three main categories of hybridization between machine learning and ontologies: learning-enhanced ontologies, semantic data mining, and learning and reasoning systems.","We provide a comprehensive examination of all these categories, emphasizing the various machine learning algorithms utilized in the studies.","Furthermore, we compared our classification with similar recent work in the field of hybrid AI and neuro-symbolic approaches."],"url":"http://arxiv.org/abs/2401.07744v1"}
{"created":"2024-01-15 14:43:40","title":"SSL-Interactions: Pretext Tasks for Interactive Trajectory Prediction","abstract":"This paper addresses motion forecasting in multi-agent environments, pivotal for ensuring safety of autonomous vehicles. Traditional as well as recent data-driven marginal trajectory prediction methods struggle to properly learn non-linear agent-to-agent interactions. We present SSL-Interactions that proposes pretext tasks to enhance interaction modeling for trajectory prediction. We introduce four interaction-aware pretext tasks to encapsulate various aspects of agent interactions: range gap prediction, closest distance prediction, direction of movement prediction, and type of interaction prediction. We further propose an approach to curate interaction-heavy scenarios from datasets. This curated data has two advantages: it provides a stronger learning signal to the interaction model, and facilitates generation of pseudo-labels for interaction-centric pretext tasks. We also propose three new metrics specifically designed to evaluate predictions in interactive scenes. Our empirical evaluations indicate SSL-Interactions outperforms state-of-the-art motion forecasting methods quantitatively with up to 8% improvement, and qualitatively, for interaction-heavy scenarios.","sentences":["This paper addresses motion forecasting in multi-agent environments, pivotal for ensuring safety of autonomous vehicles.","Traditional as well as recent data-driven marginal trajectory prediction methods struggle to properly learn non-linear agent-to-agent interactions.","We present SSL-Interactions that proposes pretext tasks to enhance interaction modeling for trajectory prediction.","We introduce four interaction-aware pretext tasks to encapsulate various aspects of agent interactions: range gap prediction, closest distance prediction, direction of movement prediction, and type of interaction prediction.","We further propose an approach to curate interaction-heavy scenarios from datasets.","This curated data has two advantages: it provides a stronger learning signal to the interaction model, and facilitates generation of pseudo-labels for interaction-centric pretext tasks.","We also propose three new metrics specifically designed to evaluate predictions in interactive scenes.","Our empirical evaluations indicate SSL-Interactions outperforms state-of-the-art motion forecasting methods quantitatively with up to 8% improvement, and qualitatively, for interaction-heavy scenarios."],"url":"http://arxiv.org/abs/2401.07729v1"}
{"created":"2024-01-15 14:41:15","title":"HexaGen3D: StableDiffusion is just one step away from Fast and Diverse Text-to-3D Generation","abstract":"Despite the latest remarkable advances in generative modeling, efficient generation of high-quality 3D assets from textual prompts remains a difficult task. A key challenge lies in data scarcity: the most extensive 3D datasets encompass merely millions of assets, while their 2D counterparts contain billions of text-image pairs. To address this, we propose a novel approach which harnesses the power of large, pretrained 2D diffusion models. More specifically, our approach, HexaGen3D, fine-tunes a pretrained text-to-image model to jointly predict 6 orthographic projections and the corresponding latent triplane. We then decode these latents to generate a textured mesh. HexaGen3D does not require per-sample optimization, and can infer high-quality and diverse objects from textual prompts in 7 seconds, offering significantly better quality-to-latency trade-offs when comparing to existing approaches. Furthermore, HexaGen3D demonstrates strong generalization to new objects or compositions.","sentences":["Despite the latest remarkable advances in generative modeling, efficient generation of high-quality 3D assets from textual prompts remains a difficult task.","A key challenge lies in data scarcity: the most extensive 3D datasets encompass merely millions of assets, while their 2D counterparts contain billions of text-image pairs.","To address this, we propose a novel approach which harnesses the power of large, pretrained 2D diffusion models.","More specifically, our approach, HexaGen3D, fine-tunes a pretrained text-to-image model to jointly predict 6 orthographic projections and the corresponding latent triplane.","We then decode these latents to generate a textured mesh.","HexaGen3D does not require per-sample optimization, and can infer high-quality and diverse objects from textual prompts in 7 seconds, offering significantly better quality-to-latency trade-offs when comparing to existing approaches.","Furthermore, HexaGen3D demonstrates strong generalization to new objects or compositions."],"url":"http://arxiv.org/abs/2401.07727v1"}
{"created":"2024-01-15 14:35:39","title":"How Social Media Big Data Can Improve Suicide Prevention","abstract":"In the light of increasing clues on social media impact on self-harm and suicide risks, there is still no evidence on who are and how factually engaged in suicide-related online behaviors. This study reports new findings of high-performance supercomputing investigation of publicly accessible big data sourced from one of the world-largest social networking site. Three-month supercomputer searching resulted in 570,156 young adult users who consumed suicide-related information on social media. Most of them were 21-24 year olds with higher share of females (58%) of predominantly younger age. Every eight user was alarmingly engrossed with up to 15 suicide-related online groups. Evidently, suicide groups on social media are highly underrated public health issue that might weaken the prevention efforts. Suicide prevention strategies that target social media users must be implemented extensively. While major gap in functional understanding of technologies relevance for use in public mental health still exists, current findings act for better understanding digital technologies utility for translational advance and offer relevant evidence-based framework for improving suicide prevention in general population.","sentences":["In the light of increasing clues on social media impact on self-harm and suicide risks, there is still no evidence on who are and how factually engaged in suicide-related online behaviors.","This study reports new findings of high-performance supercomputing investigation of publicly accessible big data sourced from one of the world-largest social networking site.","Three-month supercomputer searching resulted in 570,156 young adult users who consumed suicide-related information on social media.","Most of them were 21-24 year olds with higher share of females (58%) of predominantly younger age.","Every eight user was alarmingly engrossed with up to 15 suicide-related online groups.","Evidently, suicide groups on social media are highly underrated public health issue that might weaken the prevention efforts.","Suicide prevention strategies that target social media users must be implemented extensively.","While major gap in functional understanding of technologies relevance for use in public mental health still exists, current findings act for better understanding digital technologies utility for translational advance and offer relevant evidence-based framework for improving suicide prevention in general population."],"url":"http://arxiv.org/abs/2401.07718v1"}
{"created":"2024-01-15 14:27:03","title":"Efficient Nonparametric Tensor Decomposition for Binary and Count Data","abstract":"In numerous applications, binary reactions or event counts are observed and stored within high-order tensors. Tensor decompositions (TDs) serve as a powerful tool to handle such high-dimensional and sparse data. However, many traditional TDs are explicitly or implicitly designed based on the Gaussian distribution, which is unsuitable for discrete data. Moreover, most TDs rely on predefined multi-linear structures, such as CP and Tucker formats. Therefore, they may not be effective enough to handle complex real-world datasets. To address these issues, we propose ENTED, an \\underline{E}fficient \\underline{N}onparametric \\underline{TE}nsor \\underline{D}ecomposition for binary and count tensors. Specifically, we first employ a nonparametric Gaussian process (GP) to replace traditional multi-linear structures. Next, we utilize the \\pg augmentation which provides a unified framework to establish conjugate models for binary and count distributions. Finally, to address the computational issue of GPs, we enhance the model by incorporating sparse orthogonal variational inference of inducing points, which offers a more effective covariance approximation within GPs and stochastic natural gradient updates for nonparametric models. We evaluate our model on several real-world tensor completion tasks, considering binary and count datasets. The results manifest both better performance and computational advantages of the proposed model.","sentences":["In numerous applications, binary reactions or event counts are observed and stored within high-order tensors.","Tensor decompositions (TDs) serve as a powerful tool to handle such high-dimensional and sparse data.","However, many traditional TDs are explicitly or implicitly designed based on the Gaussian distribution, which is unsuitable for discrete data.","Moreover, most TDs rely on predefined multi-linear structures, such as CP and Tucker formats.","Therefore, they may not be effective enough to handle complex real-world datasets.","To address these issues, we propose ENTED, an \\underline{E}fficient \\underline{N}onparametric \\underline{TE}nsor \\underline{D}ecomposition for binary and count tensors.","Specifically, we first employ a nonparametric Gaussian process (GP) to replace traditional multi-linear structures.","Next, we utilize the \\pg augmentation which provides a unified framework to establish conjugate models for binary and count distributions.","Finally, to address the computational issue of GPs, we enhance the model by incorporating sparse orthogonal variational inference of inducing points, which offers a more effective covariance approximation within GPs and stochastic natural gradient updates for nonparametric models.","We evaluate our model on several real-world tensor completion tasks, considering binary and count datasets.","The results manifest both better performance and computational advantages of the proposed model."],"url":"http://arxiv.org/abs/2401.07711v1"}
{"created":"2024-01-15 14:15:30","title":"Online Learning of Piecewise Polynomial Signed Distance Fields for Manipulation Tasks","abstract":"Reasoning about distance is indispensable for establishing or avoiding contact in manipulation tasks. To this end, we present an online method for learning implicit representations of signed distance using piecewise polynomial basis functions. Starting from an arbitrary prior shape, our approach incrementally constructs a continuous representation from incoming point cloud data. It offers fast access to distance and analytical gradients without the need to store training data. We assess the accuracy of our model on a diverse set of household objects and compare it to neural network and Gaussian process counterparts. Distance reconstruction and real-time updates are further evaluated in a physical experiment by simultaneously collecting sparse point cloud data and using the evolving model to control a manipulator.","sentences":["Reasoning about distance is indispensable for establishing or avoiding contact in manipulation tasks.","To this end, we present an online method for learning implicit representations of signed distance using piecewise polynomial basis functions.","Starting from an arbitrary prior shape, our approach incrementally constructs a continuous representation from incoming point cloud data.","It offers fast access to distance and analytical gradients without the need to store training data.","We assess the accuracy of our model on a diverse set of household objects and compare it to neural network and Gaussian process counterparts.","Distance reconstruction and real-time updates are further evaluated in a physical experiment by simultaneously collecting sparse point cloud data and using the evolving model to control a manipulator."],"url":"http://arxiv.org/abs/2401.07698v1"}
{"created":"2024-01-15 14:14:16","title":"Data vs. Model Machine Learning Fairness Testing: An Empirical Study","abstract":"Although several fairness definitions and bias mitigation techniques exist in the literature, all existing solutions evaluate fairness of Machine Learning (ML) systems after the training stage. In this paper, we take the first steps towards evaluating a more holistic approach by testing for fairness both before and after model training. We evaluate the effectiveness of the proposed approach and position it within the ML development lifecycle, using an empirical analysis of the relationship between model dependent and independent fairness metrics. The study uses 2 fairness metrics, 4 ML algorithms, 5 real-world datasets and 1600 fairness evaluation cycles. We find a linear relationship between data and model fairness metrics when the distribution and the size of the training data changes. Our results indicate that testing for fairness prior to training can be a ``cheap'' and effective means of catching a biased data collection process early; detecting data drifts in production systems and minimising execution of full training cycles thus reducing development time and costs.","sentences":["Although several fairness definitions and bias mitigation techniques exist in the literature, all existing solutions evaluate fairness of Machine Learning (ML) systems after the training stage.","In this paper, we take the first steps towards evaluating a more holistic approach by testing for fairness both before and after model training.","We evaluate the effectiveness of the proposed approach and position it within the ML development lifecycle, using an empirical analysis of the relationship between model dependent and independent fairness metrics.","The study uses 2 fairness metrics, 4 ML algorithms, 5 real-world datasets and 1600 fairness evaluation cycles.","We find a linear relationship between data and model fairness metrics when the distribution and the size of the training data changes.","Our results indicate that testing for fairness prior to training can be a ``cheap'' and effective means of catching a biased data collection process early; detecting data drifts in production systems and minimising execution of full training cycles thus reducing development time and costs."],"url":"http://arxiv.org/abs/2401.07697v1"}
{"created":"2024-01-15 14:11:59","title":"Towards Automatic Translation of Machine Learning Visual Insights to Analytical Assertions","abstract":"We present our vision for developing an automated tool capable of translating visual properties observed in Machine Learning (ML) visualisations into Python assertions. The tool aims to streamline the process of manually verifying these visualisations in the ML development cycle, which is critical as real-world data and assumptions often change post-deployment. In a prior study, we mined $54,070$ Jupyter notebooks from Github and created a catalogue of $269$ semantically related visualisation-assertion (VA) pairs. Building on this catalogue, we propose to build a taxonomy that organises the VA pairs based on ML verification tasks. The input feature space comprises of a rich source of information mined from the Jupyter notebooks -- visualisations, Python source code, and associated markdown text. The effectiveness of various AI models, including traditional NLP4Code models and modern Large Language Models, will be compared using established machine translation metrics and evaluated through a qualitative study with human participants. The paper also plans to address the challenge of extending the existing VA pair dataset with additional pairs from Kaggle and to compare the tool's effectiveness with commercial generative AI models like ChatGPT. This research not only contributes to the field of ML system validation but also explores novel ways to leverage AI for automating and enhancing software engineering practices in ML.","sentences":["We present our vision for developing an automated tool capable of translating visual properties observed in Machine Learning (ML) visualisations into Python assertions.","The tool aims to streamline the process of manually verifying these visualisations in the ML development cycle, which is critical as real-world data and assumptions often change post-deployment.","In a prior study, we mined $54,070$ Jupyter notebooks from Github and created a catalogue of $269$ semantically related visualisation-assertion (VA) pairs.","Building on this catalogue, we propose to build a taxonomy that organises the VA pairs based on ML verification tasks.","The input feature space comprises of a rich source of information mined from the Jupyter notebooks -- visualisations, Python source code, and associated markdown text.","The effectiveness of various AI models, including traditional NLP4Code models and modern Large Language Models, will be compared using established machine translation metrics and evaluated through a qualitative study with human participants.","The paper also plans to address the challenge of extending the existing VA pair dataset with additional pairs from Kaggle and to compare the tool's effectiveness with commercial generative AI models like ChatGPT.","This research not only contributes to the field of ML system validation but also explores novel ways to leverage AI for automating and enhancing software engineering practices in ML."],"url":"http://arxiv.org/abs/2401.07696v1"}
{"created":"2024-01-15 13:59:51","title":"Privacy-Aware Single-Nucleotide Polymorphisms (SNPs) using Bilinear Group Accumulators in Batch Mode","abstract":"Biometric data is often highly sensitive, and a leak of this data can lead to serious privacy breaches. Some of the most sensitive of this type of data relates to the usage of DNA data on individuals. A leak of this type of data without consent could lead to privacy breaches of data protection laws. Along with this, there have been several recent data breaches related to the leak of DNA information, including from 23andMe and Ancestry. It is thus fundamental that a citizen should have the right to know if their DNA data is contained within a DNA database and ask for it to be removed if they are concerned about its usage. This paper outlines a method of hashing the core information contained within the data stores - known as Single-Nucleotide Polymorphisms (SNPs) - into a bilinear group accumulator in batch mode, which can then be searched by a trusted entity for matches. The time to create the witness proof and to verify were measured at 0.86 ms and 10.90 ms, respectively.","sentences":["Biometric data is often highly sensitive, and a leak of this data can lead to serious privacy breaches.","Some of the most sensitive of this type of data relates to the usage of DNA data on individuals.","A leak of this type of data without consent could lead to privacy breaches of data protection laws.","Along with this, there have been several recent data breaches related to the leak of DNA information, including from 23andMe and Ancestry.","It is thus fundamental that a citizen should have the right to know if their DNA data is contained within a DNA database and ask for it to be removed if they are concerned about its usage.","This paper outlines a method of hashing the core information contained within the data stores - known as Single-Nucleotide Polymorphisms (SNPs) - into a bilinear group accumulator in batch mode, which can then be searched by a trusted entity for matches.","The time to create the witness proof and to verify were measured at 0.86 ms and 10.90 ms, respectively."],"url":"http://arxiv.org/abs/2401.07691v1"}
{"created":"2024-01-15 13:48:58","title":"Cash and Card Acceptance in Retail Payments: Motivations and Factors","abstract":"The landscape of payment methods in retail is a complex and evolving area. Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options. Many factors are included in this decision process, some qualitative and some quantitative. The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors. We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments. The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible. However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process. We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs. However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency. Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented. This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021. We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference.","sentences":["The landscape of payment methods in retail is a complex and evolving area.","Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options.","Many factors are included in this decision process, some qualitative and some quantitative.","The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors.","We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments.","The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible.","However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process.","We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs.","However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency.","Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented.","This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021.","We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference."],"url":"http://arxiv.org/abs/2401.07682v1"}
{"created":"2024-01-15 13:46:07","title":"Quantitative Information Flow Control by Construction for Component-Based Systems","abstract":"Secure software architecture is increasingly important in a data-driven world. When security is neglected sensitive information might leak through unauthorized access. To mitigate this software architects needs tools and methods to quantify security risks in complex systems. This paper presents doctoral research in its early stages concerned with creating constructive methods for building secure component-based systems from a quantitative information flow specification. This research aim at developing a method that allows software architects to develop secure systems from a repository of secure components. Planned contributions are refinement rules for secure development of components from a specification and well-formedness rules for secure composition of said components.","sentences":["Secure software architecture is increasingly important in a data-driven world.","When security is neglected sensitive information might leak through unauthorized access.","To mitigate this software architects needs tools and methods to quantify security risks in complex systems.","This paper presents doctoral research in its early stages concerned with creating constructive methods for building secure component-based systems from a quantitative information flow specification.","This research aim at developing a method that allows software architects to develop secure systems from a repository of secure components.","Planned contributions are refinement rules for secure development of components from a specification and well-formedness rules for secure composition of said components."],"url":"http://arxiv.org/abs/2401.07677v1"}
{"created":"2024-01-15 13:35:21","title":"CLSA-CIM: A Cross-Layer Scheduling Approach for Computing-in-Memory Architectures","abstract":"The demand for efficient machine learning (ML) accelerators is growing rapidly, driving the development of novel computing concepts such as resistive random access memory (RRAM)-based tiled computing-in-memory (CIM) architectures. CIM allows to compute within the memory unit, resulting in faster data processing and reduced power consumption. Efficient compiler algorithms are essential to exploit the potential of tiled CIM architectures. While conventional ML compilers focus on code generation for CPUs, GPUs, and other von Neumann architectures, adaptations are needed to cover CIM architectures. Cross-layer scheduling is a promising approach, as it enhances the utilization of CIM cores, thereby accelerating computations. Although similar concepts are implicitly used in previous work, there is a lack of clear and quantifiable algorithmic definitions for cross-layer scheduling for tiled CIM architectures. To close this gap, we present CLSA-CIM, a cross-layer scheduling algorithm for tiled CIM architectures. We integrate CLSA-CIM with existing weight-mapping strategies and compare performance against state-of-the-art (SOTA) scheduling algorithms. CLSA-CIM improves the utilization by up to 17.9 x , resulting in an overall speedup increase of up to 29.2 x compared to SOTA.","sentences":["The demand for efficient machine learning (ML) accelerators is growing rapidly, driving the development of novel computing concepts such as resistive random access memory (RRAM)-based tiled computing-in-memory (CIM) architectures.","CIM allows to compute within the memory unit, resulting in faster data processing and reduced power consumption.","Efficient compiler algorithms are essential to exploit the potential of tiled CIM architectures.","While conventional ML compilers focus on code generation for CPUs, GPUs, and other von Neumann architectures, adaptations are needed to cover CIM architectures.","Cross-layer scheduling is a promising approach, as it enhances the utilization of CIM cores, thereby accelerating computations.","Although similar concepts are implicitly used in previous work, there is a lack of clear and quantifiable algorithmic definitions for cross-layer scheduling for tiled CIM architectures.","To close this gap, we present CLSA-CIM, a cross-layer scheduling algorithm for tiled CIM architectures.","We integrate CLSA-CIM with existing weight-mapping strategies and compare performance against state-of-the-art (SOTA) scheduling algorithms.","CLSA-CIM improves the utilization by up to 17.9 x , resulting in an overall speedup increase of up to 29.2 x compared to SOTA."],"url":"http://arxiv.org/abs/2401.07671v1"}
{"created":"2024-01-15 12:37:28","title":"Multi-Objective Optimization in STAR-RIS-Aided SWIPT with RSMA via Meta-Learning","abstract":"Simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) is a cutting-edge concept for the sixth-generation (6G) wireless networks. In this letter, we propose a novel system that incorporates STAR-RIS with simultaneous wireless information and power transfer (SWIPT) using rate splitting multiple access (RSMA). The proposed system facilitates communication from a multi-antenna base station (BS) to single-antenna users in a downlink transmission. The BS concurrently sends energy and information signals to multiple energy harvesting receivers (EHRs) and information data receivers (IDRs) with the support of a deployed STAR-RIS. Furthermore, a multi-objective optimization is introduced to strike a balance between users' sum rate and the total harvested energy. To achieve this, an optimization problem is formulated to optimize the energy/information beamforming vectors at the BS, the phase shifts at the STAR-RIS, and the common message rate. Subsequently, we employ a meta deep deterministic policy gradient (Meta-DDPG) approach to solve the complex problem. Simulation results validate that the proposed algorithm significantly enhances both data rate and harvested energy in comparison to conventional DDPG.","sentences":["Simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) is a cutting-edge concept for the sixth-generation (6G) wireless networks.","In this letter, we propose a novel system that incorporates STAR-RIS with simultaneous wireless information and power transfer (SWIPT) using rate splitting multiple access (RSMA).","The proposed system facilitates communication from a multi-antenna base station (BS) to single-antenna users in a downlink transmission.","The BS concurrently sends energy and information signals to multiple energy harvesting receivers (EHRs) and information data receivers (IDRs) with the support of a deployed STAR-RIS.","Furthermore, a multi-objective optimization is introduced to strike a balance between users' sum rate and the total harvested energy.","To achieve this, an optimization problem is formulated to optimize the energy/information beamforming vectors at the BS, the phase shifts at the STAR-RIS, and the common message rate.","Subsequently, we employ a meta deep deterministic policy gradient (Meta-DDPG) approach to solve the complex problem.","Simulation results validate that the proposed algorithm significantly enhances both data rate and harvested energy in comparison to conventional DDPG."],"url":"http://arxiv.org/abs/2401.07644v1"}
{"created":"2024-01-15 12:32:30","title":"Directed Ear Anonymity","abstract":"We define and study a new structural parameter for directed graphs, which we call \\emph{ear anonymity}. Our parameter aims to generalize the useful properties of \\emph{funnels} to larger digraph classes. In particular, funnels are exactly the acyclic digraphs with ear anonymity one. We prove that computing the ear anonymity of a digraph is \\NP/-hard and that it can be solved in $O(m(n + m))$-time on acyclic digraphs (where \\(n\\) is the number of vertices and \\(m\\) is the number of arcs in the input digraph). It remains open where exactly in the polynomial hierarchy the problem of computing ear anonymity lies, however for a related problem we manage to show $\\Sigma_2^p$-completeness.","sentences":["We define and study a new structural parameter for directed graphs, which we call \\emph{ear anonymity}.","Our parameter aims to generalize the useful properties of \\emph{funnels} to larger digraph classes.","In particular, funnels are exactly the acyclic digraphs with ear anonymity one.","We prove that computing the ear anonymity of a digraph is \\NP/-hard and that it can be solved in $O(m(n + m))$-time on acyclic digraphs (where \\(n\\) is the number of vertices and \\(m\\) is the number of arcs in the input digraph).","It remains open where exactly in the polynomial hierarchy the problem of computing ear anonymity lies, however for a related problem we manage to show $\\Sigma_2^p$-completeness."],"url":"http://arxiv.org/abs/2401.07640v1"}
{"created":"2024-01-15 12:32:07","title":"Compute-Efficient Active Learning","abstract":"Active learning, a powerful paradigm in machine learning, aims at reducing labeling costs by selecting the most informative samples from an unlabeled dataset. However, the traditional active learning process often demands extensive computational resources, hindering scalability and efficiency. In this paper, we address this critical issue by presenting a novel method designed to alleviate the computational burden associated with active learning on massive datasets. To achieve this goal, we introduce a simple, yet effective method-agnostic framework that outlines how to strategically choose and annotate data points, optimizing the process for efficiency while maintaining model performance. Through case studies, we demonstrate the effectiveness of our proposed method in reducing computational costs while maintaining or, in some cases, even surpassing baseline model outcomes. Code is available at https://github.com/aimotive/Compute-Efficient-Active-Learning.","sentences":["Active learning, a powerful paradigm in machine learning, aims at reducing labeling costs by selecting the most informative samples from an unlabeled dataset.","However, the traditional active learning process often demands extensive computational resources, hindering scalability and efficiency.","In this paper, we address this critical issue by presenting a novel method designed to alleviate the computational burden associated with active learning on massive datasets.","To achieve this goal, we introduce a simple, yet effective method-agnostic framework that outlines how to strategically choose and annotate data points, optimizing the process for efficiency while maintaining model performance.","Through case studies, we demonstrate the effectiveness of our proposed method in reducing computational costs while maintaining or, in some cases, even surpassing baseline model outcomes.","Code is available at https://github.com/aimotive/Compute-Efficient-Active-Learning."],"url":"http://arxiv.org/abs/2401.07639v1"}
{"created":"2024-01-15 11:20:34","title":"Multi-task robot data for dual-arm fine manipulation","abstract":"In the field of robotic manipulation, deep imitation learning is recognized as a promising approach for acquiring manipulation skills. Additionally, learning from diverse robot datasets is considered a viable method to achieve versatility and adaptability. In such research, by learning various tasks, robots achieved generality across multiple objects. However, such multi-task robot datasets have mainly focused on single-arm tasks that are relatively imprecise, not addressing the fine-grained object manipulation that robots are expected to perform in the real world. This paper introduces a dataset of diverse object manipulations that includes dual-arm tasks and/or tasks requiring fine manipulation. To this end, we have generated dataset with 224k episodes (150 hours, 1,104 language instructions) which includes dual-arm fine tasks such as bowl-moving, pencil-case opening or banana-peeling, and this data is publicly available. Additionally, this dataset includes visual attention signals as well as dual-action labels, a signal that separates actions into a robust reaching trajectory and precise interaction with objects, and language instructions to achieve robust and precise object manipulation. We applied the dataset to our Dual-Action and Attention (DAA), a model designed for fine-grained dual arm manipulation tasks and robust against covariate shifts. The model was tested with over 7k total trials in real robot manipulation tasks, demonstrating its capability in fine manipulation.","sentences":["In the field of robotic manipulation, deep imitation learning is recognized as a promising approach for acquiring manipulation skills.","Additionally, learning from diverse robot datasets is considered a viable method to achieve versatility and adaptability.","In such research, by learning various tasks, robots achieved generality across multiple objects.","However, such multi-task robot datasets have mainly focused on single-arm tasks that are relatively imprecise, not addressing the fine-grained object manipulation that robots are expected to perform in the real world.","This paper introduces a dataset of diverse object manipulations that includes dual-arm tasks and/or tasks requiring fine manipulation.","To this end, we have generated dataset with 224k episodes (150 hours, 1,104 language instructions) which includes dual-arm fine tasks such as bowl-moving, pencil-case opening or banana-peeling, and this data is publicly available.","Additionally, this dataset includes visual attention signals as well as dual-action labels, a signal that separates actions into a robust reaching trajectory and precise interaction with objects, and language instructions to achieve robust and precise object manipulation.","We applied the dataset to our Dual-Action and Attention (DAA), a model designed for fine-grained dual arm manipulation tasks and robust against covariate shifts.","The model was tested with over 7k total trials in real robot manipulation tasks, demonstrating its capability in fine manipulation."],"url":"http://arxiv.org/abs/2401.07603v1"}
{"created":"2024-01-15 11:06:43","title":"MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models","abstract":"Parameter efficient finetuning has emerged as a viable solution for improving the performance of Large Language Models without requiring massive resources and compute. Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other languages. Further, there is also a large gap between the performance of smaller open-source models and larger LLMs. Finetuning can be an effective way to bridge this gap and make language models more equitable. In this work, we finetune the LLaMA-7B and Mistral-7B models on synthetic multilingual instruction tuning data to determine its effect on model performance on five downstream tasks covering twenty three languages in all. Additionally, we experiment with various parameters, such as rank for low-rank adaptation and values of quantisation to determine their effects on downstream performance and find that higher rank and higher quantisation values benefit low-resource languages. We find that parameter efficient finetuning of smaller open source models sometimes bridges the gap between the performance of these models and the larger ones, however, English performance can take a hit. We also find that finetuning sometimes improves performance on low-resource languages, while degrading performance on high-resource languages.","sentences":["Parameter efficient finetuning has emerged as a viable solution for improving the performance of Large Language Models without requiring massive resources and compute.","Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other languages.","Further, there is also a large gap between the performance of smaller open-source models and larger LLMs.","Finetuning can be an effective way to bridge this gap and make language models more equitable.","In this work, we finetune the LLaMA-7B and Mistral-7B models on synthetic multilingual instruction tuning data to determine its effect on model performance on five downstream tasks covering twenty three languages in all.","Additionally, we experiment with various parameters, such as rank for low-rank adaptation and values of quantisation to determine their effects on downstream performance and find that higher rank and higher quantisation values benefit low-resource languages.","We find that parameter efficient finetuning of smaller open source models sometimes bridges the gap between the performance of these models and the larger ones, however, English performance can take a hit.","We also find that finetuning sometimes improves performance on low-resource languages, while degrading performance on high-resource languages."],"url":"http://arxiv.org/abs/2401.07598v1"}
{"created":"2024-01-15 11:04:47","title":"E3x: $\\mathrm{E}(3)$-Equivariant Deep Learning Made Easy","abstract":"This work introduces E3x, a software package for building neural networks that are equivariant with respect to the Euclidean group $\\mathrm{E}(3)$, consisting of translations, rotations, and reflections of three-dimensional space. Compared to ordinary neural networks, $\\mathrm{E}(3)$-equivariant models promise benefits whenever input and/or output data are quantities associated with three-dimensional objects. This is because the numeric values of such quantities (e.g. positions) typically depend on the chosen coordinate system. Under transformations of the reference frame, the values change predictably, but the underlying rules can be difficult to learn for ordinary machine learning models. With built-in $\\mathrm{E}(3)$-equivariance, neural networks are guaranteed to satisfy the relevant transformation rules exactly, resulting in superior data efficiency and accuracy. The code for E3x is available from https://github.com/google-research/e3x.","sentences":["This work introduces E3x, a software package for building neural networks that are equivariant with respect to the Euclidean group $\\mathrm{E}(3)$, consisting of translations, rotations, and reflections of three-dimensional space.","Compared to ordinary neural networks, $\\mathrm{E}(3)$-equivariant models promise benefits whenever input and/or output data are quantities associated with three-dimensional objects.","This is because the numeric values of such quantities (e.g. positions) typically depend on the chosen coordinate system.","Under transformations of the reference frame, the values change predictably, but the underlying rules can be difficult to learn for ordinary machine learning models.","With built-in $\\mathrm{E}(3)$-equivariance, neural networks are guaranteed to satisfy the relevant transformation rules exactly, resulting in superior data efficiency and accuracy.","The code for E3x is available from https://github.com/google-research/e3x."],"url":"http://arxiv.org/abs/2401.07595v1"}
{"created":"2024-01-15 10:54:35","title":"Multimodal Crowd Counting with Pix2Pix GANs","abstract":"Most state-of-the-art crowd counting methods use color (RGB) images to learn the density map of the crowd. However, these methods often struggle to achieve higher accuracy in densely crowded scenes with poor illumination. Recently, some studies have reported improvement in the accuracy of crowd counting models using a combination of RGB and thermal images. Although multimodal data can lead to better predictions, multimodal data might not be always available beforehand. In this paper, we propose the use of generative adversarial networks (GANs) to automatically generate thermal infrared (TIR) images from color (RGB) images and use both to train crowd counting models to achieve higher accuracy. We use a Pix2Pix GAN network first to translate RGB images to TIR images. Our experiments on several state-of-the-art crowd counting models and benchmark crowd datasets report significant improvement in accuracy.","sentences":["Most state-of-the-art crowd counting methods use color (RGB) images to learn the density map of the crowd.","However, these methods often struggle to achieve higher accuracy in densely crowded scenes with poor illumination.","Recently, some studies have reported improvement in the accuracy of crowd counting models using a combination of RGB and thermal images.","Although multimodal data can lead to better predictions, multimodal data might not be always available beforehand.","In this paper, we propose the use of generative adversarial networks (GANs) to automatically generate thermal infrared (TIR) images from color (RGB) images and use both to train crowd counting models to achieve higher accuracy.","We use a Pix2Pix GAN network first to translate RGB images to TIR images.","Our experiments on several state-of-the-art crowd counting models and benchmark crowd datasets report significant improvement in accuracy."],"url":"http://arxiv.org/abs/2401.07591v1"}
{"created":"2024-01-15 10:26:47","title":"PMFSNet: Polarized Multi-scale Feature Self-attention Network For Lightweight Medical Image Segmentation","abstract":"Current state-of-the-art medical image segmentation methods prioritize accuracy but often at the expense of increased computational demands and larger model sizes. Applying these large-scale models to the relatively limited scale of medical image datasets tends to induce redundant computation, complicating the process without the necessary benefits. This approach not only adds complexity but also presents challenges for the integration and deployment of lightweight models on edge devices. For instance, recent transformer-based models have excelled in 2D and 3D medical image segmentation due to their extensive receptive fields and high parameter count. However, their effectiveness comes with a risk of overfitting when applied to small datasets and often neglects the vital inductive biases of Convolutional Neural Networks (CNNs), essential for local feature representation. In this work, we propose PMFSNet, a novel medical imaging segmentation model that effectively balances global and local feature processing while avoiding the computational redundancy typical in larger models. PMFSNet streamlines the UNet-based hierarchical structure and simplifies the self-attention mechanism's computational complexity, making it suitable for lightweight applications. It incorporates a plug-and-play PMFS block, a multi-scale feature enhancement module based on attention mechanisms, to capture long-term dependencies. Extensive comprehensive results demonstrate that even with a model (less than 1 million parameters), our method achieves superior performance in various segmentation tasks across different data scales. It achieves (IoU) metrics of 84.68%, 82.02%, and 78.82% on public datasets of teeth CT (CBCT), ovarian tumors ultrasound(MMOTU), and skin lesions dermoscopy images (ISIC 2018), respectively. The source code is available at https://github.com/yykzjh/PMFSNet.","sentences":["Current state-of-the-art medical image segmentation methods prioritize accuracy but often at the expense of increased computational demands and larger model sizes.","Applying these large-scale models to the relatively limited scale of medical image datasets tends to induce redundant computation, complicating the process without the necessary benefits.","This approach not only adds complexity but also presents challenges for the integration and deployment of lightweight models on edge devices.","For instance, recent transformer-based models have excelled in 2D and 3D medical image segmentation due to their extensive receptive fields and high parameter count.","However, their effectiveness comes with a risk of overfitting when applied to small datasets and often neglects the vital inductive biases of Convolutional Neural Networks (CNNs), essential for local feature representation.","In this work, we propose PMFSNet, a novel medical imaging segmentation model that effectively balances global and local feature processing while avoiding the computational redundancy typical in larger models.","PMFSNet streamlines the UNet-based hierarchical structure and simplifies the self-attention mechanism's computational complexity, making it suitable for lightweight applications.","It incorporates a plug-and-play PMFS block, a multi-scale feature enhancement module based on attention mechanisms, to capture long-term dependencies.","Extensive comprehensive results demonstrate that even with a model (less than 1 million parameters), our method achieves superior performance in various segmentation tasks across different data scales.","It achieves (IoU) metrics of 84.68%, 82.02%, and 78.82% on public datasets of teeth CT (CBCT), ovarian tumors ultrasound(MMOTU), and skin lesions dermoscopy images (ISIC 2018), respectively.","The source code is available at https://github.com/yykzjh/PMFSNet."],"url":"http://arxiv.org/abs/2401.07579v1"}
{"created":"2024-01-15 10:18:08","title":"Cascaded Cross-Modal Transformer for Audio-Textual Classification","abstract":"Speech classification tasks often require powerful language understanding models to grasp useful features, which becomes problematic when limited training data is available. To attain superior classification performance, we propose to harness the inherent value of multimodal representations by transcribing speech using automatic speech recognition (ASR) models and translating the transcripts into different languages via pretrained translation models. We thus obtain an audio-textual (multimodal) representation for each data sample. Subsequently, we combine language-specific Bidirectional Encoder Representations from Transformers (BERT) with Wav2Vec2.0 audio features via a novel cascaded cross-modal transformer (CCMT). Our model is based on two cascaded transformer blocks. The first one combines text-specific features from distinct languages, while the second one combines acoustic features with multilingual features previously learned by the first transformer block. We employed our system in the Requests Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge. CCMT was declared the winning solution, obtaining an unweighted average recall (UAR) of 65.41% and 85.87% for complaint and request detection, respectively. Moreover, we applied our framework on the Speech Commands v2 and HarperValleyBank dialog data sets, surpassing previous studies reporting results on these benchmarks. Our code is freely available for download at: https://github.com/ristea/ccmt.","sentences":["Speech classification tasks often require powerful language understanding models to grasp useful features, which becomes problematic when limited training data is available.","To attain superior classification performance, we propose to harness the inherent value of multimodal representations by transcribing speech using automatic speech recognition (ASR) models and translating the transcripts into different languages via pretrained translation models.","We thus obtain an audio-textual (multimodal) representation for each data sample.","Subsequently, we combine language-specific Bidirectional Encoder Representations from Transformers (BERT) with Wav2Vec2.0 audio features via a novel cascaded cross-modal transformer (CCMT).","Our model is based on two cascaded transformer blocks.","The first one combines text-specific features from distinct languages, while the second one combines acoustic features with multilingual features previously learned by the first transformer block.","We employed our system in the Requests Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge.","CCMT was declared the winning solution, obtaining an unweighted average recall (UAR) of 65.41% and 85.87% for complaint and request detection, respectively.","Moreover, we applied our framework on the Speech Commands v2 and HarperValleyBank dialog data sets, surpassing previous studies reporting results on these benchmarks.","Our code is freely available for download at: https://github.com/ristea/ccmt."],"url":"http://arxiv.org/abs/2401.07575v1"}
{"created":"2024-01-15 10:16:44","title":"Exploiting GPT-4 Vision for Zero-shot Point Cloud Understanding","abstract":"In this study, we tackle the challenge of classifying the object category in point clouds, which previous works like PointCLIP struggle to address due to the inherent limitations of the CLIP architecture. Our approach leverages GPT-4 Vision (GPT-4V) to overcome these challenges by employing its advanced generative abilities, enabling a more adaptive and robust classification process. We adapt the application of GPT-4V to process complex 3D data, enabling it to achieve zero-shot recognition capabilities without altering the underlying model architecture. Our methodology also includes a systematic strategy for point cloud image visualization, mitigating domain gap and enhancing GPT-4V's efficiency. Experimental validation demonstrates our approach's superiority in diverse scenarios, setting a new benchmark in zero-shot point cloud classification.","sentences":["In this study, we tackle the challenge of classifying the object category in point clouds, which previous works like PointCLIP struggle to address due to the inherent limitations of the CLIP architecture.","Our approach leverages GPT-4 Vision (GPT-4V) to overcome these challenges by employing its advanced generative abilities, enabling a more adaptive and robust classification process.","We adapt the application of GPT-4V to process complex 3D data, enabling it to achieve zero-shot recognition capabilities without altering the underlying model architecture.","Our methodology also includes a systematic strategy for point cloud image visualization, mitigating domain gap and enhancing GPT-4V's efficiency.","Experimental validation demonstrates our approach's superiority in diverse scenarios, setting a new benchmark in zero-shot point cloud classification."],"url":"http://arxiv.org/abs/2401.07572v1"}
{"created":"2024-01-15 10:11:19","title":"A Bi-Pyramid Multimodal Fusion Method for the Diagnosis of Bipolar Disorders","abstract":"Previous research on the diagnosis of Bipolar disorder has mainly focused on resting-state functional magnetic resonance imaging. However, their accuracy can not meet the requirements of clinical diagnosis. Efficient multimodal fusion strategies have great potential for applications in multimodal data and can further improve the performance of medical diagnosis models. In this work, we utilize both sMRI and fMRI data and propose a novel multimodal diagnosis model for bipolar disorder. The proposed Patch Pyramid Feature Extraction Module extracts sMRI features, and the spatio-temporal pyramid structure extracts the fMRI features. Finally, they are fused by a fusion module to output diagnosis results with a classifier. Extensive experiments show that our proposed method outperforms others in balanced accuracy from 0.657 to 0.732 on the OpenfMRI dataset, and achieves the state of the art.","sentences":["Previous research on the diagnosis of Bipolar disorder has mainly focused on resting-state functional magnetic resonance imaging.","However, their accuracy can not meet the requirements of clinical diagnosis.","Efficient multimodal fusion strategies have great potential for applications in multimodal data and can further improve the performance of medical diagnosis models.","In this work, we utilize both sMRI and fMRI data and propose a novel multimodal diagnosis model for bipolar disorder.","The proposed Patch Pyramid Feature Extraction Module extracts sMRI features, and the spatio-temporal pyramid structure extracts the fMRI features.","Finally, they are fused by a fusion module to output diagnosis results with a classifier.","Extensive experiments show that our proposed method outperforms others in balanced accuracy from 0.657 to 0.732 on the OpenfMRI dataset, and achieves the state of the art."],"url":"http://arxiv.org/abs/2401.07571v1"}
{"created":"2024-01-15 09:59:27","title":"Call graph discovery in binary programs from unknown instruction set architectures","abstract":"This study addresses the challenge of reverse engineering binaries from unknown instruction set architectures, a complex task with potential implications for software maintenance and cyber-security. We focus on the tasks of detecting candidate call and return opcodes for automatic extraction of call graphs in order to simplify the reverse engineering process. Empirical testing on a small dataset of binary files from different architectures demonstrates that the approach can accurately detect specific opcodes under conditions of noisy data. The method lays the groundwork for a valuable tool for reverse engineering where the reverse engineer has minimal a priori knowledge of the underlying instruction set architecture.","sentences":["This study addresses the challenge of reverse engineering binaries from unknown instruction set architectures, a complex task with potential implications for software maintenance and cyber-security.","We focus on the tasks of detecting candidate call and return opcodes for automatic extraction of call graphs in order to simplify the reverse engineering process.","Empirical testing on a small dataset of binary files from different architectures demonstrates that the approach can accurately detect specific opcodes under conditions of noisy data.","The method lays the groundwork for a valuable tool for reverse engineering where the reverse engineer has minimal a priori knowledge of the underlying instruction set architecture."],"url":"http://arxiv.org/abs/2401.07565v1"}
{"created":"2024-01-15 09:50:27","title":"FedRFQ: Prototype-Based Federated Learning with Reduced Redundancy, Minimal Failure, and Enhanced Quality","abstract":"Federated learning is a powerful technique that enables collaborative learning among different clients. Prototype-based federated learning is a specific approach that improves the performance of local models under non-IID (non-Independently and Identically Distributed) settings by integrating class prototypes. However, prototype-based federated learning faces several challenges, such as prototype redundancy and prototype failure, which limit its accuracy. It is also susceptible to poisoning attacks and server malfunctions, which can degrade the prototype quality. To address these issues, we propose FedRFQ, a prototype-based federated learning approach that aims to reduce redundancy, minimize failures, and improve \\underline{q}uality. FedRFQ leverages a SoftPool mechanism, which effectively mitigates prototype redundancy and prototype failure on non-IID data. Furthermore, we introduce the BFT-detect, a BFT (Byzantine Fault Tolerance) detectable aggregation algorithm, to ensure the security of FedRFQ against poisoning attacks and server malfunctions. Finally, we conduct experiments on three different datasets, namely MNIST, FEMNIST, and CIFAR-10, and the results demonstrate that FedRFQ outperforms existing baselines in terms of accuracy when handling non-IID data.","sentences":["Federated learning is a powerful technique that enables collaborative learning among different clients.","Prototype-based federated learning is a specific approach that improves the performance of local models under non-IID (non-Independently and Identically Distributed) settings by integrating class prototypes.","However, prototype-based federated learning faces several challenges, such as prototype redundancy and prototype failure, which limit its accuracy.","It is also susceptible to poisoning attacks and server malfunctions, which can degrade the prototype quality.","To address these issues, we propose FedRFQ, a prototype-based federated learning approach that aims to reduce redundancy, minimize failures, and improve \\underline{q}uality.","FedRFQ leverages a SoftPool mechanism, which effectively mitigates prototype redundancy and prototype failure on non-IID data.","Furthermore, we introduce the BFT-detect, a BFT (Byzantine Fault Tolerance) detectable aggregation algorithm, to ensure the security of FedRFQ against poisoning attacks and server malfunctions.","Finally, we conduct experiments on three different datasets, namely MNIST, FEMNIST, and CIFAR-10, and the results demonstrate that FedRFQ outperforms existing baselines in terms of accuracy when handling non-IID data."],"url":"http://arxiv.org/abs/2401.07558v1"}
{"created":"2024-01-15 09:27:46","title":"Robust Semi-Supervised Learning for Self-learning Open-World Classes","abstract":"Existing semi-supervised learning (SSL) methods assume that labeled and unlabeled data share the same class space. However, in real-world applications, unlabeled data always contain classes not present in the labeled set, which may cause classification performance degradation of known classes. Therefore, open-world SSL approaches are researched to handle the presence of multiple unknown classes in the unlabeled data, which aims to accurately classify known classes while fine-grained distinguishing different unknown classes. To address this challenge, in this paper, we propose an open-world SSL method for Self-learning Open-world Classes (SSOC), which can explicitly self-learn multiple unknown classes. Specifically, SSOC first defines class center tokens for both known and unknown classes and autonomously learns token representations according to all samples with the cross-attention mechanism. To effectively discover novel classes, SSOC further designs a pairwise similarity loss in addition to the entropy loss, which can wisely exploit the information available in unlabeled data from instances' predictions and relationships. Extensive experiments demonstrate that SSOC outperforms the state-of-the-art baselines on multiple popular classification benchmarks. Specifically, on the ImageNet-100 dataset with a novel ratio of 90%, SSOC achieves a remarkable 22% improvement.","sentences":["Existing semi-supervised learning (SSL) methods assume that labeled and unlabeled data share the same class space.","However, in real-world applications, unlabeled data always contain classes not present in the labeled set, which may cause classification performance degradation of known classes.","Therefore, open-world SSL approaches are researched to handle the presence of multiple unknown classes in the unlabeled data, which aims to accurately classify known classes while fine-grained distinguishing different unknown classes.","To address this challenge, in this paper, we propose an open-world SSL method for Self-learning Open-world Classes (SSOC), which can explicitly self-learn multiple unknown classes.","Specifically, SSOC first defines class center tokens for both known and unknown classes and autonomously learns token representations according to all samples with the cross-attention mechanism.","To effectively discover novel classes, SSOC further designs a pairwise similarity loss in addition to the entropy loss, which can wisely exploit the information available in unlabeled data from instances' predictions and relationships.","Extensive experiments demonstrate that SSOC outperforms the state-of-the-art baselines on multiple popular classification benchmarks.","Specifically, on the ImageNet-100 dataset with a novel ratio of 90%, SSOC achieves a remarkable 22% improvement."],"url":"http://arxiv.org/abs/2401.07551v1"}
{"created":"2024-01-15 09:22:10","title":"Rabin Games and Colourful Universal Trees","abstract":"We provide an algorithm to solve Rabin and Streett games over graphs with $n$ vertices, $m$ edges, and $k$ colours that runs in $\\tilde{O}\\left(mn(k!)^{1+o(1)} \\right)$ time and $O(nk\\log k \\log n)$ space, where $\\tilde{O}$ hides poly-logarithmic factors. Our algorithm is an improvement by a super quadratic dependence on $k!$ from the currently best known run time of $O\\left(mn^2(k!)^{2+o(1)}\\right)$, obtained by converting a Rabin game into a parity game, while simultaneously improving its exponential space requirement.   Our main technical ingredient is a characterisation of progress measures for Rabin games using \\emph{colourful trees} and a combinatorial construction of succinctly-represented, universal colourful trees. Colourful universal trees are generalisations of universal trees used by Jurdzi\\'{n}ski and Lazi\\'{c} (2017) to solve parity games, as well as of Rabin progress measures of Klarlund and Kozen (1991). Our algorithm for Rabin games is a progress measure lifting algorithm where the lifting is performed on succinct, colourful, universal trees.","sentences":["We provide an algorithm to solve Rabin and Streett games over graphs with $n$ vertices, $m$ edges, and $k$ colours that runs in $\\tilde{O}\\left(mn(k!)^{1+o(1)} \\right)$ time and $O(nk\\log k \\log n)$ space, where $\\tilde{O}$ hides poly-logarithmic factors.","Our algorithm is an improvement by a super quadratic dependence on $k!$ from the currently best known run time of $O\\left(mn^2(k!)^{2+o(1)}\\right)$, obtained by converting a Rabin game into a parity game, while simultaneously improving its exponential space requirement.   ","Our main technical ingredient is a characterisation of progress measures for Rabin games using \\emph{colourful trees} and a combinatorial construction of succinctly-represented, universal colourful trees.","Colourful universal trees are generalisations of universal trees used by Jurdzi\\'{n}ski and Lazi\\'{c} (2017) to solve parity games, as well as of Rabin progress measures of Klarlund and Kozen (1991).","Our algorithm for Rabin games is a progress measure lifting algorithm where the lifting is performed on succinct, colourful, universal trees."],"url":"http://arxiv.org/abs/2401.07548v1"}
{"created":"2024-01-15 09:07:28","title":"Must: Maximizing Latent Capacity of Spatial Transcriptomics Data","abstract":"Spatial transcriptomics (ST) technologies have revolutionized the study of gene expression patterns in tissues by providing multimodality data in transcriptomic, spatial, and morphological, offering opportunities for understanding tissue biology beyond transcriptomics. However, we identify the modality bias phenomenon in ST data species, i.e., the inconsistent contribution of different modalities to the labels leads to a tendency for the analysis methods to retain the information of the dominant modality. How to mitigate the adverse effects of modality bias to satisfy various downstream tasks remains a fundamental challenge. This paper introduces Multiple-modality Structure Transformation, named MuST, a novel methodology to tackle the challenge. MuST integrates the multi-modality information contained in the ST data effectively into a uniform latent space to provide a foundation for all the downstream tasks. It learns intrinsic local structures by topology discovery strategy and topology fusion loss function to solve the inconsistencies among different modalities. Thus, these topology-based and deep learning techniques provide a solid foundation for a variety of analytical tasks while coordinating different modalities. The effectiveness of MuST is assessed by performance metrics and biological significance. The results show that it outperforms existing state-of-the-art methods with clear advantages in the precision of identifying and preserving structures of tissues and biomarkers. MuST offers a versatile toolkit for the intricate analysis of complex biological systems.","sentences":["Spatial transcriptomics (ST) technologies have revolutionized the study of gene expression patterns in tissues by providing multimodality data in transcriptomic, spatial, and morphological, offering opportunities for understanding tissue biology beyond transcriptomics.","However, we identify the modality bias phenomenon in ST data species, i.e., the inconsistent contribution of different modalities to the labels leads to a tendency for the analysis methods to retain the information of the dominant modality.","How to mitigate the adverse effects of modality bias to satisfy various downstream tasks remains a fundamental challenge.","This paper introduces Multiple-modality Structure Transformation, named MuST, a novel methodology to tackle the challenge.","MuST integrates the multi-modality information contained in the ST data effectively into a uniform latent space to provide a foundation for all the downstream tasks.","It learns intrinsic local structures by topology discovery strategy and topology fusion loss function to solve the inconsistencies among different modalities.","Thus, these topology-based and deep learning techniques provide a solid foundation for a variety of analytical tasks while coordinating different modalities.","The effectiveness of MuST is assessed by performance metrics and biological significance.","The results show that it outperforms existing state-of-the-art methods with clear advantages in the precision of identifying and preserving structures of tissues and biomarkers.","MuST offers a versatile toolkit for the intricate analysis of complex biological systems."],"url":"http://arxiv.org/abs/2401.07543v1"}
{"created":"2024-01-15 09:03:50","title":"Combining Image- and Geometric-based Deep Learning for Shape Regression: A Comparison to Pixel-level Methods for Segmentation in Chest X-Ray","abstract":"When solving a segmentation task, shaped-base methods can be beneficial compared to pixelwise classification due to geometric understanding of the target object as shape, preventing the generation of anatomical implausible predictions in particular for corrupted data. In this work, we propose a novel hybrid method that combines a lightweight CNN backbone with a geometric neural network (Point Transformer) for shape regression. Using the same CNN encoder, the Point Transformer reaches segmentation quality on per with current state-of-the-art convolutional decoders ($4\\pm1.9$ vs $3.9\\pm2.9$ error in mm and $85\\pm13$ vs $88\\pm10$ Dice), but crucially, is more stable w.r.t image distortion, starting to outperform them at a corruption level of 30%. Furthermore, we include the nnU-Net as an upper baseline, which has $3.7\\times$ more trainable parameters than our proposed method.","sentences":["When solving a segmentation task, shaped-base methods can be beneficial compared to pixelwise classification due to geometric understanding of the target object as shape, preventing the generation of anatomical implausible predictions in particular for corrupted data.","In this work, we propose a novel hybrid method that combines a lightweight CNN backbone with a geometric neural network (Point Transformer) for shape regression.","Using the same CNN encoder, the Point Transformer reaches segmentation quality on per with current state-of-the-art convolutional decoders ($4\\pm1.9$ vs $3.9\\pm2.9$ error in mm and $85\\pm13$ vs $88\\pm10$ Dice), but crucially, is more stable w.r.t image distortion, starting to outperform them at a corruption level of 30%.","Furthermore, we include the nnU-Net as an upper baseline, which has $3.7\\times$ more trainable parameters than our proposed method."],"url":"http://arxiv.org/abs/2401.07542v1"}
{"created":"2024-01-15 09:01:31","title":"Study Features via Exploring Distribution Structure","abstract":"In this paper, we present a novel framework for data redundancy measurement based on probabilistic modeling of datasets, and a new criterion for redundancy detection that is resilient to noise. We also develop new methods for data redundancy reduction using both deterministic and stochastic optimization techniques. Our framework is flexible and can handle different types of features, and our experiments on benchmark datasets demonstrate the effectiveness of our methods. We provide a new perspective on feature selection, and propose effective and robust approaches for both supervised and unsupervised learning problems.","sentences":["In this paper, we present a novel framework for data redundancy measurement based on probabilistic modeling of datasets, and a new criterion for redundancy detection that is resilient to noise.","We also develop new methods for data redundancy reduction using both deterministic and stochastic optimization techniques.","Our framework is flexible and can handle different types of features, and our experiments on benchmark datasets demonstrate the effectiveness of our methods.","We provide a new perspective on feature selection, and propose effective and robust approaches for both supervised and unsupervised learning problems."],"url":"http://arxiv.org/abs/2401.07540v1"}
{"created":"2024-01-15 08:19:22","title":"MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception","abstract":"Multimodal Large Language Models (MLLMs) have shown their remarkable abilities in visual perception and understanding recently. However, how to comprehensively evaluate the capabilities of MLLMs remains a challenge. Most of the existing benchmarks predominantly focus on assessing perception, cognition, and reasoning, neglecting the abilities of self-awareness, referring to the model's recognition of its own capability boundary. In our study, we focus on self-awareness in image perception and introduce the knowledge quadrant for MLLMs, which clearly defines the knowns and unknowns in perception. Based on this, we propose a novel benchmark specifically designed to evaluate the Self-Aware capabilities in Perception for MLLMs(MM-SAP). MM-SAP encompasses three distinct sub-datasets, each focusing on different aspects of self-awareness. We evaluated eight well-known MLLMs using MM-SAP, analyzing their self-awareness and providing detailed insights. Code and data are available at https://github.com/YHWmz/MM-SAP","sentences":["Multimodal Large Language Models (MLLMs) have shown their remarkable abilities in visual perception and understanding recently.","However, how to comprehensively evaluate the capabilities of MLLMs remains a challenge.","Most of the existing benchmarks predominantly focus on assessing perception, cognition, and reasoning, neglecting the abilities of self-awareness, referring to the model's recognition of its own capability boundary.","In our study, we focus on self-awareness in image perception and introduce the knowledge quadrant for MLLMs, which clearly defines the knowns and unknowns in perception.","Based on this, we propose a novel benchmark specifically designed to evaluate the Self-Aware capabilities in Perception for MLLMs(MM-SAP).","MM-SAP encompasses three distinct sub-datasets, each focusing on different aspects of self-awareness.","We evaluated eight well-known MLLMs using MM-SAP, analyzing their self-awareness and providing detailed insights.","Code and data are available at https://github.com/YHWmz/MM-SAP"],"url":"http://arxiv.org/abs/2401.07529v1"}
{"created":"2024-01-15 08:12:51","title":"One for All: Toward Unified Foundation Models for Earth Vision","abstract":"Foundation models characterized by extensive parameters and trained on large-scale datasets have demonstrated remarkable efficacy across various downstream tasks for remote sensing data. Current remote sensing foundation models typically specialize in a single modality or a specific spatial resolution range, limiting their versatility for downstream datasets. While there have been attempts to develop multi-modal remote sensing foundation models, they typically employ separate vision encoders for each modality or spatial resolution, necessitating a switch in backbones contingent upon the input data. To address this issue, we introduce a simple yet effective method, termed OFA-Net (One-For-All Network): employing a single, shared Transformer backbone for multiple data modalities with different spatial resolutions. Using the masked image modeling mechanism, we pre-train a single Transformer backbone on a curated multi-modal dataset with this simple design. Then the backbone model can be used in different downstream tasks, thus forging a path towards a unified foundation backbone model in Earth vision. The proposed method is evaluated on 12 distinct downstream tasks and demonstrates promising performance.","sentences":["Foundation models characterized by extensive parameters and trained on large-scale datasets have demonstrated remarkable efficacy across various downstream tasks for remote sensing data.","Current remote sensing foundation models typically specialize in a single modality or a specific spatial resolution range, limiting their versatility for downstream datasets.","While there have been attempts to develop multi-modal remote sensing foundation models, they typically employ separate vision encoders for each modality or spatial resolution, necessitating a switch in backbones contingent upon the input data.","To address this issue, we introduce a simple yet effective method, termed OFA-Net (One-For-All Network): employing a single, shared Transformer backbone for multiple data modalities with different spatial resolutions.","Using the masked image modeling mechanism, we pre-train a single Transformer backbone on a curated multi-modal dataset with this simple design.","Then the backbone model can be used in different downstream tasks, thus forging a path towards a unified foundation backbone model in Earth vision.","The proposed method is evaluated on 12 distinct downstream tasks and demonstrates promising performance."],"url":"http://arxiv.org/abs/2401.07527v1"}
{"created":"2024-01-15 07:57:58","title":"TAROT: A Hierarchical Framework with Multitask Co-Pretraining on Semi-Structured Data towards Effective Person-Job Fit","abstract":"Person-job fit is an essential part of online recruitment platforms in serving various downstream applications like Job Search and Candidate Recommendation. Recently, pretrained large language models have further enhanced the effectiveness by leveraging richer textual information in user profiles and job descriptions apart from user behavior features and job metadata. However, the general domain-oriented design struggles to capture the unique structural information within user profiles and job descriptions, leading to a loss of latent semantic correlations. We propose TAROT, a hierarchical multitask co-pretraining framework, to better utilize structural and semantic information for informative text embeddings. TAROT targets semi-structured text in profiles and jobs, and it is co-pretained with multi-grained pretraining tasks to constrain the acquired semantic information at each level. Experiments on a real-world LinkedIn dataset show significant performance improvements, proving its effectiveness in person-job fit tasks.","sentences":["Person-job fit is an essential part of online recruitment platforms in serving various downstream applications like Job Search and Candidate Recommendation.","Recently, pretrained large language models have further enhanced the effectiveness by leveraging richer textual information in user profiles and job descriptions apart from user behavior features and job metadata.","However, the general domain-oriented design struggles to capture the unique structural information within user profiles and job descriptions, leading to a loss of latent semantic correlations.","We propose TAROT, a hierarchical multitask co-pretraining framework, to better utilize structural and semantic information for informative text embeddings.","TAROT targets semi-structured text in profiles and jobs, and it is co-pretained with multi-grained pretraining tasks to constrain the acquired semantic information at each level.","Experiments on a real-world LinkedIn dataset show significant performance improvements, proving its effectiveness in person-job fit tasks."],"url":"http://arxiv.org/abs/2401.07525v1"}
{"created":"2024-01-15 07:35:29","title":"Temporal Link Prediction Using Graph Embedding Dynamics","abstract":"Graphs are a powerful representation tool in machine learning applications, with link prediction being a key task in graph learning. Temporal link prediction in dynamic networks is of particular interest due to its potential for solving complex scientific and real-world problems. Traditional approaches to temporal link prediction have focused on finding the aggregation of dynamics of the network as a unified output. In this study, we propose a novel perspective on temporal link prediction by defining nodes as Newtonian objects and incorporating the concept of velocity to predict network dynamics. By computing more specific dynamics of each node, rather than overall dynamics, we improve both accuracy and explainability in predicting future connections. We demonstrate the effectiveness of our approach using two datasets, including 17 years of co-authorship data from PubMed. Experimental results show that our temporal graph embedding dynamics approach improves downstream classification models' ability to predict future collaboration efficacy in co-authorship networks by 17.34% (AUROC improvement relative to the baseline model). Furthermore, our approach offers an interpretable layer over traditional approaches to address the temporal link prediction problem.","sentences":["Graphs are a powerful representation tool in machine learning applications, with link prediction being a key task in graph learning.","Temporal link prediction in dynamic networks is of particular interest due to its potential for solving complex scientific and real-world problems.","Traditional approaches to temporal link prediction have focused on finding the aggregation of dynamics of the network as a unified output.","In this study, we propose a novel perspective on temporal link prediction by defining nodes as Newtonian objects and incorporating the concept of velocity to predict network dynamics.","By computing more specific dynamics of each node, rather than overall dynamics, we improve both accuracy and explainability in predicting future connections.","We demonstrate the effectiveness of our approach using two datasets, including 17 years of co-authorship data from PubMed.","Experimental results show that our temporal graph embedding dynamics approach improves downstream classification models' ability to predict future collaboration efficacy in co-authorship networks by 17.34% (AUROC improvement relative to the baseline model).","Furthermore, our approach offers an interpretable layer over traditional approaches to address the temporal link prediction problem."],"url":"http://arxiv.org/abs/2401.07516v1"}
