{"created":"2024-02-14 18:58:40","title":"Reinforcement Learning from Human Feedback with Active Queries","abstract":"Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\\tilde{O}(d^2/\\Delta)$ regret bound and an $\\tilde{O}(d^2/\\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to fine-tuning LLMs. Our experiments show that ADPO, while only making about half of queries for human preference, matches the performance of the state-of-the-art DPO method.","sentences":["Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF).","Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect.","In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods.","We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\\tilde{O}(d^2/\\Delta)$ regret bound and an $\\tilde{O}(d^2/\\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\\Delta$ is the sub-optimality gap over all the contexts.","We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to fine-tuning LLMs.","Our experiments show that ADPO, while only making about half of queries for human preference, matches the performance of the state-of-the-art DPO method."],"url":"http://arxiv.org/abs/2402.09401v1"}
{"created":"2024-02-14 18:26:58","title":"GraSSRep: Graph-Based Self-Supervised Learning for Repeat Detection in Metagenomic Assembly","abstract":"Repetitive DNA (repeats) poses significant challenges for accurate and efficient genome assembly and sequence alignment. This is particularly true for metagenomic data, where genome dynamics such as horizontal gene transfer, gene duplication, and gene loss/gain complicate accurate genome assembly from metagenomic communities. Detecting repeats is a crucial first step in overcoming these challenges. To address this issue, we propose GraSSRep, a novel approach that leverages the assembly graph's structure through graph neural networks (GNNs) within a self-supervised learning framework to classify DNA sequences into repetitive and non-repetitive categories. Specifically, we frame this problem as a node classification task within a metagenomic assembly graph. In a self-supervised fashion, we rely on a high-precision (but low-recall) heuristic to generate pseudo-labels for a small proportion of the nodes. We then use those pseudo-labels to train a GNN embedding and a random forest classifier to propagate the labels to the remaining nodes. In this way, GraSSRep combines sequencing features with pre-defined and learned graph features to achieve state-of-the-art performance in repeat detection. We evaluate our method using simulated and synthetic metagenomic datasets. The results on the simulated data highlight our GraSSRep's robustness to repeat attributes, demonstrating its effectiveness in handling the complexity of repeated sequences. Additionally, our experiments with synthetic metagenomic datasets reveal that incorporating the graph structure and the GNN enhances our detection performance. Finally, in comparative analyses, GraSSRep outperforms existing repeat detection tools with respect to precision and recall.","sentences":["Repetitive DNA (repeats) poses significant challenges for accurate and efficient genome assembly and sequence alignment.","This is particularly true for metagenomic data, where genome dynamics such as horizontal gene transfer, gene duplication, and gene loss/gain complicate accurate genome assembly from metagenomic communities.","Detecting repeats is a crucial first step in overcoming these challenges.","To address this issue, we propose GraSSRep, a novel approach that leverages the assembly graph's structure through graph neural networks (GNNs) within a self-supervised learning framework to classify DNA sequences into repetitive and non-repetitive categories.","Specifically, we frame this problem as a node classification task within a metagenomic assembly graph.","In a self-supervised fashion, we rely on a high-precision (but low-recall) heuristic to generate pseudo-labels for a small proportion of the nodes.","We then use those pseudo-labels to train a GNN embedding and a random forest classifier to propagate the labels to the remaining nodes.","In this way, GraSSRep combines sequencing features with pre-defined and learned graph features to achieve state-of-the-art performance in repeat detection.","We evaluate our method using simulated and synthetic metagenomic datasets.","The results on the simulated data highlight our GraSSRep's robustness to repeat attributes, demonstrating its effectiveness in handling the complexity of repeated sequences.","Additionally, our experiments with synthetic metagenomic datasets reveal that incorporating the graph structure and the GNN enhances our detection performance.","Finally, in comparative analyses, GraSSRep outperforms existing repeat detection tools with respect to precision and recall."],"url":"http://arxiv.org/abs/2402.09381v1"}
{"created":"2024-02-14 18:26:58","title":"Safe Distributed Control of Multi-Robot Systems with Communication Delays","abstract":"Safe operation of multi-robot systems is critical, especially in communication-degraded environments such as underwater for seabed mapping, underground caves for navigation, and in extraterrestrial missions for assembly and construction. We address safety of networked autonomous systems where the information exchanged between robots incurs communication delays. We formalize a notion of distributed control barrier function (CBF) for multi-robot systems, a safety certificate amenable to a distributed implementation, which provides formal ground to using graph neural networks to learn safe distributed controllers. Further, we observe that learning a distributed controller ignoring delays can severely degrade safety. Our main contribution is a predictor-based framework to train a safe distributed controller under communication delays, where the current state of nearby robots is predicted from received data and age-of-information. Numerical experiments on multi-robot collision avoidance show that our predictor-based approach can significantly improve the safety of a learned distributed controller under communication delays","sentences":["Safe operation of multi-robot systems is critical, especially in communication-degraded environments such as underwater for seabed mapping, underground caves for navigation, and in extraterrestrial missions for assembly and construction.","We address safety of networked autonomous systems where the information exchanged between robots incurs communication delays.","We formalize a notion of distributed control barrier function (CBF) for multi-robot systems, a safety certificate amenable to a distributed implementation, which provides formal ground to using graph neural networks to learn safe distributed controllers.","Further, we observe that learning a distributed controller ignoring delays can severely degrade safety.","Our main contribution is a predictor-based framework to train a safe distributed controller under communication delays, where the current state of nearby robots is predicted from received data and age-of-information.","Numerical experiments on multi-robot collision avoidance show that our predictor-based approach can significantly improve the safety of a learned distributed controller under communication delays"],"url":"http://arxiv.org/abs/2402.09382v1"}
{"created":"2024-02-14 18:25:13","title":"Fixed-sparsity matrix approximation from matrix-vector products","abstract":"We study the problem of approximating a matrix $\\mathbf{A}$ with a matrix that has a fixed sparsity pattern (e.g., diagonal, banded, etc.), when $\\mathbf{A}$ is accessed only by matrix-vector products. We describe a simple randomized algorithm that returns an approximation with the given sparsity pattern with Frobenius-norm error at most $(1+\\varepsilon)$ times the best possible error. When each row of the desired sparsity pattern has at most $s$ nonzero entries, this algorithm requires $O(s/\\varepsilon)$ non-adaptive matrix-vector products with $\\mathbf{A}$. We proceed to prove a matching lower-bound. Specifically, we show that for any $s\\geq 1$, there are matrices $\\mathbf{A}$ such that, for any sparsity pattern with $\\Theta(s)$ nonzeros per row and column, any algorithm which obtains a $(1+\\varepsilon)$ accurate approximation of the given sparsity from matrix-vector products requires at least $\\Omega(s/\\varepsilon)$ matrix-vector products. Our bounds therefore resolve the matrix-vector product query complexity of the problem up to constant factors, even for the well-studied case of diagonal approximation, for which no previous lower bounds were known.","sentences":["We study the problem of approximating a matrix $\\mathbf{A}$ with a matrix that has a fixed sparsity pattern (e.g., diagonal, banded, etc.), when $\\mathbf{A}$ is accessed only by matrix-vector products.","We describe a simple randomized algorithm that returns an approximation with the given sparsity pattern with Frobenius-norm error at most $(1+\\varepsilon)$ times the best possible error.","When each row of the desired sparsity pattern has at most $s$ nonzero entries, this algorithm requires $O(s/\\varepsilon)$ non-adaptive matrix-vector products with $\\mathbf{A}$. We proceed to prove a matching lower-bound.","Specifically, we show that for any $s\\geq 1$, there are matrices $\\mathbf{A}$ such that, for any sparsity pattern with $\\Theta(s)$ nonzeros per row and column, any algorithm which obtains a $(1+\\varepsilon)$ accurate approximation of the given sparsity from matrix-vector products requires at least $\\Omega(s/\\varepsilon)$ matrix-vector products.","Our bounds therefore resolve the matrix-vector product query complexity of the problem up to constant factors, even for the well-studied case of diagonal approximation, for which no previous lower bounds were known."],"url":"http://arxiv.org/abs/2402.09379v1"}
{"created":"2024-02-14 18:18:29","title":"Transformers Can Achieve Length Generalization But Not Robustly","abstract":"Length generalization, defined as the ability to extrapolate from shorter training sequences to longer test ones, is a significant challenge for language models. This issue persists even with large-scale Transformers handling relatively straightforward tasks. In this paper, we test the Transformer's ability of length generalization using the task of addition of two integers. We show that the success of length generalization is intricately linked to the data format and the type of position encoding. Using the right combination of data format and position encodings, we show for the first time that standard Transformers can extrapolate to a sequence length that is 2.5x the input length. Nevertheless, unlike in-distribution generalization, length generalization remains fragile, significantly influenced by factors like random weight initialization and training data order, leading to large variances across different random seeds.","sentences":["Length generalization, defined as the ability to extrapolate from shorter training sequences to longer test ones, is a significant challenge for language models.","This issue persists even with large-scale Transformers handling relatively straightforward tasks.","In this paper, we test the Transformer's ability of length generalization using the task of addition of two integers.","We show that the success of length generalization is intricately linked to the data format and the type of position encoding.","Using the right combination of data format and position encodings, we show for the first time that standard Transformers can extrapolate to a sequence length that is 2.5x the input length.","Nevertheless, unlike in-distribution generalization, length generalization remains fragile, significantly influenced by factors like random weight initialization and training data order, leading to large variances across different random seeds."],"url":"http://arxiv.org/abs/2402.09371v1"}
{"created":"2024-02-14 18:16:54","title":"Massively Multi-Cultural Knowledge Acquisition & LM Benchmarking","abstract":"Pretrained large language models have revolutionized many applications but still face challenges related to cultural bias and a lack of cultural commonsense knowledge crucial for guiding cross-culture communication and interactions. Recognizing the shortcomings of existing methods in capturing the diverse and rich cultures across the world, this paper introduces a novel approach for massively multicultural knowledge acquisition. Specifically, our method strategically navigates from densely informative Wikipedia documents on cultural topics to an extensive network of linked pages. Leveraging this valuable source of data collection, we construct the CultureAtlas dataset, which covers a wide range of sub-country level geographical regions and ethnolinguistic groups, with data cleaning and preprocessing to ensure textual assertion sentence self-containment, as well as fine-grained cultural profile information extraction. Our dataset not only facilitates the evaluation of language model performance in culturally diverse contexts but also serves as a foundational tool for the development of culturally sensitive and aware language models. Our work marks an important step towards deeper understanding and bridging the gaps of cultural disparities in AI, to promote a more inclusive and balanced representation of global cultures in the digital domain.","sentences":["Pretrained large language models have revolutionized many applications but still face challenges related to cultural bias and a lack of cultural commonsense knowledge crucial for guiding cross-culture communication and interactions.","Recognizing the shortcomings of existing methods in capturing the diverse and rich cultures across the world, this paper introduces a novel approach for massively multicultural knowledge acquisition.","Specifically, our method strategically navigates from densely informative Wikipedia documents on cultural topics to an extensive network of linked pages.","Leveraging this valuable source of data collection, we construct the CultureAtlas dataset, which covers a wide range of sub-country level geographical regions and ethnolinguistic groups, with data cleaning and preprocessing to ensure textual assertion sentence self-containment, as well as fine-grained cultural profile information extraction.","Our dataset not only facilitates the evaluation of language model performance in culturally diverse contexts but also serves as a foundational tool for the development of culturally sensitive and aware language models.","Our work marks an important step towards deeper understanding and bridging the gaps of cultural disparities in AI, to promote a more inclusive and balanced representation of global cultures in the digital domain."],"url":"http://arxiv.org/abs/2402.09369v1"}
{"created":"2024-02-14 18:13:37","title":"Prediction of Activated Sludge Settling Characteristics from Microscopy Images with Deep Convolutional Neural Networks and Transfer Learning","abstract":"Microbial communities play a key role in biological wastewater treatment processes. Activated sludge settling characteristics, for example, are affected by microbial community composition, varying by changes in operating conditions and influent characteristics of wastewater treatment plants (WWTPs). Timely assessment and prediction of changes in microbial composition leading to settling problems, such as filamentous bulking (FB), can prevent operational challenges, reductions in treatment efficiency, and adverse environmental impacts. This study presents an innovative computer vision-based approach to assess activated sludge-settling characteristics based on the morphological properties of flocs and filaments in microscopy images. Implementing the transfer learning of deep convolutional neural network (CNN) models, this approach aims to overcome the limitations of existing quantitative image analysis techniques. The offline microscopy image dataset was collected over two years, with weekly sampling at a full-scale industrial WWTP in Belgium. Multiple data augmentation techniques were employed to enhance the generalizability of the CNN models. Various CNN architectures, including Inception v3, ResNet18, ResNet152, ConvNeXt-nano, and ConvNeXt-S, were tested to evaluate their performance in predicting sludge settling characteristics. The sludge volume index was used as the final prediction variable, but the method can easily be adjusted to predict any other settling metric of choice. The results showed that the suggested CNN-based approach provides less labour-intensive, objective, and consistent assessments, while transfer learning notably minimises the training phase, resulting in a generalizable system that can be employed in real-time applications.","sentences":["Microbial communities play a key role in biological wastewater treatment processes.","Activated sludge settling characteristics, for example, are affected by microbial community composition, varying by changes in operating conditions and influent characteristics of wastewater treatment plants (WWTPs).","Timely assessment and prediction of changes in microbial composition leading to settling problems, such as filamentous bulking (FB), can prevent operational challenges, reductions in treatment efficiency, and adverse environmental impacts.","This study presents an innovative computer vision-based approach to assess activated sludge-settling characteristics based on the morphological properties of flocs and filaments in microscopy images.","Implementing the transfer learning of deep convolutional neural network (CNN) models, this approach aims to overcome the limitations of existing quantitative image analysis techniques.","The offline microscopy image dataset was collected over two years, with weekly sampling at a full-scale industrial WWTP in Belgium.","Multiple data augmentation techniques were employed to enhance the generalizability of the CNN models.","Various CNN architectures, including Inception v3, ResNet18, ResNet152, ConvNeXt-nano, and ConvNeXt-S, were tested to evaluate their performance in predicting sludge settling characteristics.","The sludge volume index was used as the final prediction variable, but the method can easily be adjusted to predict any other settling metric of choice.","The results showed that the suggested CNN-based approach provides less labour-intensive, objective, and consistent assessments, while transfer learning notably minimises the training phase, resulting in a generalizable system that can be employed in real-time applications."],"url":"http://arxiv.org/abs/2402.09367v1"}
{"created":"2024-02-14 18:04:36","title":"HiRE: High Recall Approximate Top-$k$ Estimation for Efficient LLM Inference","abstract":"Autoregressive decoding with generative Large Language Models (LLMs) on accelerators (GPUs/TPUs) is often memory-bound where most of the time is spent on transferring model parameters from high bandwidth memory (HBM) to cache. On the other hand, recent works show that LLMs can maintain quality with significant sparsity/redundancy in the feedforward (FFN) layers by appropriately training the model to operate on a top-$k$ fraction of rows/columns (where $k \\approx 0.05$), there by suggesting a way to reduce the transfer of model parameters, and hence latency. However, exploiting this sparsity for improving latency is hindered by the fact that identifying top rows/columns is data-dependent and is usually performed using full matrix operations, severely limiting potential gains. To address these issues, we introduce HiRE (High Recall Approximate Top-k Estimation). HiRE comprises of two novel components: (i) a compression scheme to cheaply predict top-$k$ rows/columns with high recall, followed by full computation restricted to the predicted subset, and (ii) DA-TOP-$k$: an efficient multi-device approximate top-$k$ operator. We demonstrate that on a one billion parameter model, HiRE applied to both the softmax as well as feedforward layers, achieves almost matching pretraining and downstream accuracy, and speeds up inference latency by $1.47\\times$ on a single TPUv5e device.","sentences":["Autoregressive decoding with generative Large Language Models (LLMs) on accelerators (GPUs/TPUs) is often memory-bound where most of the time is spent on transferring model parameters from high bandwidth memory (HBM) to cache.","On the other hand, recent works show that LLMs can maintain quality with significant sparsity/redundancy in the feedforward (FFN) layers by appropriately training the model to operate on a top-$k$ fraction of rows/columns (where","$k \\approx 0.05$), there by suggesting a way to reduce the transfer of model parameters, and hence latency.","However, exploiting this sparsity for improving latency is hindered by the fact that identifying top rows/columns is data-dependent and is usually performed using full matrix operations, severely limiting potential gains.","To address these issues, we introduce HiRE (High Recall Approximate Top-k Estimation).","HiRE comprises of two novel components: (i) a compression scheme to cheaply predict top-$k$ rows/columns with high recall, followed by full computation restricted to the predicted subset, and (ii) DA-TOP-$k$: an efficient multi-device approximate top-$k$ operator.","We demonstrate that on a one billion parameter model, HiRE applied to both the softmax as well as feedforward layers, achieves almost matching pretraining and downstream accuracy, and speeds up inference latency by $1.47\\times$ on a single TPUv5e device."],"url":"http://arxiv.org/abs/2402.09360v1"}
{"created":"2024-02-14 18:02:24","title":"Integrating ChatGPT into Secure Hospital Networks: A Case Study on Improving Radiology Report Analysis","abstract":"This study demonstrates the first in-hospital adaptation of a cloud-based AI, similar to ChatGPT, into a secure model for analyzing radiology reports, prioritizing patient data privacy. By employing a unique sentence-level knowledge distillation method through contrastive learning, we achieve over 95% accuracy in detecting anomalies. The model also accurately flags uncertainties in its predictions, enhancing its reliability and interpretability for physicians with certainty indicators. These advancements represent significant progress in developing secure and efficient AI tools for healthcare, suggesting a promising future for in-hospital AI applications with minimal supervision.","sentences":["This study demonstrates the first in-hospital adaptation of a cloud-based AI, similar to ChatGPT, into a secure model for analyzing radiology reports, prioritizing patient data privacy.","By employing a unique sentence-level knowledge distillation method through contrastive learning, we achieve over 95% accuracy in detecting anomalies.","The model also accurately flags uncertainties in its predictions, enhancing its reliability and interpretability for physicians with certainty indicators.","These advancements represent significant progress in developing secure and efficient AI tools for healthcare, suggesting a promising future for in-hospital AI applications with minimal supervision."],"url":"http://arxiv.org/abs/2402.09358v1"}
{"created":"2024-02-14 17:46:46","title":"Generating Diverse Translation with Perturbed kNN-MT","abstract":"Generating multiple translation candidates would enable users to choose the one that satisfies their needs. Although there has been work on diversified generation, there exists room for improving the diversity mainly because the previous methods do not address the overcorrection problem -- the model underestimates a prediction that is largely different from the training data, even if that prediction is likely. This paper proposes methods that generate more diverse translations by introducing perturbed k-nearest neighbor machine translation (kNN-MT). Our methods expand the search space of kNN-MT and help incorporate diverse words into candidates by addressing the overcorrection problem. Our experiments show that the proposed methods drastically improve candidate diversity and control the degree of diversity by tuning the perturbation's magnitude.","sentences":["Generating multiple translation candidates would enable users to choose the one that satisfies their needs.","Although there has been work on diversified generation, there exists room for improving the diversity mainly because the previous methods do not address the overcorrection problem -- the model underestimates a prediction that is largely different from the training data, even if that prediction is likely.","This paper proposes methods that generate more diverse translations by introducing perturbed k-nearest neighbor machine translation (kNN-MT).","Our methods expand the search space of kNN-MT and help incorporate diverse words into candidates by addressing the overcorrection problem.","Our experiments show that the proposed methods drastically improve candidate diversity and control the degree of diversity by tuning the perturbation's magnitude."],"url":"http://arxiv.org/abs/2402.09344v1"}
{"created":"2024-02-14 17:32:57","title":"A Modern Approach to Electoral Delimitation using the Quadtree Data Structure","abstract":"The boundaries of electoral constituencies for assembly and parliamentary seats are drafted using a process referred to as delimitation, which ensures fair and equal representation of all citizens. The current delimitation exercise suffers from a number of drawbacks viz. inefficiency, gerrymandering and an uneven seat-to-population ratio, owing to existing legal and constitutional dictates. The existing methods allocate seats to every state but remain silent about their actual shape and location within the state. The main purpose of this research is to study and analyse the performance of existing delimitation algorithms and further propose a potential solution, along with its merits, that involves using a computational model based on the quadtree data structure to automate the districting process by optimizing objective population criteria. The paper presents an approach to electoral delimitation using the quadtree data structure, which is used to partition a two-dimensional geographical space by recursively subdividing it into four quadrants or regions on the basis of population as a parameter value associated with the node. The quadtree makes use of a quadrant schema of the geographical space for representing constituencies, which not only keeps count of the allocated constituencies but also holds their location-specific information. The performance of the proposed algorithm is analysed and evaluated against existing techniques and proves to be an efficient solution in terms of algorithmic complexity and boundary visualisation to the process of political districting.","sentences":["The boundaries of electoral constituencies for assembly and parliamentary seats are drafted using a process referred to as delimitation, which ensures fair and equal representation of all citizens.","The current delimitation exercise suffers from a number of drawbacks viz.","inefficiency, gerrymandering and an uneven seat-to-population ratio, owing to existing legal and constitutional dictates.","The existing methods allocate seats to every state but remain silent about their actual shape and location within the state.","The main purpose of this research is to study and analyse the performance of existing delimitation algorithms and further propose a potential solution, along with its merits, that involves using a computational model based on the quadtree data structure to automate the districting process by optimizing objective population criteria.","The paper presents an approach to electoral delimitation using the quadtree data structure, which is used to partition a two-dimensional geographical space by recursively subdividing it into four quadrants or regions on the basis of population as a parameter value associated with the node.","The quadtree makes use of a quadrant schema of the geographical space for representing constituencies, which not only keeps count of the allocated constituencies but also holds their location-specific information.","The performance of the proposed algorithm is analysed and evaluated against existing techniques and proves to be an efficient solution in terms of algorithmic complexity and boundary visualisation to the process of political districting."],"url":"http://arxiv.org/abs/2402.09336v1"}
{"created":"2024-02-14 17:17:30","title":"Information Complexity of Stochastic Convex Optimization: Applications to Generalization and Memorization","abstract":"In this work, we investigate the interplay between memorization and learning in the context of \\emph{stochastic convex optimization} (SCO). We define memorization via the information a learning algorithm reveals about its training data points. We then quantify this information using the framework of conditional mutual information (CMI) proposed by Steinke and Zakynthinou (2020). Our main result is a precise characterization of the tradeoff between the accuracy of a learning algorithm and its CMI, answering an open question posed by Livni (2023). We show that, in the $L^2$ Lipschitz--bounded setting and under strong convexity, every learner with an excess error $\\varepsilon$ has CMI bounded below by $\\Omega(1/\\varepsilon^2)$ and $\\Omega(1/\\varepsilon)$, respectively. We further demonstrate the essential role of memorization in learning problems in SCO by designing an adversary capable of accurately identifying a significant fraction of the training samples in specific SCO problems. Finally, we enumerate several implications of our results, such as a limitation of generalization bounds based on CMI and the incompressibility of samples in SCO problems.","sentences":["In this work, we investigate the interplay between memorization and learning in the context of \\emph{stochastic convex optimization} (SCO).","We define memorization via the information a learning algorithm reveals about its training data points.","We then quantify this information using the framework of conditional mutual information (CMI) proposed by Steinke and Zakynthinou (2020).","Our main result is a precise characterization of the tradeoff between the accuracy of a learning algorithm and its CMI, answering an open question posed by Livni (2023).","We show that, in the $L^2$ Lipschitz--bounded setting and under strong convexity, every learner with an excess error $\\varepsilon$ has CMI bounded below by $\\Omega(1/\\varepsilon^2)$ and $\\Omega(1/\\varepsilon)$, respectively.","We further demonstrate the essential role of memorization in learning problems in SCO by designing an adversary capable of accurately identifying a significant fraction of the training samples in specific SCO problems.","Finally, we enumerate several implications of our results, such as a limitation of generalization bounds based on CMI and the incompressibility of samples in SCO problems."],"url":"http://arxiv.org/abs/2402.09327v1"}
{"created":"2024-02-14 17:16:39","title":"PC-NeRF: Parent-Child Neural Radiance Fields Using Sparse LiDAR Frames in Autonomous Driving Environments","abstract":"Large-scale 3D scene reconstruction and novel view synthesis are vital for autonomous vehicles, especially utilizing temporally sparse LiDAR frames. However, conventional explicit representations remain a significant bottleneck towards representing the reconstructed and synthetic scenes at unlimited resolution. Although the recently developed neural radiance fields (NeRF) have shown compelling results in implicit representations, the problem of large-scale 3D scene reconstruction and novel view synthesis using sparse LiDAR frames remains unexplored. To bridge this gap, we propose a 3D scene reconstruction and novel view synthesis framework called parent-child neural radiance field (PC-NeRF). Based on its two modules, parent NeRF and child NeRF, the framework implements hierarchical spatial partitioning and multi-level scene representation, including scene, segment, and point levels. The multi-level scene representation enhances the efficient utilization of sparse LiDAR point cloud data and enables the rapid acquisition of an approximate volumetric scene representation. With extensive experiments, PC-NeRF is proven to achieve high-precision novel LiDAR view synthesis and 3D reconstruction in large-scale scenes. Moreover, PC-NeRF can effectively handle situations with sparse LiDAR frames and demonstrate high deployment efficiency with limited training epochs. Our approach implementation and the pre-trained models are available at https://github.com/biter0088/pc-nerf.","sentences":["Large-scale 3D scene reconstruction and novel view synthesis are vital for autonomous vehicles, especially utilizing temporally sparse LiDAR frames.","However, conventional explicit representations remain a significant bottleneck towards representing the reconstructed and synthetic scenes at unlimited resolution.","Although the recently developed neural radiance fields (NeRF) have shown compelling results in implicit representations, the problem of large-scale 3D scene reconstruction and novel view synthesis using sparse LiDAR frames remains unexplored.","To bridge this gap, we propose a 3D scene reconstruction and novel view synthesis framework called parent-child neural radiance field (PC-NeRF).","Based on its two modules, parent NeRF and child NeRF, the framework implements hierarchical spatial partitioning and multi-level scene representation, including scene, segment, and point levels.","The multi-level scene representation enhances the efficient utilization of sparse LiDAR point cloud data and enables the rapid acquisition of an approximate volumetric scene representation.","With extensive experiments, PC-NeRF is proven to achieve high-precision novel LiDAR view synthesis and 3D reconstruction in large-scale scenes.","Moreover, PC-NeRF can effectively handle situations with sparse LiDAR frames and demonstrate high deployment efficiency with limited training epochs.","Our approach implementation and the pre-trained models are available at https://github.com/biter0088/pc-nerf."],"url":"http://arxiv.org/abs/2402.09325v1"}
{"created":"2024-02-14 17:13:36","title":"Leveraging Pre-Trained Autoencoders for Interpretable Prototype Learning of Music Audio","abstract":"We present PECMAE, an interpretable model for music audio classification based on prototype learning. Our model is based on a previous method, APNet, which jointly learns an autoencoder and a prototypical network. Instead, we propose to decouple both training processes. This enables us to leverage existing self-supervised autoencoders pre-trained on much larger data (EnCodecMAE), providing representations with better generalization. APNet allows prototypes' reconstruction to waveforms for interpretability relying on the nearest training data samples. In contrast, we explore using a diffusion decoder that allows reconstruction without such dependency. We evaluate our method on datasets for music instrument classification (Medley-Solos-DB) and genre recognition (GTZAN and a larger in-house dataset), the latter being a more challenging task not addressed with prototypical networks before. We find that the prototype-based models preserve most of the performance achieved with the autoencoder embeddings, while the sonification of prototypes benefits understanding the behavior of the classifier.","sentences":["We present PECMAE, an interpretable model for music audio classification based on prototype learning.","Our model is based on a previous method, APNet, which jointly learns an autoencoder and a prototypical network.","Instead, we propose to decouple both training processes.","This enables us to leverage existing self-supervised autoencoders pre-trained on much larger data (EnCodecMAE), providing representations with better generalization.","APNet allows prototypes' reconstruction to waveforms for interpretability relying on the nearest training data samples.","In contrast, we explore using a diffusion decoder that allows reconstruction without such dependency.","We evaluate our method on datasets for music instrument classification (Medley-Solos-DB) and genre recognition (GTZAN and a larger in-house dataset), the latter being a more challenging task not addressed with prototypical networks before.","We find that the prototype-based models preserve most of the performance achieved with the autoencoder embeddings, while the sonification of prototypes benefits understanding the behavior of the classifier."],"url":"http://arxiv.org/abs/2402.09318v1"}
{"created":"2024-02-14 17:11:52","title":"Only My Model On My Data: A Privacy Preserving Approach Protecting one Model and Deceiving Unauthorized Black-Box Models","abstract":"Deep neural networks are extensively applied to real-world tasks, such as face recognition and medical image classification, where privacy and data protection are critical. Image data, if not protected, can be exploited to infer personal or contextual information. Existing privacy preservation methods, like encryption, generate perturbed images that are unrecognizable to even humans. Adversarial attack approaches prohibit automated inference even for authorized stakeholders, limiting practical incentives for commercial and widespread adaptation. This pioneering study tackles an unexplored practical privacy preservation use case by generating human-perceivable images that maintain accurate inference by an authorized model while evading other unauthorized black-box models of similar or dissimilar objectives, and addresses the previous research gaps. The datasets employed are ImageNet, for image classification, Celeba-HQ dataset, for identity classification, and AffectNet, for emotion classification. Our results show that the generated images can successfully maintain the accuracy of a protected model and degrade the average accuracy of the unauthorized black-box models to 11.97%, 6.63%, and 55.51% on ImageNet, Celeba-HQ, and AffectNet datasets, respectively.","sentences":["Deep neural networks are extensively applied to real-world tasks, such as face recognition and medical image classification, where privacy and data protection are critical.","Image data, if not protected, can be exploited to infer personal or contextual information.","Existing privacy preservation methods, like encryption, generate perturbed images that are unrecognizable to even humans.","Adversarial attack approaches prohibit automated inference even for authorized stakeholders, limiting practical incentives for commercial and widespread adaptation.","This pioneering study tackles an unexplored practical privacy preservation use case by generating human-perceivable images that maintain accurate inference by an authorized model while evading other unauthorized black-box models of similar or dissimilar objectives, and addresses the previous research gaps.","The datasets employed are ImageNet, for image classification, Celeba-HQ dataset, for identity classification, and AffectNet, for emotion classification.","Our results show that the generated images can successfully maintain the accuracy of a protected model and degrade the average accuracy of the unauthorized black-box models to 11.97%, 6.63%, and 55.51% on ImageNet, Celeba-HQ, and AffectNet datasets, respectively."],"url":"http://arxiv.org/abs/2402.09316v1"}
{"created":"2024-02-14 17:10:01","title":"Few-Shot Object Detection with Sparse Context Transformers","abstract":"Few-shot detection is a major task in pattern recognition which seeks to localize objects using models trained with few labeled data. One of the mainstream few-shot methods is transfer learning which consists in pretraining a detection model in a source domain prior to its fine-tuning in a target domain. However, it is challenging for fine-tuned models to effectively identify new classes in the target domain, particularly when the underlying labeled training data are scarce. In this paper, we devise a novel sparse context transformer (SCT) that effectively leverages object knowledge in the source domain, and automatically learns a sparse context from only few training images in the target domain. As a result, it combines different relevant clues in order to enhance the discrimination power of the learned detectors and reduce class confusion. We evaluate the proposed method on two challenging few-shot object detection benchmarks, and empirical results show that the proposed method obtains competitive performance compared to the related state-of-the-art.","sentences":["Few-shot detection is a major task in pattern recognition which seeks to localize objects using models trained with few labeled data.","One of the mainstream few-shot methods is transfer learning which consists in pretraining a detection model in a source domain prior to its fine-tuning in a target domain.","However, it is challenging for fine-tuned models to effectively identify new classes in the target domain, particularly when the underlying labeled training data are scarce.","In this paper, we devise a novel sparse context transformer (SCT) that effectively leverages object knowledge in the source domain, and automatically learns a sparse context from only few training images in the target domain.","As a result, it combines different relevant clues in order to enhance the discrimination power of the learned detectors and reduce class confusion.","We evaluate the proposed method on two challenging few-shot object detection benchmarks, and empirical results show that the proposed method obtains competitive performance compared to the related state-of-the-art."],"url":"http://arxiv.org/abs/2402.09315v1"}
{"created":"2024-02-14 16:49:13","title":"Embracing the black box: Heading towards foundation models for causal discovery from time series data","abstract":"Causal discovery from time series data encompasses many existing solutions, including those based on deep learning techniques. However, these methods typically do not endorse one of the most prevalent paradigms in deep learning: End-to-end learning. To address this gap, we explore what we call Causal Pretraining. A methodology that aims to learn a direct mapping from multivariate time series to the underlying causal graphs in a supervised manner. Our empirical findings suggest that causal discovery in a supervised manner is possible, assuming that the training and test time series samples share most of their dynamics. More importantly, we found evidence that the performance of Causal Pretraining can increase with data and model size, even if the additional data do not share the same dynamics. Further, we provide examples where causal discovery for real-world data with causally pretrained neural networks is possible within limits. We argue that this hints at the possibility of a foundation model for causal discovery.","sentences":["Causal discovery from time series data encompasses many existing solutions, including those based on deep learning techniques.","However, these methods typically do not endorse one of the most prevalent paradigms in deep learning: End-to-end learning.","To address this gap, we explore what we call Causal Pretraining.","A methodology that aims to learn a direct mapping from multivariate time series to the underlying causal graphs in a supervised manner.","Our empirical findings suggest that causal discovery in a supervised manner is possible, assuming that the training and test time series samples share most of their dynamics.","More importantly, we found evidence that the performance of Causal Pretraining can increase with data and model size, even if the additional data do not share the same dynamics.","Further, we provide examples where causal discovery for real-world data with causally pretrained neural networks is possible within limits.","We argue that this hints at the possibility of a foundation model for causal discovery."],"url":"http://arxiv.org/abs/2402.09305v1"}
{"created":"2024-02-14 16:47:20","title":"Immediate generalisation in humans but a generalisation lag in deep neural networks$\\unicode{x2014}$evidence for representational divergence?","abstract":"Recent research has seen many behavioral comparisons between humans and deep neural networks (DNNs) in the domain of image classification. Often, comparison studies focus on the end-result of the learning process by measuring and comparing the similarities in the representations of object categories once they have been formed. However, the process of how these representations emerge$\\unicode{x2014}$that is, the behavioral changes and intermediate stages observed during the acquisition$\\unicode{x2014}$is less often directly and empirically compared.   Here we report a detailed investigation of how transferable representations are acquired in human observers and various classic and state-of-the-art DNNs. We develop a constrained supervised learning environment in which we align learning-relevant parameters such as starting point, input modality, available input data and the feedback provided. Across the whole learning process we evaluate and compare how well learned representations can be generalized to previously unseen test data.   Our findings indicate that in terms of absolute classification performance DNNs demonstrate a level of data efficiency comparable to$\\unicode{x2014}$and sometimes even exceeding that$\\unicode{x2014}$of human learners, challenging some prevailing assumptions in the field. However, comparisons across the entire learning process reveal significant representational differences: while DNNs' learning is characterized by a pronounced generalisation lag, humans appear to immediately acquire generalizable representations without a preliminary phase of learning training set-specific information that is only later transferred to novel data.","sentences":["Recent research has seen many behavioral comparisons between humans and deep neural networks (DNNs) in the domain of image classification.","Often, comparison studies focus on the end-result of the learning process by measuring and comparing the similarities in the representations of object categories once they have been formed.","However, the process of how these representations emerge$\\unicode{x2014}$that is, the behavioral changes and intermediate stages observed during the acquisition$\\unicode{x2014}$is less often directly and empirically compared.   ","Here we report a detailed investigation of how transferable representations are acquired in human observers and various classic and state-of-the-art DNNs.","We develop a constrained supervised learning environment in which we align learning-relevant parameters such as starting point, input modality, available input data and the feedback provided.","Across the whole learning process we evaluate and compare how well learned representations can be generalized to previously unseen test data.   ","Our findings indicate that in terms of absolute classification performance DNNs demonstrate a level of data efficiency comparable to$\\unicode{x2014}$and sometimes even exceeding that$\\unicode{x2014}$of human learners, challenging some prevailing assumptions in the field.","However, comparisons across the entire learning process reveal significant representational differences: while DNNs' learning is characterized by a pronounced generalisation lag, humans appear to immediately acquire generalizable representations without a preliminary phase of learning training set-specific information that is only later transferred to novel data."],"url":"http://arxiv.org/abs/2402.09303v1"}
{"created":"2024-02-14 16:21:47","title":"EcoVal: An Efficient Data Valuation Framework for Machine Learning","abstract":"Quantifying the value of data within a machine learning workflow can play a pivotal role in making more strategic decisions in machine learning initiatives. The existing Shapley value based frameworks for data valuation in machine learning are computationally expensive as they require considerable amount of repeated training of the model to obtain the Shapley value. In this paper, we introduce an efficient data valuation framework EcoVal, to estimate the value of data for machine learning models in a fast and practical manner. Instead of directly working with individual data sample, we determine the value of a cluster of similar data points. This value is further propagated amongst all the member cluster points. We show that the overall data value can be determined by estimating the intrinsic and extrinsic value of each data. This is enabled by formulating the performance of a model as a \\textit{production function}, a concept which is popularly used to estimate the amount of output based on factors like labor and capital in a traditional free economic market. We provide a formal proof of our valuation technique and elucidate the principles and mechanisms that enable its accelerated performance. We demonstrate the real-world applicability of our method by showcasing its effectiveness for both in-distribution and out-of-sample data. This work addresses one of the core challenges of efficient data valuation at scale in machine learning models.","sentences":["Quantifying the value of data within a machine learning workflow can play a pivotal role in making more strategic decisions in machine learning initiatives.","The existing Shapley value based frameworks for data valuation in machine learning are computationally expensive as they require considerable amount of repeated training of the model to obtain the Shapley value.","In this paper, we introduce an efficient data valuation framework EcoVal, to estimate the value of data for machine learning models in a fast and practical manner.","Instead of directly working with individual data sample, we determine the value of a cluster of similar data points.","This value is further propagated amongst all the member cluster points.","We show that the overall data value can be determined by estimating the intrinsic and extrinsic value of each data.","This is enabled by formulating the performance of a model as a \\textit{production function}, a concept which is popularly used to estimate the amount of output based on factors like labor and capital in a traditional free economic market.","We provide a formal proof of our valuation technique and elucidate the principles and mechanisms that enable its accelerated performance.","We demonstrate the real-world applicability of our method by showcasing its effectiveness for both in-distribution and out-of-sample data.","This work addresses one of the core challenges of efficient data valuation at scale in machine learning models."],"url":"http://arxiv.org/abs/2402.09288v1"}
{"created":"2024-02-14 16:19:09","title":"Nutrition Facts, Drug Facts, and Model Facts: Putting AI Ethics into Practice in Gun Violence Research","abstract":"Objective: Firearm injury research necessitates using data from often-exploited vulnerable populations of Black and Brown Americans. In order to minimize distrust, this study provides a framework for establishing AI trust and transparency with the general population. Methods: We propose a Model Facts template that is easily extendable and decomposes accuracy and demographics into standardized and minimally complex values. This framework allows general users to assess the validity and biases of a model without diving into technical model documentation. Examples: We apply the Model Facts template on two previously published models, a violence risk identification model and a suicide risk prediction model. We demonstrate the ease of accessing the appropriate information when the data is structured appropriately. Discussion: The Model Facts template is limited in its current form to human based data and biases. Like nutrition facts, it also will require some educational resources for users to grasp its full utility. Human computer interaction experiments should be conducted to ensure that the interaction between user interface and model interface is as desired. Conclusion: The Model Facts label is the first framework dedicated to establishing trust with end users and general population consumers. Implementation of Model Facts into firearm injury research will provide public health practitioners and those impacted by firearm injury greater faith in the tools the research provides.","sentences":["Objective: Firearm injury research necessitates using data from often-exploited vulnerable populations of Black and Brown Americans.","In order to minimize distrust, this study provides a framework for establishing AI trust and transparency with the general population.","Methods: We propose a Model Facts template that is easily extendable and decomposes accuracy and demographics into standardized and minimally complex values.","This framework allows general users to assess the validity and biases of a model without diving into technical model documentation.","Examples: We apply the Model Facts template on two previously published models, a violence risk identification model and a suicide risk prediction model.","We demonstrate the ease of accessing the appropriate information when the data is structured appropriately.","Discussion:","The Model Facts template is limited in its current form to human based data and biases.","Like nutrition facts, it also will require some educational resources for users to grasp its full utility.","Human computer interaction experiments should be conducted to ensure that the interaction between user interface and model interface is as desired.","Conclusion: The Model Facts label is the first framework dedicated to establishing trust with end users and general population consumers.","Implementation of Model Facts into firearm injury research will provide public health practitioners and those impacted by firearm injury greater faith in the tools the research provides."],"url":"http://arxiv.org/abs/2402.09286v1"}
{"created":"2024-02-14 16:10:45","title":"Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies","abstract":"The integration of Large Language Models (LLMs) like GPT-4 into traditional Natural Language Processing (NLP) tasks has opened new avenues for enhancing model performance while reducing the reliance on extensive human annotations. This paper presents a novel approach that leverages the Chain of Thought (CoT) prompting technique to distill knowledge from GPT-4, subsequently applying it to improve the efficiency and effectiveness of a smaller model, BERT, on Named Entity Recognition (NER) tasks. Our method involves a two-phase training process: initially employing GPT-4 annotated data for pre-training and then refining the model with a combination of distilled and original human-annotated data. The results demonstrate that our mixed-training strategy significantly outperforms models trained solely on human annotations, achieving superior F1-scores and showcasing a cost-effective solution for resource-limited or closed-network settings. The study also discusses the challenges encountered, such as LLM output variability and the tendency towards hallucinations, proposing future work directions to enhance prompt design and annotation selection. Our findings indicate a promising synergy between LLM insights and traditional NLP techniques, paving the way for more accessible and robust NLP applications.","sentences":["The integration of Large Language Models (LLMs) like GPT-4 into traditional Natural Language Processing (NLP) tasks has opened new avenues for enhancing model performance while reducing the reliance on extensive human annotations.","This paper presents a novel approach that leverages the Chain of Thought (CoT) prompting technique to distill knowledge from GPT-4, subsequently applying it to improve the efficiency and effectiveness of a smaller model, BERT, on Named Entity Recognition (NER) tasks.","Our method involves a two-phase training process: initially employing GPT-4 annotated data for pre-training and then refining the model with a combination of distilled and original human-annotated data.","The results demonstrate that our mixed-training strategy significantly outperforms models trained solely on human annotations, achieving superior F1-scores and showcasing a cost-effective solution for resource-limited or closed-network settings.","The study also discusses the challenges encountered, such as LLM output variability and the tendency towards hallucinations, proposing future work directions to enhance prompt design and annotation selection.","Our findings indicate a promising synergy between LLM insights and traditional NLP techniques, paving the way for more accessible and robust NLP applications."],"url":"http://arxiv.org/abs/2402.09282v1"}
{"created":"2024-02-14 16:10:42","title":"Synergistic eigenanalysis of covariance and Hessian matrices for enhanced binary classification","abstract":"Covariance and Hessian matrices have been analyzed separately in the literature for classification problems. However, integrating these matrices has the potential to enhance their combined power in improving classification performance. We present a novel approach that combines the eigenanalysis of a covariance matrix evaluated on a training set with a Hessian matrix evaluated on a deep learning model to achieve optimal class separability in binary classification tasks. Our approach is substantiated by formal proofs that establish its capability to maximize between-class mean distance and minimize within-class variances. By projecting data into the combined space of the most relevant eigendirections from both matrices, we achieve optimal class separability as per the linear discriminant analysis (LDA) criteria. Empirical validation across neural and health datasets consistently supports our theoretical framework and demonstrates that our method outperforms established methods. Our method stands out by addressing both LDA criteria, unlike PCA and the Hessian method, which predominantly emphasize one criterion each. This comprehensive approach captures intricate patterns and relationships, enhancing classification performance. Furthermore, through the utilization of both LDA criteria, our method outperforms LDA itself by leveraging higher-dimensional feature spaces, in accordance with Cover's theorem, which favors linear separability in higher dimensions. Our method also surpasses kernel-based methods and manifold learning techniques in performance. Additionally, our approach sheds light on complex DNN decision-making, rendering them comprehensible within a 2D space.","sentences":["Covariance and Hessian matrices have been analyzed separately in the literature for classification problems.","However, integrating these matrices has the potential to enhance their combined power in improving classification performance.","We present a novel approach that combines the eigenanalysis of a covariance matrix evaluated on a training set with a Hessian matrix evaluated on a deep learning model to achieve optimal class separability in binary classification tasks.","Our approach is substantiated by formal proofs that establish its capability to maximize between-class mean distance and minimize within-class variances.","By projecting data into the combined space of the most relevant eigendirections from both matrices, we achieve optimal class separability as per the linear discriminant analysis (LDA) criteria.","Empirical validation across neural and health datasets consistently supports our theoretical framework and demonstrates that our method outperforms established methods.","Our method stands out by addressing both LDA criteria, unlike PCA and the Hessian method, which predominantly emphasize one criterion each.","This comprehensive approach captures intricate patterns and relationships, enhancing classification performance.","Furthermore, through the utilization of both LDA criteria, our method outperforms LDA itself by leveraging higher-dimensional feature spaces, in accordance with Cover's theorem, which favors linear separability in higher dimensions.","Our method also surpasses kernel-based methods and manifold learning techniques in performance.","Additionally, our approach sheds light on complex DNN decision-making, rendering them comprehensible within a 2D space."],"url":"http://arxiv.org/abs/2402.09281v1"}
{"created":"2024-02-14 15:59:24","title":"Insights and caveats from mining local and global temporal motifs in cryptocurrency transaction networks","abstract":"Distributed ledger technologies have opened up a wealth of fine-grained transaction data from cryptocurrencies like Bitcoin and Ethereum. This allows research into problems like anomaly detection, anti-money laundering, pattern mining and activity clustering (where data from traditional currencies is rarely available). The formalism of temporal networks offers a natural way of representing this data and offers access to a wealth of metrics and models. However, the large scale of the data presents a challenge using standard graph analysis techniques. We use temporal motifs to analyse two Bitcoin datasets and one NFT dataset, using sequences of three transactions and up to three users. We show that the commonly used technique of simply counting temporal motifs over all users and all time can give misleading conclusions. Here we also study the motifs contributed by each user and discover that the motif distribution is heavy-tailed and that the key players have diverse motif signatures. We study the motifs that occur in different time periods and find events and anomalous activity that cannot be seen just by a count on the whole dataset. Studying motif completion time reveals dynamics driven by human behaviour as well as algorithmic behaviour.","sentences":["Distributed ledger technologies have opened up a wealth of fine-grained transaction data from cryptocurrencies like Bitcoin and Ethereum.","This allows research into problems like anomaly detection, anti-money laundering, pattern mining and activity clustering (where data from traditional currencies is rarely available).","The formalism of temporal networks offers a natural way of representing this data and offers access to a wealth of metrics and models.","However, the large scale of the data presents a challenge using standard graph analysis techniques.","We use temporal motifs to analyse two Bitcoin datasets and one NFT dataset, using sequences of three transactions and up to three users.","We show that the commonly used technique of simply counting temporal motifs over all users and all time can give misleading conclusions.","Here we also study the motifs contributed by each user and discover that the motif distribution is heavy-tailed and that the key players have diverse motif signatures.","We study the motifs that occur in different time periods and find events and anomalous activity that cannot be seen just by a count on the whole dataset.","Studying motif completion time reveals dynamics driven by human behaviour as well as algorithmic behaviour."],"url":"http://arxiv.org/abs/2402.09272v1"}
{"created":"2024-02-14 15:59:22","title":"Hybrid Machine Learning techniques in the management of harmful algal blooms impact","abstract":"Harmful algal blooms (HABs) are episodes of high concentrations of algae that are potentially toxic for human consumption. Mollusc farming can be affected by HABs because, as filter feeders, they can accumulate high concentrations of marine biotoxins in their tissues. To avoid the risk to human consumption, harvesting is prohibited when toxicity is detected. At present, the closure of production areas is based on expert knowledge and the existence of a predictive model would help when conditions are complex and sampling is not possible. Although the concentration of toxin in meat is the method most commonly used by experts in the control of shellfish production areas, it is rarely used as a target by automatic prediction models. This is largely due to the irregularity of the data due to the established sampling programs. As an alternative, the activity status of production areas has been proposed as a target variable based on whether mollusc meat has a toxicity level below or above the legal limit. This new option is the most similar to the actual functioning of the control of shellfish production areas. For this purpose, we have made a comparison between hybrid machine learning models like Neural-Network-Adding Bootstrap (BAGNET) and Discriminative Nearest Neighbor Classification (SVM-KNN) when estimating the state of production areas. The study has been carried out in several estuaries with different levels of complexity in the episodes of algal blooms to demonstrate the generalization capacity of the models in bloom detection. As a result, we could observe that, with an average recall value of 93.41% and without dropping below 90% in any of the estuaries, BAGNET outperforms the other models both in terms of results and robustness.","sentences":["Harmful algal blooms (HABs) are episodes of high concentrations of algae that are potentially toxic for human consumption.","Mollusc farming can be affected by HABs because, as filter feeders, they can accumulate high concentrations of marine biotoxins in their tissues.","To avoid the risk to human consumption, harvesting is prohibited when toxicity is detected.","At present, the closure of production areas is based on expert knowledge and the existence of a predictive model would help when conditions are complex and sampling is not possible.","Although the concentration of toxin in meat is the method most commonly used by experts in the control of shellfish production areas, it is rarely used as a target by automatic prediction models.","This is largely due to the irregularity of the data due to the established sampling programs.","As an alternative, the activity status of production areas has been proposed as a target variable based on whether mollusc meat has a toxicity level below or above the legal limit.","This new option is the most similar to the actual functioning of the control of shellfish production areas.","For this purpose, we have made a comparison between hybrid machine learning models like Neural-Network-Adding Bootstrap (BAGNET) and Discriminative Nearest Neighbor Classification (SVM-KNN) when estimating the state of production areas.","The study has been carried out in several estuaries with different levels of complexity in the episodes of algal blooms to demonstrate the generalization capacity of the models in bloom detection.","As a result, we could observe that, with an average recall value of 93.41% and without dropping below 90% in any of the estuaries, BAGNET outperforms the other models both in terms of results and robustness."],"url":"http://arxiv.org/abs/2402.09271v1"}
{"created":"2024-02-14 15:51:55","title":"Computational Complexity of Preferred Subset Repairs on Data-Graphs","abstract":"The problem of repairing inconsistent knowledge bases has a long history within the communities of database theory and knowledge representation and reasoning, especially from the perspective of structured data. However, as the data available in real-world domains becomes more complex and interconnected, the need naturally arises for developing new types of repositories, representation languages, and semantics, to allow for more suitable ways to query and reason about it. Graph databases provide an effective way to represent relationships among semi-structured data, and allow processing and querying these connections efficiently. In this work, we focus on the problem of computing prioritized repairs over graph databases with data values, using a notion of consistency based on Reg-GXPath expressions as integrity constraints. We present several preference criteria based on the standard subset repair semantics, incorporating weights, multisets, and set-based priority levels. We study the most common repairing tasks, showing that it is possible to maintain the same computational complexity as in the case where no preference criterion is available for exploitation. To complete the picture, we explore the complexity of consistent query answering in this setting and obtain tight lower and upper bounds for all the preference criteria introduced.","sentences":["The problem of repairing inconsistent knowledge bases has a long history within the communities of database theory and knowledge representation and reasoning, especially from the perspective of structured data.","However, as the data available in real-world domains becomes more complex and interconnected, the need naturally arises for developing new types of repositories, representation languages, and semantics, to allow for more suitable ways to query and reason about it.","Graph databases provide an effective way to represent relationships among semi-structured data, and allow processing and querying these connections efficiently.","In this work, we focus on the problem of computing prioritized repairs over graph databases with data values, using a notion of consistency based on Reg-GXPath expressions as integrity constraints.","We present several preference criteria based on the standard subset repair semantics, incorporating weights, multisets, and set-based priority levels.","We study the most common repairing tasks, showing that it is possible to maintain the same computational complexity as in the case where no preference criterion is available for exploitation.","To complete the picture, we explore the complexity of consistent query answering in this setting and obtain tight lower and upper bounds for all the preference criteria introduced."],"url":"http://arxiv.org/abs/2402.09265v1"}
{"created":"2024-02-14 15:51:28","title":"UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers","abstract":"Traditional machine learning techniques are prone to generating inaccurate predictions when confronted with shifts in the distribution of data between the training and testing phases. This vulnerability can lead to severe consequences, especially in applications such as mobile healthcare. Uncertainty estimation has the potential to mitigate this issue by assessing the reliability of a model's output. However, existing uncertainty estimation techniques often require substantial computational resources and memory, making them impractical for implementation on microcontrollers (MCUs). This limitation hinders the feasibility of many important on-device wearable event detection (WED) applications, such as heart attack detection.   In this paper, we present UR2M, a novel Uncertainty and Resource-aware event detection framework for MCUs. Specifically, we (i) develop an uncertainty-aware WED based on evidential theory for accurate event detection and reliable uncertainty estimation; (ii) introduce a cascade ML framework to achieve efficient model inference via early exits, by sharing shallower model layers among different event models; (iii) optimize the deployment of the model and MCU library for system efficiency. We conducted extensive experiments and compared UR2M to traditional uncertainty baselines using three wearable datasets. Our results demonstrate that UR2M achieves up to 864% faster inference speed, 857% energy-saving for uncertainty estimation, 55% memory saving on two popular MCUs, and a 22% improvement in uncertainty quantification performance.   UR2M can be deployed on a wide range of MCUs, significantly expanding real-time and reliable WED applications.","sentences":["Traditional machine learning techniques are prone to generating inaccurate predictions when confronted with shifts in the distribution of data between the training and testing phases.","This vulnerability can lead to severe consequences, especially in applications such as mobile healthcare.","Uncertainty estimation has the potential to mitigate this issue by assessing the reliability of a model's output.","However, existing uncertainty estimation techniques often require substantial computational resources and memory, making them impractical for implementation on microcontrollers (MCUs).","This limitation hinders the feasibility of many important on-device wearable event detection (WED) applications, such as heart attack detection.   ","In this paper, we present UR2M, a novel Uncertainty and Resource-aware event detection framework for MCUs.","Specifically, we (i) develop an uncertainty-aware WED based on evidential theory for accurate event detection and reliable uncertainty estimation; (ii) introduce a cascade ML framework to achieve efficient model inference via early exits, by sharing shallower model layers among different event models; (iii) optimize the deployment of the model and MCU library for system efficiency.","We conducted extensive experiments and compared UR2M to traditional uncertainty baselines using three wearable datasets.","Our results demonstrate that UR2M achieves up to 864% faster inference speed, 857% energy-saving for uncertainty estimation, 55% memory saving on two popular MCUs, and a 22% improvement in uncertainty quantification performance.   ","UR2M can be deployed on a wide range of MCUs, significantly expanding real-time and reliable WED applications."],"url":"http://arxiv.org/abs/2402.09264v1"}
{"created":"2024-02-14 15:45:56","title":"SyntaxShap: Syntax-aware Explainability Method for Text Generation","abstract":"To harness the power of large language models in safety-critical domains we need to ensure the explainability of their predictions. However, despite the significant attention to model interpretability, there remains an unexplored domain in explaining sequence-to-sequence tasks using methods tailored for textual data. This paper introduces SyntaxShap, a local, model-agnostic explainability method for text generation that takes into consideration the syntax in the text data. The presented work extends Shapley values to account for parsing-based syntactic dependencies. Taking a game theoric approach, SyntaxShap only considers coalitions constraint by the dependency tree. We adopt a model-based evaluation to compare SyntaxShap and its weighted form to state-of-the-art explainability methods adapted to text generation tasks, using diverse metrics including faithfulness, complexity, coherency, and semantic alignment of the explanations to the model. We show that our syntax-aware method produces explanations that help build more faithful, coherent, and interpretable explanations for predictions by autoregressive models.","sentences":["To harness the power of large language models in safety-critical domains we need to ensure the explainability of their predictions.","However, despite the significant attention to model interpretability, there remains an unexplored domain in explaining sequence-to-sequence tasks using methods tailored for textual data.","This paper introduces SyntaxShap, a local, model-agnostic explainability method for text generation that takes into consideration the syntax in the text data.","The presented work extends Shapley values to account for parsing-based syntactic dependencies.","Taking a game theoric approach, SyntaxShap only considers coalitions constraint by the dependency tree.","We adopt a model-based evaluation to compare SyntaxShap and its weighted form to state-of-the-art explainability methods adapted to text generation tasks, using diverse metrics including faithfulness, complexity, coherency, and semantic alignment of the explanations to the model.","We show that our syntax-aware method produces explanations that help build more faithful, coherent, and interpretable explanations for predictions by autoregressive models."],"url":"http://arxiv.org/abs/2402.09259v1"}
{"created":"2024-02-14 15:32:07","title":"Efficient One-stage Video Object Detection by Exploiting Temporal Consistency","abstract":"Recently, one-stage detectors have achieved competitive accuracy and faster speed compared with traditional two-stage detectors on image data. However, in the field of video object detection (VOD), most existing VOD methods are still based on two-stage detectors. Moreover, directly adapting existing VOD methods to one-stage detectors introduces unaffordable computational costs. In this paper, we first analyse the computational bottlenecks of using one-stage detectors for VOD. Based on the analysis, we present a simple yet efficient framework to address the computational bottlenecks and achieve efficient one-stage VOD by exploiting the temporal consistency in video frames. Specifically, our method consists of a location-prior network to filter out background regions and a size-prior network to skip unnecessary computations on low-level feature maps for specific frames. We test our method on various modern one-stage detectors and conduct extensive experiments on the ImageNet VID dataset. Excellent experimental results demonstrate the superior effectiveness, efficiency, and compatibility of our method. The code is available at https://github.com/guanxiongsun/vfe.pytorch.","sentences":["Recently, one-stage detectors have achieved competitive accuracy and faster speed compared with traditional two-stage detectors on image data.","However, in the field of video object detection (VOD), most existing VOD methods are still based on two-stage detectors.","Moreover, directly adapting existing VOD methods to one-stage detectors introduces unaffordable computational costs.","In this paper, we first analyse the computational bottlenecks of using one-stage detectors for VOD.","Based on the analysis, we present a simple yet efficient framework to address the computational bottlenecks and achieve efficient one-stage VOD by exploiting the temporal consistency in video frames.","Specifically, our method consists of a location-prior network to filter out background regions and a size-prior network to skip unnecessary computations on low-level feature maps for specific frames.","We test our method on various modern one-stage detectors and conduct extensive experiments on the ImageNet VID dataset.","Excellent experimental results demonstrate the superior effectiveness, efficiency, and compatibility of our method.","The code is available at https://github.com/guanxiongsun/vfe.pytorch."],"url":"http://arxiv.org/abs/2402.09241v1"}
{"created":"2024-02-14 15:23:59","title":"Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models","abstract":"To build intelligent machine learning systems, there are two broad approaches. One approach is to build inherently interpretable models, as endeavored by the growing field of causal representation learning. The other approach is to build highly-performant foundation models and then invest efforts into understanding how they work. In this work, we relate these two approaches and study how to learn human-interpretable concepts from data. Weaving together ideas from both fields, we formally define a notion of concepts and show that they can be provably recovered from diverse data. Experiments on synthetic data and large language models show the utility of our unified approach.","sentences":["To build intelligent machine learning systems, there are two broad approaches.","One approach is to build inherently interpretable models, as endeavored by the growing field of causal representation learning.","The other approach is to build highly-performant foundation models and then invest efforts into understanding how they work.","In this work, we relate these two approaches and study how to learn human-interpretable concepts from data.","Weaving together ideas from both fields, we formally define a notion of concepts and show that they can be provably recovered from diverse data.","Experiments on synthetic data and large language models show the utility of our unified approach."],"url":"http://arxiv.org/abs/2402.09236v1"}
{"created":"2024-02-14 15:22:59","title":"Multi-Hierarchical Surrogate Learning for Structural Dynamical Crash Simulations Using Graph Convolutional Neural Networks","abstract":"Crash simulations play an essential role in improving vehicle safety, design optimization, and injury risk estimation. Unfortunately, numerical solutions of such problems using state-of-the-art high-fidelity models require significant computational effort. Conventional data-driven surrogate modeling approaches create low-dimensional embeddings for evolving the dynamics in order to circumvent this computational effort. Most approaches directly operate on high-resolution data obtained from numerical discretization, which is both costly and complicated for mapping the flow of information over large spatial distances. Furthermore, working with a fixed resolution prevents the adaptation of surrogate models to environments with variable computing capacities, different visualization resolutions, and different accuracy requirements. We thus propose a multi-hierarchical framework for structurally creating a series of surrogate models for a kart frame, which is a good proxy for industrial-relevant crash simulations, at different levels of resolution. For multiscale phenomena, macroscale features are captured on a coarse surrogate, whereas microscale effects are resolved by finer ones. The learned behavior of the individual surrogates is passed from coarse to finer levels through transfer learning. In detail, we perform a mesh simplification on the kart model to obtain multi-resolution representations of it. We then train a graph-convolutional neural network-based surrogate that learns parameter-dependent low-dimensional latent dynamics on the coarsest representation. Subsequently, another, similarly structured surrogate is trained on the residual of the first surrogate using a finer resolution. This step can be repeated multiple times. By doing so, we construct multiple surrogates for the same system with varying hardware requirements and increasing accuracy.","sentences":["Crash simulations play an essential role in improving vehicle safety, design optimization, and injury risk estimation.","Unfortunately, numerical solutions of such problems using state-of-the-art high-fidelity models require significant computational effort.","Conventional data-driven surrogate modeling approaches create low-dimensional embeddings for evolving the dynamics in order to circumvent this computational effort.","Most approaches directly operate on high-resolution data obtained from numerical discretization, which is both costly and complicated for mapping the flow of information over large spatial distances.","Furthermore, working with a fixed resolution prevents the adaptation of surrogate models to environments with variable computing capacities, different visualization resolutions, and different accuracy requirements.","We thus propose a multi-hierarchical framework for structurally creating a series of surrogate models for a kart frame, which is a good proxy for industrial-relevant crash simulations, at different levels of resolution.","For multiscale phenomena, macroscale features are captured on a coarse surrogate, whereas microscale effects are resolved by finer ones.","The learned behavior of the individual surrogates is passed from coarse to finer levels through transfer learning.","In detail, we perform a mesh simplification on the kart model to obtain multi-resolution representations of it.","We then train a graph-convolutional neural network-based surrogate that learns parameter-dependent low-dimensional latent dynamics on the coarsest representation.","Subsequently, another, similarly structured surrogate is trained on the residual of the first surrogate using a finer resolution.","This step can be repeated multiple times.","By doing so, we construct multiple surrogates for the same system with varying hardware requirements and increasing accuracy."],"url":"http://arxiv.org/abs/2402.09234v2"}
{"created":"2024-02-14 15:21:37","title":"Iterated Straight-Line Programs","abstract":"We explore an extension to straight-line programs (SLPs) that outperforms, for some text families, the measure $\\delta$ based on substring complexity, a lower bound for most measures and compressors exploiting repetitiveness (which are crucial in areas like Bioinformatics). The extension, called iterated SLPs (ISLPs), allows rules of the form $A \\rightarrow \\Pi_{i=k_1}^{k_2} B_1^{i^{c_1}}\\cdots B_t^{i^{c_t}}$, for which we show how to extract any substring of length $\\lambda$, from the represented text $T[1.. n]$, in time $O(\\lambda + \\log^2 n\\log\\log n)$. This is the first compressed representation for repetitive texts breaking $\\delta$ while, at the same time, supporting direct access to arbitrary text symbols in polylogarithmic time. As a byproduct, we extend Ganardi et al.'s technique to balance any SLP (so it has a derivation tree of logarithmic height) to a wide generalization of SLPs, including ISLPs.","sentences":["We explore an extension to straight-line programs (SLPs) that outperforms, for some text families, the measure $\\delta$ based on substring complexity, a lower bound for most measures and compressors exploiting repetitiveness (which are crucial in areas like Bioinformatics).","The extension, called iterated SLPs (ISLPs), allows rules of the form $A \\rightarrow \\Pi_{i=k_1}^{k_2} B_1^{i^{c_1}}\\cdots B_t^{i^{c_t}}$, for which we show how to extract any substring of length $\\lambda$, from the represented text $T[1.. n]$, in time $O(\\lambda + \\log^2 n\\log\\log","n)$. This is the first compressed representation for repetitive texts breaking $\\delta$ while, at the same time, supporting direct access to arbitrary text symbols in polylogarithmic time.","As a byproduct, we extend Ganardi et al.'s technique to balance any SLP (so it has a derivation tree of logarithmic height) to a wide generalization of SLPs, including ISLPs."],"url":"http://arxiv.org/abs/2402.09232v1"}
{"created":"2024-02-14 15:10:37","title":"Directional Convergence Near Small Initializations and Saddles in Two-Homogeneous Neural Networks","abstract":"This paper examines gradient flow dynamics of two-homogeneous neural networks for small initializations, where all weights are initialized near the origin. For both square and logistic losses, it is shown that for sufficiently small initializations, the gradient flow dynamics spend sufficient time in the neighborhood of the origin to allow the weights of the neural network to approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of a neural correlation function that quantifies the correlation between the output of the neural network and corresponding labels in the training data set. For square loss, it has been observed that neural networks undergo saddle-to-saddle dynamics when initialized close to the origin. Motivated by this, this paper also shows a similar directional convergence among weights of small magnitude in the neighborhood of certain saddle points.","sentences":["This paper examines gradient flow dynamics of two-homogeneous neural networks for small initializations, where all weights are initialized near the origin.","For both square and logistic losses, it is shown that for sufficiently small initializations, the gradient flow dynamics spend sufficient time in the neighborhood of the origin to allow the weights of the neural network to approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of a neural correlation function that quantifies the correlation between the output of the neural network and corresponding labels in the training data set.","For square loss, it has been observed that neural networks undergo saddle-to-saddle dynamics when initialized close to the origin.","Motivated by this, this paper also shows a similar directional convergence among weights of small magnitude in the neighborhood of certain saddle points."],"url":"http://arxiv.org/abs/2402.09226v1"}
{"created":"2024-02-14 15:09:01","title":"Is my Data in your AI Model? Membership Inference Test with Application to Face Images","abstract":"This paper introduces the Membership Inference Test (MINT), a novel approach that aims to empirically assess if specific data was used during the training of Artificial Intelligence (AI) models. Specifically, we propose two novel MINT architectures designed to learn the distinct activation patterns that emerge when an audited model is exposed to data used during its training process. The first architecture is based on a Multilayer Perceptron (MLP) network and the second one is based on Convolutional Neural Networks (CNNs). The proposed MINT architectures are evaluated on a challenging face recognition task, considering three state-of-the-art face recognition models. Experiments are carried out using six publicly available databases, comprising over 22 million face images in total. Also, different experimental scenarios are considered depending on the context available of the AI model to test. Promising results, up to 90% accuracy, are achieved using our proposed MINT approach, suggesting that it is possible to recognize if an AI model has been trained with specific data.","sentences":["This paper introduces the Membership Inference Test (MINT), a novel approach that aims to empirically assess if specific data was used during the training of Artificial Intelligence (AI) models.","Specifically, we propose two novel MINT architectures designed to learn the distinct activation patterns that emerge when an audited model is exposed to data used during its training process.","The first architecture is based on a Multilayer Perceptron (MLP) network and the second one is based on Convolutional Neural Networks (CNNs).","The proposed MINT architectures are evaluated on a challenging face recognition task, considering three state-of-the-art face recognition models.","Experiments are carried out using six publicly available databases, comprising over 22 million face images in total.","Also, different experimental scenarios are considered depending on the context available of the AI model to test.","Promising results, up to 90% accuracy, are achieved using our proposed MINT approach, suggesting that it is possible to recognize if an AI model has been trained with specific data."],"url":"http://arxiv.org/abs/2402.09225v1"}
{"created":"2024-02-14 14:57:25","title":"A case study of university student networks and the COVID-19 pandemic using a social network analysis approach in halls of residence","abstract":"The COVID-19 pandemic has meant that young university students have had to adapt their learning and have a reduced relational context. Adversity contexts build models of human behaviour based on relationships. However, there is a lack of studies that analyse the behaviour of university students based on their social structure in the context of a pandemic. This information could be useful in making decisions on how to plan collective responses to adversities. The Social Network Analysis (SNA) method has been chosen to address this structural perspective. The aim of our research is to describe the structural behaviour of students in university residences during the COVID-19 pandemic with a more in-depth analysis of student leaders. A descriptive cross-sectional study was carried out at one Spanish Public University, Le\\'on, from 23th October 2020 to 20th November 2020. The participation was of 93 students, from four halls of residence. The data were collected from a database created specifically at the university to \"track\" contacts in the COVID-19 pandemic, SiVeUle. We applied the SNA for the analysis of the data. The leadership on the university residence was measured using centrality measures. The top leaders were analyzed using the Egonetwork and an assessment of the key players. Students with higher social reputations experience higher levels of pandemic contagion in relation to COVID-19 infection. The results were statistically significant between the centrality in the network and the results of the COVID-19 infection. The most leading students showed a high degree of Betweenness, and three students had the key player structure in the network. Networking behaviour of university students in halls of residence could be related to contagion in the COVID-19 pandemic.","sentences":["The COVID-19 pandemic has meant that young university students have had to adapt their learning and have a reduced relational context.","Adversity contexts build models of human behaviour based on relationships.","However, there is a lack of studies that analyse the behaviour of university students based on their social structure in the context of a pandemic.","This information could be useful in making decisions on how to plan collective responses to adversities.","The Social Network Analysis (SNA) method has been chosen to address this structural perspective.","The aim of our research is to describe the structural behaviour of students in university residences during the COVID-19 pandemic with a more in-depth analysis of student leaders.","A descriptive cross-sectional study was carried out at one Spanish Public University, Le\\'on, from 23th October 2020 to 20th November 2020.","The participation was of 93 students, from four halls of residence.","The data were collected from a database created specifically at the university to \"track\" contacts in the COVID-19 pandemic, SiVeUle.","We applied the SNA for the analysis of the data.","The leadership on the university residence was measured using centrality measures.","The top leaders were analyzed using the Egonetwork and an assessment of the key players.","Students with higher social reputations experience higher levels of pandemic contagion in relation to COVID-19 infection.","The results were statistically significant between the centrality in the network and the results of the COVID-19 infection.","The most leading students showed a high degree of Betweenness, and three students had the key player structure in the network.","Networking behaviour of university students in halls of residence could be related to contagion in the COVID-19 pandemic."],"url":"http://arxiv.org/abs/2402.09219v1"}
{"created":"2024-02-14 14:48:28","title":"Identification of cohesive subgroups in a university hall of residence during the COVID-19 pandemic using a social network analysis approach","abstract":"The aims: (i) analyze connectivity between subgroups of university students, (ii) assess which bridges of relational contacts are essential for connecting or disconnecting subgroups and (iii) to explore the similarities between the attributes of the subgroup nodes in relation to the pandemic context. During the COVID-19 pandemic, young university students have experienced significant changes in their relationships, especially in the halls of residence. Previous research has shown the importance of relationship structure in contagion processes. However, there is a lack of studies in the university setting, where students live closely together. The case study methodology was applied to carry out a descriptive study. The participation consisted of 43 university students living in the same hall of residence. Social network analysis has been applied for data analysis. Factions and Girvan Newman algorithms have been applied to detect the existing cohesive subgroups. The UCINET tool was used for the calculation of the SNA measure. A visualization of the global network will be carried out using Gephi software. After applying the Girvan-Newman and Factions, in both cases it was found that the best division into subgroups was the one that divided the network into 4 subgroups. There is high degree of cohesion within the subgroups and a low cohesion between them. The relationship between subgroup membership and gender was significant. The degree of COVID-19 infection is related to the degree of clustering between the students. College students form subgroups in their residence. Social network analysis facilitates an understanding of structural behavior during the pandemic. The study provides evidence on the importance of gender, race and the building where they live in creating network structures that favor, or not, contagion during a pandemic.","sentences":["The aims: (i) analyze connectivity between subgroups of university students, (ii) assess which bridges of relational contacts are essential for connecting or disconnecting subgroups and (iii) to explore the similarities between the attributes of the subgroup nodes in relation to the pandemic context.","During the COVID-19 pandemic, young university students have experienced significant changes in their relationships, especially in the halls of residence.","Previous research has shown the importance of relationship structure in contagion processes.","However, there is a lack of studies in the university setting, where students live closely together.","The case study methodology was applied to carry out a descriptive study.","The participation consisted of 43 university students living in the same hall of residence.","Social network analysis has been applied for data analysis.","Factions and Girvan Newman algorithms have been applied to detect the existing cohesive subgroups.","The UCINET tool was used for the calculation of the SNA measure.","A visualization of the global network will be carried out using Gephi software.","After applying the Girvan-Newman and Factions, in both cases it was found that the best division into subgroups was the one that divided the network into 4 subgroups.","There is high degree of cohesion within the subgroups and a low cohesion between them.","The relationship between subgroup membership and gender was significant.","The degree of COVID-19 infection is related to the degree of clustering between the students.","College students form subgroups in their residence.","Social network analysis facilitates an understanding of structural behavior during the pandemic.","The study provides evidence on the importance of gender, race and the building where they live in creating network structures that favor, or not, contagion during a pandemic."],"url":"http://arxiv.org/abs/2402.09213v1"}
{"created":"2024-02-14 14:36:30","title":"Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents","abstract":"Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions. Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise user intentions. To bridge this gap, we introduce Intention-in-Interaction (IN3), a novel benchmark designed to inspect users' implicit intentions through explicit queries. Next, we propose the incorporation of model experts as the upstream in agent designs to enhance user-agent interaction. Employing IN3, we empirically train Mistral-Interact, a powerful model that proactively assesses task vagueness, inquires user intentions, and refines them into actionable goals before starting downstream agent task execution. Integrating it into the XAgent framework, we comprehensively evaluate the enhanced agent system regarding user instruction understanding and execution, revealing that our approach notably excels at identifying vague user tasks, recovering and summarizing critical missing information, setting precise and necessary agent execution goals, and minimizing redundant tool usage, thus boosting overall efficiency. All the data and codes are released.","sentences":["Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions.","Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise user intentions.","To bridge this gap, we introduce Intention-in-Interaction (IN3), a novel benchmark designed to inspect users' implicit intentions through explicit queries.","Next, we propose the incorporation of model experts as the upstream in agent designs to enhance user-agent interaction.","Employing IN3, we empirically train Mistral-Interact, a powerful model that proactively assesses task vagueness, inquires user intentions, and refines them into actionable goals before starting downstream agent task execution.","Integrating it into the XAgent framework, we comprehensively evaluate the enhanced agent system regarding user instruction understanding and execution, revealing that our approach notably excels at identifying vague user tasks, recovering and summarizing critical missing information, setting precise and necessary agent execution goals, and minimizing redundant tool usage, thus boosting overall efficiency.","All the data and codes are released."],"url":"http://arxiv.org/abs/2402.09205v1"}
{"created":"2024-02-14 14:35:57","title":"Domain-adaptive and Subgroup-specific Cascaded Temperature Regression for Out-of-distribution Calibration","abstract":"Although deep neural networks yield high classification accuracy given sufficient training data, their predictions are typically overconfident or under-confident, i.e., the prediction confidences cannot truly reflect the accuracy. Post-hoc calibration tackles this problem by calibrating the prediction confidences without re-training the classification model. However, current approaches assume congruence between test and validation data distributions, limiting their applicability to out-of-distribution scenarios. To this end, we propose a novel meta-set-based cascaded temperature regression method for post-hoc calibration. Our method tailors fine-grained scaling functions to distinct test sets by simulating various domain shifts through data augmentation on the validation set. We partition each meta-set into subgroups based on predicted category and confidence level, capturing diverse uncertainties. A regression network is then trained to derive category-specific and confidence-level-specific scaling, achieving calibration across meta-sets. Extensive experimental results on MNIST, CIFAR-10, and TinyImageNet demonstrate the effectiveness of the proposed method.","sentences":["Although deep neural networks yield high classification accuracy given sufficient training data, their predictions are typically overconfident or under-confident, i.e., the prediction confidences cannot truly reflect the accuracy.","Post-hoc calibration tackles this problem by calibrating the prediction confidences without re-training the classification model.","However, current approaches assume congruence between test and validation data distributions, limiting their applicability to out-of-distribution scenarios.","To this end, we propose a novel meta-set-based cascaded temperature regression method for post-hoc calibration.","Our method tailors fine-grained scaling functions to distinct test sets by simulating various domain shifts through data augmentation on the validation set.","We partition each meta-set into subgroups based on predicted category and confidence level, capturing diverse uncertainties.","A regression network is then trained to derive category-specific and confidence-level-specific scaling, achieving calibration across meta-sets.","Extensive experimental results on MNIST, CIFAR-10, and TinyImageNet demonstrate the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2402.09204v1"}
{"created":"2024-02-14 14:33:39","title":"Better-than-KL PAC-Bayes Bounds","abstract":"Let $f(\\theta, X_1),$ $ \\dots,$ $ f(\\theta, X_n)$ be a sequence of random elements, where $f$ is a fixed scalar function, $X_1, \\dots, X_n$ are independent random variables (data), and $\\theta$ is a random parameter distributed according to some data-dependent posterior distribution $P_n$. In this paper, we consider the problem of proving concentration inequalities to estimate the mean of the sequence. An example of such a problem is the estimation of the generalization error of some predictor trained by a stochastic algorithm, such as a neural network where $f$ is a loss function. Classically, this problem is approached through a PAC-Bayes analysis where, in addition to the posterior, we choose a prior distribution which captures our belief about the inductive bias of the learning problem. Then, the key quantity in PAC-Bayes concentration bounds is a divergence that captures the complexity of the learning problem where the de facto standard choice is the KL divergence. However, the tightness of this choice has rarely been questioned.   In this paper, we challenge the tightness of the KL-divergence-based bounds by showing that it is possible to achieve a strictly tighter bound. In particular, we demonstrate new high-probability PAC-Bayes bounds with a novel and better-than-KL divergence that is inspired by Zhang et al. (2022). Our proof is inspired by recent advances in regret analysis of gambling algorithms, and its use to derive concentration inequalities. Our result is first-of-its-kind in that existing PAC-Bayes bounds with non-KL divergences are not known to be strictly better than KL. Thus, we believe our work marks the first step towards identifying optimal rates of PAC-Bayes bounds.","sentences":["Let $f(\\theta, X_1),$ $ \\dots,$ $ f(\\theta, X_n)$ be a sequence of random elements, where $f$ is a fixed scalar function, $X_1, \\dots, X_n$ are independent random variables (data), and $\\theta$ is a random parameter distributed according to some data-dependent posterior distribution $P_n$. In this paper, we consider the problem of proving concentration inequalities to estimate the mean of the sequence.","An example of such a problem is the estimation of the generalization error of some predictor trained by a stochastic algorithm, such as a neural network where $f$ is a loss function.","Classically, this problem is approached through a PAC-Bayes analysis where, in addition to the posterior, we choose a prior distribution which captures our belief about the inductive bias of the learning problem.","Then, the key quantity in PAC-Bayes concentration bounds is a divergence that captures the complexity of the learning problem where the de facto standard choice is the KL divergence.","However, the tightness of this choice has rarely been questioned.   ","In this paper, we challenge the tightness of the KL-divergence-based bounds by showing that it is possible to achieve a strictly tighter bound.","In particular, we demonstrate new high-probability PAC-Bayes bounds with a novel and better-than-KL divergence that is inspired by Zhang et al. (2022).","Our proof is inspired by recent advances in regret analysis of gambling algorithms, and its use to derive concentration inequalities.","Our result is first-of-its-kind in that existing PAC-Bayes bounds with non-KL divergences are not known to be strictly better than KL.","Thus, we believe our work marks the first step towards identifying optimal rates of PAC-Bayes bounds."],"url":"http://arxiv.org/abs/2402.09201v1"}
{"created":"2024-02-14 14:33:17","title":"Discovering Command and Control (C2) Channels on Tor and Public Networks Using Reinforcement Learning","abstract":"Command and control (C2) channels are an essential component of many types of cyber attacks, as they enable attackers to remotely control their malware-infected machines and execute harmful actions, such as propagating malicious code across networks, exfiltrating confidential data, or initiating distributed denial of service (DDoS) attacks. Identifying these C2 channels is therefore crucial in helping to mitigate and prevent cyber attacks. However, identifying C2 channels typically involves a manual process, requiring deep knowledge and expertise in cyber operations. In this paper, we propose a reinforcement learning (RL) based approach to automatically emulate C2 attack campaigns using both the normal (public) and the Tor networks. In addition, payload size and network firewalls are configured to simulate real-world attack scenarios. Results on a typical network configuration show that the RL agent can automatically discover resilient C2 attack paths utilizing both Tor-based and conventional communication channels, while also bypassing network firewalls.","sentences":["Command and control (C2) channels are an essential component of many types of cyber attacks, as they enable attackers to remotely control their malware-infected machines and execute harmful actions, such as propagating malicious code across networks, exfiltrating confidential data, or initiating distributed denial of service (DDoS) attacks.","Identifying these C2 channels is therefore crucial in helping to mitigate and prevent cyber attacks.","However, identifying C2 channels typically involves a manual process, requiring deep knowledge and expertise in cyber operations.","In this paper, we propose a reinforcement learning (RL) based approach to automatically emulate C2 attack campaigns using both the normal (public) and the Tor networks.","In addition, payload size and network firewalls are configured to simulate real-world attack scenarios.","Results on a typical network configuration show that the RL agent can automatically discover resilient C2 attack paths utilizing both Tor-based and conventional communication channels, while also bypassing network firewalls."],"url":"http://arxiv.org/abs/2402.09200v1"}
{"created":"2024-02-14 14:27:52","title":"Implementing local-explainability in Gradient Boosting Trees: Feature Contribution","abstract":"Gradient Boost Decision Trees (GBDT) is a powerful additive model based on tree ensembles. Its nature makes GBDT a black-box model even though there are multiple explainable artificial intelligence (XAI) models obtaining information by reinterpreting the model globally and locally. Each tree of the ensemble is a transparent model itself but the final outcome is the result of a sum of these trees and it is not easy to clarify.   In this paper, a feature contribution method for GBDT is developed. The proposed method takes advantage of the GBDT architecture to calculate the contribution of each feature using the residue of each node. This algorithm allows to calculate the sequence of node decisions given a prediction.   Theoretical proofs and multiple experiments have been carried out to demonstrate the performance of our method which is not only a local explicability model for the GBDT algorithm but also a unique option that reflects GBDTs internal behavior. The proposal is aligned to the contribution of characteristics having impact in some artificial intelligence problems such as ethical analysis of Artificial Intelligence (AI) and comply with the new European laws such as the General Data Protection Regulation (GDPR) about the right to explain and nondiscrimination.","sentences":["Gradient Boost Decision Trees (GBDT) is a powerful additive model based on tree ensembles.","Its nature makes GBDT a black-box model even though there are multiple explainable artificial intelligence (XAI) models obtaining information by reinterpreting the model globally and locally.","Each tree of the ensemble is a transparent model itself but the final outcome is the result of a sum of these trees and it is not easy to clarify.   ","In this paper, a feature contribution method for GBDT is developed.","The proposed method takes advantage of the GBDT architecture to calculate the contribution of each feature using the residue of each node.","This algorithm allows to calculate the sequence of node decisions given a prediction.   ","Theoretical proofs and multiple experiments have been carried out to demonstrate the performance of our method which is not only a local explicability model for the GBDT algorithm but also a unique option that reflects GBDTs internal behavior.","The proposal is aligned to the contribution of characteristics having impact in some artificial intelligence problems such as ethical analysis of Artificial Intelligence (AI) and comply with the new European laws such as the General Data Protection Regulation (GDPR) about the right to explain and nondiscrimination."],"url":"http://arxiv.org/abs/2402.09197v1"}
{"created":"2024-02-14 14:17:21","title":"(Ir)rationality and Cognitive Biases in Large Language Models","abstract":"Do large language models (LLMs) display rational reasoning? LLMs have been shown to contain human biases due to the data they have been trained on; whether this is reflected in rational reasoning remains less clear. In this paper, we answer this question by evaluating seven language models using tasks from the cognitive psychology literature. We find that, like humans, LLMs display irrationality in these tasks. However, the way this irrationality is displayed does not reflect that shown by humans. When incorrect answers are given by LLMs to these tasks, they are often incorrect in ways that differ from human-like biases. On top of this, the LLMs reveal an additional layer of irrationality in the significant inconsistency of the responses. Aside from the experimental results, this paper seeks to make a methodological contribution by showing how we can assess and compare different capabilities of these types of models, in this case with respect to rational reasoning.","sentences":["Do large language models (LLMs) display rational reasoning?","LLMs have been shown to contain human biases due to the data they have been trained on; whether this is reflected in rational reasoning remains less clear.","In this paper, we answer this question by evaluating seven language models using tasks from the cognitive psychology literature.","We find that, like humans, LLMs display irrationality in these tasks.","However, the way this irrationality is displayed does not reflect that shown by humans.","When incorrect answers are given by LLMs to these tasks, they are often incorrect in ways that differ from human-like biases.","On top of this, the LLMs reveal an additional layer of irrationality in the significant inconsistency of the responses.","Aside from the experimental results, this paper seeks to make a methodological contribution by showing how we can assess and compare different capabilities of these types of models, in this case with respect to rational reasoning."],"url":"http://arxiv.org/abs/2402.09193v1"}
{"created":"2024-02-14 14:08:06","title":"Traj-LIO: A Resilient Multi-LiDAR Multi-IMU State Estimator Through Sparse Gaussian Process","abstract":"Nowadays, sensor suits have been equipped with redundant LiDARs and IMUs to mitigate the risks associated with sensor failure. It is challenging for the previous discrete-time and IMU-driven kinematic systems to incorporate multiple asynchronized sensors, which are susceptible to abnormal IMU data. To address these limitations, we introduce a multi-LiDAR multi-IMU state estimator by taking advantage of Gaussian Process (GP) that predicts a non-parametric continuous-time trajectory to capture sensors' spatial-temporal movement with limited control states. Since the kinematic model driven by three types of linear time-invariant stochastic differential equations are independent of external sensor measurements, our proposed approach is capable of handling different sensor configurations and resilient to sensor failures. Moreover, we replace the conventional $\\mathrm{SE}(3)$ state representation with the combination of $\\mathrm{SO}(3)$ and vector space, which enables GP-based LiDAR-inertial system to fulfill the real-time requirement. Extensive experiments on the public datasets demonstrate the versatility and resilience of our proposed multi-LiDAR multi-IMU state estimator. To contribute to the community, we will make our source code publicly available.","sentences":["Nowadays, sensor suits have been equipped with redundant LiDARs and IMUs to mitigate the risks associated with sensor failure.","It is challenging for the previous discrete-time and IMU-driven kinematic systems to incorporate multiple asynchronized sensors, which are susceptible to abnormal IMU data.","To address these limitations, we introduce a multi-LiDAR multi-IMU state estimator by taking advantage of Gaussian Process (GP) that predicts a non-parametric continuous-time trajectory to capture sensors' spatial-temporal movement with limited control states.","Since the kinematic model driven by three types of linear time-invariant stochastic differential equations are independent of external sensor measurements, our proposed approach is capable of handling different sensor configurations and resilient to sensor failures.","Moreover, we replace the conventional $\\mathrm{SE}(3)$ state representation with the combination of $\\mathrm{SO}(3)$ and vector space, which enables GP-based LiDAR-inertial system to fulfill the real-time requirement.","Extensive experiments on the public datasets demonstrate the versatility and resilience of our proposed multi-LiDAR multi-IMU state estimator.","To contribute to the community, we will make our source code publicly available."],"url":"http://arxiv.org/abs/2402.09189v1"}
{"created":"2024-02-14 13:36:20","title":"Evolving Restricted Boltzmann Machine-Kohonen Network for Online Clustering","abstract":"A novel online clustering algorithm is presented where an Evolving Restricted Boltzmann Machine (ERBM) is embedded with a Kohonen Network called ERBM-KNet. The proposed ERBM-KNet efficiently handles streaming data in a single-pass mode using the ERBM, employing a bias-variance strategy for neuron growing and pruning, as well as online clustering based on a cluster update strategy for cluster prediction and cluster center update using KNet. Initially, ERBM evolves its architecture while processing unlabeled image data, effectively disentangling the data distribution in the latent space. Subsequently, the KNet utilizes the feature extracted from ERBM to predict the number of clusters and updates the cluster centers. By overcoming the common challenges associated with clustering algorithms, such as prior initialization of the number of clusters and subpar clustering accuracy, the proposed ERBM-KNet offers significant improvements. Extensive experimental evaluations on four benchmarks and one industry dataset demonstrate the superiority of ERBM-KNet compared to state-of-the-art approaches.","sentences":["A novel online clustering algorithm is presented where an Evolving Restricted Boltzmann Machine (ERBM) is embedded with a Kohonen Network called ERBM-KNet.","The proposed ERBM-KNet efficiently handles streaming data in a single-pass mode using the ERBM, employing a bias-variance strategy for neuron growing and pruning, as well as online clustering based on a cluster update strategy for cluster prediction and cluster center update using KNet.","Initially, ERBM evolves its architecture while processing unlabeled image data, effectively disentangling the data distribution in the latent space.","Subsequently, the KNet utilizes the feature extracted from ERBM to predict the number of clusters and updates the cluster centers.","By overcoming the common challenges associated with clustering algorithms, such as prior initialization of the number of clusters and subpar clustering accuracy, the proposed ERBM-KNet offers significant improvements.","Extensive experimental evaluations on four benchmarks and one industry dataset demonstrate the superiority of ERBM-KNet compared to state-of-the-art approaches."],"url":"http://arxiv.org/abs/2402.09167v1"}
{"created":"2024-02-14 13:32:23","title":"Deinterleaving of Discrete Renewal Process Mixtures with Application to Electronic Support Measures","abstract":"In this paper, we propose a new deinterleaving method for mixtures of discrete renewal Markov chains. This method relies on the maximization of a penalized likelihood score. It exploits all available information about both the sequence of the different symbols and their arrival times. A theoretical analysis is carried out to prove that minimizing this score allows to recover the true partition of symbols in the large sample limit, under mild conditions on the component processes. This theoretical analysis is then validated by experiments on synthetic data. Finally, the method is applied to deinterleave pulse trains received from different emitters in a RESM (Radar Electronic Support Measurements) context and we show that the proposed method competes favorably with state-of-the-art methods on simulated warfare datasets.","sentences":["In this paper, we propose a new deinterleaving method for mixtures of discrete renewal Markov chains.","This method relies on the maximization of a penalized likelihood score.","It exploits all available information about both the sequence of the different symbols and their arrival times.","A theoretical analysis is carried out to prove that minimizing this score allows to recover the true partition of symbols in the large sample limit, under mild conditions on the component processes.","This theoretical analysis is then validated by experiments on synthetic data.","Finally, the method is applied to deinterleave pulse trains received from different emitters in a RESM (Radar Electronic Support Measurements) context and we show that the proposed method competes favorably with state-of-the-art methods on simulated warfare datasets."],"url":"http://arxiv.org/abs/2402.09166v1"}
{"created":"2024-02-14 13:31:53","title":"Unifying Invariance and Spuriousity for Graph Out-of-Distribution via Probability of Necessity and Sufficiency","abstract":"Graph Out-of-Distribution (OOD), requiring that models trained on biased data generalize to the unseen test data, has a massive of real-world applications. One of the most mainstream methods is to extract the invariant subgraph by aligning the original and augmented data with the help of environment augmentation. However, these solutions might lead to the loss or redundancy of semantic subgraph and further result in suboptimal generalization. To address this challenge, we propose a unified framework to exploit the Probability of Necessity and Sufficiency to extract the Invariant Substructure (PNSIS). Beyond that, this framework further leverages the spurious subgraph to boost the generalization performance in an ensemble manner to enhance the robustness on the noise data. Specificially, we first consider the data generation process for graph data. Under mild conditions, we show that the invariant subgraph can be extracted by minimizing an upper bound, which is built on the theoretical advance of probability of necessity and sufficiency. To further bridge the theory and algorithm, we devise the PNSIS model, which involves an invariant subgraph extractor for invariant graph learning as well invariant and spurious subgraph classifiers for generalization enhancement. Experimental results demonstrate that our \\textbf{PNSIS} model outperforms the state-of-the-art techniques on graph OOD on several benchmarks, highlighting the effectiveness in real-world scenarios.","sentences":["Graph Out-of-Distribution (OOD), requiring that models trained on biased data generalize to the unseen test data, has a massive of real-world applications.","One of the most mainstream methods is to extract the invariant subgraph by aligning the original and augmented data with the help of environment augmentation.","However, these solutions might lead to the loss or redundancy of semantic subgraph and further result in suboptimal generalization.","To address this challenge, we propose a unified framework to exploit the Probability of Necessity and Sufficiency to extract the Invariant Substructure (PNSIS).","Beyond that, this framework further leverages the spurious subgraph to boost the generalization performance in an ensemble manner to enhance the robustness on the noise data.","Specificially, we first consider the data generation process for graph data.","Under mild conditions, we show that the invariant subgraph can be extracted by minimizing an upper bound, which is built on the theoretical advance of probability of necessity and sufficiency.","To further bridge the theory and algorithm, we devise the PNSIS model, which involves an invariant subgraph extractor for invariant graph learning as well invariant and spurious subgraph classifiers for generalization enhancement.","Experimental results demonstrate that our \\textbf{PNSIS} model outperforms the state-of-the-art techniques on graph OOD on several benchmarks, highlighting the effectiveness in real-world scenarios."],"url":"http://arxiv.org/abs/2402.09165v1"}
{"created":"2024-02-14 13:20:24","title":"Wireless Crowd Detection for Smart Overtourism Mitigation","abstract":"Overtourism occurs when the number of tourists exceeds the carrying capacity of a destination, leading to negative impacts on the environment, culture, and quality of life for residents. By monitoring overtourism, destination managers can identify areas of concern and implement measures to mitigate the negative impacts of tourism while promoting smarter tourism practices. This can help ensure that tourism benefits both visitors and residents while preserving the natural and cultural resources that make these destinations so appealing.   This chapter describes a low-cost approach to monitoring overtourism based on mobile devices' wireless activity. A flexible architecture was designed for a smart tourism toolkit to be used by Small and Medium-sized Enterprises (SMEs) in crowding management solutions, to build better tourism services, improve efficiency and sustainability, and reduce the overwhelming feeling of pressure in critical hotspots.   The crowding sensors count the number of surrounding mobile devices, by detecting trace elements of wireless technologies, mitigating the effect of MAC address randomization. They run detection programs for several technologies, and fingerprinting analysis results are only stored locally in an anonymized database, without infringing privacy rights. After that edge computing, sensors communicate the crowding information to a cloud server, by using a variety of uplink techniques to mitigate local connectivity limitations, something that has been often disregarded in alternative approaches.   Field validation of sensors has been performed on Iscte's campus. Preliminary results show that these sensors can be deployed in multiple scenarios and provide a diversity of spatio-temporal crowding data that can scaffold tourism overcrowding management strategies.","sentences":["Overtourism occurs when the number of tourists exceeds the carrying capacity of a destination, leading to negative impacts on the environment, culture, and quality of life for residents.","By monitoring overtourism, destination managers can identify areas of concern and implement measures to mitigate the negative impacts of tourism while promoting smarter tourism practices.","This can help ensure that tourism benefits both visitors and residents while preserving the natural and cultural resources that make these destinations so appealing.   ","This chapter describes a low-cost approach to monitoring overtourism based on mobile devices' wireless activity.","A flexible architecture was designed for a smart tourism toolkit to be used by Small and Medium-sized Enterprises (SMEs) in crowding management solutions, to build better tourism services, improve efficiency and sustainability, and reduce the overwhelming feeling of pressure in critical hotspots.   ","The crowding sensors count the number of surrounding mobile devices, by detecting trace elements of wireless technologies, mitigating the effect of MAC address randomization.","They run detection programs for several technologies, and fingerprinting analysis results are only stored locally in an anonymized database, without infringing privacy rights.","After that edge computing, sensors communicate the crowding information to a cloud server, by using a variety of uplink techniques to mitigate local connectivity limitations, something that has been often disregarded in alternative approaches.   ","Field validation of sensors has been performed on Iscte's campus.","Preliminary results show that these sensors can be deployed in multiple scenarios and provide a diversity of spatio-temporal crowding data that can scaffold tourism overcrowding management strategies."],"url":"http://arxiv.org/abs/2402.09158v1"}
{"created":"2024-02-14 13:08:25","title":"Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for Chinese Mental Health Text Analysis","abstract":"In the current environment, psychological issues are prevalent and widespread, with social media serving as a key outlet for individuals to share their feelings. This results in the generation of vast quantities of data daily, where negative emotions have the potential to precipitate crisis situations. There is a recognized need for models capable of efficient analysis. While pre-trained language models have demonstrated their effectiveness broadly, there's a noticeable gap in pre-trained models tailored for specialized domains like psychology. To address this, we have collected a huge dataset from Chinese social media platforms and enriched it with publicly available datasets to create a comprehensive database encompassing 3.36 million text entries. To enhance the model's applicability to psychological text analysis, we integrated psychological lexicons into the pre-training masking mechanism. Building on an existing Chinese language model, we performed adaptive training to develop a model specialized for the psychological domain. We assessed our model's effectiveness across four public benchmarks, where it not only surpassed the performance of standard pre-trained models but also showed a inclination for making psychologically relevant predictions. Due to concerns regarding data privacy, the dataset will not be made publicly available. However, we have made the pre-trained models and codes publicly accessible to the community via: https://github.com/zwzzzQAQ/Chinese-MentalBERT.","sentences":["In the current environment, psychological issues are prevalent and widespread, with social media serving as a key outlet for individuals to share their feelings.","This results in the generation of vast quantities of data daily, where negative emotions have the potential to precipitate crisis situations.","There is a recognized need for models capable of efficient analysis.","While pre-trained language models have demonstrated their effectiveness broadly, there's a noticeable gap in pre-trained models tailored for specialized domains like psychology.","To address this, we have collected a huge dataset from Chinese social media platforms and enriched it with publicly available datasets to create a comprehensive database encompassing 3.36 million text entries.","To enhance the model's applicability to psychological text analysis, we integrated psychological lexicons into the pre-training masking mechanism.","Building on an existing Chinese language model, we performed adaptive training to develop a model specialized for the psychological domain.","We assessed our model's effectiveness across four public benchmarks, where it not only surpassed the performance of standard pre-trained models but also showed a inclination for making psychologically relevant predictions.","Due to concerns regarding data privacy, the dataset will not be made publicly available.","However, we have made the pre-trained models and codes publicly accessible to the community via: https://github.com/zwzzzQAQ/Chinese-MentalBERT."],"url":"http://arxiv.org/abs/2402.09151v1"}
{"created":"2024-02-14 12:59:43","title":"Better Decremental and Fully Dynamic Sensitivity Oracles for Subgraph Connectivity","abstract":"We study the \\emph{sensitivity oracles problem for subgraph connectivity} in the \\emph{decremental} and \\emph{fully dynamic} settings. In the fully dynamic setting, we preprocess an $n$-vertices $m$-edges undirected graph $G$ with $n_{\\rm off}$ deactivated vertices initially and the others are activated. Then we receive a single update $D\\subseteq V(G)$ of size $|D| = d \\leq d_{\\star}$, representing vertices whose states will be switched. Finally, we get a sequence of queries, each of which asks the connectivity of two given vertices $u$ and $v$ in the activated subgraph. The decremental setting is a special case when there is no deactivated vertex initially, and it is also known as the \\emph{vertex-failure connectivity oracles} problem.   We present a better deterministic vertex-failure connectivity oracle with $\\widehat{O}(d_{\\star}m)$ preprocessing time, $\\widetilde{O}(m)$ space, $\\widetilde{O}(d^{2})$ update time and $O(d)$ query time, which improves the update time of the previous almost-optimal oracle [Long-Saranurak, FOCS 2022] from $\\widehat{O}(d^{2})$ to $\\widetilde{O}(d^{2})$.   We also present a better deterministic fully dynamic sensitivity oracle for subgraph connectivity with $\\widehat{O}(\\min\\{m(n_{\\rm off} + d_{\\star}),n^{\\omega}\\})$ preprocessing time, $\\widetilde{O}(\\min\\{m(n_{\\rm off} + d_{\\star}),n^{2}\\})$ space, $\\widetilde{O}(d^{2})$ update time and $O(d)$ query time, which significantly improves the update time of the state of the art [Hu-Kosinas-Polak, 2023] from $\\widetilde{O}(d^{4})$ to $\\widetilde{O}(d^{2})$. Furthermore, our solution is even almost-optimal assuming popular fine-grained complexity conjectures.","sentences":["We study the \\emph{sensitivity oracles problem for subgraph connectivity} in the \\emph{decremental} and \\emph{fully dynamic} settings.","In the fully dynamic setting, we preprocess an $n$-vertices $m$-edges undirected graph $G$ with $n_{\\rm off}$ deactivated vertices initially and the others are activated.","Then we receive a single update $D\\subseteq V(G)$ of size $|D| = d \\leq d_{\\star}$, representing vertices whose states will be switched.","Finally, we get a sequence of queries, each of which asks the connectivity of two given vertices $u$ and $v$ in the activated subgraph.","The decremental setting is a special case when there is no deactivated vertex initially, and it is also known as the \\emph{vertex-failure connectivity oracles} problem.   ","We present a better deterministic vertex-failure connectivity oracle with $\\widehat{O}(d_{\\star}m)$ preprocessing time, $\\widetilde{O}(m)$ space, $\\widetilde{O}(d^{2})$ update time and $O(d)$ query time, which improves the update time of the previous almost-optimal oracle [Long-Saranurak, FOCS 2022] from $\\widehat{O}(d^{2})$ to $\\widetilde{O}(d^{2})$.   We also present a better deterministic fully dynamic sensitivity oracle for subgraph connectivity with $\\widehat{O}(\\min\\{m(n_{\\rm off} + d_{\\star}),n^{\\omega}\\})$ preprocessing time, $\\widetilde{O}(\\min\\{m(n_{\\rm off} + d_{\\star}),n^{2}\\})$ space, $\\widetilde{O}(d^{2})$ update time and $O(d)$ query time, which significantly improves the update time of the state of the art [Hu-Kosinas-Polak, 2023] from $\\widetilde{O}(d^{4})$ to $\\widetilde{O}(d^{2})$. Furthermore, our solution is even almost-optimal assuming popular fine-grained complexity conjectures."],"url":"http://arxiv.org/abs/2402.09150v1"}
{"created":"2024-02-14 12:28:14","title":"Recommendation Algorithm Based on Recommendation Sessions","abstract":"The enormous development of the Internet, both in the geographical scale and in the area of using its possibilities in everyday life, determines the creation and collection of huge amounts of data. Due to the scale, it is not possible to analyse them using traditional methods, therefore it makes a necessary to use modern methods and techniques. Such methods are provided, among others, by the area of recommendations. The aim of this study is to present a new algorithm in the area of recommendation systems, the algorithm based on data from various sets of information, both static (categories of objects, features of objects) and dynamic (user behaviour).","sentences":["The enormous development of the Internet, both in the geographical scale and in the area of using its possibilities in everyday life, determines the creation and collection of huge amounts of data.","Due to the scale, it is not possible to analyse them using traditional methods, therefore it makes a necessary to use modern methods and techniques.","Such methods are provided, among others, by the area of recommendations.","The aim of this study is to present a new algorithm in the area of recommendation systems, the algorithm based on data from various sets of information, both static (categories of objects, features of objects) and dynamic (user behaviour)."],"url":"http://arxiv.org/abs/2402.09130v1"}
{"created":"2024-02-14 11:55:50","title":"Measuring Exploration in Reinforcement Learning via Optimal Transport in Policy Space","abstract":"Exploration is the key ingredient of reinforcement learning (RL) that determines the speed and success of learning. Here, we quantify and compare the amount of exploration and learning accomplished by a Reinforcement Learning (RL) algorithm. Specifically, we propose a novel measure, named Exploration Index, that quantifies the relative effort of knowledge transfer (transferability) by an RL algorithm in comparison to supervised learning (SL) that transforms the initial data distribution of RL to the corresponding final data distribution. The comparison is established by formulating learning in RL as a sequence of SL tasks, and using optimal transport based metrics to compare the total path traversed by the RL and SL algorithms in the data distribution space. We perform extensive empirical analysis on various environments and with multiple algorithms to demonstrate that the exploration index yields insights about the exploration behaviour of any RL algorithm, and also allows us to compare the exploratory behaviours of different RL algorithms.","sentences":["Exploration is the key ingredient of reinforcement learning (RL) that determines the speed and success of learning.","Here, we quantify and compare the amount of exploration and learning accomplished by a Reinforcement Learning (RL) algorithm.","Specifically, we propose a novel measure, named Exploration Index, that quantifies the relative effort of knowledge transfer (transferability) by an RL algorithm in comparison to supervised learning (SL) that transforms the initial data distribution of RL to the corresponding final data distribution.","The comparison is established by formulating learning in RL as a sequence of SL tasks, and using optimal transport based metrics to compare the total path traversed by the RL and SL algorithms in the data distribution space.","We perform extensive empirical analysis on various environments and with multiple algorithms to demonstrate that the exploration index yields insights about the exploration behaviour of any RL algorithm, and also allows us to compare the exploratory behaviours of different RL algorithms."],"url":"http://arxiv.org/abs/2402.09113v1"}
{"created":"2024-02-14 11:42:15","title":"Headset: Human emotion awareness under partial occlusions multimodal dataset","abstract":"The volumetric representation of human interactions is one of the fundamental domains in the development of immersive media productions and telecommunication applications. Particularly in the context of the rapid advancement of Extended Reality (XR) applications, this volumetric data has proven to be an essential technology for future XR elaboration. In this work, we present a new multimodal database to help advance the development of immersive technologies. Our proposed database provides ethically compliant and diverse volumetric data, in particular 27 participants displaying posed facial expressions and subtle body movements while speaking, plus 11 participants wearing head-mounted displays (HMDs). The recording system consists of a volumetric capture (VoCap) studio, including 31 synchronized modules with 62 RGB cameras and 31 depth cameras. In addition to textured meshes, point clouds, and multi-view RGB-D data, we use one Lytro Illum camera for providing light field (LF) data simultaneously. Finally, we also provide an evaluation of our dataset employment with regard to the tasks of facial expression classification, HMDs removal, and point cloud reconstruction. The dataset can be helpful in the evaluation and performance testing of various XR algorithms, including but not limited to facial expression recognition and reconstruction, facial reenactment, and volumetric video. HEADSET and its all associated raw data and license agreement will be publicly available for research purposes.","sentences":["The volumetric representation of human interactions is one of the fundamental domains in the development of immersive media productions and telecommunication applications.","Particularly in the context of the rapid advancement of Extended Reality (XR) applications, this volumetric data has proven to be an essential technology for future XR elaboration.","In this work, we present a new multimodal database to help advance the development of immersive technologies.","Our proposed database provides ethically compliant and diverse volumetric data, in particular 27 participants displaying posed facial expressions and subtle body movements while speaking, plus 11 participants wearing head-mounted displays (HMDs).","The recording system consists of a volumetric capture (VoCap) studio, including 31 synchronized modules with 62 RGB cameras and 31 depth cameras.","In addition to textured meshes, point clouds, and multi-view RGB-D data, we use one Lytro Illum camera for providing light field (LF) data simultaneously.","Finally, we also provide an evaluation of our dataset employment with regard to the tasks of facial expression classification, HMDs removal, and point cloud reconstruction.","The dataset can be helpful in the evaluation and performance testing of various XR algorithms, including but not limited to facial expression recognition and reconstruction, facial reenactment, and volumetric video.","HEADSET and its all associated raw data and license agreement will be publicly available for research purposes."],"url":"http://arxiv.org/abs/2402.09107v1"}
{"created":"2024-02-14 11:26:30","title":"Scheduling for On-Board Federated Learning with Satellite Clusters","abstract":"Mega-constellations of small satellites have evolved into a source of massive amount of valuable data. To manage this data efficiently, on-board federated learning (FL) enables satellites to train a machine learning (ML) model collaboratively without having to share the raw data. This paper introduces a scheme for scheduling on-board FL for constellations connected with intra-orbit inter-satellite links. The proposed scheme utilizes the predictable visibility pattern between satellites and ground station (GS), both at the individual satellite level and cumulatively within the entire orbit, to mitigate intermittent connectivity and best use of available time. To this end, two distinct schedulers are employed: one for coordinating the FL procedures among orbits, and the other for controlling those within each orbit. These two schedulers cooperatively determine the appropriate time to perform global updates in GS and then allocate suitable duration to satellites within each orbit for local training, proportional to usable time until next global update. This scheme leads to improved test accuracy within a shorter time.","sentences":["Mega-constellations of small satellites have evolved into a source of massive amount of valuable data.","To manage this data efficiently, on-board federated learning (FL) enables satellites to train a machine learning (ML) model collaboratively without having to share the raw data.","This paper introduces a scheme for scheduling on-board FL for constellations connected with intra-orbit inter-satellite links.","The proposed scheme utilizes the predictable visibility pattern between satellites and ground station (GS), both at the individual satellite level and cumulatively within the entire orbit, to mitigate intermittent connectivity and best use of available time.","To this end, two distinct schedulers are employed: one for coordinating the FL procedures among orbits, and the other for controlling those within each orbit.","These two schedulers cooperatively determine the appropriate time to perform global updates in GS and then allocate suitable duration to satellites within each orbit for local training, proportional to usable time until next global update.","This scheme leads to improved test accuracy within a shorter time."],"url":"http://arxiv.org/abs/2402.09105v1"}
{"created":"2024-02-14 11:20:47","title":"Towards Realistic Landmark-Guided Facial Video Inpainting Based on GANs","abstract":"Facial video inpainting plays a crucial role in a wide range of applications, including but not limited to the removal of obstructions in video conferencing and telemedicine, enhancement of facial expression analysis, privacy protection, integration of graphical overlays, and virtual makeup. This domain presents serious challenges due to the intricate nature of facial features and the inherent human familiarity with faces, heightening the need for accurate and persuasive completions. In addressing challenges specifically related to occlusion removal in this context, our focus is on the progressive task of generating complete images from facial data covered by masks, ensuring both spatial and temporal coherence. Our study introduces a network designed for expression-based video inpainting, employing generative adversarial networks (GANs) to handle static and moving occlusions across all frames. By utilizing facial landmarks and an occlusion-free reference image, our model maintains the user's identity consistently across frames. We further enhance emotional preservation through a customized facial expression recognition (FER) loss function, ensuring detailed inpainted outputs. Our proposed framework exhibits proficiency in eliminating occlusions from facial videos in an adaptive form, whether appearing static or dynamic on the frames, while providing realistic and coherent results.","sentences":["Facial video inpainting plays a crucial role in a wide range of applications, including but not limited to the removal of obstructions in video conferencing and telemedicine, enhancement of facial expression analysis, privacy protection, integration of graphical overlays, and virtual makeup.","This domain presents serious challenges due to the intricate nature of facial features and the inherent human familiarity with faces, heightening the need for accurate and persuasive completions.","In addressing challenges specifically related to occlusion removal in this context, our focus is on the progressive task of generating complete images from facial data covered by masks, ensuring both spatial and temporal coherence.","Our study introduces a network designed for expression-based video inpainting, employing generative adversarial networks (GANs) to handle static and moving occlusions across all frames.","By utilizing facial landmarks and an occlusion-free reference image, our model maintains the user's identity consistently across frames.","We further enhance emotional preservation through a customized facial expression recognition (FER) loss function, ensuring detailed inpainted outputs.","Our proposed framework exhibits proficiency in eliminating occlusions from facial videos in an adaptive form, whether appearing static or dynamic on the frames, while providing realistic and coherent results."],"url":"http://arxiv.org/abs/2402.09100v1"}
{"created":"2024-02-14 11:17:14","title":"A Digital Twin prototype for traffic sign recognition of a learning-enabled autonomous vehicle","abstract":"In this paper, we present a novel digital twin prototype for a learning-enabled self-driving vehicle. The primary objective of this digital twin is to perform traffic sign recognition and lane keeping. The digital twin architecture relies on co-simulation and uses the Functional Mock-up Interface and SystemC Transaction Level Modeling standards. The digital twin consists of four clients, i) a vehicle model that is designed in Amesim tool, ii) an environment model developed in Prescan, iii) a lane-keeping controller designed in Robot Operating System, and iv) a perception and speed control module developed in the formal modeling language of BIP (Behavior, Interaction, Priority). These clients interface with the digital twin platform, PAVE360-Veloce System Interconnect (PAVE360-VSI). PAVE360-VSI acts as the co-simulation orchestrator and is responsible for synchronization, interconnection, and data exchange through a server. The server establishes connections among the different clients and also ensures adherence to the Ethernet protocol. We conclude with illustrative digital twin simulations and recommendations for future work.","sentences":["In this paper, we present a novel digital twin prototype for a learning-enabled self-driving vehicle.","The primary objective of this digital twin is to perform traffic sign recognition and lane keeping.","The digital twin architecture relies on co-simulation and uses the Functional Mock-up Interface and SystemC Transaction Level Modeling standards.","The digital twin consists of four clients, i) a vehicle model that is designed in Amesim tool, ii) an environment model developed in Prescan, iii) a lane-keeping controller designed in Robot Operating System, and iv) a perception and speed control module developed in the formal modeling language of BIP (Behavior, Interaction, Priority).","These clients interface with the digital twin platform, PAVE360-Veloce System Interconnect (PAVE360-VSI).","PAVE360-VSI acts as the co-simulation orchestrator and is responsible for synchronization, interconnection, and data exchange through a server.","The server establishes connections among the different clients and also ensures adherence to the Ethernet protocol.","We conclude with illustrative digital twin simulations and recommendations for future work."],"url":"http://arxiv.org/abs/2402.09097v1"}
{"created":"2024-02-14 11:16:50","title":"FedSiKD: Clients Similarity and Knowledge Distillation: Addressing Non-i.i.d. and Constraints in Federated Learning","abstract":"In recent years, federated learning (FL) has emerged as a promising technique for training machine learning models in a decentralized manner while also preserving data privacy. The non-independent and identically distributed (non-i.i.d.) nature of client data, coupled with constraints on client or edge devices, presents significant challenges in FL. Furthermore, learning across a high number of communication rounds can be risky and potentially unsafe for model exploitation. Traditional FL approaches may suffer from these challenges. Therefore, we introduce FedSiKD, which incorporates knowledge distillation (KD) within a similarity-based federated learning framework. As clients join the system, they securely share relevant statistics about their data distribution, promoting intra-cluster homogeneity. This enhances optimization efficiency and accelerates the learning process, effectively transferring knowledge between teacher and student models and addressing device constraints. FedSiKD outperforms state-of-the-art algorithms by achieving higher accuracy, exceeding by 25\\% and 18\\% for highly skewed data at $\\alpha = {0.1,0.5}$ on the HAR and MNIST datasets, respectively. Its faster convergence is illustrated by a 17\\% and 20\\% increase in accuracy within the first five rounds on the HAR and MNIST datasets, respectively, highlighting its early-stage learning proficiency. Code is publicly available and hosted on GitHub (https://github.com/SimuEnv/FedSiKD)","sentences":["In recent years, federated learning (FL) has emerged as a promising technique for training machine learning models in a decentralized manner while also preserving data privacy.","The non-independent and identically distributed (non-i.i.d.)","nature of client data, coupled with constraints on client or edge devices, presents significant challenges in FL.","Furthermore, learning across a high number of communication rounds can be risky and potentially unsafe for model exploitation.","Traditional FL approaches may suffer from these challenges.","Therefore, we introduce FedSiKD, which incorporates knowledge distillation (KD) within a similarity-based federated learning framework.","As clients join the system, they securely share relevant statistics about their data distribution, promoting intra-cluster homogeneity.","This enhances optimization efficiency and accelerates the learning process, effectively transferring knowledge between teacher and student models and addressing device constraints.","FedSiKD outperforms state-of-the-art algorithms by achieving higher accuracy, exceeding by 25\\% and 18\\% for highly skewed data at $\\alpha = {0.1,0.5}$ on the HAR and MNIST datasets, respectively.","Its faster convergence is illustrated by a 17\\% and 20\\% increase in accuracy within the first five rounds on the HAR and MNIST datasets, respectively, highlighting its early-stage learning proficiency.","Code is publicly available and hosted on GitHub (https://github.com/SimuEnv/FedSiKD)"],"url":"http://arxiv.org/abs/2402.09095v1"}
{"created":"2024-02-14 10:32:58","title":"Affine transformation estimation improves visual self-supervised learning","abstract":"The standard approach to modern self-supervised learning is to generate random views through data augmentations and minimise a loss computed from the representations of these views. This inherently encourages invariance to the transformations that comprise the data augmentation function. In this work, we show that adding a module to constrain the representations to be predictive of an affine transformation improves the performance and efficiency of the learning process. The module is agnostic to the base self-supervised model and manifests in the form of an additional loss term that encourages an aggregation of the encoder representations to be predictive of an affine transformation applied to the input images. We perform experiments in various modern self-supervised models and see a performance improvement in all cases. Further, we perform an ablation study on the components of the affine transformation to understand which of them is affecting performance the most, as well as on key architectural design decisions.","sentences":["The standard approach to modern self-supervised learning is to generate random views through data augmentations and minimise a loss computed from the representations of these views.","This inherently encourages invariance to the transformations that comprise the data augmentation function.","In this work, we show that adding a module to constrain the representations to be predictive of an affine transformation improves the performance and efficiency of the learning process.","The module is agnostic to the base self-supervised model and manifests in the form of an additional loss term that encourages an aggregation of the encoder representations to be predictive of an affine transformation applied to the input images.","We perform experiments in various modern self-supervised models and see a performance improvement in all cases.","Further, we perform an ablation study on the components of the affine transformation to understand which of them is affecting performance the most, as well as on key architectural design decisions."],"url":"http://arxiv.org/abs/2402.09071v1"}
{"created":"2024-02-14 10:24:04","title":"Solid Waste Detection in Remote Sensing Images: A Survey","abstract":"The detection and characterization of illegal solid waste disposal sites are essential for environmental protection, particularly for mitigating pollution and health hazards. Improperly managed landfills contaminate soil and groundwater via rainwater infiltration, posing threats to both animals and humans. Traditional landfill identification approaches, such as on-site inspections, are time-consuming and expensive. Remote sensing is a cost-effective solution for the identification and monitoring of solid waste disposal sites that enables broad coverage and repeated acquisitions over time. Earth Observation (EO) satellites, equipped with an array of sensors and imaging capabilities, have been providing high-resolution data for several decades. Researchers proposed specialized techniques that leverage remote sensing imagery to perform a range of tasks such as waste site detection, dumping site monitoring, and assessment of suitable locations for new landfills. This review aims to provide a detailed illustration of the most relevant proposals for the detection and monitoring of solid waste sites by describing and comparing the approaches, the implemented techniques, and the employed data. Furthermore, since the data sources are of the utmost importance for developing an effective solid waste detection model, a comprehensive overview of the satellites and publicly available data sets is presented. Finally, this paper identifies the open issues in the state-of-the-art and discusses the relevant research directions for reducing the costs and improving the effectiveness of novel solid waste detection methods.","sentences":["The detection and characterization of illegal solid waste disposal sites are essential for environmental protection, particularly for mitigating pollution and health hazards.","Improperly managed landfills contaminate soil and groundwater via rainwater infiltration, posing threats to both animals and humans.","Traditional landfill identification approaches, such as on-site inspections, are time-consuming and expensive.","Remote sensing is a cost-effective solution for the identification and monitoring of solid waste disposal sites that enables broad coverage and repeated acquisitions over time.","Earth Observation (EO) satellites, equipped with an array of sensors and imaging capabilities, have been providing high-resolution data for several decades.","Researchers proposed specialized techniques that leverage remote sensing imagery to perform a range of tasks such as waste site detection, dumping site monitoring, and assessment of suitable locations for new landfills.","This review aims to provide a detailed illustration of the most relevant proposals for the detection and monitoring of solid waste sites by describing and comparing the approaches, the implemented techniques, and the employed data.","Furthermore, since the data sources are of the utmost importance for developing an effective solid waste detection model, a comprehensive overview of the satellites and publicly available data sets is presented.","Finally, this paper identifies the open issues in the state-of-the-art and discusses the relevant research directions for reducing the costs and improving the effectiveness of novel solid waste detection methods."],"url":"http://arxiv.org/abs/2402.09066v1"}
{"created":"2024-02-14 10:15:43","title":"I can't see it but I can Fine-tune it: On Encrypted Fine-tuning of Transformers using Fully Homomorphic Encryption","abstract":"In today's machine learning landscape, fine-tuning pretrained transformer models has emerged as an essential technique, particularly in scenarios where access to task-aligned training data is limited. However, challenges surface when data sharing encounters obstacles due to stringent privacy regulations or user apprehension regarding personal information disclosure. Earlier works based on secure multiparty computation (SMC) and fully homomorphic encryption (FHE) for privacy-preserving machine learning (PPML) focused more on privacy-preserving inference than privacy-preserving training. In response, we introduce BlindTuner, a privacy-preserving fine-tuning system that enables transformer training exclusively on homomorphically encrypted data for image classification. Our extensive experimentation validates BlindTuner's effectiveness by demonstrating comparable accuracy to non-encrypted models. Notably, our findings highlight a substantial speed enhancement of 1.5x to 600x over previous work in this domain.","sentences":["In today's machine learning landscape, fine-tuning pretrained transformer models has emerged as an essential technique, particularly in scenarios where access to task-aligned training data is limited.","However, challenges surface when data sharing encounters obstacles due to stringent privacy regulations or user apprehension regarding personal information disclosure.","Earlier works based on secure multiparty computation (SMC) and fully homomorphic encryption (FHE) for privacy-preserving machine learning (PPML) focused more on privacy-preserving inference than privacy-preserving training.","In response, we introduce BlindTuner, a privacy-preserving fine-tuning system that enables transformer training exclusively on homomorphically encrypted data for image classification.","Our extensive experimentation validates BlindTuner's effectiveness by demonstrating comparable accuracy to non-encrypted models.","Notably, our findings highlight a substantial speed enhancement of 1.5x to 600x over previous work in this domain."],"url":"http://arxiv.org/abs/2402.09059v1"}
{"created":"2024-02-14 10:05:19","title":"Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection","abstract":"The growing importance of multi-modal humor detection within affective computing correlates with the expanding influence of short-form video sharing on social media platforms. In this paper, we propose a novel two-branch hierarchical model for short-form video humor detection (SVHD), named Comment-aided Video-Language Alignment (CVLA) via data-augmented multi-modal contrastive pre-training. Notably, our CVLA not only operates on raw signals across various modal channels but also yields an appropriate multi-modal representation by aligning the video and language components within a consistent semantic space. The experimental results on two humor detection datasets, including DY11k and UR-FUNNY, demonstrate that CVLA dramatically outperforms state-of-the-art and several competitive baseline approaches. Our dataset, code and model release at https://github.com/yliu-cs/CVLA.","sentences":["The growing importance of multi-modal humor detection within affective computing correlates with the expanding influence of short-form video sharing on social media platforms.","In this paper, we propose a novel two-branch hierarchical model for short-form video humor detection (SVHD), named Comment-aided Video-Language Alignment (CVLA) via data-augmented multi-modal contrastive pre-training.","Notably, our CVLA not only operates on raw signals across various modal channels but also yields an appropriate multi-modal representation by aligning the video and language components within a consistent semantic space.","The experimental results on two humor detection datasets, including DY11k and UR-FUNNY, demonstrate that CVLA dramatically outperforms state-of-the-art and several competitive baseline approaches.","Our dataset, code and model release at https://github.com/yliu-cs/CVLA."],"url":"http://arxiv.org/abs/2402.09055v1"}
{"created":"2024-02-14 09:51:05","title":"L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects","abstract":"Diffusion-based image generation models such as DALL-E 3 and Stable Diffusion-XL demonstrate remarkable capabilities in generating images with realistic and unique compositions. Yet, these models are not robust in precisely reasoning about physical and spatial configurations of objects, especially when instructed with unconventional, thereby out-of-distribution descriptions, such as \"a chair with five legs\". In this paper, we propose a language agent with chain-of-3D-thoughts (L3GO), an inference-time approach that can reason about part-based 3D mesh generation of unconventional objects that current data-driven diffusion models struggle with. More concretely, we use large language models as agents to compose a desired object via trial-and-error within the 3D simulation environment. To facilitate our investigation, we develop a new benchmark, Unconventionally Feasible Objects (UFO), as well as SimpleBlenv, a wrapper environment built on top of Blender where language agents can build and compose atomic building blocks via API calls. Human and automatic GPT-4V evaluations show that our approach surpasses the standard GPT-4 and other language agents (e.g., ReAct and Reflexion) for 3D mesh generation on ShapeNet. Moreover, when tested on our UFO benchmark, our approach outperforms other state-of-the-art text-to-2D image and text-to-3D models based on human evaluation.","sentences":["Diffusion-based image generation models such as DALL-E 3 and Stable Diffusion-XL demonstrate remarkable capabilities in generating images with realistic and unique compositions.","Yet, these models are not robust in precisely reasoning about physical and spatial configurations of objects, especially when instructed with unconventional, thereby out-of-distribution descriptions, such as \"a chair with five legs\".","In this paper, we propose a language agent with chain-of-3D-thoughts (L3GO), an inference-time approach that can reason about part-based 3D mesh generation of unconventional objects that current data-driven diffusion models struggle with.","More concretely, we use large language models as agents to compose a desired object via trial-and-error within the 3D simulation environment.","To facilitate our investigation, we develop a new benchmark, Unconventionally Feasible Objects (UFO), as well as SimpleBlenv, a wrapper environment built on top of Blender where language agents can build and compose atomic building blocks via API calls.","Human and automatic GPT-4V evaluations show that our approach surpasses the standard GPT-4 and other language agents (e.g., ReAct and Reflexion) for 3D mesh generation on ShapeNet.","Moreover, when tested on our UFO benchmark, our approach outperforms other state-of-the-art text-to-2D image and text-to-3D models based on human evaluation."],"url":"http://arxiv.org/abs/2402.09052v1"}
{"created":"2024-02-14 09:43:35","title":"Inference of Abstraction for a Unified Account of Reasoning and Learning","abstract":"Inspired by Bayesian approaches to brain function in neuroscience, we give a simple theory of probabilistic inference for a unified account of reasoning and learning. We simply model how data cause symbolic knowledge in terms of its satisfiability in formal logic. The underlying idea is that reasoning is a process of deriving symbolic knowledge from data via abstraction, i.e., selective ignorance. The logical consequence relation is discussed for its proof-based theoretical correctness. The MNIST dataset is discussed for its experiment-based empirical correctness.","sentences":["Inspired by Bayesian approaches to brain function in neuroscience, we give a simple theory of probabilistic inference for a unified account of reasoning and learning.","We simply model how data cause symbolic knowledge in terms of its satisfiability in formal logic.","The underlying idea is that reasoning is a process of deriving symbolic knowledge from data via abstraction, i.e., selective ignorance.","The logical consequence relation is discussed for its proof-based theoretical correctness.","The MNIST dataset is discussed for its experiment-based empirical correctness."],"url":"http://arxiv.org/abs/2402.09046v1"}
{"created":"2024-02-14 09:38:09","title":"Under manipulations, are some AI models harder to audit?","abstract":"Auditors need robust methods to assess the compliance of web platforms with the law. However, since they hardly ever have access to the algorithm, implementation, or training data used by a platform, the problem is harder than a simple metric estimation. Within the recent framework of manipulation-proof auditing, we study in this paper the feasibility of robust audits in realistic settings, in which models exhibit large capacities. We first prove a constraining result: if a web platform uses models that may fit any data, no audit strategy -- whether active or not -- can outperform random sampling when estimating properties such as demographic parity. To better understand the conditions under which state-of-the-art auditing techniques may remain competitive, we then relate the manipulability of audits to the capacity of the targeted models, using the Rademacher complexity. We empirically validate these results on popular models of increasing capacities, thus confirming experimentally that large-capacity models, which are commonly used in practice, are particularly hard to audit robustly. These results refine the limits of the auditing problem, and open up enticing questions on the connection between model capacity and the ability of platforms to manipulate audit attempts.","sentences":["Auditors need robust methods to assess the compliance of web platforms with the law.","However, since they hardly ever have access to the algorithm, implementation, or training data used by a platform, the problem is harder than a simple metric estimation.","Within the recent framework of manipulation-proof auditing, we study in this paper the feasibility of robust audits in realistic settings, in which models exhibit large capacities.","We first prove a constraining result: if a web platform uses models that may fit any data, no audit strategy -- whether active or not -- can outperform random sampling when estimating properties such as demographic parity.","To better understand the conditions under which state-of-the-art auditing techniques may remain competitive, we then relate the manipulability of audits to the capacity of the targeted models, using the Rademacher complexity.","We empirically validate these results on popular models of increasing capacities, thus confirming experimentally that large-capacity models, which are commonly used in practice, are particularly hard to audit robustly.","These results refine the limits of the auditing problem, and open up enticing questions on the connection between model capacity and the ability of platforms to manipulate audit attempts."],"url":"http://arxiv.org/abs/2402.09043v1"}
{"created":"2024-02-14 09:21:00","title":"Can Text-to-image Model Assist Multi-modal Learning for Visual Recognition with Visual Modality Missing?","abstract":"Multi-modal learning has emerged as an increasingly promising avenue in vision recognition, driving innovations across diverse domains ranging from media and education to healthcare and transportation. Despite its success, the robustness of multi-modal learning for visual recognition is often challenged by the unavailability of a subset of modalities, especially the visual modality. Conventional approaches to mitigate missing modalities in multi-modal learning rely heavily on algorithms and modality fusion schemes. In contrast, this paper explores the use of text-to-image models to assist multi-modal learning. Specifically, we propose a simple but effective multi-modal learning framework GTI-MM to enhance the data efficiency and model robustness against missing visual modality by imputing the missing data with generative transformers. Using multiple multi-modal datasets with visual recognition tasks, we present a comprehensive analysis of diverse conditions involving missing visual modality in data, including model training. Our findings reveal that synthetic images benefit training data efficiency with visual data missing in training and improve model robustness with visual data missing involving training and testing. Moreover, we demonstrate GTI-MM is effective with lower generation quantity and simple prompt techniques.","sentences":["Multi-modal learning has emerged as an increasingly promising avenue in vision recognition, driving innovations across diverse domains ranging from media and education to healthcare and transportation.","Despite its success, the robustness of multi-modal learning for visual recognition is often challenged by the unavailability of a subset of modalities, especially the visual modality.","Conventional approaches to mitigate missing modalities in multi-modal learning rely heavily on algorithms and modality fusion schemes.","In contrast, this paper explores the use of text-to-image models to assist multi-modal learning.","Specifically, we propose a simple but effective multi-modal learning framework GTI-MM to enhance the data efficiency and model robustness against missing visual modality by imputing the missing data with generative transformers.","Using multiple multi-modal datasets with visual recognition tasks, we present a comprehensive analysis of diverse conditions involving missing visual modality in data, including model training.","Our findings reveal that synthetic images benefit training data efficiency with visual data missing in training and improve model robustness with visual data missing involving training and testing.","Moreover, we demonstrate GTI-MM is effective with lower generation quantity and simple prompt techniques."],"url":"http://arxiv.org/abs/2402.09036v1"}
{"created":"2024-02-14 09:20:13","title":"Enhancing Sequential Model Performance with Squared Sigmoid TanH (SST) Activation Under Data Constraints","abstract":"Activation functions enable neural networks to learn complex representations by introducing non-linearities. While feedforward models commonly use rectified linear units, sequential models like recurrent neural networks, long short-term memory (LSTMs) and gated recurrent units (GRUs) still rely on Sigmoid and TanH activation functions. However, these classical activation functions often struggle to model sparse patterns when trained on small sequential datasets to effectively capture temporal dependencies. To address this limitation, we propose squared Sigmoid TanH (SST) activation specifically tailored to enhance the learning capability of sequential models under data constraints. SST applies mathematical squaring to amplify differences between strong and weak activations as signals propagate over time, facilitating improved gradient flow and information filtering. We evaluate SST-powered LSTMs and GRUs for diverse applications, such as sign language recognition, regression, and time-series classification tasks, where the dataset is limited. Our experiments demonstrate that SST models consistently outperform RNN-based models with baseline activations, exhibiting improved test accuracy.","sentences":["Activation functions enable neural networks to learn complex representations by introducing non-linearities.","While feedforward models commonly use rectified linear units, sequential models like recurrent neural networks, long short-term memory (LSTMs) and gated recurrent units (GRUs) still rely on Sigmoid and TanH activation functions.","However, these classical activation functions often struggle to model sparse patterns when trained on small sequential datasets to effectively capture temporal dependencies.","To address this limitation, we propose squared Sigmoid TanH (SST) activation specifically tailored to enhance the learning capability of sequential models under data constraints.","SST applies mathematical squaring to amplify differences between strong and weak activations as signals propagate over time, facilitating improved gradient flow and information filtering.","We evaluate SST-powered LSTMs and GRUs for diverse applications, such as sign language recognition, regression, and time-series classification tasks, where the dataset is limited.","Our experiments demonstrate that SST models consistently outperform RNN-based models with baseline activations, exhibiting improved test accuracy."],"url":"http://arxiv.org/abs/2402.09034v1"}
{"created":"2024-02-14 08:56:41","title":"Review-Incorporated Model-Agnostic Profile Injection Attacks on Recommender Systems","abstract":"Recent studies have shown that recommender systems (RSs) are highly vulnerable to data poisoning attacks. Understanding attack tactics helps improve the robustness of RSs. We intend to develop efficient attack methods that use limited resources to generate high-quality fake user profiles to achieve 1) transferability among black-box RSs 2) and imperceptibility among detectors. In order to achieve these goals, we introduce textual reviews of products to enhance the generation quality of the profiles. Specifically, we propose a novel attack framework named R-Trojan, which formulates the attack objectives as an optimization problem and adopts a tailored transformer-based generative adversarial network (GAN) to solve it so that high-quality attack profiles can be produced. Comprehensive experiments on real-world datasets demonstrate that R-Trojan greatly outperforms state-of-the-art attack methods on various victim RSs under black-box settings and show its good imperceptibility.","sentences":["Recent studies have shown that recommender systems (RSs) are highly vulnerable to data poisoning attacks.","Understanding attack tactics helps improve the robustness of RSs.","We intend to develop efficient attack methods that use limited resources to generate high-quality fake user profiles to achieve 1) transferability among black-box RSs 2) and imperceptibility among detectors.","In order to achieve these goals, we introduce textual reviews of products to enhance the generation quality of the profiles.","Specifically, we propose a novel attack framework named R-Trojan, which formulates the attack objectives as an optimization problem and adopts a tailored transformer-based generative adversarial network (GAN) to solve it so that high-quality attack profiles can be produced.","Comprehensive experiments on real-world datasets demonstrate that R-Trojan greatly outperforms state-of-the-art attack methods on various victim RSs under black-box settings and show its good imperceptibility."],"url":"http://arxiv.org/abs/2402.09023v1"}
{"created":"2024-02-14 08:36:52","title":"Improved Deterministic Distributed Maximum Weight Independent Set Approximation in Sparse Graphs","abstract":"We design new deterministic CONGEST approximation algorithms for \\emph{maximum weight independent set (MWIS)} in \\emph{sparse graphs}. As our main results, we obtain new $\\Delta(1+\\epsilon)$-approximation algorithms as well as algorithms whose approximation ratio depend strictly on $\\alpha$, in graphs with maximum degree $\\Delta$ and arboricity $\\alpha$. For (deterministic) $\\Delta(1+\\epsilon)$-approximation, the current state-of-the-art is due to a recent breakthrough by Faour et al.\\ [SODA 2023] that showed an $O(\\log^{2} (\\Delta W)\\cdot \\log (1/\\epsilon)+\\log ^{*}n)$-round algorithm, where $W$ is the largest node-weight (this bound translates to $O(\\log^{2} n\\cdot\\log (1/\\epsilon))$ under the common assumption that $W=\\text{poly}(n)$). As for $\\alpha$-dependent approximations, a deterministic CONGEST $(8(1+\\epsilon)\\cdot\\alpha)$-approximation algorithm with runtime $O(\\log^{3} n\\cdot\\log (1/\\epsilon))$ can be derived by combining the aforementioned algorithm of Faour et al.\\ with a method presented by Kawarabayashi et al.\\ [DISC 2020].","sentences":["We design new deterministic CONGEST approximation algorithms for \\emph{maximum weight independent set (MWIS)} in \\emph{sparse graphs}.","As our main results, we obtain new $\\Delta(1+\\epsilon)$-approximation algorithms as well as algorithms whose approximation ratio depend strictly on $\\alpha$, in graphs with maximum degree $\\Delta$ and arboricity $\\alpha$. For (deterministic) $\\Delta(1+\\epsilon)$-approximation, the current state-of-the-art is due to a recent breakthrough by Faour et al.\\","[SODA 2023] that showed an $O(\\log^{2} (\\Delta W)\\cdot \\log (1/\\epsilon)+\\log ^{*}n)$-round algorithm, where $W$ is the largest node-weight (this bound translates to $O(\\log^{2} n\\cdot\\log (1/\\epsilon))$ under the common assumption that $W=\\text{poly}(n)$).","As for $\\alpha$-dependent approximations, a deterministic CONGEST $(8(1+\\epsilon)\\cdot\\alpha)$-approximation algorithm with runtime $O(\\log^{3} n\\cdot\\log (1/\\epsilon))$ can be derived by combining the aforementioned algorithm of Faour et al.\\ with a method presented by Kawarabayashi et al.\\","[DISC 2020]."],"url":"http://arxiv.org/abs/2402.09011v1"}
{"created":"2024-02-14 08:17:21","title":"Gradient Alignment with Prototype Feature for Fully Test-time Adaptation","abstract":"In context of Test-time Adaptation(TTA), we propose a regularizer, dubbed Gradient Alignment with Prototype feature (GAP), which alleviates the inappropriate guidance from entropy minimization loss from misclassified pseudo label. We developed a gradient alignment loss to precisely manage the adaptation process, ensuring that changes made for some data don't negatively impact the model's performance on other data. We introduce a prototype feature of a class as a proxy measure of the negative impact. To make GAP regularizer feasible under the TTA constraints, where model can only access test data without labels, we tailored its formula in two ways: approximating prototype features with weight vectors of the classifier, calculating gradient without back-propagation. We demonstrate GAP significantly improves TTA methods across various datasets, which proves its versatility and effectiveness.","sentences":["In context of Test-time Adaptation(TTA), we propose a regularizer, dubbed Gradient Alignment with Prototype feature (GAP), which alleviates the inappropriate guidance from entropy minimization loss from misclassified pseudo label.","We developed a gradient alignment loss to precisely manage the adaptation process, ensuring that changes made for some data don't negatively impact the model's performance on other data.","We introduce a prototype feature of a class as a proxy measure of the negative impact.","To make GAP regularizer feasible under the TTA constraints, where model can only access test data without labels, we tailored its formula in two ways: approximating prototype features with weight vectors of the classifier, calculating gradient without back-propagation.","We demonstrate GAP significantly improves TTA methods across various datasets, which proves its versatility and effectiveness."],"url":"http://arxiv.org/abs/2402.09004v1"}
{"created":"2024-02-14 07:52:28","title":"Exploring Federated Deep Learning for Standardising Naming Conventions in Radiotherapy Data","abstract":"Standardising structure volume names in radiotherapy (RT) data is necessary to enable data mining and analyses, especially across multi-institutional centres. This process is time and resource intensive, which highlights the need for new automated and efficient approaches to handle the task. Several machine learning-based methods have been proposed and evaluated to standardise nomenclature. However, no studies have considered that RT patient records are distributed across multiple data centres. This paper introduces a method that emulates real-world environments to establish standardised nomenclature. This is achieved by integrating decentralised real-time data and federated learning (FL). A multimodal deep artificial neural network was proposed to standardise RT data in federated settings. Three types of possible attributes were extracted from the structures to train the deep learning models: tabular, visual, and volumetric. Simulated experiments were carried out to train the models across several scenarios including multiple data centres, input modalities, and aggregation strategies. The models were compared against models developed with single modalities in federated settings, in addition to models trained in centralised settings. Categorical classification accuracy was calculated on hold-out samples to inform the models performance. Our results highlight the need for fusing multiple modalities when training such models, with better performance reported with tabular-volumetric models. In addition, we report comparable accuracy compared to models built in centralised settings. This demonstrates the suitability of FL for handling the standardization task. Additional ablation analyses showed that the total number of samples in the data centres and the number of data centres highly affects the training process and should be carefully considered when building standardisation models.","sentences":["Standardising structure volume names in radiotherapy (RT) data is necessary to enable data mining and analyses, especially across multi-institutional centres.","This process is time and resource intensive, which highlights the need for new automated and efficient approaches to handle the task.","Several machine learning-based methods have been proposed and evaluated to standardise nomenclature.","However, no studies have considered that RT patient records are distributed across multiple data centres.","This paper introduces a method that emulates real-world environments to establish standardised nomenclature.","This is achieved by integrating decentralised real-time data and federated learning (FL).","A multimodal deep artificial neural network was proposed to standardise RT data in federated settings.","Three types of possible attributes were extracted from the structures to train the deep learning models: tabular, visual, and volumetric.","Simulated experiments were carried out to train the models across several scenarios including multiple data centres, input modalities, and aggregation strategies.","The models were compared against models developed with single modalities in federated settings, in addition to models trained in centralised settings.","Categorical classification accuracy was calculated on hold-out samples to inform the models performance.","Our results highlight the need for fusing multiple modalities when training such models, with better performance reported with tabular-volumetric models.","In addition, we report comparable accuracy compared to models built in centralised settings.","This demonstrates the suitability of FL for handling the standardization task.","Additional ablation analyses showed that the total number of samples in the data centres and the number of data centres highly affects the training process and should be carefully considered when building standardisation models."],"url":"http://arxiv.org/abs/2402.08999v1"}
{"created":"2024-02-14 07:41:48","title":"CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding","abstract":"The study of decoding visual neural information faces challenges in generalizing single-subject decoding models to multiple subjects, due to individual differences. Moreover, the limited availability of data from a single subject has a constraining impact on model performance. Although prior multi-subject decoding methods have made significant progress, they still suffer from several limitations, including difficulty in extracting global neural response features, linear scaling of model parameters with the number of subjects, and inadequate characterization of the relationship between neural responses of different subjects to various stimuli. To overcome these limitations, we propose a CLIP-guided Multi-sUbject visual neural information SEmantic Decoding (CLIP-MUSED) method. Our method consists of a Transformer-based feature extractor to effectively model global neural representations. It also incorporates learnable subject-specific tokens that facilitates the aggregation of multi-subject data without a linear increase of parameters. Additionally, we employ representational similarity analysis (RSA) to guide token representation learning based on the topological relationship of visual stimuli in the representation space of CLIP, enabling full characterization of the relationship between neural responses of different subjects under different stimuli. Finally, token representations are used for multi-subject semantic decoding. Our proposed method outperforms single-subject decoding methods and achieves state-of-the-art performance among the existing multi-subject methods on two fMRI datasets. Visualization results provide insights into the effectiveness of our proposed method. Code is available at https://github.com/CLIP-MUSED/CLIP-MUSED.","sentences":["The study of decoding visual neural information faces challenges in generalizing single-subject decoding models to multiple subjects, due to individual differences.","Moreover, the limited availability of data from a single subject has a constraining impact on model performance.","Although prior multi-subject decoding methods have made significant progress, they still suffer from several limitations, including difficulty in extracting global neural response features, linear scaling of model parameters with the number of subjects, and inadequate characterization of the relationship between neural responses of different subjects to various stimuli.","To overcome these limitations, we propose a CLIP-guided Multi-sUbject visual neural information SEmantic Decoding (CLIP-MUSED) method.","Our method consists of a Transformer-based feature extractor to effectively model global neural representations.","It also incorporates learnable subject-specific tokens that facilitates the aggregation of multi-subject data without a linear increase of parameters.","Additionally, we employ representational similarity analysis (RSA) to guide token representation learning based on the topological relationship of visual stimuli in the representation space of CLIP, enabling full characterization of the relationship between neural responses of different subjects under different stimuli.","Finally, token representations are used for multi-subject semantic decoding.","Our proposed method outperforms single-subject decoding methods and achieves state-of-the-art performance among the existing multi-subject methods on two fMRI datasets.","Visualization results provide insights into the effectiveness of our proposed method.","Code is available at https://github.com/CLIP-MUSED/CLIP-MUSED."],"url":"http://arxiv.org/abs/2402.08994v1"}
{"created":"2024-02-14 06:57:21","title":"Detecting Adversarial Spectrum Attacks via Distance to Decision Boundary Statistics","abstract":"Machine learning has been adopted for efficient cooperative spectrum sensing. However, it incurs an additional security risk due to attacks leveraging adversarial machine learning to create malicious spectrum sensing values to deceive the fusion center, called adversarial spectrum attacks. In this paper, we propose an efficient framework for detecting adversarial spectrum attacks. Our design leverages the concept of the distance to the decision boundary (DDB) observed at the fusion center and compares the training and testing DDB distributions to identify adversarial spectrum attacks. We create a computationally efficient way to compute the DDB for machine learning based spectrum sensing systems. Experimental results based on realistic spectrum data show that our method, under typical settings, achieves a high detection rate of up to 99\\% and maintains a low false alarm rate of less than 1\\%. In addition, our method to compute the DDB based on spectrum data achieves 54\\%--64\\% improvements in computational efficiency over existing distance calculation methods. The proposed DDB-based detection framework offers a practical and efficient solution for identifying malicious sensing values created by adversarial spectrum attacks.","sentences":["Machine learning has been adopted for efficient cooperative spectrum sensing.","However, it incurs an additional security risk due to attacks leveraging adversarial machine learning to create malicious spectrum sensing values to deceive the fusion center, called adversarial spectrum attacks.","In this paper, we propose an efficient framework for detecting adversarial spectrum attacks.","Our design leverages the concept of the distance to the decision boundary (DDB) observed at the fusion center and compares the training and testing DDB distributions to identify adversarial spectrum attacks.","We create a computationally efficient way to compute the DDB for machine learning based spectrum sensing systems.","Experimental results based on realistic spectrum data show that our method, under typical settings, achieves a high detection rate of up to 99\\% and maintains a low false alarm rate of less than 1\\%.","In addition, our method to compute the DDB based on spectrum data achieves 54\\%--64\\% improvements in computational efficiency over existing distance calculation methods.","The proposed DDB-based detection framework offers a practical and efficient solution for identifying malicious sensing values created by adversarial spectrum attacks."],"url":"http://arxiv.org/abs/2402.08986v1"}
{"created":"2024-02-14 06:51:49","title":"MEL: Efficient Multi-Task Evolutionary Learning for High-Dimensional Feature Selection","abstract":"Feature selection is a crucial step in data mining to enhance model performance by reducing data dimensionality. However, the increasing dimensionality of collected data exacerbates the challenge known as the \"curse of dimensionality\", where computation grows exponentially with the number of dimensions. To tackle this issue, evolutionary computational (EC) approaches have gained popularity due to their simplicity and applicability. Unfortunately, the diverse designs of EC methods result in varying abilities to handle different data, often underutilizing and not sharing information effectively. In this paper, we propose a novel approach called PSO-based Multi-task Evolutionary Learning (MEL) that leverages multi-task learning to address these challenges. By incorporating information sharing between different feature selection tasks, MEL achieves enhanced learning ability and efficiency. We evaluate the effectiveness of MEL through extensive experiments on 22 high-dimensional datasets. Comparing against 24 EC approaches, our method exhibits strong competitiveness. Additionally, we have open-sourced our code on GitHub at https://github.com/wangxb96/MEL.","sentences":["Feature selection is a crucial step in data mining to enhance model performance by reducing data dimensionality.","However, the increasing dimensionality of collected data exacerbates the challenge known as the \"curse of dimensionality\", where computation grows exponentially with the number of dimensions.","To tackle this issue, evolutionary computational (EC) approaches have gained popularity due to their simplicity and applicability.","Unfortunately, the diverse designs of EC methods result in varying abilities to handle different data, often underutilizing and not sharing information effectively.","In this paper, we propose a novel approach called PSO-based Multi-task Evolutionary Learning (MEL) that leverages multi-task learning to address these challenges.","By incorporating information sharing between different feature selection tasks, MEL achieves enhanced learning ability and efficiency.","We evaluate the effectiveness of MEL through extensive experiments on 22 high-dimensional datasets.","Comparing against 24 EC approaches, our method exhibits strong competitiveness.","Additionally, we have open-sourced our code on GitHub at https://github.com/wangxb96/MEL."],"url":"http://arxiv.org/abs/2402.08982v1"}
{"created":"2024-02-14 06:50:16","title":"OmniBOR: A System for Automatic, Verifiable Artifact Resolution across Software Supply Chains","abstract":"Software supply chain attacks, which exploit the build process or artifacts used in the process of building a software product, are increasingly of concern. To combat these attacks, one must be able to check that every artifact that a software product depends on does not contain vulnerabilities. In this paper, we introduce OmniBOR, (Universal Bill of Receipts) a minimalistic scheme for build tools to create an artifact dependency graph which can be used to track every software artifact incorporated into a built software product. We present the architecture of OmniBOR, the underlying data representations, and two implementations that produce OmniBOR data and embed an OmniBOR Identifier into built software, including a compiler-based approach and one based on tracing the build process. We demonstrate the efficacy of this approach on benchmarks including a Linux distribution for applications such as Common Vulnerabilities and Exposures (CVE) detection and software bill of materials (SBOM) computation.","sentences":["Software supply chain attacks, which exploit the build process or artifacts used in the process of building a software product, are increasingly of concern.","To combat these attacks, one must be able to check that every artifact that a software product depends on does not contain vulnerabilities.","In this paper, we introduce OmniBOR, (Universal Bill of Receipts) a minimalistic scheme for build tools to create an artifact dependency graph which can be used to track every software artifact incorporated into a built software product.","We present the architecture of OmniBOR, the underlying data representations, and two implementations that produce OmniBOR data and embed an OmniBOR Identifier into built software, including a compiler-based approach and one based on tracing the build process.","We demonstrate the efficacy of this approach on benchmarks including a Linux distribution for applications such as Common Vulnerabilities and Exposures (CVE) detection and software bill of materials (SBOM) computation."],"url":"http://arxiv.org/abs/2402.08980v1"}
{"created":"2024-02-14 06:47:30","title":"Prismatic: Interactive Multi-View Cluster Analysis of Concept Stocks","abstract":"Financial cluster analysis allows investors to discover investment alternatives and avoid undertaking excessive risks. However, this analytical task faces substantial challenges arising from many pairwise comparisons, the dynamic correlations across time spans, and the ambiguity in deriving implications from business relational knowledge. We propose Prismatic, a visual analytics system that integrates quantitative analysis of historical performance and qualitative analysis of business relational knowledge to cluster correlated businesses interactively. Prismatic features three clustering processes: dynamic cluster generation, knowledge-based cluster exploration, and correlation-based cluster validation. Utilizing a multi-view clustering approach, it enriches data-driven clusters with knowledge-driven similarity, providing a nuanced understanding of business correlations. Through well-coordinated visual views, Prismatic facilitates a comprehensive interpretation of intertwined quantitative and qualitative features, demonstrating its usefulness and effectiveness via case studies on formulating concept stocks and extensive interviews with domain experts.","sentences":["Financial cluster analysis allows investors to discover investment alternatives and avoid undertaking excessive risks.","However, this analytical task faces substantial challenges arising from many pairwise comparisons, the dynamic correlations across time spans, and the ambiguity in deriving implications from business relational knowledge.","We propose Prismatic, a visual analytics system that integrates quantitative analysis of historical performance and qualitative analysis of business relational knowledge to cluster correlated businesses interactively.","Prismatic features three clustering processes: dynamic cluster generation, knowledge-based cluster exploration, and correlation-based cluster validation.","Utilizing a multi-view clustering approach, it enriches data-driven clusters with knowledge-driven similarity, providing a nuanced understanding of business correlations.","Through well-coordinated visual views, Prismatic facilitates a comprehensive interpretation of intertwined quantitative and qualitative features, demonstrating its usefulness and effectiveness via case studies on formulating concept stocks and extensive interviews with domain experts."],"url":"http://arxiv.org/abs/2402.08978v1"}
{"created":"2024-02-14 06:43:02","title":"Confidence-aware Fine-tuning of Sequential Recommendation Systems via Conformal Prediction","abstract":"In Sequential Recommendation Systems, Cross-Entropy (CE) loss is commonly used but fails to harness item confidence scores during training. Recognizing the critical role of confidence in aligning training objectives with evaluation metrics, we propose CPFT, a versatile framework that enhances recommendation confidence by integrating Conformal Prediction (CP)-based losses with CE loss during fine-tuning. CPFT dynamically generates a set of items with a high probability of containing the ground truth, enriching the training process by incorporating validation data without compromising its role in model selection. This innovative approach, coupled with CP-based losses, sharpens the focus on refining recommendation sets, thereby elevating the confidence in potential item predictions. By fine-tuning item confidence through CP-based losses, CPFT significantly enhances model performance, leading to more precise and trustworthy recommendations that increase user trust and satisfaction. Our extensive evaluation across five diverse datasets and four distinct sequential models confirms CPFT's substantial impact on improving recommendation quality through strategic confidence optimization. Access to the framework's code will be provided following the acceptance of the paper.","sentences":["In Sequential Recommendation Systems, Cross-Entropy (CE) loss is commonly used but fails to harness item confidence scores during training.","Recognizing the critical role of confidence in aligning training objectives with evaluation metrics, we propose CPFT, a versatile framework that enhances recommendation confidence by integrating Conformal Prediction (CP)-based losses with CE loss during fine-tuning.","CPFT dynamically generates a set of items with a high probability of containing the ground truth, enriching the training process by incorporating validation data without compromising its role in model selection.","This innovative approach, coupled with CP-based losses, sharpens the focus on refining recommendation sets, thereby elevating the confidence in potential item predictions.","By fine-tuning item confidence through CP-based losses, CPFT significantly enhances model performance, leading to more precise and trustworthy recommendations that increase user trust and satisfaction.","Our extensive evaluation across five diverse datasets and four distinct sequential models confirms CPFT's substantial impact on improving recommendation quality through strategic confidence optimization.","Access to the framework's code will be provided following the acceptance of the paper."],"url":"http://arxiv.org/abs/2402.08976v1"}
{"created":"2024-02-14 06:38:40","title":"Examining the Unique Online Risk Experiences and Mental Health Outcomes of LGBTQ+ versus Heterosexual Youth","abstract":"We collected and analyzed Instagram direct messages (DMs) from 173 youth aged 13-21 (including 86 LGBTQ+ youth). We examined youth's risk-flagged social media trace data with their self-reported mental health outcomes to examine how the differing online experiences of LGBTQ+ youth compare with their heterosexual counterparts. We found that LGBTQ+ youth experienced significantly more high-risk online interactions compared to heterosexual youth. LGBTQ+ youth reported overall poorer mental health, with online harassment specifically amplifying Self-Harm and Injury. LGBTQ+ youth's mental well-being linked positively to sexual messages, unlike heterosexual youth. Qualitatively, we found that most of the risk-flagged messages of LGBTQ+ youth were sexually motivated; however, a silver lining was that they sought support for their sexual identity from peers on the platform. The study highlights the importance of tailored online safety and inclusive design for LGBTQ+ youth, with implications for CHI community advancements in fostering a supportive online environments.","sentences":["We collected and analyzed Instagram direct messages (DMs) from 173 youth aged 13-21 (including 86 LGBTQ+ youth).","We examined youth's risk-flagged social media trace data with their self-reported mental health outcomes to examine how the differing online experiences of LGBTQ+ youth compare with their heterosexual counterparts.","We found that LGBTQ+ youth experienced significantly more high-risk online interactions compared to heterosexual youth.","LGBTQ+ youth reported overall poorer mental health, with online harassment specifically amplifying Self-Harm and Injury.","LGBTQ+ youth's mental well-being linked positively to sexual messages, unlike heterosexual youth.","Qualitatively, we found that most of the risk-flagged messages of LGBTQ+ youth were sexually motivated; however, a silver lining was that they sought support for their sexual identity from peers on the platform.","The study highlights the importance of tailored online safety and inclusive design for LGBTQ+ youth, with implications for CHI community advancements in fostering a supportive online environments."],"url":"http://arxiv.org/abs/2402.08974v1"}
{"created":"2024-02-14 06:33:22","title":"Structured Language Generation Model for Robust Structure Prediction","abstract":"We propose Structured Language Generation Model (SLGM), a mixture of new loss function and inference method for better generalization of structured outputs. Previous studies on structure prediction (e.g. NER, RE) make use of explicit dataset information, which would boost performance, yet it might pose challenges to robust generalization in real-world situations. Instead, our model gives generalized format information about data indirectly. With format information, we could reduce sequence-to-sequence problem into classification problem via loss calibration and formatted decoding. Our experimental results showed SLGM successfully maintain performance without dataset information, and showed much less format errors. We also showed our model can work like adapters on individual dataset, with no additional training.","sentences":["We propose Structured Language Generation Model (SLGM), a mixture of new loss function and inference method for better generalization of structured outputs.","Previous studies on structure prediction (e.g. NER, RE) make use of explicit dataset information, which would boost performance, yet it might pose challenges to robust generalization in real-world situations.","Instead, our model gives generalized format information about data indirectly.","With format information, we could reduce sequence-to-sequence problem into classification problem via loss calibration and formatted decoding.","Our experimental results showed SLGM successfully maintain performance without dataset information, and showed much less format errors.","We also showed our model can work like adapters on individual dataset, with no additional training."],"url":"http://arxiv.org/abs/2402.08971v1"}
{"created":"2024-02-14 06:25:50","title":"GrounDial: Human-norm Grounded Safe Dialog Response Generation","abstract":"Current conversational AI systems based on large language models (LLMs) are known to generate unsafe responses, agreeing to offensive user input or including toxic content. Previous research aimed to alleviate the toxicity, by fine-tuning LLM with manually annotated safe dialogue histories. However, the dependency on additional tuning requires substantial costs. To remove the dependency, we propose GrounDial, where response safety is achieved by grounding responses to commonsense social rules without requiring fine-tuning. A hybrid approach of in-context learning and human-norm-guided decoding of GrounDial enables the response to be quantitatively and qualitatively safer even without additional data or tuning.","sentences":["Current conversational AI systems based on large language models (LLMs) are known to generate unsafe responses, agreeing to offensive user input or including toxic content.","Previous research aimed to alleviate the toxicity, by fine-tuning LLM with manually annotated safe dialogue histories.","However, the dependency on additional tuning requires substantial costs.","To remove the dependency, we propose GrounDial, where response safety is achieved by grounding responses to commonsense social rules without requiring fine-tuning.","A hybrid approach of in-context learning and human-norm-guided decoding of GrounDial enables the response to be quantitatively and qualitatively safer even without additional data or tuning."],"url":"http://arxiv.org/abs/2402.08968v1"}
{"created":"2024-02-14 06:20:48","title":"Pretraining Vision-Language Model for Difference Visual Question Answering in Longitudinal Chest X-rays","abstract":"Difference visual question answering (diff-VQA) is a challenging task that requires answering complex questions based on differences between a pair of images. This task is particularly important in reading chest X-ray images because radiologists often compare multiple images of the same patient taken at different times to track disease progression and changes in its severity in their clinical practice. However, previous works focused on designing specific network architectures for the diff-VQA task, missing opportunities to enhance the model's performance using a pretrained vision-language model (VLM). Here, we introduce a novel VLM called PLURAL, which is pretrained on natural and longitudinal chest X-ray data for the diff-VQA task. The model is developed using a step-by-step approach, starting with being pretrained on natural images and texts, followed by being trained using longitudinal chest X-ray data. The longitudinal data consist of pairs of X-ray images, along with question-answer sets and radiologist's reports that describe the changes in lung abnormalities and diseases over time. Our experimental results show that the PLURAL model outperforms state-of-the-art methods not only in diff-VQA for longitudinal X-rays but also in conventional VQA for a single X-ray image. Through extensive experiments, we demonstrate the effectiveness of the proposed VLM architecture and pretraining method in improving the model's performance.","sentences":["Difference visual question answering (diff-VQA) is a challenging task that requires answering complex questions based on differences between a pair of images.","This task is particularly important in reading chest X-ray images because radiologists often compare multiple images of the same patient taken at different times to track disease progression and changes in its severity in their clinical practice.","However, previous works focused on designing specific network architectures for the diff-VQA task, missing opportunities to enhance the model's performance using a pretrained vision-language model (VLM).","Here, we introduce a novel VLM called PLURAL, which is pretrained on natural and longitudinal chest X-ray data for the diff-VQA task.","The model is developed using a step-by-step approach, starting with being pretrained on natural images and texts, followed by being trained using longitudinal chest X-ray data.","The longitudinal data consist of pairs of X-ray images, along with question-answer sets and radiologist's reports that describe the changes in lung abnormalities and diseases over time.","Our experimental results show that the PLURAL model outperforms state-of-the-art methods not only in diff-VQA for longitudinal X-rays but also in conventional VQA for a single X-ray image.","Through extensive experiments, we demonstrate the effectiveness of the proposed VLM architecture and pretraining method in improving the model's performance."],"url":"http://arxiv.org/abs/2402.08966v1"}
{"created":"2024-02-14 06:10:44","title":"Predicting User Experience on Laptops from Hardware Specifications","abstract":"Estimating the overall user experience (UX) on a device is a common challenge faced by manufacturers. Today, device makers primarily rely on microbenchmark scores, such as Geekbench, that stress test specific hardware components, such as CPU or RAM, but do not satisfactorily capture consumer workloads. System designers often rely on domain-specific heuristics and extensive testing of prototypes to reach a desired UX goal, and yet there is often a mismatch between the manufacturers' performance claims and the consumers' experience.   We present our initial results on predicting real-life experience on laptops from their hardware specifications. We target web applications that run on Chromebooks (ChromeOS laptops) for a simple and fair aggregation of experience across applications and workloads. On 54 laptops, we track 9 UX metrics on common end-user workloads: web browsing, video playback and audio/video calls. We focus on a subset of high-level metrics exposed by the Chrome browser, that are part of the Web Vitals initiative for judging the UX on web applications.   With a dataset of 100K UX data points, we train gradient boosted regression trees that predict the metric values from device specifications. Across our 9 metrics, we note a mean $R^2$ score (goodness-of-fit on our dataset) of 97.8% and a mean MAAPE (percentage error in prediction on unseen data) of 10.1%.","sentences":["Estimating the overall user experience (UX) on a device is a common challenge faced by manufacturers.","Today, device makers primarily rely on microbenchmark scores, such as Geekbench, that stress test specific hardware components, such as CPU or RAM, but do not satisfactorily capture consumer workloads.","System designers often rely on domain-specific heuristics and extensive testing of prototypes to reach a desired UX goal, and yet there is often a mismatch between the manufacturers' performance claims and the consumers' experience.   ","We present our initial results on predicting real-life experience on laptops from their hardware specifications.","We target web applications that run on Chromebooks (ChromeOS laptops) for a simple and fair aggregation of experience across applications and workloads.","On 54 laptops, we track 9 UX metrics on common end-user workloads: web browsing, video playback and audio/video calls.","We focus on a subset of high-level metrics exposed by the Chrome browser, that are part of the Web Vitals initiative for judging the UX on web applications.   ","With a dataset of 100K UX data points, we train gradient boosted regression trees that predict the metric values from device specifications.","Across our 9 metrics, we note a mean $R^2$ score (goodness-of-fit on our dataset) of 97.8% and a mean MAAPE (percentage error in prediction on unseen data) of 10.1%."],"url":"http://arxiv.org/abs/2402.08964v1"}
{"created":"2024-02-14 06:09:36","title":"DUEL: Duplicate Elimination on Active Memory for Self-Supervised Class-Imbalanced Learning","abstract":"Recent machine learning algorithms have been developed using well-curated datasets, which often require substantial cost and resources. On the other hand, the direct use of raw data often leads to overfitting towards frequently occurring class information. To address class imbalances cost-efficiently, we propose an active data filtering process during self-supervised pre-training in our novel framework, Duplicate Elimination (DUEL). This framework integrates an active memory inspired by human working memory and introduces distinctiveness information, which measures the diversity of the data in the memory, to optimize both the feature extractor and the memory. The DUEL policy, which replaces the most duplicated data with new samples, aims to enhance the distinctiveness information in the memory and thereby mitigate class imbalances. We validate the effectiveness of the DUEL framework in class-imbalanced environments, demonstrating its robustness and providing reliable results in downstream tasks. We also analyze the role of the DUEL policy in the training process through various metrics and visualizations.","sentences":["Recent machine learning algorithms have been developed using well-curated datasets, which often require substantial cost and resources.","On the other hand, the direct use of raw data often leads to overfitting towards frequently occurring class information.","To address class imbalances cost-efficiently, we propose an active data filtering process during self-supervised pre-training in our novel framework, Duplicate Elimination (DUEL).","This framework integrates an active memory inspired by human working memory and introduces distinctiveness information, which measures the diversity of the data in the memory, to optimize both the feature extractor and the memory.","The DUEL policy, which replaces the most duplicated data with new samples, aims to enhance the distinctiveness information in the memory and thereby mitigate class imbalances.","We validate the effectiveness of the DUEL framework in class-imbalanced environments, demonstrating its robustness and providing reliable results in downstream tasks.","We also analyze the role of the DUEL policy in the training process through various metrics and visualizations."],"url":"http://arxiv.org/abs/2402.08963v1"}
{"created":"2024-02-14 05:57:58","title":"MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data","abstract":"Recent large language models (LLMs) have witnessed significant advancement in various tasks, including mathematical reasoning and theorem proving. As these two tasks require strict and formal multi-step inference, they are appealing domains for exploring the reasoning ability of LLMs but still face important challenges. Previous studies such as Chain-of-Thought (CoT) have revealed the effectiveness of intermediate steps guidance. However, such step-wise annotation requires heavy labor, leading to insufficient training steps for current benchmarks. To fill this gap, this work introduces MUSTARD, a data generation framework that masters uniform synthesis of theorem and proof data of high quality and diversity. MUSTARD synthesizes data in three stages: (1) It samples a few mathematical concept seeds as the problem category. (2) Then, it prompts a generative language model with the sampled concepts to obtain both the problems and their step-wise formal solutions. (3) Lastly, the framework utilizes a proof assistant (e.g., Lean Prover) to filter the valid proofs. With the proposed MUSTARD, we present a theorem-and-proof benchmark MUSTARDSAUCE with 5,866 valid data points. Each data point contains an informal statement, an informal proof, and a translated formal proof that passes the prover validation. We perform extensive analysis and demonstrate that MUSTARD generates validated high-quality step-by-step data. We further apply the MUSTARDSAUCE for fine-tuning smaller language models. The fine-tuned Llama 2-7B achieves a 15.41% average relative performance gain in automated theorem proving, and 8.18% in math word problems. Codes and data are available at https://github.com/Eleanor-H/MUSTARD.","sentences":["Recent large language models (LLMs) have witnessed significant advancement in various tasks, including mathematical reasoning and theorem proving.","As these two tasks require strict and formal multi-step inference, they are appealing domains for exploring the reasoning ability of LLMs but still face important challenges.","Previous studies such as Chain-of-Thought (CoT) have revealed the effectiveness of intermediate steps guidance.","However, such step-wise annotation requires heavy labor, leading to insufficient training steps for current benchmarks.","To fill this gap, this work introduces MUSTARD, a data generation framework that masters uniform synthesis of theorem and proof data of high quality and diversity.","MUSTARD synthesizes data in three stages: (1) It samples a few mathematical concept seeds as the problem category.","(2) Then, it prompts a generative language model with the sampled concepts to obtain both the problems and their step-wise formal solutions.","(3) Lastly, the framework utilizes a proof assistant (e.g., Lean Prover) to filter the valid proofs.","With the proposed MUSTARD, we present a theorem-and-proof benchmark MUSTARDSAUCE with 5,866 valid data points.","Each data point contains an informal statement, an informal proof, and a translated formal proof that passes the prover validation.","We perform extensive analysis and demonstrate that MUSTARD generates validated high-quality step-by-step data.","We further apply the MUSTARDSAUCE for fine-tuning smaller language models.","The fine-tuned Llama 2-7B achieves a 15.41% average relative performance gain in automated theorem proving, and 8.18% in math word problems.","Codes and data are available at https://github.com/Eleanor-H/MUSTARD."],"url":"http://arxiv.org/abs/2402.08957v1"}
{"created":"2024-02-14 05:52:23","title":"Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models","abstract":"Large language models (LLMs) have performed well on several reasoning benchmarks, including ones that test analogical reasoning abilities. However, it has been debated whether they are actually performing humanlike abstract reasoning or instead employing less general processes that rely on similarity to what has been seen in their training data. Here we investigate the generality of analogy-making abilities previously claimed for LLMs (Webb, Holyoak, & Lu, 2023). We take one set of analogy problems used to evaluate LLMs and create a set of \"counterfactual\" variants-versions that test the same abstract reasoning abilities but that are likely dissimilar from any pre-training data. We test humans and three GPT models on both the original and counterfactual problems, and show that, while the performance of humans remains high for all the problems, the GPT models' performance declines sharply on the counterfactual set. This work provides evidence that, despite previously reported successes of LLMs on analogical reasoning, these models lack the robustness and generality of human analogy-making.","sentences":["Large language models (LLMs) have performed well on several reasoning benchmarks, including ones that test analogical reasoning abilities.","However, it has been debated whether they are actually performing humanlike abstract reasoning or instead employing less general processes that rely on similarity to what has been seen in their training data.","Here we investigate the generality of analogy-making abilities previously claimed for LLMs (Webb, Holyoak, & Lu, 2023).","We take one set of analogy problems used to evaluate LLMs and create a set of \"counterfactual\" variants-versions that test the same abstract reasoning abilities but that are likely dissimilar from any pre-training data.","We test humans and three GPT models on both the original and counterfactual problems, and show that, while the performance of humans remains high for all the problems, the GPT models' performance declines sharply on the counterfactual set.","This work provides evidence that, despite previously reported successes of LLMs on analogical reasoning, these models lack the robustness and generality of human analogy-making."],"url":"http://arxiv.org/abs/2402.08955v1"}
{"created":"2024-02-14 05:08:47","title":"Evaluating DTW Measures via a Synthesis Framework for Time-Series Data","abstract":"Time-series data originate from various applications that describe specific observations or quantities of interest over time. Their analysis often involves the comparison across different time-series data sequences, which in turn requires the alignment of these sequences. Dynamic Time Warping (DTW) is the standard approach to achieve an optimal alignment between two temporal signals. Different variations of DTW have been proposed to address various needs for signal alignment or classifications. However, a comprehensive evaluation of their performance in these time-series data processing tasks is lacking. Most DTW measures perform well on certain types of time-series data without a clear explanation of the reason. To address that, we propose a synthesis framework to model the variation between two time-series data sequences for comparison. Our synthesis framework can produce a realistic initial signal and deform it with controllable variations that mimic real-world scenarios. With this synthesis framework, we produce a large number of time-series sequence pairs with different but known variations, which are used to assess the performance of a number of well-known DTW measures for the tasks of alignment and classification. We report their performance on different variations and suggest the proper DTW measure to use based on the type of variations between two time-series sequences. This is the first time such a guideline is presented for selecting a proper DTW measure. To validate our conclusion, we apply our findings to real-world applications, i.e., the detection of the formation top for the oil and gas industry and the pattern search in streamlines for flow visualization.","sentences":["Time-series data originate from various applications that describe specific observations or quantities of interest over time.","Their analysis often involves the comparison across different time-series data sequences, which in turn requires the alignment of these sequences.","Dynamic Time Warping (DTW) is the standard approach to achieve an optimal alignment between two temporal signals.","Different variations of DTW have been proposed to address various needs for signal alignment or classifications.","However, a comprehensive evaluation of their performance in these time-series data processing tasks is lacking.","Most DTW measures perform well on certain types of time-series data without a clear explanation of the reason.","To address that, we propose a synthesis framework to model the variation between two time-series data sequences for comparison.","Our synthesis framework can produce a realistic initial signal and deform it with controllable variations that mimic real-world scenarios.","With this synthesis framework, we produce a large number of time-series sequence pairs with different but known variations, which are used to assess the performance of a number of well-known DTW measures for the tasks of alignment and classification.","We report their performance on different variations and suggest the proper DTW measure to use based on the type of variations between two time-series sequences.","This is the first time such a guideline is presented for selecting a proper DTW measure.","To validate our conclusion, we apply our findings to real-world applications, i.e., the detection of the formation top for the oil and gas industry and the pattern search in streamlines for flow visualization."],"url":"http://arxiv.org/abs/2402.08943v1"}
{"created":"2024-02-14 04:44:05","title":"AINeedsPlanner: AWorkbook to Support Effective Collaboration Between AI Experts and Clients","abstract":"Clients often partner with AI experts to develop AI applications tailored to their needs. In these partnerships, careful planning and clear communication are critical, as inaccurate or incomplete specifications can result in misaligned model characteristics, expensive reworks, and potential friction between collaborators. Unfortunately, given the complexity of requirements ranging from functionality, data, and governance, effective guidelines for collaborative specification of requirements in client-AI expert collaborations are missing. In this work, we introduce AINeedsPlanner, a workbook that AI experts and clients can use to facilitate effective interchange and clear specifications. The workbook is based on (1) an interview of 10 completed AI application project teams, which identifies and characterizes steps in AI application planning and (2) a study with 12 AI experts, which defines a taxonomy of AI experts' information needs and dimensions that affect the information needs. Finally, we demonstrate the workbook's utility with two case studies in real-world settings.","sentences":["Clients often partner with AI experts to develop AI applications tailored to their needs.","In these partnerships, careful planning and clear communication are critical, as inaccurate or incomplete specifications can result in misaligned model characteristics, expensive reworks, and potential friction between collaborators.","Unfortunately, given the complexity of requirements ranging from functionality, data, and governance, effective guidelines for collaborative specification of requirements in client-AI expert collaborations are missing.","In this work, we introduce AINeedsPlanner, a workbook that AI experts and clients can use to facilitate effective interchange and clear specifications.","The workbook is based on (1) an interview of 10 completed AI application project teams, which identifies and characterizes steps in AI application planning and (2) a study with 12 AI experts, which defines a taxonomy of AI experts' information needs and dimensions that affect the information needs.","Finally, we demonstrate the workbook's utility with two case studies in real-world settings."],"url":"http://arxiv.org/abs/2402.08938v1"}
{"created":"2024-02-14 04:34:48","title":"Predictive Temporal Attention on Event-based Video Stream for Energy-efficient Situation Awareness","abstract":"The Dynamic Vision Sensor (DVS) is an innovative technology that efficiently captures and encodes visual information in an event-driven manner. By combining it with event-driven neuromorphic processing, the sparsity in DVS camera output can result in high energy efficiency. However, similar to many embedded systems, the off-chip communication between the camera and processor presents a bottleneck in terms of power consumption. Inspired by the predictive coding model and expectation suppression phenomenon found in human brain, we propose a temporal attention mechanism to throttle the camera output and pay attention to it only when the visual events cannot be well predicted. The predictive attention not only reduces power consumption in the sensor-processor interface but also effectively decreases the computational workload by filtering out noisy events. We demonstrate that the predictive attention can reduce 46.7% of data communication between the camera and the processor and reduce 43.8% computation activities in the processor.","sentences":["The Dynamic Vision Sensor (DVS) is an innovative technology that efficiently captures and encodes visual information in an event-driven manner.","By combining it with event-driven neuromorphic processing, the sparsity in DVS camera output can result in high energy efficiency.","However, similar to many embedded systems, the off-chip communication between the camera and processor presents a bottleneck in terms of power consumption.","Inspired by the predictive coding model and expectation suppression phenomenon found in human brain, we propose a temporal attention mechanism to throttle the camera output and pay attention to it only when the visual events cannot be well predicted.","The predictive attention not only reduces power consumption in the sensor-processor interface but also effectively decreases the computational workload by filtering out noisy events.","We demonstrate that the predictive attention can reduce 46.7% of data communication between the camera and the processor and reduce 43.8% computation activities in the processor."],"url":"http://arxiv.org/abs/2402.08936v1"}
{"created":"2024-02-14 04:03:38","title":"Second Order Methods for Bandit Optimization and Control","abstract":"Bandit convex optimization (BCO) is a general framework for online decision making under uncertainty. While tight regret bounds for general convex losses have been established, existing algorithms achieving these bounds have prohibitive computational costs for high dimensional data.   In this paper, we propose a simple and practical BCO algorithm inspired by the online Newton step algorithm. We show that our algorithm achieves optimal (in terms of horizon) regret bounds for a large class of convex functions that we call $\\kappa$-convex. This class contains a wide range of practically relevant loss functions including linear, quadratic, and generalized linear models. In addition to optimal regret, this method is the most efficient known algorithm for several well-studied applications including bandit logistic regression.   Furthermore, we investigate the adaptation of our second-order bandit algorithm to online convex optimization with memory. We show that for loss functions with a certain affine structure, the extended algorithm attains optimal regret. This leads to an algorithm with optimal regret for bandit LQR/LQG problems under a fully adversarial noise model, thereby resolving an open question posed in \\citep{gradu2020non} and \\citep{sun2023optimal}.   Finally, we show that the more general problem of BCO with (non-affine) memory is harder. We derive a $\\tilde{\\Omega}(T^{2/3})$ regret lower bound, even under the assumption of smooth and quadratic losses.","sentences":["Bandit convex optimization (BCO) is a general framework for online decision making under uncertainty.","While tight regret bounds for general convex losses have been established, existing algorithms achieving these bounds have prohibitive computational costs for high dimensional data.   ","In this paper, we propose a simple and practical BCO algorithm inspired by the online Newton step algorithm.","We show that our algorithm achieves optimal (in terms of horizon) regret bounds for a large class of convex functions that we call $\\kappa$-convex.","This class contains a wide range of practically relevant loss functions including linear, quadratic, and generalized linear models.","In addition to optimal regret, this method is the most efficient known algorithm for several well-studied applications including bandit logistic regression.   ","Furthermore, we investigate the adaptation of our second-order bandit algorithm to online convex optimization with memory.","We show that for loss functions with a certain affine structure, the extended algorithm attains optimal regret.","This leads to an algorithm with optimal regret for bandit LQR/LQG problems under a fully adversarial noise model, thereby resolving an open question posed in \\citep{gradu2020non} and \\citep{sun2023optimal}.   ","Finally, we show that the more general problem of BCO with (non-affine) memory is harder.","We derive a $\\tilde{\\Omega}(T^{2/3})$ regret lower bound, even under the assumption of smooth and quadratic losses."],"url":"http://arxiv.org/abs/2402.08929v1"}
{"created":"2024-02-14 03:56:27","title":"MaxMin-RLHF: Towards Equitable Alignment of Large Language Models with Diverse Human Preferences","abstract":"Reinforcement Learning from Human Feedback (RLHF) aligns language models to human preferences by employing a singular reward model derived from preference data. However, such an approach overlooks the rich diversity of human preferences inherent in data collected from multiple users. In this work, we first derive an impossibility result of alignment with single reward RLHF, thereby highlighting its insufficiency in representing diverse human preferences. To provide an equitable solution to the problem, we learn a mixture of preference distributions via an expectation-maximization algorithm and propose a MaxMin alignment objective for policy learning inspired by the Egalitarian principle in social choice theory to better represent diverse human preferences. We elucidate the connection of our proposed approach to distributionally robust optimization and general utility RL, thereby highlighting the generality and robustness of our proposed solution. We present comprehensive experimental results on small-scale (GPT-2) and large-scale language models (with Tulu2-7B) and show the efficacy of the proposed approach in the presence of diversity among human preferences. Our algorithm achieves an average improvement of more than 16% in win-rates over conventional RLHF algorithms and improves the win-rate (accuracy) for minority groups by over 33% without compromising the performance of majority groups, showcasing the robustness and fairness of our approach. We remark that our findings in this work are not only limited to language models but also extend to reinforcement learning in general.","sentences":["Reinforcement Learning from Human Feedback (RLHF) aligns language models to human preferences by employing a singular reward model derived from preference data.","However, such an approach overlooks the rich diversity of human preferences inherent in data collected from multiple users.","In this work, we first derive an impossibility result of alignment with single reward RLHF, thereby highlighting its insufficiency in representing diverse human preferences.","To provide an equitable solution to the problem, we learn a mixture of preference distributions via an expectation-maximization algorithm and propose a MaxMin alignment objective for policy learning inspired by the Egalitarian principle in social choice theory to better represent diverse human preferences.","We elucidate the connection of our proposed approach to distributionally robust optimization and general utility RL, thereby highlighting the generality and robustness of our proposed solution.","We present comprehensive experimental results on small-scale (GPT-2) and large-scale language models (with Tulu2-7B) and show the efficacy of the proposed approach in the presence of diversity among human preferences.","Our algorithm achieves an average improvement of more than 16% in win-rates over conventional RLHF algorithms and improves the win-rate (accuracy) for minority groups by over 33% without compromising the performance of majority groups, showcasing the robustness and fairness of our approach.","We remark that our findings in this work are not only limited to language models but also extend to reinforcement learning in general."],"url":"http://arxiv.org/abs/2402.08925v1"}
{"created":"2024-02-14 03:45:26","title":"IMUOptimize: A Data-Driven Approach to Optimal IMU Placement for Human Pose Estimation with Transformer Architecture","abstract":"This paper presents a novel approach for predicting human poses using IMU data, diverging from previous studies such as DIP-IMU, IMUPoser, and TransPose, which use up to 6 IMUs in conjunction with bidirectional RNNs. We introduce two main innovations: a data-driven strategy for optimal IMU placement and a transformer-based model architecture for time series analysis. Our findings indicate that our approach not only outperforms traditional 6 IMU-based biRNN models but also that the transformer architecture significantly enhances pose reconstruction from data obtained from 24 IMU locations, with equivalent performance to biRNNs when using only 6 IMUs. The enhanced accuracy provided by our optimally chosen locations, when coupled with the parallelizability and performance of transformers, provides significant improvements to the field of IMU-based pose estimation.","sentences":["This paper presents a novel approach for predicting human poses using IMU data, diverging from previous studies such as DIP-IMU, IMUPoser, and TransPose, which use up to 6 IMUs in conjunction with bidirectional RNNs.","We introduce two main innovations: a data-driven strategy for optimal IMU placement and a transformer-based model architecture for time series analysis.","Our findings indicate that our approach not only outperforms traditional 6 IMU-based biRNN models but also that the transformer architecture significantly enhances pose reconstruction from data obtained from 24 IMU locations, with equivalent performance to biRNNs when using only 6 IMUs.","The enhanced accuracy provided by our optimally chosen locations, when coupled with the parallelizability and performance of transformers, provides significant improvements to the field of IMU-based pose estimation."],"url":"http://arxiv.org/abs/2402.08923v1"}
{"created":"2024-02-14 03:43:05","title":"The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes","abstract":"Large-scale black-box models have become ubiquitous across numerous applications. Understanding the influence of individual training data sources on predictions made by these models is crucial for improving their trustworthiness. Current influence estimation techniques involve computing gradients for every training point or repeated training on different subsets. These approaches face obvious computational challenges when scaled up to large datasets and models.   In this paper, we introduce and explore the Mirrored Influence Hypothesis, highlighting a reciprocal nature of influence between training and test data. Specifically, it suggests that evaluating the influence of training data on test predictions can be reformulated as an equivalent, yet inverse problem: assessing how the predictions for training samples would be altered if the model were trained on specific test samples. Through both empirical and theoretical validations, we demonstrate the wide applicability of our hypothesis. Inspired by this, we introduce a new method for estimating the influence of training data, which requires calculating gradients for specific test samples, paired with a forward pass for each training point. This approach can capitalize on the common asymmetry in scenarios where the number of test samples under concurrent examination is much smaller than the scale of the training dataset, thus gaining a significant improvement in efficiency compared to existing approaches.   We demonstrate the applicability of our method across a range of scenarios, including data attribution in diffusion models, data leakage detection, analysis of memorization, mislabeled data detection, and tracing behavior in language models. Our code will be made available at https://github.com/ruoxi-jia-group/Forward-INF.","sentences":["Large-scale black-box models have become ubiquitous across numerous applications.","Understanding the influence of individual training data sources on predictions made by these models is crucial for improving their trustworthiness.","Current influence estimation techniques involve computing gradients for every training point or repeated training on different subsets.","These approaches face obvious computational challenges when scaled up to large datasets and models.   ","In this paper, we introduce and explore the Mirrored Influence Hypothesis, highlighting a reciprocal nature of influence between training and test data.","Specifically, it suggests that evaluating the influence of training data on test predictions can be reformulated as an equivalent, yet inverse problem: assessing how the predictions for training samples would be altered if the model were trained on specific test samples.","Through both empirical and theoretical validations, we demonstrate the wide applicability of our hypothesis.","Inspired by this, we introduce a new method for estimating the influence of training data, which requires calculating gradients for specific test samples, paired with a forward pass for each training point.","This approach can capitalize on the common asymmetry in scenarios where the number of test samples under concurrent examination is much smaller than the scale of the training dataset, thus gaining a significant improvement in efficiency compared to existing approaches.   ","We demonstrate the applicability of our method across a range of scenarios, including data attribution in diffusion models, data leakage detection, analysis of memorization, mislabeled data detection, and tracing behavior in language models.","Our code will be made available at https://github.com/ruoxi-jia-group/Forward-INF."],"url":"http://arxiv.org/abs/2402.08922v1"}
{"created":"2024-02-14 03:31:17","title":"Interpretable Measures of Conceptual Similarity by Complexity-Constrained Descriptive Auto-Encoding","abstract":"Quantifying the degree of similarity between images is a key copyright issue for image-based machine learning. In legal doctrine however, determining the degree of similarity between works requires subjective analysis, and fact-finders (judges and juries) can demonstrate considerable variability in these subjective judgement calls. Images that are structurally similar can be deemed dissimilar, whereas images of completely different scenes can be deemed similar enough to support a claim of copying. We seek to define and compute a notion of \"conceptual similarity\" among images that captures high-level relations even among images that do not share repeated elements or visually similar components. The idea is to use a base multi-modal model to generate \"explanations\" (captions) of visual data at increasing levels of complexity. Then, similarity can be measured by the length of the caption needed to discriminate between the two images: Two highly dissimilar images can be discriminated early in their description, whereas conceptually dissimilar ones will need more detail to be distinguished. We operationalize this definition and show that it correlates with subjective (averaged human evaluation) assessment, and beats existing baselines on both image-to-image and text-to-text similarity benchmarks. Beyond just providing a number, our method also offers interpretability by pointing to the specific level of granularity of the description where the source data are differentiated.","sentences":["Quantifying the degree of similarity between images is a key copyright issue for image-based machine learning.","In legal doctrine however, determining the degree of similarity between works requires subjective analysis, and fact-finders (judges and juries) can demonstrate considerable variability in these subjective judgement calls.","Images that are structurally similar can be deemed dissimilar, whereas images of completely different scenes can be deemed similar enough to support a claim of copying.","We seek to define and compute a notion of \"conceptual similarity\" among images that captures high-level relations even among images that do not share repeated elements or visually similar components.","The idea is to use a base multi-modal model to generate \"explanations\" (captions) of visual data at increasing levels of complexity.","Then, similarity can be measured by the length of the caption needed to discriminate between the two images: Two highly dissimilar images can be discriminated early in their description, whereas conceptually dissimilar ones will need more detail to be distinguished.","We operationalize this definition and show that it correlates with subjective (averaged human evaluation) assessment, and beats existing baselines on both image-to-image and text-to-text similarity benchmarks.","Beyond just providing a number, our method also offers interpretability by pointing to the specific level of granularity of the description where the source data are differentiated."],"url":"http://arxiv.org/abs/2402.08919v1"}
{"created":"2024-02-14 02:46:47","title":"Tackling Negative Transfer on Graphs","abstract":"Transfer learning aims to boost the learning on the target task leveraging knowledge learned from other relevant tasks. However, when the source and target are not closely related, the learning performance may be adversely affected, a phenomenon known as negative transfer. In this paper, we investigate the negative transfer in graph transfer learning, which is important yet underexplored. We reveal that, unlike image or text, negative transfer commonly occurs in graph-structured data, even when source and target graphs share semantic similarities. Specifically, we identify that structural differences significantly amplify the dissimilarities in the node embeddings across graphs. To mitigate this, we bring a new insight: for semantically similar graphs, although structural differences lead to significant distribution shift in node embeddings, their impact on subgraph embeddings could be marginal. Building on this insight, we introduce two effective yet elegant methods, Subgraph Pooling (SP) and Subgraph Pooling++ (SP++), that transfer subgraph-level knowledge across graphs. We theoretically analyze the role of SP in reducing graph discrepancy and conduct extensive experiments to evaluate its superiority under various settings. Our code and datasets are available at: https://github.com/Zehong-Wang/Subgraph-Pooling.","sentences":["Transfer learning aims to boost the learning on the target task leveraging knowledge learned from other relevant tasks.","However, when the source and target are not closely related, the learning performance may be adversely affected, a phenomenon known as negative transfer.","In this paper, we investigate the negative transfer in graph transfer learning, which is important yet underexplored.","We reveal that, unlike image or text, negative transfer commonly occurs in graph-structured data, even when source and target graphs share semantic similarities.","Specifically, we identify that structural differences significantly amplify the dissimilarities in the node embeddings across graphs.","To mitigate this, we bring a new insight: for semantically similar graphs, although structural differences lead to significant distribution shift in node embeddings, their impact on subgraph embeddings could be marginal.","Building on this insight, we introduce two effective yet elegant methods, Subgraph Pooling (SP) and Subgraph Pooling++ (SP++), that transfer subgraph-level knowledge across graphs.","We theoretically analyze the role of SP in reducing graph discrepancy and conduct extensive experiments to evaluate its superiority under various settings.","Our code and datasets are available at: https://github.com/Zehong-Wang/Subgraph-Pooling."],"url":"http://arxiv.org/abs/2402.08907v1"}
{"created":"2024-02-14 00:42:19","title":"DUDF: Differentiable Unsigned Distance Fields with Hyperbolic Scaling","abstract":"In recent years, there has been a growing interest in training Neural Networks to approximate Unsigned Distance Fields (UDFs) for representing open surfaces in the context of 3D reconstruction. However, UDFs are non-differentiable at the zero level set which leads to significant errors in distances and gradients, generally resulting in fragmented and discontinuous surfaces. In this paper, we propose to learn a hyperbolic scaling of the unsigned distance field, which defines a new Eikonal problem with distinct boundary conditions. This allows our formulation to integrate seamlessly with state-of-the-art continuously differentiable implicit neural representation networks, largely applied in the literature to represent signed distance fields. Our approach not only addresses the challenge of open surface representation but also demonstrates significant improvement in reconstruction quality and training performance. Moreover, the unlocked field's differentiability allows the accurate computation of essential topological properties such as normal directions and curvatures, pervasive in downstream tasks such as rendering. Through extensive experiments, we validate our approach across various data sets and against competitive baselines. The results demonstrate enhanced accuracy and up to an order of magnitude increase in speed compared to previous methods.","sentences":["In recent years, there has been a growing interest in training Neural Networks to approximate Unsigned Distance Fields (UDFs) for representing open surfaces in the context of 3D reconstruction.","However, UDFs are non-differentiable at the zero level set which leads to significant errors in distances and gradients, generally resulting in fragmented and discontinuous surfaces.","In this paper, we propose to learn a hyperbolic scaling of the unsigned distance field, which defines a new Eikonal problem with distinct boundary conditions.","This allows our formulation to integrate seamlessly with state-of-the-art continuously differentiable implicit neural representation networks, largely applied in the literature to represent signed distance fields.","Our approach not only addresses the challenge of open surface representation but also demonstrates significant improvement in reconstruction quality and training performance.","Moreover, the unlocked field's differentiability allows the accurate computation of essential topological properties such as normal directions and curvatures, pervasive in downstream tasks such as rendering.","Through extensive experiments, we validate our approach across various data sets and against competitive baselines.","The results demonstrate enhanced accuracy and up to an order of magnitude increase in speed compared to previous methods."],"url":"http://arxiv.org/abs/2402.08876v1"}
{"created":"2024-02-14 00:30:18","title":"ScamSpot: Fighting Financial Fraud in Instagram Comments","abstract":"The long-standing problem of spam and fraudulent messages in the comment sections of Instagram pages in the financial sector claims new victims every day. Instagram's current spam filter proves inadequate, and existing research approaches are primarily confined to theoretical concepts. Practical implementations with evaluated results are missing. To solve this problem, we propose ScamSpot, a comprehensive system that includes a browser extension, a fine-tuned BERT model and a REST API. This approach ensures public accessibility of our results for Instagram users using the Chrome browser. Furthermore, we conduct a data annotation study, shedding light on the reasons and causes of the problem and evaluate the system through user feedback and comparison with existing models. ScamSpot is an open-source project and is publicly available at https://scamspot.github.io/.","sentences":["The long-standing problem of spam and fraudulent messages in the comment sections of Instagram pages in the financial sector claims new victims every day.","Instagram's current spam filter proves inadequate, and existing research approaches are primarily confined to theoretical concepts.","Practical implementations with evaluated results are missing.","To solve this problem, we propose ScamSpot, a comprehensive system that includes a browser extension, a fine-tuned BERT model and a REST API.","This approach ensures public accessibility of our results for Instagram users using the Chrome browser.","Furthermore, we conduct a data annotation study, shedding light on the reasons and causes of the problem and evaluate the system through user feedback and comparison with existing models.","ScamSpot is an open-source project and is publicly available at https://scamspot.github.io/."],"url":"http://arxiv.org/abs/2402.08869v1"}
{"created":"2024-02-14 00:29:18","title":"Distributed Optimization with Consensus Constraint for Multi-Robot Semantic Octree Mapping","abstract":"This work develops a distributed optimization algorithm for multi-robot 3-D semantic mapping using streaming range and visual observations and single-hop communication. Our approach relies on gradient-based optimization of the observation log-likelihood of each robot subject to a map consensus constraint to build a common multi-class map of the environment. This formulation leads to closed-form updates which resemble Bayes rule with one-hop prior averaging. To reduce the amount of information exchanged among the robots, we utilize an octree data structure that compresses the multi-class map distribution using adaptive-resolution.","sentences":["This work develops a distributed optimization algorithm for multi-robot 3-D semantic mapping using streaming range and visual observations and single-hop communication.","Our approach relies on gradient-based optimization of the observation log-likelihood of each robot subject to a map consensus constraint to build a common multi-class map of the environment.","This formulation leads to closed-form updates which resemble Bayes rule with one-hop prior averaging.","To reduce the amount of information exchanged among the robots, we utilize an octree data structure that compresses the multi-class map distribution using adaptive-resolution."],"url":"http://arxiv.org/abs/2402.08867v1"}
{"created":"2024-02-13 23:56:04","title":"Safe Planning for Articulated Robots Using Reachability-based Obstacle Avoidance With Spheres","abstract":"Generating safe motion plans in real-time is necessary for the wide-scale deployment of robots in unstructured and human-centric environments. These motion plans must be safe to ensure humans are not harmed and nearby objects are not damaged. However, they must also be generated in real-time to ensure the robot can quickly adapt to changes in the environment. Many trajectory optimization methods introduce heuristics that trade-off safety and real-time performance, which can lead to potentially unsafe plans. This paper addresses this challenge by proposing Safe Planning for Articulated Robots Using Reachability-based Obstacle Avoidance With Spheres (SPARROWS). SPARROWS is a receding-horizon trajectory planner that utilizes the combination of a novel reachable set representation and an exact signed distance function to generate provably-safe motion plans. At runtime, SPARROWS uses parameterized trajectories to compute reachable sets composed entirely of spheres that overapproximate the swept volume of the robot's motion. SPARROWS then performs trajectory optimization to select a safe trajectory that is guaranteed to be collision-free. We demonstrate that SPARROWS' novel reachable set is significantly less conservative than previous approaches. We also demonstrate that SPARROWS outperforms a variety of state-of-the-art methods in solving challenging motion planning tasks in cluttered environments. Code, data, and video demonstrations can be found at \\url{https://roahmlab.github.io/sparrows/}.","sentences":["Generating safe motion plans in real-time is necessary for the wide-scale deployment of robots in unstructured and human-centric environments.","These motion plans must be safe to ensure humans are not harmed and nearby objects are not damaged.","However, they must also be generated in real-time to ensure the robot can quickly adapt to changes in the environment.","Many trajectory optimization methods introduce heuristics that trade-off safety and real-time performance, which can lead to potentially unsafe plans.","This paper addresses this challenge by proposing Safe Planning for Articulated Robots Using Reachability-based Obstacle Avoidance With Spheres (SPARROWS).","SPARROWS is a receding-horizon trajectory planner that utilizes the combination of a novel reachable set representation and an exact signed distance function to generate provably-safe motion plans.","At runtime, SPARROWS uses parameterized trajectories to compute reachable sets composed entirely of spheres that overapproximate the swept volume of the robot's motion.","SPARROWS then performs trajectory optimization to select a safe trajectory that is guaranteed to be collision-free.","We demonstrate that SPARROWS' novel reachable set is significantly less conservative than previous approaches.","We also demonstrate that SPARROWS outperforms a variety of state-of-the-art methods in solving challenging motion planning tasks in cluttered environments.","Code, data, and video demonstrations can be found at \\url{https://roahmlab.github.io/sparrows/}."],"url":"http://arxiv.org/abs/2402.08857v1"}
{"created":"2024-02-13 23:29:09","title":"Hybrid Inverse Reinforcement Learning","abstract":"The inverse reinforcement learning approach to imitation learning is a double-edged sword. On the one hand, it can enable learning from a smaller number of expert demonstrations with more robustness to error compounding than behavioral cloning approaches. On the other hand, it requires that the learner repeatedly solve a computationally expensive reinforcement learning (RL) problem. Often, much of this computation is wasted searching over policies very dissimilar to the expert's. In this work, we propose using hybrid RL -- training on a mixture of online and expert data -- to curtail unnecessary exploration. Intuitively, the expert data focuses the learner on good states during training, which reduces the amount of exploration required to compute a strong policy. Notably, such an approach doesn't need the ability to reset the learner to arbitrary states in the environment, a requirement of prior work in efficient inverse RL. More formally, we derive a reduction from inverse RL to expert-competitive RL (rather than globally optimal RL) that allows us to dramatically reduce interaction during the inner policy search loop while maintaining the benefits of the IRL approach. This allows us to derive both model-free and model-based hybrid inverse RL algorithms with strong policy performance guarantees. Empirically, we find that our approaches are significantly more sample efficient than standard inverse RL and several other baselines on a suite of continuous control tasks.","sentences":["The inverse reinforcement learning approach to imitation learning is a double-edged sword.","On the one hand, it can enable learning from a smaller number of expert demonstrations with more robustness to error compounding than behavioral cloning approaches.","On the other hand, it requires that the learner repeatedly solve a computationally expensive reinforcement learning (RL) problem.","Often, much of this computation is wasted searching over policies very dissimilar to the expert's.","In this work, we propose using hybrid RL -- training on a mixture of online and expert data -- to curtail unnecessary exploration.","Intuitively, the expert data focuses the learner on good states during training, which reduces the amount of exploration required to compute a strong policy.","Notably, such an approach doesn't need the ability to reset the learner to arbitrary states in the environment, a requirement of prior work in efficient inverse RL.","More formally, we derive a reduction from inverse RL to expert-competitive RL (rather than globally optimal RL) that allows us to dramatically reduce interaction during the inner policy search loop while maintaining the benefits of the IRL approach.","This allows us to derive both model-free and model-based hybrid inverse RL algorithms with strong policy performance guarantees.","Empirically, we find that our approaches are significantly more sample efficient than standard inverse RL and several other baselines on a suite of continuous control tasks."],"url":"http://arxiv.org/abs/2402.08848v1"}
{"created":"2024-02-13 23:25:04","title":"An Embarrassingly Simple Approach for LLM with Strong ASR Capacity","abstract":"In this paper, we focus on solving one of the most important tasks in the field of speech processing, i.e., automatic speech recognition (ASR), with speech foundation encoders and large language models (LLM). Recent works have complex designs such as compressing the output temporally for the speech encoder, tackling modal alignment for the projector, and utilizing parameter-efficient fine-tuning for the LLM. We found that delicate designs are not necessary, while an embarrassingly simple composition of off-the-shelf speech encoder, LLM, and the only trainable linear projector is competent for the ASR task. To be more specific, we benchmark and explore various combinations of LLMs and speech encoders, leading to the optimal LLM-based ASR system, which we call SLAM-ASR. The proposed SLAM-ASR provides a clean setup and little task-specific design, where only the linear projector is trained. To the best of our knowledge, SLAM-ASR achieves the best performance on the Librispeech benchmark among LLM-based ASR models and even outperforms the latest LLM-based audio-universal model trained on massive pair data. Finally, we explore the capability emergence of LLM-based ASR in the process of modal alignment. We hope that our study can facilitate the research on extending LLM with cross-modality capacity and shed light on the LLM-based ASR community.","sentences":["In this paper, we focus on solving one of the most important tasks in the field of speech processing, i.e., automatic speech recognition (ASR), with speech foundation encoders and large language models (LLM).","Recent works have complex designs such as compressing the output temporally for the speech encoder, tackling modal alignment for the projector, and utilizing parameter-efficient fine-tuning for the LLM.","We found that delicate designs are not necessary, while an embarrassingly simple composition of off-the-shelf speech encoder, LLM, and the only trainable linear projector is competent for the ASR task.","To be more specific, we benchmark and explore various combinations of LLMs and speech encoders, leading to the optimal LLM-based ASR system, which we call SLAM-ASR.","The proposed SLAM-ASR provides a clean setup and little task-specific design, where only the linear projector is trained.","To the best of our knowledge, SLAM-ASR achieves the best performance on the Librispeech benchmark among LLM-based ASR models and even outperforms the latest LLM-based audio-universal model trained on massive pair data.","Finally, we explore the capability emergence of LLM-based ASR in the process of modal alignment.","We hope that our study can facilitate the research on extending LLM with cross-modality capacity and shed light on the LLM-based ASR community."],"url":"http://arxiv.org/abs/2402.08846v1"}
{"created":"2024-02-13 22:26:24","title":"eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data","abstract":"With tremendous efforts on developing effective e-commerce models, conventional e-commerce models show limited success in generalist e-commerce modeling, and suffer from unsatisfactory performance on new users and new products - a typical out-of-domain generalization challenge. Meanwhile, large language models (LLMs) demonstrate outstanding performance in generalist modeling and out-of-domain generalizability in many fields. Toward fully unleashing their power for e-commerce, in this paper, we construct ECInstruct, the first open-sourced, large-scale, and high-quality benchmark instruction dataset for e-commerce. Leveraging ECInstruct, we develop eCeLLM, a series of e-commerce LLMs, by instruction-tuning general-purpose LLMs. Our comprehensive experiments and evaluation demonstrate that eCeLLM models substantially outperform baseline models, including the most advanced GPT-4, and the state-of-the-art task-specific models in in-domain evaluation. Moreover, eCeLLM exhibits excellent generalizability to out-of-domain settings, including unseen products and unseen instructions, highlighting its superiority as a generalist e-commerce model. Both the ECInstruct dataset and the eCeLLM models show great potential in empowering versatile and effective LLMs for e-commerce. ECInstruct and eCeLLM models are publicly accessible through https://ninglab.github.io/eCeLLM.","sentences":["With tremendous efforts on developing effective e-commerce models, conventional e-commerce models show limited success in generalist e-commerce modeling, and suffer from unsatisfactory performance on new users and new products - a typical out-of-domain generalization challenge.","Meanwhile, large language models (LLMs) demonstrate outstanding performance in generalist modeling and out-of-domain generalizability in many fields.","Toward fully unleashing their power for e-commerce, in this paper, we construct ECInstruct, the first open-sourced, large-scale, and high-quality benchmark instruction dataset for e-commerce.","Leveraging ECInstruct, we develop eCeLLM, a series of e-commerce LLMs, by instruction-tuning general-purpose LLMs.","Our comprehensive experiments and evaluation demonstrate that eCeLLM models substantially outperform baseline models, including the most advanced GPT-4, and the state-of-the-art task-specific models in in-domain evaluation.","Moreover, eCeLLM exhibits excellent generalizability to out-of-domain settings, including unseen products and unseen instructions, highlighting its superiority as a generalist e-commerce model.","Both the ECInstruct dataset and the eCeLLM models show great potential in empowering versatile and effective LLMs for e-commerce.","ECInstruct and eCeLLM models are publicly accessible through https://ninglab.github.io/eCeLLM."],"url":"http://arxiv.org/abs/2402.08831v1"}
{"created":"2024-02-13 22:22:51","title":"Sequence graphs realizations and ambiguity in language models","abstract":"Several popular language models represent local contexts in an input text as bags of words. Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in x, with edges representing the (ordered) co-occurrence of two words within a sliding window of size w. However, this compressed representation is not generally bijective, and may introduce some degree of ambiguity. Some sequence graphs may admit several realizations as a sequence, while others may not admit any realization. In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and computational point of view. We consider the existence and enumeration of realizations of a sequence graph under multiple settings: window size w, presence/absence of graph orientation, and presence/absence of weights (multiplicities). When w = 2, we provide polynomial time algorithms for realizability and enumeration in all cases except the undirected/weighted setting, where we show the #P-hardness of enumeration. For a window of size at least 3, we prove hardness of all variants, even when w is considered as a constant, with the notable exception of the undirected/unweighted case for which we propose an XP algorithms for both (realizability and enumeration) problems, tight due to a corresponding W[1]-hardness result. We conclude with an integer program formulation to solve the realizability problem, and with dynamic programming to solve the enumeration problem. This work leaves open the membership to NP for both problems, a non-trivial question due to the existence of minimum realizations having exponential size on the instance encoding.","sentences":["Several popular language models represent local contexts in an input text as bags of words.","Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in x, with edges representing the (ordered) co-occurrence of two words within a sliding window of size w.","However, this compressed representation is not generally bijective, and may introduce some degree of ambiguity.","Some sequence graphs may admit several realizations as a sequence, while others may not admit any realization.","In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and computational point of view.","We consider the existence and enumeration of realizations of a sequence graph under multiple settings: window size w, presence/absence of graph orientation, and presence/absence of weights (multiplicities).","When w = 2, we provide polynomial time algorithms for realizability and enumeration in all cases except the undirected/weighted setting, where we show the #P-hardness of enumeration.","For a window of size at least 3, we prove hardness of all variants, even when w is considered as a constant, with the notable exception of the undirected/unweighted case for which we propose an XP algorithms for both (realizability and enumeration) problems, tight due to a corresponding W[1]-hardness result.","We conclude with an integer program formulation to solve the realizability problem, and with dynamic programming to solve the enumeration problem.","This work leaves open the membership to NP for both problems, a non-trivial question due to the existence of minimum realizations having exponential size on the instance encoding."],"url":"http://arxiv.org/abs/2402.08830v1"}
{"created":"2024-02-13 22:10:57","title":"Equilibria of Data Marketplaces with Privacy-Aware Sellers under Endogenous Privacy Costs","abstract":"We study a two-sided online data ecosystem comprised of an online platform, users on the platform, and downstream learners or data buyers. The learners can buy user data on the platform (to run a statistic or machine learning task). Potential users decide whether to join by looking at the trade-off between i) their benefit from joining the platform and interacting with other users and ii) the privacy costs they incur from sharing their data.   First, we introduce a novel modeling element for two-sided data platforms: the privacy costs of the users are endogenous and depend on how much of their data is purchased by the downstream learners. Then, we characterize marketplace equilibria in certain simple settings. In particular, we provide a full characterization in two variants of our model that correspond to different utility functions for the users: i) when each user gets a constant benefit for participating in the platform and ii) when each user's benefit is linearly increasing in the number of other users that participate. In both variants, equilibria in our setting are significantly different from equilibria when privacy costs are exogenous and fixed, highlighting the importance of taking endogeneity in the privacy costs into account. Finally, we provide simulations and semi-synthetic experiments to extend our results to more general assumptions. We experiment with different distributions of users' privacy costs and different functional forms of the users' utilities for joining the platform.","sentences":["We study a two-sided online data ecosystem comprised of an online platform, users on the platform, and downstream learners or data buyers.","The learners can buy user data on the platform (to run a statistic or machine learning task).","Potential users decide whether to join by looking at the trade-off between i) their benefit from joining the platform and interacting with other users and ii) the privacy costs they incur from sharing their data.   ","First, we introduce a novel modeling element for two-sided data platforms: the privacy costs of the users are endogenous and depend on how much of their data is purchased by the downstream learners.","Then, we characterize marketplace equilibria in certain simple settings.","In particular, we provide a full characterization in two variants of our model that correspond to different utility functions for the users: i) when each user gets a constant benefit for participating in the platform and ii) when each user's benefit is linearly increasing in the number of other users that participate.","In both variants, equilibria in our setting are significantly different from equilibria when privacy costs are exogenous and fixed, highlighting the importance of taking endogeneity in the privacy costs into account.","Finally, we provide simulations and semi-synthetic experiments to extend our results to more general assumptions.","We experiment with different distributions of users' privacy costs and different functional forms of the users' utilities for joining the platform."],"url":"http://arxiv.org/abs/2402.08826v1"}
{"created":"2024-02-13 22:07:57","title":"Disambiguated Node Classification with Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) have demonstrated significant success in learning from graph-structured data across various domains. Despite their great successful, one critical challenge is often overlooked by existing works, i.e., the learning of message propagation that can generalize effectively to underrepresented graph regions. These minority regions often exhibit irregular homophily/heterophily patterns and diverse neighborhood class distributions, resulting in ambiguity. In this work, we investigate the ambiguity problem within GNNs, its impact on representation learning, and the development of richer supervision signals to fight against this problem. We conduct a fine-grained evaluation of GNN, analyzing the existence of ambiguity in different graph regions and its relation with node positions. To disambiguate node embeddings, we propose a novel method, {\\method}, which exploits additional optimization guidance to enhance representation learning, particularly for nodes in ambiguous regions. {\\method} identifies ambiguous nodes based on temporal inconsistency of predictions and introduces a disambiguation regularization by employing contrastive learning in a topology-aware manner. {\\method} promotes discriminativity of node representations and can alleviating semantic mixing caused by message propagation, effectively addressing the ambiguity problem. Empirical results validate the efficiency of {\\method} and highlight its potential to improve GNN performance in underrepresented graph regions.","sentences":["Graph Neural Networks (GNNs) have demonstrated significant success in learning from graph-structured data across various domains.","Despite their great successful, one critical challenge is often overlooked by existing works, i.e., the learning of message propagation that can generalize effectively to underrepresented graph regions.","These minority regions often exhibit irregular homophily/heterophily patterns and diverse neighborhood class distributions, resulting in ambiguity.","In this work, we investigate the ambiguity problem within GNNs, its impact on representation learning, and the development of richer supervision signals to fight against this problem.","We conduct a fine-grained evaluation of GNN, analyzing the existence of ambiguity in different graph regions and its relation with node positions.","To disambiguate node embeddings, we propose a novel method, {\\method}, which exploits additional optimization guidance to enhance representation learning, particularly for nodes in ambiguous regions.","{\\method} identifies ambiguous nodes based on temporal inconsistency of predictions and introduces a disambiguation regularization by employing contrastive learning in a topology-aware manner.","{\\method} promotes discriminativity of node representations and can alleviating semantic mixing caused by message propagation, effectively addressing the ambiguity problem.","Empirical results validate the efficiency of {\\method} and highlight its potential to improve GNN performance in underrepresented graph regions."],"url":"http://arxiv.org/abs/2402.08824v1"}
{"created":"2024-02-13 22:07:29","title":"RanDumb: A Simple Approach that Questions the Efficacy of Continual Representation Learning","abstract":"We propose RanDumb to examine the efficacy of continual representation learning. RanDumb embeds raw pixels using a fixed random transform which approximates an RBF-Kernel, initialized before seeing any data, and learns a simple linear classifier on top. We present a surprising and consistent finding: RanDumb significantly outperforms the continually learned representations using deep networks across numerous continual learning benchmarks, demonstrating the poor performance of representation learning in these scenarios. RanDumb stores no exemplars and performs a single pass over the data, processing one sample at a time. It complements GDumb, operating in a low-exemplar regime where GDumb has especially poor performance. We reach the same consistent conclusions when RanDumb is extended to scenarios with pretrained models replacing the random transform with pretrained feature extractor. Our investigation is both surprising and alarming as it questions our understanding of how to effectively design and train models that require efficient continual representation learning, and necessitates a principled reinvestigation of the widely explored problem formulation itself. Our code is available at https://github.com/drimpossible/RanDumb.","sentences":["We propose RanDumb to examine the efficacy of continual representation learning.","RanDumb embeds raw pixels using a fixed random transform which approximates an RBF-Kernel, initialized before seeing any data, and learns a simple linear classifier on top.","We present a surprising and consistent finding:","RanDumb significantly outperforms the continually learned representations using deep networks across numerous continual learning benchmarks, demonstrating the poor performance of representation learning in these scenarios.","RanDumb stores no exemplars and performs a single pass over the data, processing one sample at a time.","It complements GDumb, operating in a low-exemplar regime where GDumb has especially poor performance.","We reach the same consistent conclusions when RanDumb is extended to scenarios with pretrained models replacing the random transform with pretrained feature extractor.","Our investigation is both surprising and alarming as it questions our understanding of how to effectively design and train models that require efficient continual representation learning, and necessitates a principled reinvestigation of the widely explored problem formulation itself.","Our code is available at https://github.com/drimpossible/RanDumb."],"url":"http://arxiv.org/abs/2402.08823v1"}
{"created":"2024-02-13 21:46:53","title":"Parameterized dynamic data structure for Split Completion","abstract":"We design a randomized data structure that, for a fully dynamic graph $G$ updated by edge insertions and deletions and integers $k, d$ fixed upon initialization, maintains the answer to the Split Completion problem: whether one can add $k$ edges to $G$ to obtain a split graph. The data structure can be initialized on an edgeless $n$-vertex graph in time $n \\cdot (k d \\cdot \\log n)^{\\mathcal{O}(1)}$, and the amortized time complexity of an update is $5^k \\cdot (k d \\cdot \\log n)^{\\mathcal{O}(1)}$. The answer provided by the data structure is correct with probability $1-\\mathcal{O}(n^{-d})$.","sentences":["We design a randomized data structure that, for a fully dynamic graph $G$ updated by edge insertions and deletions and integers $k, d$ fixed upon initialization, maintains the answer to the Split Completion problem: whether one can add $k$ edges to $G$ to obtain a split graph.","The data structure can be initialized on an edgeless $n$-vertex graph in time $n \\cdot (k d \\cdot \\log n)^{\\mathcal{O}(1)}$, and the amortized time complexity of an update is $5^k","\\cdot (k d \\cdot \\log n)^{\\mathcal{O}(1)}$.","The answer provided by the data structure is correct with probability $1-\\mathcal{O}(n^{-d})$."],"url":"http://arxiv.org/abs/2402.08816v1"}
{"created":"2024-02-13 21:33:12","title":"Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis through Rapid Prototyping, Iteration and Curation","abstract":"Complex data analysis inherently seeks unexpected insights through exploratory \\re{visual analysis} methods, transcending logical, step-by-step processing. However, \\re{existing interfaces such as notebooks and dashboards have limitations in exploration and comparison for visual data analysis}. Addressing these limitations, we introduce a \"design-like\" intelligent canvas environment integrating generative AI into data analysis, offering rapid prototyping, iteration, and comparative visualization management. Our dual contributions include the integration of generative AI components into a canvas interface, and empirical findings from a user study (N=10) evaluating the effectiveness of the canvas interface.","sentences":["Complex data analysis inherently seeks unexpected insights through exploratory \\re{visual analysis} methods, transcending logical, step-by-step processing.","However, \\re{existing interfaces such as notebooks and dashboards have limitations in exploration and comparison for visual data analysis}.","Addressing these limitations, we introduce a \"design-like\" intelligent canvas environment integrating generative AI into data analysis, offering rapid prototyping, iteration, and comparative visualization management.","Our dual contributions include the integration of generative AI components into a canvas interface, and empirical findings from a user study (N=10) evaluating the effectiveness of the canvas interface."],"url":"http://arxiv.org/abs/2402.08812v1"}
{"created":"2024-02-13 21:19:00","title":"Multi-Label Zero-Shot Product Attribute-Value Extraction","abstract":"E-commerce platforms should provide detailed product descriptions (attribute values) for effective product search and recommendation. However, attribute value information is typically not available for new products. To predict unseen attribute values, large quantities of labeled training data are needed to train a traditional supervised learning model. Typically, it is difficult, time-consuming, and costly to manually label large quantities of new product profiles. In this paper, we propose a novel method to efficiently and effectively extract unseen attribute values from new products in the absence of labeled data (zero-shot setting). We propose HyperPAVE, a multi-label zero-shot attribute value extraction model that leverages inductive inference in heterogeneous hypergraphs. In particular, our proposed technique constructs heterogeneous hypergraphs to capture complex higher-order relations (i.e. user behavior information) to learn more accurate feature representations for graph nodes. Furthermore, our proposed HyperPAVE model uses an inductive link prediction mechanism to infer future connections between unseen nodes. This enables HyperPAVE to identify new attribute values without the need for labeled training data. We conduct extensive experiments with ablation studies on different categories of the MAVE dataset. The results demonstrate that our proposed HyperPAVE model significantly outperforms existing classification-based, generation-based large language models for attribute value extraction in the zero-shot setting.","sentences":["E-commerce platforms should provide detailed product descriptions (attribute values) for effective product search and recommendation.","However, attribute value information is typically not available for new products.","To predict unseen attribute values, large quantities of labeled training data are needed to train a traditional supervised learning model.","Typically, it is difficult, time-consuming, and costly to manually label large quantities of new product profiles.","In this paper, we propose a novel method to efficiently and effectively extract unseen attribute values from new products in the absence of labeled data (zero-shot setting).","We propose HyperPAVE, a multi-label zero-shot attribute value extraction model that leverages inductive inference in heterogeneous hypergraphs.","In particular, our proposed technique constructs heterogeneous hypergraphs to capture complex higher-order relations (i.e. user behavior information) to learn more accurate feature representations for graph nodes.","Furthermore, our proposed HyperPAVE model uses an inductive link prediction mechanism to infer future connections between unseen nodes.","This enables HyperPAVE to identify new attribute values without the need for labeled training data.","We conduct extensive experiments with ablation studies on different categories of the MAVE dataset.","The results demonstrate that our proposed HyperPAVE model significantly outperforms existing classification-based, generation-based large language models for attribute value extraction in the zero-shot setting."],"url":"http://arxiv.org/abs/2402.08802v1"}
{"created":"2024-02-13 21:10:21","title":"Computing Power and the Governance of Artificial Intelligence","abstract":"Computing power, or \"compute,\" is crucial for the development and deployment of artificial intelligence (AI) capabilities. As a result, governments and companies have started to leverage compute as a means to govern AI. For example, governments are investing in domestic compute capacity, controlling the flow of compute to competing countries, and subsidizing compute access to certain sectors. However, these efforts only scratch the surface of how compute can be used to govern AI development and deployment. Relative to other key inputs to AI (data and algorithms), AI-relevant compute is a particularly effective point of intervention: it is detectable, excludable, and quantifiable, and is produced via an extremely concentrated supply chain. These characteristics, alongside the singular importance of compute for cutting-edge AI models, suggest that governing compute can contribute to achieving common policy objectives, such as ensuring the safety and beneficial use of AI. More precisely, policymakers could use compute to facilitate regulatory visibility of AI, allocate resources to promote beneficial outcomes, and enforce restrictions against irresponsible or malicious AI development and usage. However, while compute-based policies and technologies have the potential to assist in these areas, there is significant variation in their readiness for implementation. Some ideas are currently being piloted, while others are hindered by the need for fundamental research. Furthermore, naive or poorly scoped approaches to compute governance carry significant risks in areas like privacy, economic impacts, and centralization of power. We end by suggesting guardrails to minimize these risks from compute governance.","sentences":["Computing power, or \"compute,\" is crucial for the development and deployment of artificial intelligence (AI) capabilities.","As a result, governments and companies have started to leverage compute as a means to govern AI.","For example, governments are investing in domestic compute capacity, controlling the flow of compute to competing countries, and subsidizing compute access to certain sectors.","However, these efforts only scratch the surface of how compute can be used to govern AI development and deployment.","Relative to other key inputs to AI (data and algorithms), AI-relevant compute is a particularly effective point of intervention: it is detectable, excludable, and quantifiable, and is produced via an extremely concentrated supply chain.","These characteristics, alongside the singular importance of compute for cutting-edge AI models, suggest that governing compute can contribute to achieving common policy objectives, such as ensuring the safety and beneficial use of AI.","More precisely, policymakers could use compute to facilitate regulatory visibility of AI, allocate resources to promote beneficial outcomes, and enforce restrictions against irresponsible or malicious AI development and usage.","However, while compute-based policies and technologies have the potential to assist in these areas, there is significant variation in their readiness for implementation.","Some ideas are currently being piloted, while others are hindered by the need for fundamental research.","Furthermore, naive or poorly scoped approaches to compute governance carry significant risks in areas like privacy, economic impacts, and centralization of power.","We end by suggesting guardrails to minimize these risks from compute governance."],"url":"http://arxiv.org/abs/2402.08797v1"}
{"created":"2024-02-13 20:51:58","title":"Rethinking Machine Unlearning for Large Language Models","abstract":"We explore machine unlearning (MU) in the domain of large language models (LLMs), referred to as LLM unlearning. This initiative aims to eliminate undesirable data influence (e.g., sensitive or illegal information) and the associated model capabilities, while maintaining the integrity of essential knowledge generation and not affecting causally unrelated information. We envision LLM unlearning becoming a pivotal element in the life-cycle management of LLMs, potentially standing as an essential foundation for developing generative AI that is not only safe, secure, and trustworthy, but also resource-efficient without the need of full retraining. We navigate the unlearning landscape in LLMs from conceptual formulation, methodologies, metrics, and applications. In particular, we highlight the often-overlooked aspects of existing LLM unlearning research, e.g., unlearning scope, data-model interaction, and multifaceted efficacy assessment. We also draw connections between LLM unlearning and related areas such as model editing, influence functions, model explanation, adversarial training, and reinforcement learning. Furthermore, we outline an effective assessment framework for LLM unlearning and explore its applications in copyright and privacy safeguards and sociotechnical harm reduction.","sentences":["We explore machine unlearning (MU) in the domain of large language models (LLMs), referred to as LLM unlearning.","This initiative aims to eliminate undesirable data influence (e.g., sensitive or illegal information) and the associated model capabilities, while maintaining the integrity of essential knowledge generation and not affecting causally unrelated information.","We envision LLM unlearning becoming a pivotal element in the life-cycle management of LLMs, potentially standing as an essential foundation for developing generative AI that is not only safe, secure, and trustworthy, but also resource-efficient without the need of full retraining.","We navigate the unlearning landscape in LLMs from conceptual formulation, methodologies, metrics, and applications.","In particular, we highlight the often-overlooked aspects of existing LLM unlearning research, e.g., unlearning scope, data-model interaction, and multifaceted efficacy assessment.","We also draw connections between LLM unlearning and related areas such as model editing, influence functions, model explanation, adversarial training, and reinforcement learning.","Furthermore, we outline an effective assessment framework for LLM unlearning and explore its applications in copyright and privacy safeguards and sociotechnical harm reduction."],"url":"http://arxiv.org/abs/2402.08787v1"}
{"created":"2024-02-13 20:47:17","title":"InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment","abstract":"Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates? In this paper, we propose InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment. Specifically, we first propose a structured format verbalizer to unify all graph data into a universal code-like format, which can simply represent the graph without any external graph-specific encoders. Furthermore, a graph instruction tuning stage is introduced to guide LLMs in solving graph reasoning and generation tasks. Finally, we identify potential hallucination problems in graph tasks and sample negative instances for preference alignment, the target of which is to enhance the output's reliability of the model. Extensive experiments across multiple graph-centric tasks exhibit that InstructGraph can achieve the best performance and outperform GPT-4 and LLaMA2 by more than 13\\% and 38\\%, respectively.","sentences":["Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates?","In this paper, we propose InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment.","Specifically, we first propose a structured format verbalizer to unify all graph data into a universal code-like format, which can simply represent the graph without any external graph-specific encoders.","Furthermore, a graph instruction tuning stage is introduced to guide LLMs in solving graph reasoning and generation tasks.","Finally, we identify potential hallucination problems in graph tasks and sample negative instances for preference alignment, the target of which is to enhance the output's reliability of the model.","Extensive experiments across multiple graph-centric tasks exhibit that InstructGraph can achieve the best performance and outperform GPT-4 and LLaMA2 by more than 13\\% and 38\\%, respectively."],"url":"http://arxiv.org/abs/2402.08785v1"}
{"created":"2024-02-13 20:46:37","title":"Preconditioners for the Stochastic Training of Implicit Neural Representations","abstract":"Implicit neural representations have emerged as a powerful technique for encoding complex continuous multidimensional signals as neural networks, enabling a wide range of applications in computer vision, robotics, and geometry. While Adam is commonly used for training due to its stochastic proficiency, it entails lengthy training durations. To address this, we explore alternative optimization techniques for accelerated training without sacrificing accuracy. Traditional second-order optimizers like L-BFGS are suboptimal in stochastic settings, making them unsuitable for large-scale data sets. Instead, we propose stochastic training using curvature-aware diagonal preconditioners, showcasing their effectiveness across various signal modalities such as images, shape reconstruction, and Neural Radiance Fields (NeRF).","sentences":["Implicit neural representations have emerged as a powerful technique for encoding complex continuous multidimensional signals as neural networks, enabling a wide range of applications in computer vision, robotics, and geometry.","While Adam is commonly used for training due to its stochastic proficiency, it entails lengthy training durations.","To address this, we explore alternative optimization techniques for accelerated training without sacrificing accuracy.","Traditional second-order optimizers like L-BFGS are suboptimal in stochastic settings, making them unsuitable for large-scale data sets.","Instead, we propose stochastic training using curvature-aware diagonal preconditioners, showcasing their effectiveness across various signal modalities such as images, shape reconstruction, and Neural Radiance Fields (NeRF)."],"url":"http://arxiv.org/abs/2402.08784v1"}
{"created":"2024-02-13 20:29:36","title":"Enhanced Deep Q-Learning for 2D Self-Driving Cars: Implementation and Evaluation on a Custom Track Environment","abstract":"This research project presents the implementation of a Deep Q-Learning Network (DQN) for a self-driving car on a 2-dimensional (2D) custom track, with the objective of enhancing the DQN network's performance. It encompasses the development of a custom driving environment using Pygame on a track surrounding the University of Memphis map, as well as the design and implementation of the DQN model. The algorithm utilizes data from 7 sensors installed in the car, which measure the distance between the car and the track. These sensors are positioned in front of the vehicle, spaced 20 degrees apart, enabling them to sense a wide area ahead. We successfully implemented the DQN and also a modified version of the DQN with a priority-based action selection mechanism, which we refer to as modified DQN. The model was trained over 1000 episodes, and the average reward received by the agent was found to be around 40, which is approximately 60% higher than the original DQN and around 50% higher than the vanilla neural network.","sentences":["This research project presents the implementation of a Deep Q-Learning Network (DQN) for a self-driving car on a 2-dimensional (2D) custom track, with the objective of enhancing the DQN network's performance.","It encompasses the development of a custom driving environment using Pygame on a track surrounding the University of Memphis map, as well as the design and implementation of the DQN model.","The algorithm utilizes data from 7 sensors installed in the car, which measure the distance between the car and the track.","These sensors are positioned in front of the vehicle, spaced 20 degrees apart, enabling them to sense a wide area ahead.","We successfully implemented the DQN and also a modified version of the DQN with a priority-based action selection mechanism, which we refer to as modified DQN.","The model was trained over 1000 episodes, and the average reward received by the agent was found to be around 40, which is approximately 60% higher than the original DQN and around 50% higher than the vanilla neural network."],"url":"http://arxiv.org/abs/2402.08780v1"}
{"created":"2024-02-13 20:17:24","title":"Almost Tight Bounds for Online Hypergraph Matching","abstract":"In the online hypergraph matching problem, hyperedges of size $k$ over a common ground set arrive online in adversarial order. The goal is to obtain a maximum matching (disjoint set of hyperedges). A na\\\"ive greedy algorithm for this problem achieves a competitive ratio of $\\frac{1}{k}$. We show that no (randomized) online algorithm has competitive ratio better than $\\frac{2+o(1)}{k}$. If edges are allowed to be assigned fractionally, we give a deterministic online algorithm with competitive ratio $\\frac{1-o(1)}{\\ln(k)}$ and show that no online algorithm can have competitive ratio strictly better than $\\frac{1+o(1)}{\\ln(k)}$. Lastly, we give a $\\frac{1-o(1)}{\\ln(k)}$ competitive algorithm for the fractional edge-weighted version of the problem under a free disposal assumption.","sentences":["In the online hypergraph matching problem, hyperedges of size $k$ over a common ground set arrive online in adversarial order.","The goal is to obtain a maximum matching (disjoint set of hyperedges).","A na\\\"ive greedy algorithm for this problem achieves a competitive ratio of $\\frac{1}{k}$. We show that no (randomized) online algorithm has competitive ratio better than $\\frac{2+o(1)}{k}$. If edges are allowed to be assigned fractionally, we give a deterministic online algorithm with competitive ratio $\\frac{1-o(1)}{\\ln(k)}$ and show that no online algorithm can have competitive ratio strictly better than $\\frac{1+o(1)}{\\ln(k)}$. Lastly, we give a $\\frac{1-o(1)}{\\ln(k)}$ competitive algorithm for the fractional edge-weighted version of the problem under a free disposal assumption."],"url":"http://arxiv.org/abs/2402.08775v1"}
{"created":"2024-02-13 20:04:39","title":"FLASH: Federated Learning Across Simultaneous Heterogeneities","abstract":"The key premise of federated learning (FL) is to train ML models across a diverse set of data-owners (clients), without exchanging local data. An overarching challenge to this date is client heterogeneity, which may arise not only from variations in data distribution, but also in data quality, as well as compute/communication latency. An integrated view of these diverse and concurrent sources of heterogeneity is critical; for instance, low-latency clients may have poor data quality, and vice versa. In this work, we propose FLASH(Federated Learning Across Simultaneous Heterogeneities), a lightweight and flexible client selection algorithm that outperforms state-of-the-art FL frameworks under extensive sources of heterogeneity, by trading-off the statistical information associated with the client's data quality, data distribution, and latency. FLASH is the first method, to our knowledge, for handling all these heterogeneities in a unified manner. To do so, FLASH models the learning dynamics through contextual multi-armed bandits (CMAB) and dynamically selects the most promising clients. Through extensive experiments, we demonstrate that FLASH achieves substantial and consistent improvements over state-of-the-art baselines -- as much as 10% in absolute accuracy -- thanks to its unified approach. Importantly, FLASH also outperforms federated aggregation methods that are designed to handle highly heterogeneous settings and even enjoys a performance boost when integrated with them.","sentences":["The key premise of federated learning (FL) is to train ML models across a diverse set of data-owners (clients), without exchanging local data.","An overarching challenge to this date is client heterogeneity, which may arise not only from variations in data distribution, but also in data quality, as well as compute/communication latency.","An integrated view of these diverse and concurrent sources of heterogeneity is critical; for instance, low-latency clients may have poor data quality, and vice versa.","In this work, we propose FLASH(Federated Learning Across Simultaneous Heterogeneities), a lightweight and flexible client selection algorithm that outperforms state-of-the-art FL frameworks under extensive sources of heterogeneity, by trading-off the statistical information associated with the client's data quality, data distribution, and latency.","FLASH is the first method, to our knowledge, for handling all these heterogeneities in a unified manner.","To do so, FLASH models the learning dynamics through contextual multi-armed bandits (CMAB) and dynamically selects the most promising clients.","Through extensive experiments, we demonstrate that FLASH achieves substantial and consistent improvements over state-of-the-art baselines -- as much as 10% in absolute accuracy -- thanks to its unified approach.","Importantly, FLASH also outperforms federated aggregation methods that are designed to handle highly heterogeneous settings and even enjoys a performance boost when integrated with them."],"url":"http://arxiv.org/abs/2402.08769v1"}
{"created":"2024-02-13 19:58:24","title":"A Dataset for the Detection of Dehumanizing Language","abstract":"Dehumanization is a mental process that enables the exclusion and ill treatment of a group of people. In this paper, we present two data sets of dehumanizing text, a large, automatically collected corpus and a smaller, manually annotated data set. Both data sets include a combination of political discourse and dialogue from movie subtitles. Our methods give us a broad and varied amount of dehumanization data to work with, enabling further exploratory analysis and automatic classification of dehumanization patterns. Both data sets will be publicly released.","sentences":["Dehumanization is a mental process that enables the exclusion and ill treatment of a group of people.","In this paper, we present two data sets of dehumanizing text, a large, automatically collected corpus and a smaller, manually annotated data set.","Both data sets include a combination of political discourse and dialogue from movie subtitles.","Our methods give us a broad and varied amount of dehumanization data to work with, enabling further exploratory analysis and automatic classification of dehumanization patterns.","Both data sets will be publicly released."],"url":"http://arxiv.org/abs/2402.08764v1"}
{"created":"2024-02-13 19:54:29","title":"JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models","abstract":"The permanence of online content combined with the enhanced authorship identification techniques calls for stronger computational methods to protect the identity and privacy of online authorship when needed, e.g., blind reviews for scientific papers, anonymous online reviews, or anonymous interactions in the mental health forums. In this paper, we propose an unsupervised inference-time approach to authorship obfuscation to address the unique challenges of authorship obfuscation: lack of supervision data for diverse authorship and domains, and the need for a sufficient level of revision beyond simple paraphrasing to obfuscate the authorship, all the while preserving the original content and fluency.   We introduce JAMDEC, a user-controlled, inference-time algorithm for authorship obfuscation that can be in principle applied to any text and authorship. Our approach builds on small language models such as GPT2-XL in order to help avoid disclosing the original content to proprietary LLM's APIs, while also reducing the performance gap between small and large language models via algorithmic enhancement. The key idea behind our approach is to boost the creative power of smaller language models through constrained decoding, while also allowing for user-specified controls and flexibility. Experimental results demonstrate that our approach based on GPT2-XL outperforms previous state-of-the-art methods based on comparably small models, while performing competitively against GPT3.5 175B, a propriety model that is two orders of magnitudes larger.","sentences":["The permanence of online content combined with the enhanced authorship identification techniques calls for stronger computational methods to protect the identity and privacy of online authorship when needed, e.g., blind reviews for scientific papers, anonymous online reviews, or anonymous interactions in the mental health forums.","In this paper, we propose an unsupervised inference-time approach to authorship obfuscation to address the unique challenges of authorship obfuscation: lack of supervision data for diverse authorship and domains, and the need for a sufficient level of revision beyond simple paraphrasing to obfuscate the authorship, all the while preserving the original content and fluency.   ","We introduce JAMDEC, a user-controlled, inference-time algorithm for authorship obfuscation that can be in principle applied to any text and authorship.","Our approach builds on small language models such as GPT2-XL in order to help avoid disclosing the original content to proprietary LLM's APIs, while also reducing the performance gap between small and large language models via algorithmic enhancement.","The key idea behind our approach is to boost the creative power of smaller language models through constrained decoding, while also allowing for user-specified controls and flexibility.","Experimental results demonstrate that our approach based on GPT2-XL outperforms previous state-of-the-art methods based on comparably small models, while performing competitively against GPT3.5 175B, a propriety model that is two orders of magnitudes larger."],"url":"http://arxiv.org/abs/2402.08761v1"}
{"created":"2024-02-13 19:49:17","title":"Learning How To Ask: Cycle-Consistency Refines Prompts in Multimodal Foundation Models","abstract":"When LLMs perform zero-shot inference, they typically use a prompt with a task specification, and generate a completion. However, there is no work to explore the possibility of the reverse - going from completion to task specification. In this paper, we employ both directions to perform cycle-supervised learning entirely in-context. Our goal is to create a forward map f : X -> Y (e.g. image -> generated caption), coupled with a backward map g : Y -> X (e.g. caption -> generated image) to construct a cycle-consistency \"loss\" (formulated as an update to the prompt) to enforce g(f(X)) ~= X. The technique, called CyclePrompt, uses cycle-consistency as a free supervisory signal to iteratively craft the prompt. Importantly, CyclePrompt reinforces model performance without expensive fine-tuning, without training data, and without the complexity of external environments (e.g. compilers, APIs). We demonstrate CyclePrompt in two domains: code generation and image captioning. Our results on the HumanEval coding benchmark put us in first place on the leaderboard among models that do not rely on extra training data or usage of external environments, and third overall. Compared to the GPT4 baseline, we improve accuracy from 80.5% to 87.2%. In the vision-language space, we generate detailed image captions which outperform baseline zero-shot GPT4V captions, when tested against natural (VQAv2) and diagrammatic (FigureQA) visual question-answering benchmarks. To the best of our knowledge, this is the first use of self-supervised learning for prompting.","sentences":["When LLMs perform zero-shot inference, they typically use a prompt with a task specification, and generate a completion.","However, there is no work to explore the possibility of the reverse - going from completion to task specification.","In this paper, we employ both directions to perform cycle-supervised learning entirely in-context.","Our goal is to create a forward map f : X -> Y (e.g. image -> generated caption), coupled with a backward map g : Y -> X (e.g. caption -> generated image) to construct a cycle-consistency \"loss\" (formulated as an update to the prompt) to enforce g(f(X))","~= X.","The technique, called CyclePrompt, uses cycle-consistency as a free supervisory signal to iteratively craft the prompt.","Importantly, CyclePrompt reinforces model performance without expensive fine-tuning, without training data, and without the complexity of external environments (e.g. compilers, APIs).","We demonstrate CyclePrompt in two domains: code generation and image captioning.","Our results on the HumanEval coding benchmark put us in first place on the leaderboard among models that do not rely on extra training data or usage of external environments, and third overall.","Compared to the GPT4 baseline, we improve accuracy from 80.5% to 87.2%.","In the vision-language space, we generate detailed image captions which outperform baseline zero-shot GPT4V captions, when tested against natural (VQAv2) and diagrammatic (FigureQA) visual question-answering benchmarks.","To the best of our knowledge, this is the first use of self-supervised learning for prompting."],"url":"http://arxiv.org/abs/2402.08756v1"}
{"created":"2024-02-13 19:46:39","title":"LLM-driven Imitation of Subrational Behavior : Illusion or Reality?","abstract":"Modeling subrational agents, such as humans or economic households, is inherently challenging due to the difficulty in calibrating reinforcement learning models or collecting data that involves human subjects. Existing work highlights the ability of Large Language Models (LLMs) to address complex reasoning tasks and mimic human communication, while simulation using LLMs as agents shows emergent social behaviors, potentially improving our comprehension of human conduct. In this paper, we propose to investigate the use of LLMs to generate synthetic human demonstrations, which are then used to learn subrational agent policies though Imitation Learning. We make an assumption that LLMs can be used as implicit computational models of humans, and propose a framework to use synthetic demonstrations derived from LLMs to model subrational behaviors that are characteristic of humans (e.g., myopic behavior or preference for risk aversion). We experimentally evaluate the ability of our framework to model sub-rationality through four simple scenarios, including the well-researched ultimatum game and marshmallow experiment. To gain confidence in our framework, we are able to replicate well-established findings from prior human studies associated with the above scenarios. We conclude by discussing the potential benefits, challenges and limitations of our framework.","sentences":["Modeling subrational agents, such as humans or economic households, is inherently challenging due to the difficulty in calibrating reinforcement learning models or collecting data that involves human subjects.","Existing work highlights the ability of Large Language Models (LLMs) to address complex reasoning tasks and mimic human communication, while simulation using LLMs as agents shows emergent social behaviors, potentially improving our comprehension of human conduct.","In this paper, we propose to investigate the use of LLMs to generate synthetic human demonstrations, which are then used to learn subrational agent policies though Imitation Learning.","We make an assumption that LLMs can be used as implicit computational models of humans, and propose a framework to use synthetic demonstrations derived from LLMs to model subrational behaviors that are characteristic of humans (e.g., myopic behavior or preference for risk aversion).","We experimentally evaluate the ability of our framework to model sub-rationality through four simple scenarios, including the well-researched ultimatum game and marshmallow experiment.","To gain confidence in our framework, we are able to replicate well-established findings from prior human studies associated with the above scenarios.","We conclude by discussing the potential benefits, challenges and limitations of our framework."],"url":"http://arxiv.org/abs/2402.08755v1"}
{"created":"2024-02-13 19:36:23","title":"Automated detection of motion artifacts in brain MR images using deep learning and explainable artificial intelligence","abstract":"Quality assessment, including inspecting the images for artifacts, is a critical step during MRI data acquisition to ensure data quality and downstream analysis or interpretation success. This study demonstrates a deep learning model to detect rigid motion in T1-weighted brain images. We leveraged a 2D CNN for three-class classification and tested it on publicly available retrospective and prospective datasets. Grad-CAM heatmaps enabled the identification of failure modes and provided an interpretation of the model's results. The model achieved average precision and recall metrics of 85% and 80% on six motion-simulated retrospective datasets. Additionally, the model's classifications on the prospective dataset showed a strong inverse correlation (-0.84) compared to average edge strength, an image quality metric indicative of motion. This model is part of the ArtifactID tool, aimed at inline automatic detection of Gibbs ringing, wrap-around, and motion artifacts. This tool automates part of the time-consuming QA process and augments expertise on-site, particularly relevant in low-resource settings where local MR knowledge is scarce.","sentences":["Quality assessment, including inspecting the images for artifacts, is a critical step during MRI data acquisition to ensure data quality and downstream analysis or interpretation success.","This study demonstrates a deep learning model to detect rigid motion in T1-weighted brain images.","We leveraged a 2D CNN for three-class classification and tested it on publicly available retrospective and prospective datasets.","Grad-CAM heatmaps enabled the identification of failure modes and provided an interpretation of the model's results.","The model achieved average precision and recall metrics of 85% and 80% on six motion-simulated retrospective datasets.","Additionally, the model's classifications on the prospective dataset showed a strong inverse correlation (-0.84) compared to average edge strength, an image quality metric indicative of motion.","This model is part of the ArtifactID tool, aimed at inline automatic detection of Gibbs ringing, wrap-around, and motion artifacts.","This tool automates part of the time-consuming QA process and augments expertise on-site, particularly relevant in low-resource settings where local MR knowledge is scarce."],"url":"http://arxiv.org/abs/2402.08749v1"}
{"created":"2024-02-13 19:27:06","title":"Unveiling Hidden Energy Anomalies: Harnessing Deep Learning to Optimize Energy Management in Sports Facilities","abstract":"Anomaly detection in sport facilities has gained significant attention due to its potential to promote energy saving and optimizing operational efficiency. In this research article, we investigate the role of machine learning, particularly deep learning, in anomaly detection for sport facilities. We explore the challenges and perspectives of utilizing deep learning methods for this task, aiming to address the drawbacks and limitations of conventional approaches. Our proposed approach involves feature extraction from the data collected in sport facilities. We present a problem formulation using Deep Feedforward Neural Networks (DFNN) and introduce threshold estimation techniques to identify anomalies effectively. Furthermore, we propose methods to reduce false alarms, ensuring the reliability and accuracy of anomaly detection. To evaluate the effectiveness of our approach, we conduct experiments on aquatic center dataset at Qatar University. The results demonstrate the superiority of our deep learning-based method over conventional techniques, highlighting its potential in real-world applications. Typically, 94.33% accuracy and 92.92% F1-score have been achieved using the proposed scheme.","sentences":["Anomaly detection in sport facilities has gained significant attention due to its potential to promote energy saving and optimizing operational efficiency.","In this research article, we investigate the role of machine learning, particularly deep learning, in anomaly detection for sport facilities.","We explore the challenges and perspectives of utilizing deep learning methods for this task, aiming to address the drawbacks and limitations of conventional approaches.","Our proposed approach involves feature extraction from the data collected in sport facilities.","We present a problem formulation using Deep Feedforward Neural Networks (DFNN) and introduce threshold estimation techniques to identify anomalies effectively.","Furthermore, we propose methods to reduce false alarms, ensuring the reliability and accuracy of anomaly detection.","To evaluate the effectiveness of our approach, we conduct experiments on aquatic center dataset at Qatar University.","The results demonstrate the superiority of our deep learning-based method over conventional techniques, highlighting its potential in real-world applications.","Typically, 94.33% accuracy and 92.92% F1-score have been achieved using the proposed scheme."],"url":"http://arxiv.org/abs/2402.08742v1"}
