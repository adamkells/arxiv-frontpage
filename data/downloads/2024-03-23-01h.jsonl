{"created":"2024-03-21 17:59:41","title":"Simplified Diffusion Schr\u00f6dinger Bridge","abstract":"This paper introduces a novel theoretical simplification of the Diffusion Schr\\\"odinger Bridge (DSB) that facilitates its unification with Score-based Generative Models (SGMs), addressing the limitations of DSB in complex data generation and enabling faster convergence and enhanced performance. By employing SGMs as an initial solution for DSB, our approach capitalizes on the strengths of both frameworks, ensuring a more efficient training process and improving the performance of SGM. We also propose a reparameterization technique that, despite theoretical approximations, practically improves the network's fitting capabilities. Our extensive experimental evaluations confirm the effectiveness of the simplified DSB, demonstrating its significant improvements. We believe the contributions of this work pave the way for advanced generative modeling. The code is available at https://github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge.","sentences":["This paper introduces a novel theoretical simplification of the Diffusion Schr\\\"odinger Bridge (DSB) that facilitates its unification with Score-based Generative Models (SGMs), addressing the limitations of DSB in complex data generation and enabling faster convergence and enhanced performance.","By employing SGMs as an initial solution for DSB, our approach capitalizes on the strengths of both frameworks, ensuring a more efficient training process and improving the performance of SGM.","We also propose a reparameterization technique that, despite theoretical approximations, practically improves the network's fitting capabilities.","Our extensive experimental evaluations confirm the effectiveness of the simplified DSB, demonstrating its significant improvements.","We believe the contributions of this work pave the way for advanced generative modeling.","The code is available at https://github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge."],"url":"http://arxiv.org/abs/2403.14623v1"}
{"created":"2024-03-21 17:59:16","title":"ClusteringSDF: Self-Organized Neural Implicit Surfaces for 3D Decomposition","abstract":"3D decomposition/segmentation still remains a challenge as large-scale 3D annotated data is not readily available. Contemporary approaches typically leverage 2D machine-generated segments, integrating them for 3D consistency. While the majority of these methods are based on NeRFs, they face a potential weakness that the instance/semantic embedding features derive from independent MLPs, thus preventing the segmentation network from learning the geometric details of the objects directly through radiance and density. In this paper, we propose ClusteringSDF, a novel approach to achieve both segmentation and reconstruction in 3D via the neural implicit surface representation, specifically Signal Distance Function (SDF), where the segmentation rendering is directly integrated with the volume rendering of neural implicit surfaces. Although based on ObjectSDF++, ClusteringSDF no longer requires the ground-truth segments for supervision while maintaining the capability of reconstructing individual object surfaces, but purely with the noisy and inconsistent labels from pre-trained models.As the core of ClusteringSDF, we introduce a high-efficient clustering mechanism for lifting the 2D labels to 3D and the experimental results on the challenging scenes from ScanNet and Replica datasets show that ClusteringSDF can achieve competitive performance compared against the state-of-the-art with significantly reduced training time.","sentences":["3D decomposition/segmentation still remains a challenge as large-scale 3D annotated data is not readily available.","Contemporary approaches typically leverage 2D machine-generated segments, integrating them for 3D consistency.","While the majority of these methods are based on NeRFs, they face a potential weakness that the instance/semantic embedding features derive from independent MLPs, thus preventing the segmentation network from learning the geometric details of the objects directly through radiance and density.","In this paper, we propose ClusteringSDF, a novel approach to achieve both segmentation and reconstruction in 3D via the neural implicit surface representation, specifically Signal Distance Function (SDF), where the segmentation rendering is directly integrated with the volume rendering of neural implicit surfaces.","Although based on ObjectSDF++, ClusteringSDF no longer requires the ground-truth segments for supervision while maintaining the capability of reconstructing individual object surfaces, but purely with the noisy and inconsistent labels from pre-trained models.","As the core of ClusteringSDF, we introduce a high-efficient clustering mechanism for lifting the 2D labels to 3D and the experimental results on the challenging scenes from ScanNet and Replica datasets show that ClusteringSDF can achieve competitive performance compared against the state-of-the-art with significantly reduced training time."],"url":"http://arxiv.org/abs/2403.14619v1"}
{"created":"2024-03-21 17:57:03","title":"T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy","abstract":"We present T-Rex2, a highly practical model for open-set object detection. Previous open-set object detection methods relying on text prompts effectively encapsulate the abstract concept of common objects, but struggle with rare or complex object representation due to data scarcity and descriptive limitations. Conversely, visual prompts excel in depicting novel objects through concrete visual examples, but fall short in conveying the abstract concept of objects as effectively as text prompts. Recognizing the complementary strengths and weaknesses of both text and visual prompts, we introduce T-Rex2 that synergizes both prompts within a single model through contrastive learning. T-Rex2 accepts inputs in diverse formats, including text prompts, visual prompts, and the combination of both, so that it can handle different scenarios by switching between the two prompt modalities. Comprehensive experiments demonstrate that T-Rex2 exhibits remarkable zero-shot object detection capabilities across a wide spectrum of scenarios. We show that text prompts and visual prompts can benefit from each other within the synergy, which is essential to cover massive and complicated real-world scenarios and pave the way towards generic object detection. Model API is now available at \\url{https://github.com/IDEA-Research/T-Rex}.","sentences":["We present T-Rex2, a highly practical model for open-set object detection.","Previous open-set object detection methods relying on text prompts effectively encapsulate the abstract concept of common objects, but struggle with rare or complex object representation due to data scarcity and descriptive limitations.","Conversely, visual prompts excel in depicting novel objects through concrete visual examples, but fall short in conveying the abstract concept of objects as effectively as text prompts.","Recognizing the complementary strengths and weaknesses of both text and visual prompts, we introduce T-Rex2 that synergizes both prompts within a single model through contrastive learning.","T-Rex2 accepts inputs in diverse formats, including text prompts, visual prompts, and the combination of both, so that it can handle different scenarios by switching between the two prompt modalities.","Comprehensive experiments demonstrate that T-Rex2 exhibits remarkable zero-shot object detection capabilities across a wide spectrum of scenarios.","We show that text prompts and visual prompts can benefit from each other within the synergy, which is essential to cover massive and complicated real-world scenarios and pave the way towards generic object detection.","Model API is now available at \\url{https://github.com/IDEA-Research/T-Rex}."],"url":"http://arxiv.org/abs/2403.14610v1"}
{"created":"2024-03-21 17:55:16","title":"The Elements of Differentiable Programming","abstract":"Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation. By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs.","sentences":["Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming.","This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible.","As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics.","This book presents a comprehensive review of the fundamental concepts useful for differentiable programming.","We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two.","Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation.","By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs."],"url":"http://arxiv.org/abs/2403.14606v1"}
{"created":"2024-03-21 17:47:28","title":"Envisioning the Next-Generation AI Coding Assistants: Insights & Proposals","abstract":"As a research-product hybrid group in AI for Software Engineering (AI4SE), we present four key takeaways from our experience developing in-IDE AI coding assistants. AI coding assistants should set clear expectations for usage, integrate with advanced IDE capabilities and existing extensions, use extendable backend designs, and collect app data responsibly for downstream analyses. We propose open questions and challenges that academia and industry should address to realize the vision of next-generation AI coding assistants.","sentences":["As a research-product hybrid group in AI for Software Engineering (AI4SE), we present four key takeaways from our experience developing in-IDE AI coding assistants.","AI coding assistants should set clear expectations for usage, integrate with advanced IDE capabilities and existing extensions, use extendable backend designs, and collect app data responsibly for downstream analyses.","We propose open questions and challenges that academia and industry should address to realize the vision of next-generation AI coding assistants."],"url":"http://arxiv.org/abs/2403.14592v1"}
{"created":"2024-03-21 17:43:44","title":"ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training","abstract":"Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotations or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent executes multiple trajectories for the failed tasks, and selects the successful ones to supplement its failed trajectory for contrastive self-training. Realized by policy gradient methods with binarized rewards, the contrastive self-training with accumulated trajectories facilitates a closed loop for multiple rounds of language agent self-improvement. We conduct experiments using QLoRA fine-tuning with the open-sourced Mistral-7B-Instruct-v0.2. In AlfWorld, the agent trained with A$^3$T obtains a 1-shot success rate of 96%, and 100% success with 4 iterative rounds. In WebShop, the 1-shot performance of the A$^3$T agent matches human average, and 4 rounds of iterative refinement lead to the performance approaching human experts. A$^3$T agents significantly outperform existing techniques, including prompting with GPT-4, advanced agent frameworks, and fully fine-tuned LLMs.","sentences":["Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models.","Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data.","However, collecting such trajectories still requires considerable human effort, by either artificial annotations or implementations of diverse prompting frameworks.","In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct.","The central role is an ActRe prompting agent, which explains the reason for an arbitrary action.","When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales.","Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action.","In this way, the ReAct-style agent executes multiple trajectories for the failed tasks, and selects the successful ones to supplement its failed trajectory for contrastive self-training.","Realized by policy gradient methods with binarized rewards, the contrastive self-training with accumulated trajectories facilitates a closed loop for multiple rounds of language agent self-improvement.","We conduct experiments using QLoRA fine-tuning with the open-sourced Mistral-7B-Instruct-v0.2.","In AlfWorld, the agent trained with A$^3$T obtains a 1-shot success rate of 96%, and 100% success with 4 iterative rounds.","In WebShop, the 1-shot performance of the A$^3$T agent matches human average, and 4 rounds of iterative refinement lead to the performance approaching human experts.","A$^3$T agents significantly outperform existing techniques, including prompting with GPT-4, advanced agent frameworks, and fully fine-tuned LLMs."],"url":"http://arxiv.org/abs/2403.14589v1"}
{"created":"2024-03-21 17:36:08","title":"Large Language Models for Multi-Choice Question Classification of Medical Subjects","abstract":"The aim of this paper is to evaluate whether large language models trained on multi-choice question data can be used to discriminate between medical subjects. This is an important and challenging task for automatic question answering. To achieve this goal, we train deep neural networks for multi-class classification of questions into the inferred medical subjects. Using our Multi-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art results on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their development and test sets, respectively. In this sense, we show the capability of AI and LLMs in particular for multi-classification tasks in the Healthcare domain.","sentences":["The aim of this paper is to evaluate whether large language models trained on multi-choice question data can be used to discriminate between medical subjects.","This is an important and challenging task for automatic question answering.","To achieve this goal, we train deep neural networks for multi-class classification of questions into the inferred medical subjects.","Using our Multi-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art results on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their development and test sets, respectively.","In this sense, we show the capability of AI and LLMs in particular for multi-classification tasks in the Healthcare domain."],"url":"http://arxiv.org/abs/2403.14582v1"}
{"created":"2024-03-21 17:35:07","title":"Global, robust and comparable digital carbon assets","abstract":"Carbon credits purchased in the voluntary carbon market allow unavoidable emissions, such as from international flights for essential travel, to be offset by an equivalent climate benefit, such as avoiding emissions from tropical deforestation. However, many concerns regarding the credibility of these offsetting claims have been raised. Moreover, the credit market is manual, therefore inefficient and unscalable, and non-fungible, therefore illiquid. To address these issues, we propose an efficient digital methodology that combines remote sensing data, modern econometric techniques, and on-chain certification and trading to create a new digital carbon asset (the PACT stablecoin) against which carbon offsetting claims can be transparently verified. PACT stablecoins are produced as outputs from a reproducible computational pipeline for estimating the climate benefits of carbon offset projects that not only quantifies the CO2 emissions involved, but also allows for similar credits to be pooled based on their co-benefits such as biodiversity and jurisdictional attributes, increasing liquidity through fungibility within pools. We implement and evaluate the PACT carbon stablecoin on the Tezos blockchain, which is designed to facilitate low-cost transactions while minimizing environmental impact. Our implementation includes a contract for a registry for tracking issuance, ownership, and retirement of credits, and a custodian contract to bridge on-chain and off-chain transactions. Our work brings scale and trust to the voluntary carbon market by providing a transparent, scalable, and efficient framework for high integrity carbon credit transactions.","sentences":["Carbon credits purchased in the voluntary carbon market allow unavoidable emissions, such as from international flights for essential travel, to be offset by an equivalent climate benefit, such as avoiding emissions from tropical deforestation.","However, many concerns regarding the credibility of these offsetting claims have been raised.","Moreover, the credit market is manual, therefore inefficient and unscalable, and non-fungible, therefore illiquid.","To address these issues, we propose an efficient digital methodology that combines remote sensing data, modern econometric techniques, and on-chain certification and trading to create a new digital carbon asset (the PACT stablecoin) against which carbon offsetting claims can be transparently verified.","PACT stablecoins are produced as outputs from a reproducible computational pipeline for estimating the climate benefits of carbon offset projects that not only quantifies the CO2 emissions involved, but also allows for similar credits to be pooled based on their co-benefits such as biodiversity and jurisdictional attributes, increasing liquidity through fungibility within pools.","We implement and evaluate the PACT carbon stablecoin on the Tezos blockchain, which is designed to facilitate low-cost transactions while minimizing environmental impact.","Our implementation includes a contract for a registry for tracking issuance, ownership, and retirement of credits, and a custodian contract to bridge on-chain and off-chain transactions.","Our work brings scale and trust to the voluntary carbon market by providing a transparent, scalable, and efficient framework for high integrity carbon credit transactions."],"url":"http://arxiv.org/abs/2403.14581v1"}
{"created":"2024-03-21 17:09:20","title":"A survey on Concept-based Approaches For Model Improvement","abstract":"The focus of recent research has shifted from merely increasing the Deep Neural Networks (DNNs) performance in various tasks to DNNs, which are more interpretable to humans. The field of eXplainable Artificial Intelligence (XAI) has observed various techniques, including saliency-based and concept-based approaches. Concept-based approaches explain the model's decisions in simple human understandable terms called Concepts. Concepts are human interpretable units of data and are the thinking ground of humans. Explanations in terms of concepts enable detecting spurious correlations, inherent biases, or clever-hans. With the advent of concept-based explanations, there have been various concept representation methods and automatic concept discovery algorithms. Some recent methods use concepts for post-hoc model disentanglement evaluation, while others use them for ante-hoc training. The concept-based approaches are new, with many representations coming up, and there is very limited work on Concept-based Model improvement. We provide a systematic review and taxonomy of various concept representations and their discovery algorithms in DNNs, specifically in vision. We also provide details on concept-based model improvement literature, which is the first to survey concept-based model improvement methods.","sentences":["The focus of recent research has shifted from merely increasing the Deep Neural Networks (DNNs) performance in various tasks to DNNs, which are more interpretable to humans.","The field of eXplainable Artificial Intelligence (XAI) has observed various techniques, including saliency-based and concept-based approaches.","Concept-based approaches explain the model's decisions in simple human understandable terms called Concepts.","Concepts are human interpretable units of data and are the thinking ground of humans.","Explanations in terms of concepts enable detecting spurious correlations, inherent biases, or clever-hans.","With the advent of concept-based explanations, there have been various concept representation methods and automatic concept discovery algorithms.","Some recent methods use concepts for post-hoc model disentanglement evaluation, while others use them for ante-hoc training.","The concept-based approaches are new, with many representations coming up, and there is very limited work on Concept-based Model improvement.","We provide a systematic review and taxonomy of various concept representations and their discovery algorithms in DNNs, specifically in vision.","We also provide details on concept-based model improvement literature, which is the first to survey concept-based model improvement methods."],"url":"http://arxiv.org/abs/2403.14566v1"}
{"created":"2024-03-21 17:05:38","title":"Looking Together $\\neq$ Seeing the Same Thing: Understanding Surgeons' Visual Needs During Intra-operative Coordination and Instruction","abstract":"Shared gaze visualizations have been found to enhance collaboration and communication outcomes in diverse HCI scenarios including computer supported collaborative work and learning contexts. Given the importance of gaze in surgery operations, especially when a surgeon trainer and trainee need to coordinate their actions, research on the use of gaze to facilitate intra-operative coordination and instruction has been limited and shows mixed implications. We performed a field observation of 8 surgeries and an interview study with 14 surgeons to understand their visual needs during operations, informing ways to leverage and augment gaze to enhance intra-operative coordination and instruction. We found that trainees have varying needs in receiving visual guidance which are often unfulfilled by the trainers' instructions. It is critical for surgeons to control the timing of the gaze-based visualizations and effectively interpret gaze data. We suggest overlay technologies, e.g., gaze-based summaries and depth sensing, to augment raw gaze in support of surgical coordination and instruction.","sentences":["Shared gaze visualizations have been found to enhance collaboration and communication outcomes in diverse HCI scenarios including computer supported collaborative work and learning contexts.","Given the importance of gaze in surgery operations, especially when a surgeon trainer and trainee need to coordinate their actions, research on the use of gaze to facilitate intra-operative coordination and instruction has been limited and shows mixed implications.","We performed a field observation of 8 surgeries and an interview study with 14 surgeons to understand their visual needs during operations, informing ways to leverage and augment gaze to enhance intra-operative coordination and instruction.","We found that trainees have varying needs in receiving visual guidance which are often unfulfilled by the trainers' instructions.","It is critical for surgeons to control the timing of the gaze-based visualizations and effectively interpret gaze data.","We suggest overlay technologies, e.g., gaze-based summaries and depth sensing, to augment raw gaze in support of surgical coordination and instruction."],"url":"http://arxiv.org/abs/2403.14561v1"}
{"created":"2024-03-21 16:52:01","title":"Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling","abstract":"Today's most accurate language models are trained on orders of magnitude more language data than human language learners receive - but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs' representations and predictions more accurate (and more human-like) with more ecologically plausible supervision? This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve textual representations. LexiContrastive Grounding combines a next token prediction strategy with a contrastive visual grounding objective, focusing on early-layer representations that encode lexical information. Across multiple word-learning and sentence-understanding benchmarks, LexiContrastive Grounding not only outperforms standard language-only models in learning efficiency, but also improves upon vision-and-language learning procedures including CLIP, GIT, Flamingo, and Vokenization. Moreover, LexiContrastive Grounding improves perplexity by around 5% on multiple language modeling tasks. This work underscores the potential of incorporating visual grounding into language models, aligning more closely with the multimodal nature of human language acquisition.","sentences":["Today's most accurate language models are trained on orders of magnitude more language data than human language learners receive - but with no supervision from other sensory modalities that play a crucial role in human learning.","Can we make LMs' representations and predictions more accurate (and more human-like) with more ecologically plausible supervision?","This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve textual representations.","LexiContrastive Grounding combines a next token prediction strategy with a contrastive visual grounding objective, focusing on early-layer representations that encode lexical information.","Across multiple word-learning and sentence-understanding benchmarks, LexiContrastive Grounding not only outperforms standard language-only models in learning efficiency, but also improves upon vision-and-language learning procedures including CLIP, GIT, Flamingo, and Vokenization.","Moreover, LexiContrastive Grounding improves perplexity by around 5% on multiple language modeling tasks.","This work underscores the potential of incorporating visual grounding into language models, aligning more closely with the multimodal nature of human language acquisition."],"url":"http://arxiv.org/abs/2403.14551v1"}
{"created":"2024-03-21 16:50:12","title":"Dynamic Explanation Emphasis in Human-XAI Interaction with Communication Robot","abstract":"Communication robots have the potential to contribute to effective human-XAI interaction as an interface that goes beyond textual or graphical explanations. One of their strengths is that they can use physical and vocal expressions to add detailed nuances to explanations. However, it is not clear how a robot can apply such expressions, or in particular, how we can develop a strategy to adaptively use such expressions depending on the task and user in dynamic interactions. To address this question, this paper proposes DynEmph, a method for a communication robot to decide where to emphasize XAI-generated explanations with physical expressions. It predicts the effect of emphasizing certain points on a user and aims to minimize the expected difference between predicted user decisions and AI-suggested ones. DynEmph features a strategy for deciding where to emphasize in a data-driven manner, relieving engineers from the need to manually design a strategy. We further conducted experiments to investigate how emphasis selection strategies affect the performance of user decisions. The results suggest that, while a naive strategy (emphasizing explanations for an AI's most probable class) does not necessarily work better, DynEmph effectively guides users to better decisions under the condition that the performance of the AI suggestion is high.","sentences":["Communication robots have the potential to contribute to effective human-XAI interaction as an interface that goes beyond textual or graphical explanations.","One of their strengths is that they can use physical and vocal expressions to add detailed nuances to explanations.","However, it is not clear how a robot can apply such expressions, or in particular, how we can develop a strategy to adaptively use such expressions depending on the task and user in dynamic interactions.","To address this question, this paper proposes DynEmph, a method for a communication robot to decide where to emphasize XAI-generated explanations with physical expressions.","It predicts the effect of emphasizing certain points on a user and aims to minimize the expected difference between predicted user decisions and AI-suggested ones.","DynEmph features a strategy for deciding where to emphasize in a data-driven manner, relieving engineers from the need to manually design a strategy.","We further conducted experiments to investigate how emphasis selection strategies affect the performance of user decisions.","The results suggest that, while a naive strategy (emphasizing explanations for an AI's most probable class) does not necessarily work better, DynEmph effectively guides users to better decisions under the condition that the performance of the AI suggestion is high."],"url":"http://arxiv.org/abs/2403.14550v1"}
{"created":"2024-03-21 16:48:45","title":"Estimating Physical Information Consistency of Channel Data Augmentation for Remote Sensing Images","abstract":"The application of data augmentation for deep learning (DL) methods plays an important role in achieving state-of-the-art results in supervised, semi-supervised, and self-supervised image classification. In particular, channel transformations (e.g., solarize, grayscale, brightness adjustments) are integrated into data augmentation pipelines for remote sensing (RS) image classification tasks. However, contradicting beliefs exist about their proper applications to RS images. A common point of critique is that the application of channel augmentation techniques may lead to physically inconsistent spectral data (i.e., pixel signatures). To shed light on the open debate, we propose an approach to estimate whether a channel augmentation technique affects the physical information of RS images. To this end, the proposed approach estimates a score that measures the alignment of a pixel signature within a time series that can be naturally subject to deviations caused by factors such as acquisition conditions or phenological states of vegetation. We compare the scores associated with original and augmented pixel signatures to evaluate the physical consistency. Experimental results on a multi-label image classification task show that channel augmentations yielding a score that exceeds the expected deviation of original pixel signatures can not improve the performance of a baseline model trained without augmentation.","sentences":["The application of data augmentation for deep learning (DL) methods plays an important role in achieving state-of-the-art results in supervised, semi-supervised, and self-supervised image classification.","In particular, channel transformations (e.g., solarize, grayscale, brightness adjustments) are integrated into data augmentation pipelines for remote sensing (RS) image classification tasks.","However, contradicting beliefs exist about their proper applications to RS images.","A common point of critique is that the application of channel augmentation techniques may lead to physically inconsistent spectral data (i.e., pixel signatures).","To shed light on the open debate, we propose an approach to estimate whether a channel augmentation technique affects the physical information of RS images.","To this end, the proposed approach estimates a score that measures the alignment of a pixel signature within a time series that can be naturally subject to deviations caused by factors such as acquisition conditions or phenological states of vegetation.","We compare the scores associated with original and augmented pixel signatures to evaluate the physical consistency.","Experimental results on a multi-label image classification task show that channel augmentations yielding a score that exceeds the expected deviation of original pixel signatures can not improve the performance of a baseline model trained without augmentation."],"url":"http://arxiv.org/abs/2403.14547v1"}
{"created":"2024-03-21 16:44:49","title":"Learning Hierarchical Control For Constrained Dynamic Task Assignment","abstract":"This paper introduces a novel data-driven hierarchical control scheme for managing a fleet of nonlinear, capacity-constrained autonomous agents in an iterative environment. We propose a control framework consisting of a high-level dynamic task assignment and routing layer and low-level motion planning and tracking layer. Each layer of the control hierarchy uses a data-driven MPC policy, maintaining bounded computational complexity at each calculation of a new task assignment or actuation input. We utilize collected data to iteratively refine estimates of agent capacity usage, and update MPC policy parameters accordingly. Our approach leverages tools from iterative learning control to integrate learning at both levels of the hierarchy, and coordinates learning between levels in order to maintain closed-loop feasibility and performance improvement of the connected architecture.","sentences":["This paper introduces a novel data-driven hierarchical control scheme for managing a fleet of nonlinear, capacity-constrained autonomous agents in an iterative environment.","We propose a control framework consisting of a high-level dynamic task assignment and routing layer and low-level motion planning and tracking layer.","Each layer of the control hierarchy uses a data-driven MPC policy, maintaining bounded computational complexity at each calculation of a new task assignment or actuation input.","We utilize collected data to iteratively refine estimates of agent capacity usage, and update MPC policy parameters accordingly.","Our approach leverages tools from iterative learning control to integrate learning at both levels of the hierarchy, and coordinates learning between levels in order to maintain closed-loop feasibility and performance improvement of the connected architecture."],"url":"http://arxiv.org/abs/2403.14545v1"}
{"created":"2024-03-21 16:40:10","title":"Object-Centric Domain Randomization for 3D Shape Reconstruction in the Wild","abstract":"One of the biggest challenges in single-view 3D shape reconstruction in the wild is the scarcity of <3D shape, 2D image>-paired data from real-world environments. Inspired by remarkable achievements via domain randomization, we propose ObjectDR which synthesizes such paired data via a random simulation of visual variations in object appearances and backgrounds. Our data synthesis framework exploits a conditional generative model (e.g., ControlNet) to generate images conforming to spatial conditions such as 2.5D sketches, which are obtainable through a rendering process of 3D shapes from object collections (e.g., Objaverse-XL). To simulate diverse variations while preserving object silhouettes embedded in spatial conditions, we also introduce a disentangled framework which leverages an initial object guidance. After synthesizing a wide range of data, we pre-train a model on them so that it learns to capture a domain-invariant geometry prior which is consistent across various domains. We validate its effectiveness by substantially improving 3D shape reconstruction models on a real-world benchmark. In a scale-up evaluation, our pre-training achieves 23.6% superior results compared with the pre-training on high-quality computer graphics renderings.","sentences":["One of the biggest challenges in single-view 3D shape reconstruction in the wild is the scarcity of <3D shape, 2D image>-paired data from real-world environments.","Inspired by remarkable achievements via domain randomization, we propose ObjectDR which synthesizes such paired data via a random simulation of visual variations in object appearances and backgrounds.","Our data synthesis framework exploits a conditional generative model (e.g., ControlNet) to generate images conforming to spatial conditions such as 2.5D sketches, which are obtainable through a rendering process of 3D shapes from object collections (e.g., Objaverse-XL).","To simulate diverse variations while preserving object silhouettes embedded in spatial conditions, we also introduce a disentangled framework which leverages an initial object guidance.","After synthesizing a wide range of data, we pre-train a model on them so that it learns to capture a domain-invariant geometry prior which is consistent across various domains.","We validate its effectiveness by substantially improving 3D shape reconstruction models on a real-world benchmark.","In a scale-up evaluation, our pre-training achieves 23.6% superior results compared with the pre-training on high-quality computer graphics renderings."],"url":"http://arxiv.org/abs/2403.14539v1"}
{"created":"2024-03-21 16:11:44","title":"Building a Language-Learning Game for Brazilian Indigenous Languages: A Case of Study","abstract":"In this paper we discuss a first attempt to build a language learning game for brazilian indigenous languages and the challenges around it. We present a design for the tool with gamification aspects. Then we describe a process to automatically generate language exercises and questions from a dependency treebank and a lexical database for Tupian languages. We discuss the limitations of our prototype highlighting ethical and practical implementation concerns. Finally, we conclude that new data gathering processes should be established in partnership with indigenous communities and oriented for educational purposes.","sentences":["In this paper we discuss a first attempt to build a language learning game for brazilian indigenous languages and the challenges around it.","We present a design for the tool with gamification aspects.","Then we describe a process to automatically generate language exercises and questions from a dependency treebank and a lexical database for Tupian languages.","We discuss the limitations of our prototype highlighting ethical and practical implementation concerns.","Finally, we conclude that new data gathering processes should be established in partnership with indigenous communities and oriented for educational purposes."],"url":"http://arxiv.org/abs/2403.14515v1"}
{"created":"2024-03-21 16:07:30","title":"Universal Differential Equations as a Common Modeling Language for Neuroscience","abstract":"The unprecedented availability of large-scale datasets in neuroscience has spurred the exploration of artificial deep neural networks (DNNs) both as empirical tools and as models of natural neural systems. Their appeal lies in their ability to approximate arbitrary functions directly from observations, circumventing the need for cumbersome mechanistic modeling. However, without appropriate constraints, DNNs risk producing implausible models, diminishing their scientific value. Moreover, the interpretability of DNNs poses a significant challenge, particularly with the adoption of more complex expressive architectures. In this perspective, we argue for universal differential equations (UDEs) as a unifying approach for model development and validation in neuroscience. UDEs view differential equations as parameterizable, differentiable mathematical objects that can be augmented and trained with scalable deep learning techniques. This synergy facilitates the integration of decades of extensive literature in calculus, numerical analysis, and neural modeling with emerging advancements in AI into a potent framework. We provide a primer on this burgeoning topic in scientific machine learning and demonstrate how UDEs fill in a critical gap between mechanistic, phenomenological, and data-driven models in neuroscience. We outline a flexible recipe for modeling neural systems with UDEs and discuss how they can offer principled solutions to inherent challenges across diverse neuroscience applications such as understanding neural computation, controlling neural systems, neural decoding, and normative modeling.","sentences":["The unprecedented availability of large-scale datasets in neuroscience has spurred the exploration of artificial deep neural networks (DNNs) both as empirical tools and as models of natural neural systems.","Their appeal lies in their ability to approximate arbitrary functions directly from observations, circumventing the need for cumbersome mechanistic modeling.","However, without appropriate constraints, DNNs risk producing implausible models, diminishing their scientific value.","Moreover, the interpretability of DNNs poses a significant challenge, particularly with the adoption of more complex expressive architectures.","In this perspective, we argue for universal differential equations (UDEs) as a unifying approach for model development and validation in neuroscience.","UDEs view differential equations as parameterizable, differentiable mathematical objects that can be augmented and trained with scalable deep learning techniques.","This synergy facilitates the integration of decades of extensive literature in calculus, numerical analysis, and neural modeling with emerging advancements in AI into a potent framework.","We provide a primer on this burgeoning topic in scientific machine learning and demonstrate how UDEs fill in a critical gap between mechanistic, phenomenological, and data-driven models in neuroscience.","We outline a flexible recipe for modeling neural systems with UDEs and discuss how they can offer principled solutions to inherent challenges across diverse neuroscience applications such as understanding neural computation, controlling neural systems, neural decoding, and normative modeling."],"url":"http://arxiv.org/abs/2403.14510v1"}
{"created":"2024-03-21 16:02:52","title":"Constrained Reinforcement Learning with Smoothed Log Barrier Function","abstract":"Reinforcement Learning (RL) has been widely applied to many control tasks and substantially improved the performances compared to conventional control methods in many domains where the reward function is well defined. However, for many real-world problems, it is often more convenient to formulate optimization problems in terms of rewards and constraints simultaneously. Optimizing such constrained problems via reward shaping can be difficult as it requires tedious manual tuning of reward functions with several interacting terms. Recent formulations which include constraints mostly require a pre-training phase, which often needs human expertise to collect data or assumes having a sub-optimal policy readily available. We propose a new constrained RL method called CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which achieves competitive performance without any pre-training by applying a linear smoothed log barrier function to an additional safety critic. It implements an adaptive penalty for policy learning and alleviates the numerical issues that are known to complicate the application of the log barrier function method. As a result, we show that with CSAC-LB, we achieve state-of-the-art performance on several constrained control tasks with different levels of difficulty and evaluate our methods in a locomotion task on a real quadruped robot platform.","sentences":["Reinforcement Learning (RL) has been widely applied to many control tasks and substantially improved the performances compared to conventional control methods in many domains where the reward function is well defined.","However, for many real-world problems, it is often more convenient to formulate optimization problems in terms of rewards and constraints simultaneously.","Optimizing such constrained problems via reward shaping can be difficult as it requires tedious manual tuning of reward functions with several interacting terms.","Recent formulations which include constraints mostly require a pre-training phase, which often needs human expertise to collect data or assumes having a sub-optimal policy readily available.","We propose a new constrained RL method called CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which achieves competitive performance without any pre-training by applying a linear smoothed log barrier function to an additional safety critic.","It implements an adaptive penalty for policy learning and alleviates the numerical issues that are known to complicate the application of the log barrier function method.","As a result, we show that with CSAC-LB, we achieve state-of-the-art performance on several constrained control tasks with different levels of difficulty and evaluate our methods in a locomotion task on a real quadruped robot platform."],"url":"http://arxiv.org/abs/2403.14508v1"}
{"created":"2024-03-21 15:56:15","title":"Soft Learning Probabilistic Circuits","abstract":"Probabilistic Circuits (PCs) are prominent tractable probabilistic models, allowing for a range of exact inferences. This paper focuses on the main algorithm for training PCs, LearnSPN, a gold standard due to its efficiency, performance, and ease of use, in particular for tabular data. We show that LearnSPN is a greedy likelihood maximizer under mild assumptions. While inferences in PCs may use the entire circuit structure for processing queries, LearnSPN applies a hard method for learning them, propagating at each sum node a data point through one and only one of the children/edges as in a hard clustering process. We propose a new learning procedure named SoftLearn, that induces a PC using a soft clustering process. We investigate the effect of this learning-inference compatibility in PCs. Our experiments show that SoftLearn outperforms LearnSPN in many situations, yielding better likelihoods and arguably better samples. We also analyze comparable tractable models to highlight the differences between soft/hard learning and model querying.","sentences":["Probabilistic Circuits (PCs) are prominent tractable probabilistic models, allowing for a range of exact inferences.","This paper focuses on the main algorithm for training PCs, LearnSPN, a gold standard due to its efficiency, performance, and ease of use, in particular for tabular data.","We show that LearnSPN is a greedy likelihood maximizer under mild assumptions.","While inferences in PCs may use the entire circuit structure for processing queries, LearnSPN applies a hard method for learning them, propagating at each sum node a data point through one and only one of the children/edges as in a hard clustering process.","We propose a new learning procedure named SoftLearn, that induces a PC using a soft clustering process.","We investigate the effect of this learning-inference compatibility in PCs.","Our experiments show that SoftLearn outperforms LearnSPN in many situations, yielding better likelihoods and arguably better samples.","We also analyze comparable tractable models to highlight the differences between soft/hard learning and model querying."],"url":"http://arxiv.org/abs/2403.14504v1"}
{"created":"2024-03-21 15:46:19","title":"MULDE: Multiscale Log-Density Estimation via Denoising Score Matching for Video Anomaly Detection","abstract":"We propose a novel approach to video anomaly detection: we treat feature vectors extracted from videos as realizations of a random variable with a fixed distribution and model this distribution with a neural network. This lets us estimate the likelihood of test videos and detect video anomalies by thresholding the likelihood estimates. We train our video anomaly detector using a modification of denoising score matching, a method that injects training data with noise to facilitate modeling its distribution. To eliminate hyperparameter selection, we model the distribution of noisy video features across a range of noise levels and introduce a regularizer that tends to align the models for different levels of noise. At test time, we combine anomaly indications at multiple noise scales with a Gaussian mixture model. Running our video anomaly detector induces minimal delays as inference requires merely extracting the features and forward-propagating them through a shallow neural network and a Gaussian mixture model. Our experiments on five popular video anomaly detection benchmarks demonstrate state-of-the-art performance, both in the object-centric and in the frame-centric setup.","sentences":["We propose a novel approach to video anomaly detection: we treat feature vectors extracted from videos as realizations of a random variable with a fixed distribution and model this distribution with a neural network.","This lets us estimate the likelihood of test videos and detect video anomalies by thresholding the likelihood estimates.","We train our video anomaly detector using a modification of denoising score matching, a method that injects training data with noise to facilitate modeling its distribution.","To eliminate hyperparameter selection, we model the distribution of noisy video features across a range of noise levels and introduce a regularizer that tends to align the models for different levels of noise.","At test time, we combine anomaly indications at multiple noise scales with a Gaussian mixture model.","Running our video anomaly detector induces minimal delays as inference requires merely extracting the features and forward-propagating them through a shallow neural network and a Gaussian mixture model.","Our experiments on five popular video anomaly detection benchmarks demonstrate state-of-the-art performance, both in the object-centric and in the frame-centric setup."],"url":"http://arxiv.org/abs/2403.14497v1"}
{"created":"2024-03-21 15:39:05","title":"Induced Subforests and Superforests","abstract":"Graph isomorphism, subgraph isomorphism, and maximum common subgraphs are classical well-investigated objects. Their (parameterized) complexity and efficiently tractable cases have been studied. In the present paper, for a given set of forests, we study maximum common induced subforests and minimum common induced superforests. We show that finding a maximum subforest is NP-hard already for two subdivided stars while finding a minimum superforest is tractable for two trees but NP-hard for three trees. For a given set of $k$ trees, we present an efficient greedy $\\left(\\frac{k}{2}-\\frac{1}{2}+\\frac{1}{k}\\right)$-approximation algorithm for the minimum superforest problem. Finally, we present a polynomial time approximation scheme for the maximum subforest problem for any given set of forests.","sentences":["Graph isomorphism, subgraph isomorphism, and maximum common subgraphs are classical well-investigated objects.","Their (parameterized) complexity and efficiently tractable cases have been studied.","In the present paper, for a given set of forests, we study maximum common induced subforests and minimum common induced superforests.","We show that finding a maximum subforest is NP-hard already for two subdivided stars while finding a minimum superforest is tractable for two trees but NP-hard for three trees.","For a given set of $k$ trees, we present an efficient greedy $\\left(\\frac{k}{2}-\\frac{1}{2}+\\frac{1}{k}\\right)$-approximation algorithm for the minimum superforest problem.","Finally, we present a polynomial time approximation scheme for the maximum subforest problem for any given set of forests."],"url":"http://arxiv.org/abs/2403.14492v1"}
{"created":"2024-03-21 15:37:37","title":"Adversary-Robust Graph-Based Learning of WSIs","abstract":"Enhancing the robustness of deep learning models against adversarial attacks is crucial, especially in critical domains like healthcare where significant financial interests heighten the risk of such attacks. Whole slide images (WSIs) are high-resolution, digitized versions of tissue samples mounted on glass slides, scanned using sophisticated imaging equipment. The digital analysis of WSIs presents unique challenges due to their gigapixel size and multi-resolution storage format. In this work, we aim at improving the robustness of cancer Gleason grading classification systems against adversarial attacks, addressing challenges at both the image and graph levels. As regards the proposed algorithm, we develop a novel and innovative graph-based model which utilizes GNN to extract features from the graph representation of WSIs. A denoising module, along with a pooling layer is incorporated to manage the impact of adversarial attacks on the WSIs. The process concludes with a transformer module that classifies various grades of prostate cancer based on the processed data. To assess the effectiveness of the proposed method, we conducted a comparative analysis using two scenarios. Initially, we trained and tested the model without the denoiser using WSIs that had not been exposed to any attack. We then introduced a range of attacks at either the image or graph level and processed them through the proposed network. The performance of the model was evaluated in terms of accuracy and kappa scores. The results from this comparison showed a significant improvement in cancer diagnosis accuracy, highlighting the robustness and efficiency of the proposed method in handling adversarial challenges in the context of medical imaging.","sentences":["Enhancing the robustness of deep learning models against adversarial attacks is crucial, especially in critical domains like healthcare where significant financial interests heighten the risk of such attacks.","Whole slide images (WSIs) are high-resolution, digitized versions of tissue samples mounted on glass slides, scanned using sophisticated imaging equipment.","The digital analysis of WSIs presents unique challenges due to their gigapixel size and multi-resolution storage format.","In this work, we aim at improving the robustness of cancer Gleason grading classification systems against adversarial attacks, addressing challenges at both the image and graph levels.","As regards the proposed algorithm, we develop a novel and innovative graph-based model which utilizes GNN to extract features from the graph representation of WSIs.","A denoising module, along with a pooling layer is incorporated to manage the impact of adversarial attacks on the WSIs.","The process concludes with a transformer module that classifies various grades of prostate cancer based on the processed data.","To assess the effectiveness of the proposed method, we conducted a comparative analysis using two scenarios.","Initially, we trained and tested the model without the denoiser using WSIs that had not been exposed to any attack.","We then introduced a range of attacks at either the image or graph level and processed them through the proposed network.","The performance of the model was evaluated in terms of accuracy and kappa scores.","The results from this comparison showed a significant improvement in cancer diagnosis accuracy, highlighting the robustness and efficiency of the proposed method in handling adversarial challenges in the context of medical imaging."],"url":"http://arxiv.org/abs/2403.14489v1"}
{"created":"2024-03-21 15:31:28","title":"HyperGALE: ASD Classification via Hypergraph Gated Attention with Learnable Hyperedges","abstract":"Autism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by varied social cognitive challenges and repetitive behavioral patterns. Identifying reliable brain imaging-based biomarkers for ASD has been a persistent challenge due to the spectrum's diverse symptomatology. Existing baselines in the field have made significant strides in this direction, yet there remains room for improvement in both performance and interpretability. We propose \\emph{HyperGALE}, which builds upon the hypergraph by incorporating learned hyperedges and gated attention mechanisms. This approach has led to substantial improvements in the model's ability to interpret complex brain graph data, offering deeper insights into ASD biomarker characterization. Evaluated on the extensive ABIDE II dataset, \\emph{HyperGALE} not only improves interpretability but also demonstrates statistically significant enhancements in key performance metrics compared to both previous baselines and the foundational hypergraph model. The advancement \\emph{HyperGALE} brings to ASD research highlights the potential of sophisticated graph-based techniques in neurodevelopmental studies. The source code and implementation instructions are available at GitHub:https://github.com/mehular0ra/HyperGALE.","sentences":["Autism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by varied social cognitive challenges and repetitive behavioral patterns.","Identifying reliable brain imaging-based biomarkers for ASD has been a persistent challenge due to the spectrum's diverse symptomatology.","Existing baselines in the field have made significant strides in this direction, yet there remains room for improvement in both performance and interpretability.","We propose \\emph{HyperGALE}, which builds upon the hypergraph by incorporating learned hyperedges and gated attention mechanisms.","This approach has led to substantial improvements in the model's ability to interpret complex brain graph data, offering deeper insights into ASD biomarker characterization.","Evaluated on the extensive ABIDE II dataset, \\emph{HyperGALE} not only improves interpretability but also demonstrates statistically significant enhancements in key performance metrics compared to both previous baselines and the foundational hypergraph model.","The advancement \\emph{HyperGALE} brings to ASD research highlights the potential of sophisticated graph-based techniques in neurodevelopmental studies.","The source code and implementation instructions are available at GitHub:https://github.com/mehular0ra/HyperGALE."],"url":"http://arxiv.org/abs/2403.14484v1"}
{"created":"2024-03-21 15:29:24","title":"Utilizing the LightGBM Algorithm for Operator User Credit Assessment Research","abstract":"Mobile Internet user credit assessment is an important way for communication operators to establish decisions and formulate measures, and it is also a guarantee for operators to obtain expected benefits. However, credit evaluation methods have long been monopolized by financial industries such as banks and credit. As supporters and providers of platform network technology and network resources, communication operators are also builders and maintainers of communication networks. Internet data improves the user's credit evaluation strategy. This paper uses the massive data provided by communication operators to carry out research on the operator's user credit evaluation model based on the fusion LightGBM algorithm. First, for the massive data related to user evaluation provided by operators, key features are extracted by data preprocessing and feature engineering methods, and a multi-dimensional feature set with statistical significance is constructed; then, linear regression, decision tree, LightGBM, and other machine learning algorithms build multiple basic models to find the best basic model; finally, integrates Averaging, Voting, Blending, Stacking and other integrated algorithms to refine multiple fusion models, and finally establish the most suitable fusion model for operator user evaluation.","sentences":["Mobile Internet user credit assessment is an important way for communication operators to establish decisions and formulate measures, and it is also a guarantee for operators to obtain expected benefits.","However, credit evaluation methods have long been monopolized by financial industries such as banks and credit.","As supporters and providers of platform network technology and network resources, communication operators are also builders and maintainers of communication networks.","Internet data improves the user's credit evaluation strategy.","This paper uses the massive data provided by communication operators to carry out research on the operator's user credit evaluation model based on the fusion LightGBM algorithm.","First, for the massive data related to user evaluation provided by operators, key features are extracted by data preprocessing and feature engineering methods, and a multi-dimensional feature set with statistical significance is constructed; then, linear regression, decision tree, LightGBM, and other machine learning algorithms build multiple basic models to find the best basic model; finally, integrates Averaging, Voting, Blending, Stacking and other integrated algorithms to refine multiple fusion models, and finally establish the most suitable fusion model for operator user evaluation."],"url":"http://arxiv.org/abs/2403.14483v1"}
{"created":"2024-03-21 15:20:07","title":"The Ethics of ChatGPT in Medicine and Healthcare: A Systematic Review on Large Language Models (LLMs)","abstract":"With the introduction of ChatGPT, Large Language Models (LLMs) have received enormous attention in healthcare. Despite their potential benefits, researchers have underscored various ethical implications. While individual instances have drawn much attention, the debate lacks a systematic overview of practical applications currently researched and ethical issues connected to them. Against this background, this work aims to map the ethical landscape surrounding the current stage of deployment of LLMs in medicine and healthcare. Electronic databases and preprint servers were queried using a comprehensive search strategy. Studies were screened and extracted following a modified rapid review approach. Methodological quality was assessed using a hybrid approach. For 53 records, a meta-aggregative synthesis was performed. Four fields of applications emerged and testify to a vivid exploration phase. Advantages of using LLMs are attributed to their capacity in data analysis, personalized information provisioning, support in decision-making, mitigating information loss and enhancing information accessibility. However, we also identifies recurrent ethical concerns connected to fairness, bias, non-maleficence, transparency, and privacy. A distinctive concern is the tendency to produce harmful misinformation or convincingly but inaccurate content. A recurrent plea for ethical guidance and human oversight is evident. Given the variety of use cases, it is suggested that the ethical guidance debate be reframed to focus on defining what constitutes acceptable human oversight across the spectrum of applications. This involves considering diverse settings, varying potentials for harm, and different acceptable thresholds for performance and certainty in healthcare. In addition, a critical inquiry is necessary to determine the extent to which the current experimental use of LLMs is necessary and justified.","sentences":["With the introduction of ChatGPT, Large Language Models (LLMs) have received enormous attention in healthcare.","Despite their potential benefits, researchers have underscored various ethical implications.","While individual instances have drawn much attention, the debate lacks a systematic overview of practical applications currently researched and ethical issues connected to them.","Against this background, this work aims to map the ethical landscape surrounding the current stage of deployment of LLMs in medicine and healthcare.","Electronic databases and preprint servers were queried using a comprehensive search strategy.","Studies were screened and extracted following a modified rapid review approach.","Methodological quality was assessed using a hybrid approach.","For 53 records, a meta-aggregative synthesis was performed.","Four fields of applications emerged and testify to a vivid exploration phase.","Advantages of using LLMs are attributed to their capacity in data analysis, personalized information provisioning, support in decision-making, mitigating information loss and enhancing information accessibility.","However, we also identifies recurrent ethical concerns connected to fairness, bias, non-maleficence, transparency, and privacy.","A distinctive concern is the tendency to produce harmful misinformation or convincingly but inaccurate content.","A recurrent plea for ethical guidance and human oversight is evident.","Given the variety of use cases, it is suggested that the ethical guidance debate be reframed to focus on defining what constitutes acceptable human oversight across the spectrum of applications.","This involves considering diverse settings, varying potentials for harm, and different acceptable thresholds for performance and certainty in healthcare.","In addition, a critical inquiry is necessary to determine the extent to which the current experimental use of LLMs is necessary and justified."],"url":"http://arxiv.org/abs/2403.14473v1"}
{"created":"2024-03-21 15:13:54","title":"Universal Feature Selection for Simultaneous Interpretability of Multitask Datasets","abstract":"Extracting meaningful features from complex, high-dimensional datasets across scientific domains remains challenging. Current methods often struggle with scalability, limiting their applicability to large datasets, or make restrictive assumptions about feature-property relationships, hindering their ability to capture complex interactions. BoUTS's general and scalable feature selection algorithm surpasses these limitations to identify both universal features relevant to all datasets and task-specific features predictive for specific subsets. Evaluated on seven diverse chemical regression datasets, BoUTS achieves state-of-the-art feature sparsity while maintaining prediction accuracy comparable to specialized methods. Notably, BoUTS's universal features enable domain-specific knowledge transfer between datasets, and suggest deep connections in seemingly-disparate chemical datasets. We expect these results to have important repercussions in manually-guided inverse problems. Beyond its current application, BoUTS holds immense potential for elucidating data-poor systems by leveraging information from similar data-rich systems. BoUTS represents a significant leap in cross-domain feature selection, potentially leading to advancements in various scientific fields.","sentences":["Extracting meaningful features from complex, high-dimensional datasets across scientific domains remains challenging.","Current methods often struggle with scalability, limiting their applicability to large datasets, or make restrictive assumptions about feature-property relationships, hindering their ability to capture complex interactions.","BoUTS's general and scalable feature selection algorithm surpasses these limitations to identify both universal features relevant to all datasets and task-specific features predictive for specific subsets.","Evaluated on seven diverse chemical regression datasets, BoUTS achieves state-of-the-art feature sparsity while maintaining prediction accuracy comparable to specialized methods.","Notably, BoUTS's universal features enable domain-specific knowledge transfer between datasets, and suggest deep connections in seemingly-disparate chemical datasets.","We expect these results to have important repercussions in manually-guided inverse problems.","Beyond its current application, BoUTS holds immense potential for elucidating data-poor systems by leveraging information from similar data-rich systems.","BoUTS represents a significant leap in cross-domain feature selection, potentially leading to advancements in various scientific fields."],"url":"http://arxiv.org/abs/2403.14466v1"}
{"created":"2024-03-21 14:53:50","title":"Exploring 3D Human Pose Estimation and Forecasting from the Robot's Perspective: The HARPER Dataset","abstract":"We introduce HARPER, a novel dataset for 3D body pose estimation and forecast in dyadic interactions between users and \\spot, the quadruped robot manufactured by Boston Dynamics. The key-novelty is the focus on the robot's perspective, i.e., on the data captured by the robot's sensors. These make 3D body pose analysis challenging because being close to the ground captures humans only partially. The scenario underlying HARPER includes 15 actions, of which 10 involve physical contact between the robot and users. The Corpus contains not only the recordings of the built-in stereo cameras of Spot, but also those of a 6-camera OptiTrack system (all recordings are synchronized). This leads to ground-truth skeletal representations with a precision lower than a millimeter. In addition, the Corpus includes reproducible benchmarks on 3D Human Pose Estimation, Human Pose Forecasting, and Collision Prediction, all based on publicly available baseline approaches. This enables future HARPER users to rigorously compare their results with those we provide in this work.","sentences":["We introduce HARPER, a novel dataset for 3D body pose estimation and forecast in dyadic interactions between users and \\spot, the quadruped robot manufactured by Boston Dynamics.","The key-novelty is the focus on the robot's perspective, i.e., on the data captured by the robot's sensors.","These make 3D body pose analysis challenging because being close to the ground captures humans only partially.","The scenario underlying HARPER includes 15 actions, of which 10 involve physical contact between the robot and users.","The Corpus contains not only the recordings of the built-in stereo cameras of Spot, but also those of a 6-camera OptiTrack system (all recordings are synchronized).","This leads to ground-truth skeletal representations with a precision lower than a millimeter.","In addition, the Corpus includes reproducible benchmarks on 3D Human Pose Estimation, Human Pose Forecasting, and Collision Prediction, all based on publicly available baseline approaches.","This enables future HARPER users to rigorously compare their results with those we provide in this work."],"url":"http://arxiv.org/abs/2403.14447v1"}
{"created":"2024-03-21 14:52:03","title":"History-Independent Concurrent Objects","abstract":"A data structure is called history independent if its internal memory representation does not reveal the history of operations applied to it, only its current state. In this paper we study history independence for concurrent data structures, and establish foundational possibility and impossibility results. We show that a large class of concurrent objects cannot be implemented from smaller base objects in a manner that is both wait-free and history independent; but if we settle for either lock-freedom instead of wait-freedom or for a weak notion of history independence, then at least one object in the class, multi-valued single-reader single-writer registers, can be implemented from smaller base objects, binary registers.   On the other hand, using large base objects, we give a strong possibility result in the form of a universal construction: an object with $s$ possible states can be implemented in a wait-free, history-independent manner from compare-and-swap base objects that each have $O(s + 2^n)$ possible memory states, where $n$ is the number of processes in the system.","sentences":["A data structure is called history independent if its internal memory representation does not reveal the history of operations applied to it, only its current state.","In this paper we study history independence for concurrent data structures, and establish foundational possibility and impossibility results.","We show that a large class of concurrent objects cannot be implemented from smaller base objects in a manner that is both wait-free and history independent; but if we settle for either lock-freedom instead of wait-freedom or for a weak notion of history independence, then at least one object in the class, multi-valued single-reader single-writer registers, can be implemented from smaller base objects, binary registers.   ","On the other hand, using large base objects, we give a strong possibility result in the form of a universal construction: an object with $s$ possible states can be implemented in a wait-free, history-independent manner from compare-and-swap base objects that each have $O(s + 2^n)$ possible memory states, where $n$ is the number of processes in the system."],"url":"http://arxiv.org/abs/2403.14445v1"}
{"created":"2024-03-21 14:45:41","title":"Raw Instinct: Trust Your Classifiers and Skip the Conversion","abstract":"Using RAW-images in computer vision problems is surprisingly underexplored considering that converting from RAW to RGB does not introduce any new capture information. In this paper, we show that a sufficiently advanced classifier can yield equivalent results on RAW input compared to RGB and present a new public dataset consisting of RAW images and the corresponding converted RGB images. Classifying images directly from RAW is attractive, as it allows for skipping the conversion to RGB, lowering computation time significantly. Two CNN classifiers are used to classify the images in both formats, confirming that classification performance can indeed be preserved. We furthermore show that the total computation time from RAW image data to classification results for RAW images can be up to 8.46 times faster than RGB. These results contribute to the evidence found in related works, that using RAW images as direct input to computer vision algorithms looks very promising.","sentences":["Using RAW-images in computer vision problems is surprisingly underexplored considering that converting from RAW to RGB does not introduce any new capture information.","In this paper, we show that a sufficiently advanced classifier can yield equivalent results on RAW input compared to RGB and present a new public dataset consisting of RAW images and the corresponding converted RGB images.","Classifying images directly from RAW is attractive, as it allows for skipping the conversion to RGB, lowering computation time significantly.","Two CNN classifiers are used to classify the images in both formats, confirming that classification performance can indeed be preserved.","We furthermore show that the total computation time from RAW image data to classification results for RAW images can be up to 8.46 times faster than RGB.","These results contribute to the evidence found in related works, that using RAW images as direct input to computer vision algorithms looks very promising."],"url":"http://arxiv.org/abs/2403.14439v1"}
{"created":"2024-03-21 14:41:58","title":"Biased Binary Attribute Classifiers Ignore the Majority Classes","abstract":"To visualize the regions of interest that classifiers base their decisions on, different Class Activation Mapping (CAM) methods have been developed. However, all of these techniques target categorical classifiers only, though most real-world tasks are binary classification. In this paper, we extend gradient-based CAM techniques to work with binary classifiers and visualize the active regions for binary facial attribute classifiers. When training an unbalanced binary classifier on an imbalanced dataset, it is well-known that the majority class, i.e. the class with many training samples, is mostly predicted much better than minority class with few training instances. In our experiments on the CelebA dataset, we verify these results, when training an unbalanced classifier to extract 40 facial attributes simultaneously. One would expect that the biased classifier has learned to extract features mainly for the majority classes and that the proportional energy of the activations mainly reside in certain specific regions of the image where the attribute is located. However, we find very little regular activation for samples of majority classes, while the active regions for minority classes seem mostly reasonable and overlap with our expectations. These results suggest that biased classifiers mainly rely on bias activation for majority classes. When training a balanced classifier on the imbalanced data by employing attribute-specific class weights, majority and minority classes are classified similarly well and show expected activations for almost all attributes","sentences":["To visualize the regions of interest that classifiers base their decisions on, different Class Activation Mapping (CAM) methods have been developed.","However, all of these techniques target categorical classifiers only, though most real-world tasks are binary classification.","In this paper, we extend gradient-based CAM techniques to work with binary classifiers and visualize the active regions for binary facial attribute classifiers.","When training an unbalanced binary classifier on an imbalanced dataset, it is well-known that the majority class, i.e. the class with many training samples, is mostly predicted much better than minority class with few training instances.","In our experiments on the CelebA dataset, we verify these results, when training an unbalanced classifier to extract 40 facial attributes simultaneously.","One would expect that the biased classifier has learned to extract features mainly for the majority classes and that the proportional energy of the activations mainly reside in certain specific regions of the image where the attribute is located.","However, we find very little regular activation for samples of majority classes, while the active regions for minority classes seem mostly reasonable and overlap with our expectations.","These results suggest that biased classifiers mainly rely on bias activation for majority classes.","When training a balanced classifier on the imbalanced data by employing attribute-specific class weights, majority and minority classes are classified similarly well and show expected activations for almost all attributes"],"url":"http://arxiv.org/abs/2403.14435v1"}
{"created":"2024-03-21 14:36:59","title":"Style-Extracting Diffusion Models for Semi-Supervised Histopathology Segmentation","abstract":"Deep learning-based image generation has seen significant advancements with diffusion models, notably improving the quality of generated images. Despite these developments, generating images with unseen characteristics beneficial for downstream tasks has received limited attention. To bridge this gap, we propose Style-Extracting Diffusion Models, featuring two conditioning mechanisms. Specifically, we utilize 1) a style conditioning mechanism which allows to inject style information of previously unseen images during image generation and 2) a content conditioning which can be targeted to a downstream task, e.g., layout for segmentation. We introduce a trainable style encoder to extract style information from images, and an aggregation block that merges style information from multiple style inputs. This architecture enables the generation of images with unseen styles in a zero-shot manner, by leveraging styles from unseen images, resulting in more diverse generations. In this work, we use the image layout as target condition and first show the capability of our method on a natural image dataset as a proof-of-concept. We further demonstrate its versatility in histopathology, where we combine prior knowledge about tissue composition and unannotated data to create diverse synthetic images with known layouts. This allows us to generate additional synthetic data to train a segmentation network in a semi-supervised fashion. We verify the added value of the generated images by showing improved segmentation results and lower performance variability between patients when synthetic images are included during segmentation training. Our code will be made publicly available at [LINK].","sentences":["Deep learning-based image generation has seen significant advancements with diffusion models, notably improving the quality of generated images.","Despite these developments, generating images with unseen characteristics beneficial for downstream tasks has received limited attention.","To bridge this gap, we propose Style-Extracting Diffusion Models, featuring two conditioning mechanisms.","Specifically, we utilize 1) a style conditioning mechanism which allows to inject style information of previously unseen images during image generation and 2) a content conditioning which can be targeted to a downstream task, e.g., layout for segmentation.","We introduce a trainable style encoder to extract style information from images, and an aggregation block that merges style information from multiple style inputs.","This architecture enables the generation of images with unseen styles in a zero-shot manner, by leveraging styles from unseen images, resulting in more diverse generations.","In this work, we use the image layout as target condition and first show the capability of our method on a natural image dataset as a proof-of-concept.","We further demonstrate its versatility in histopathology, where we combine prior knowledge about tissue composition and unannotated data to create diverse synthetic images with known layouts.","This allows us to generate additional synthetic data to train a segmentation network in a semi-supervised fashion.","We verify the added value of the generated images by showing improved segmentation results and lower performance variability between patients when synthetic images are included during segmentation training.","Our code will be made publicly available at [LINK]."],"url":"http://arxiv.org/abs/2403.14429v1"}
{"created":"2024-03-21 14:36:55","title":"FHAUC: Privacy Preserving AUC Calculation for Federated Learning using Fully Homomorphic Encryption","abstract":"Ensuring data privacy is a significant challenge for machine learning applications, not only during model training but also during evaluation. Federated learning has gained significant research interest in recent years as a result. Current research on federated learning primarily focuses on preserving privacy during the training phase. However, model evaluation has not been adequately addressed, despite the potential for significant privacy leaks during this phase as well. In this paper, we demonstrate that the state-of-the-art AUC computation method for federated learning systems, which utilizes differential privacy, still leaks sensitive information about the test data while also requiring a trusted central entity to perform the computations. More importantly, we show that the performance of this method becomes completely unusable as the data size decreases. In this context, we propose an efficient, accurate, robust, and more secure evaluation algorithm capable of computing the AUC in horizontal federated learning systems. Our approach not only enhances security compared to the current state-of-the-art but also surpasses the state-of-the-art AUC computation method in both approximation performance and computational robustness, as demonstrated by experimental results. To illustrate, our approach can efficiently calculate the AUC of a federated learning system involving 100 parties, achieving 99.93% accuracy in just 0.68 seconds, regardless of data size, while providing complete data privacy.","sentences":["Ensuring data privacy is a significant challenge for machine learning applications, not only during model training but also during evaluation.","Federated learning has gained significant research interest in recent years as a result.","Current research on federated learning primarily focuses on preserving privacy during the training phase.","However, model evaluation has not been adequately addressed, despite the potential for significant privacy leaks during this phase as well.","In this paper, we demonstrate that the state-of-the-art AUC computation method for federated learning systems, which utilizes differential privacy, still leaks sensitive information about the test data while also requiring a trusted central entity to perform the computations.","More importantly, we show that the performance of this method becomes completely unusable as the data size decreases.","In this context, we propose an efficient, accurate, robust, and more secure evaluation algorithm capable of computing the AUC in horizontal federated learning systems.","Our approach not only enhances security compared to the current state-of-the-art but also surpasses the state-of-the-art AUC computation method in both approximation performance and computational robustness, as demonstrated by experimental results.","To illustrate, our approach can efficiently calculate the AUC of a federated learning system involving 100 parties, achieving 99.93% accuracy in just 0.68 seconds, regardless of data size, while providing complete data privacy."],"url":"http://arxiv.org/abs/2403.14428v1"}
{"created":"2024-03-21 14:28:43","title":"Task-optimal data-driven surrogate models for eNMPC via differentiable simulation and optimization","abstract":"We present a method for end-to-end learning of Koopman surrogate models for optimal performance in control. In contrast to previous contributions that employ standard reinforcement learning (RL) algorithms, we use a training algorithm that exploits the potential differentiability of environments based on mechanistic simulation models. We evaluate the performance of our method by comparing it to that of other controller type and training algorithm combinations on a literature known eNMPC case study. Our method exhibits superior performance on this problem, thereby constituting a promising avenue towards more capable controllers that employ dynamic surrogate models.","sentences":["We present a method for end-to-end learning of Koopman surrogate models for optimal performance in control.","In contrast to previous contributions that employ standard reinforcement learning (RL) algorithms, we use a training algorithm that exploits the potential differentiability of environments based on mechanistic simulation models.","We evaluate the performance of our method by comparing it to that of other controller type and training algorithm combinations on a literature known eNMPC case study.","Our method exhibits superior performance on this problem, thereby constituting a promising avenue towards more capable controllers that employ dynamic surrogate models."],"url":"http://arxiv.org/abs/2403.14425v1"}
{"created":"2024-03-21 14:17:28","title":"DP-RDM: Adapting Diffusion Models to Private Domains Without Fine-Tuning","abstract":"Text-to-image diffusion models have been shown to suffer from sample-level memorization, possibly reproducing near-perfect replica of images that they are trained on, which may be undesirable. To remedy this issue, we develop the first differentially private (DP) retrieval-augmented generation algorithm that is capable of generating high-quality image samples while providing provable privacy guarantees. Specifically, we assume access to a text-to-image diffusion model trained on a small amount of public data, and design a DP retrieval mechanism to augment the text prompt with samples retrieved from a private retrieval dataset. Our \\emph{differentially private retrieval-augmented diffusion model} (DP-RDM) requires no fine-tuning on the retrieval dataset to adapt to another domain, and can use state-of-the-art generative models to generate high-quality image samples while satisfying rigorous DP guarantees. For instance, when evaluated on MS-COCO, our DP-RDM can generate samples with a privacy budget of $\\epsilon=10$, while providing a $3.5$ point improvement in FID compared to public-only retrieval for up to $10,000$ queries.","sentences":["Text-to-image diffusion models have been shown to suffer from sample-level memorization, possibly reproducing near-perfect replica of images that they are trained on, which may be undesirable.","To remedy this issue, we develop the first differentially private (DP) retrieval-augmented generation algorithm that is capable of generating high-quality image samples while providing provable privacy guarantees.","Specifically, we assume access to a text-to-image diffusion model trained on a small amount of public data, and design a DP retrieval mechanism to augment the text prompt with samples retrieved from a private retrieval dataset.","Our \\emph{differentially private retrieval-augmented diffusion model} (DP-RDM) requires no fine-tuning on the retrieval dataset to adapt to another domain, and can use state-of-the-art generative models to generate high-quality image samples while satisfying rigorous DP guarantees.","For instance, when evaluated on MS-COCO, our DP-RDM can generate samples with a privacy budget of $\\epsilon=10$, while providing a $3.5$ point improvement in FID compared to public-only retrieval for up to $10,000$ queries."],"url":"http://arxiv.org/abs/2403.14421v1"}
{"created":"2024-03-21 14:02:04","title":"Random Graph Modeling: A survey of the concepts","abstract":"Random graph (RG) models play a central role in the complex networks analysis. They help to understand, control, and predict phenomena occurring, for instance, in social networks, biological networks, the Internet, etc.   Despite a large number of RG models presented in the literature, there are few concepts underlying them. Instead of trying to classify a wide variety of very dispersed models, we capture and describe concepts they exploit considering preferential attachment, copying principle, hyperbolic geometry, recursively defined structure, edge switching, Monte Carlo sampling, etc. We analyze RG models, extract their basic principles, and build a taxonomy of concepts they are based on. We also discuss how these concepts are combined in RG models and how they work in typical applications like benchmarks, null models, and data anonymization.","sentences":["Random graph (RG) models play a central role in the complex networks analysis.","They help to understand, control, and predict phenomena occurring, for instance, in social networks, biological networks, the Internet, etc.   ","Despite a large number of RG models presented in the literature, there are few concepts underlying them.","Instead of trying to classify a wide variety of very dispersed models, we capture and describe concepts they exploit considering preferential attachment, copying principle, hyperbolic geometry, recursively defined structure, edge switching, Monte Carlo sampling, etc.","We analyze RG models, extract their basic principles, and build a taxonomy of concepts they are based on.","We also discuss how these concepts are combined in RG models and how they work in typical applications like benchmarks, null models, and data anonymization."],"url":"http://arxiv.org/abs/2403.14415v1"}
{"created":"2024-03-21 13:59:32","title":"Efficient Model Learning and Adaptive Tracking Control of Magnetic Micro-Robots for Non-Contact Manipulation","abstract":"Magnetic microrobots can be navigated by an external magnetic field to autonomously move within living organisms with complex and unstructured environments. Potential applications include drug delivery, diagnostics, and therapeutic interventions. Existing techniques commonly impart magnetic properties to the target object,or drive the robot to contact and then manipulate the object, both probably inducing physical damage. This paper considers a non-contact formulation, where the robot spins to generate a repulsive field to push the object without physical contact. Under such a formulation, the main challenge is that the motion model between the input of the magnetic field and the output velocity of the target object is commonly unknown and difficult to analyze. To deal with it, this paper proposes a data-driven-based solution. A neural network is constructed to efficiently estimate the motion model. Then, an approximate model-based optimal control scheme is developed to push the object to track a time-varying trajectory, maintaining the non-contact with distance constraints. Furthermore, a straightforward planner is introduced to assess the adaptability of non-contact manipulation in a cluttered unstructured environment. Experimental results are presented to show the tracking and navigation performance of the proposed scheme.","sentences":["Magnetic microrobots can be navigated by an external magnetic field to autonomously move within living organisms with complex and unstructured environments.","Potential applications include drug delivery, diagnostics, and therapeutic interventions.","Existing techniques commonly impart magnetic properties to the target object,or drive the robot to contact and then manipulate the object, both probably inducing physical damage.","This paper considers a non-contact formulation, where the robot spins to generate a repulsive field to push the object without physical contact.","Under such a formulation, the main challenge is that the motion model between the input of the magnetic field and the output velocity of the target object is commonly unknown and difficult to analyze.","To deal with it, this paper proposes a data-driven-based solution.","A neural network is constructed to efficiently estimate the motion model.","Then, an approximate model-based optimal control scheme is developed to push the object to track a time-varying trajectory, maintaining the non-contact with distance constraints.","Furthermore, a straightforward planner is introduced to assess the adaptability of non-contact manipulation in a cluttered unstructured environment.","Experimental results are presented to show the tracking and navigation performance of the proposed scheme."],"url":"http://arxiv.org/abs/2403.14414v1"}
{"created":"2024-03-21 13:57:45","title":"GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning","abstract":"Deep neural networks often exhibit sub-optimal performance under covariate and category shifts. Source-Free Domain Adaptation (SFDA) presents a promising solution to this dilemma, yet most SFDA approaches are restricted to closed-set scenarios. In this paper, we explore Source-Free Universal Domain Adaptation (SF-UniDA) aiming to accurately classify \"known\" data belonging to common categories and segregate them from target-private \"unknown\" data. We propose a novel Global and Local Clustering (GLC) technique, which comprises an adaptive one-vs-all global clustering algorithm to discern between target classes, complemented by a local k-NN clustering strategy to mitigate negative transfer. Despite the effectiveness, the inherent closed-set source architecture leads to uniform treatment of \"unknown\" data, impeding the identification of distinct \"unknown\" categories. To address this, we evolve GLC to GLC++, integrating a contrastive affinity learning strategy. We examine the superiority of GLC and GLC++ across multiple benchmarks and category shift scenarios. Remarkably, in the most challenging open-partial-set scenarios, GLC and GLC++ surpass GATE by 16.7% and 18.6% in H-score on VisDA, respectively. GLC++ enhances the novel category clustering accuracy of GLC by 4.3% in open-set scenarios on Office-Home. Furthermore, the introduced contrastive learning strategy not only enhances GLC but also significantly facilitates existing methodologies.","sentences":["Deep neural networks often exhibit sub-optimal performance under covariate and category shifts.","Source-Free Domain Adaptation (SFDA) presents a promising solution to this dilemma, yet most SFDA approaches are restricted to closed-set scenarios.","In this paper, we explore Source-Free Universal Domain Adaptation (SF-UniDA) aiming to accurately classify \"known\" data belonging to common categories and segregate them from target-private \"unknown\" data.","We propose a novel Global and Local Clustering (GLC) technique, which comprises an adaptive one-vs-all global clustering algorithm to discern between target classes, complemented by a local k-NN clustering strategy to mitigate negative transfer.","Despite the effectiveness, the inherent closed-set source architecture leads to uniform treatment of \"unknown\" data, impeding the identification of distinct \"unknown\" categories.","To address this, we evolve GLC to GLC++, integrating a contrastive affinity learning strategy.","We examine the superiority of GLC and GLC++ across multiple benchmarks and category shift scenarios.","Remarkably, in the most challenging open-partial-set scenarios, GLC and GLC++ surpass GATE by 16.7% and 18.6% in H-score on VisDA, respectively.","GLC++ enhances the novel category clustering accuracy of GLC by 4.3% in open-set scenarios on Office-Home.","Furthermore, the introduced contrastive learning strategy not only enhances GLC but also significantly facilitates existing methodologies."],"url":"http://arxiv.org/abs/2403.14410v1"}
{"created":"2024-03-21 13:52:55","title":"Physics-Informed Diffusion Models","abstract":"Generative models such as denoising diffusion models are quickly advancing their ability to approximate highly complex data distributions. They are also increasingly leveraged in scientific machine learning, where samples from the implied data distribution are expected to adhere to specific governing equations. We present a framework to inform denoising diffusion models on underlying constraints on such generated samples during model training. Our approach improves the alignment of the generated samples with the imposed constraints and significantly outperforms existing methods without affecting inference speed. Additionally, our findings suggest that incorporating such constraints during training provides a natural regularization against overfitting. Our framework is easy to implement and versatile in its applicability for imposing equality and inequality constraints as well as auxiliary optimization objectives.","sentences":["Generative models such as denoising diffusion models are quickly advancing their ability to approximate highly complex data distributions.","They are also increasingly leveraged in scientific machine learning, where samples from the implied data distribution are expected to adhere to specific governing equations.","We present a framework to inform denoising diffusion models on underlying constraints on such generated samples during model training.","Our approach improves the alignment of the generated samples with the imposed constraints and significantly outperforms existing methods without affecting inference speed.","Additionally, our findings suggest that incorporating such constraints during training provides a natural regularization against overfitting.","Our framework is easy to implement and versatile in its applicability for imposing equality and inequality constraints as well as auxiliary optimization objectives."],"url":"http://arxiv.org/abs/2403.14404v1"}
{"created":"2024-03-21 13:52:17","title":"XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception","abstract":"Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments. Augmenting these systems with visual signals has the potential to improve robustness to noise. However, audio-visual (AV) data is only available in limited amounts and for fewer languages than audio-only resources. To address this gap, we present XLAVS-R, a cross-lingual audio-visual speech representation model for noise-robust speech recognition and translation in over 100 languages. It is designed to maximize the benefits of limited multilingual AV pre-training data, by building on top of audio-only multilingual pre-training and simplifying existing pre-training schemes. Extensive evaluation on the MuAViC benchmark shows the strength of XLAVS-R on downstream audio-visual speech recognition and translation tasks, where it outperforms the previous state of the art by up to 18.5% WER and 4.7 BLEU given noisy AV inputs, and enables strong zero-shot audio-visual ability with audio-only fine-tuning.","sentences":["Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments.","Augmenting these systems with visual signals has the potential to improve robustness to noise.","However, audio-visual (AV) data is only available in limited amounts and for fewer languages than audio-only resources.","To address this gap, we present XLAVS-R, a cross-lingual audio-visual speech representation model for noise-robust speech recognition and translation in over 100 languages.","It is designed to maximize the benefits of limited multilingual AV pre-training data, by building on top of audio-only multilingual pre-training and simplifying existing pre-training schemes.","Extensive evaluation on the MuAViC benchmark shows the strength of XLAVS-R on downstream audio-visual speech recognition and translation tasks, where it outperforms the previous state of the art by up to 18.5% WER and 4.7 BLEU given noisy AV inputs, and enables strong zero-shot audio-visual ability with audio-only fine-tuning."],"url":"http://arxiv.org/abs/2403.14402v1"}
{"created":"2024-03-21 13:29:54","title":"From Large to Tiny: Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision","abstract":"Addressing the challenge of high annotation costs in solving Math Word Problems (MWPs) through full supervision with intermediate equations, recent works have proposed weakly supervised task settings that rely solely on the final answer as a supervised signal. Existing leading approaches typically employ various search techniques to infer intermediate equations, but cannot ensure their semantic consistency with natural language descriptions. The rise of Large Language Models (LLMs) like ChatGPT has opened up new possibilities for addressing MWPs directly. However, the computational demands of LLMs make them less than ideal for use in settings where resources are tight. In light of these challenges, we introduce an innovative two-stage framework that adeptly transfers mathematical Expertise from large to tiny language models. In \\emph{Distillation Stage}, we propose a series of extraction processes that satisfy the properties of MWPs to distill mathematical knowledge from LLMs to construct problem-equation pairs required for supervised training. In \\emph{Refinement Stage}, Due to Knowledge distilling method cannot guarantee the full utilization of all data, we further utilize the unsuccessfully searched data effectively by Knowledge Refine method. Finally, We train a small model using distilled data generated through two-stage methods. As our method fully leverages the semantic understanding capabilities during the searching 'problem-equation' pair, it demonstrates significantly improved performance on the Math23K and Weak12K datasets compared to existing small model methods, while maintaining a much lower computational cost than ChatGPT.","sentences":["Addressing the challenge of high annotation costs in solving Math Word Problems (MWPs) through full supervision with intermediate equations, recent works have proposed weakly supervised task settings that rely solely on the final answer as a supervised signal.","Existing leading approaches typically employ various search techniques to infer intermediate equations, but cannot ensure their semantic consistency with natural language descriptions.","The rise of Large Language Models (LLMs) like ChatGPT has opened up new possibilities for addressing MWPs directly.","However, the computational demands of LLMs make them less than ideal for use in settings where resources are tight.","In light of these challenges, we introduce an innovative two-stage framework that adeptly transfers mathematical Expertise from large to tiny language models.","In \\emph{Distillation Stage}, we propose a series of extraction processes that satisfy the properties of MWPs to distill mathematical knowledge from LLMs to construct problem-equation pairs required for supervised training.","In \\emph{Refinement Stage}, Due to Knowledge distilling method cannot guarantee the full utilization of all data, we further utilize the unsuccessfully searched data effectively by Knowledge Refine method.","Finally, We train a small model using distilled data generated through two-stage methods.","As our method fully leverages the semantic understanding capabilities during the searching 'problem-equation' pair, it demonstrates significantly improved performance on the Math23K and Weak12K datasets compared to existing small model methods, while maintaining a much lower computational cost than ChatGPT."],"url":"http://arxiv.org/abs/2403.14390v1"}
{"created":"2024-03-21 13:09:23","title":"Knowledge-Enhanced Recommendation with User-Centric Subgraph Network","abstract":"Recommendation systems, as widely implemented nowadays on various platforms, recommend relevant items to users based on their preferences. The classical methods which rely on user-item interaction matrices has limitations, especially in scenarios where there is a lack of interaction data for new items. Knowledge graph (KG)-based recommendation systems have emerged as a promising solution. However, most KG-based methods adopt node embeddings, which do not provide personalized recommendations for different users and cannot generalize well to the new items. To address these limitations, we propose Knowledge-enhanced User-Centric subgraph Network (KUCNet), a subgraph learning approach with graph neural network (GNN) for effective recommendation. KUCNet constructs a U-I subgraph for each user-item pair that captures both the historical information of user-item interactions and the side information provided in KG. An attention-based GNN is designed to encode the U-I subgraphs for recommendation. Considering efficiency, the pruned user-centric computation graph is further introduced such that multiple U-I subgraphs can be simultaneously computed and that the size can be pruned by Personalized PageRank. Our proposed method achieves accurate, efficient, and interpretable recommendations especially for new items. Experimental results demonstrate the superiority of KUCNet over state-of-the-art KG-based and collaborative filtering (CF)-based methods.","sentences":["Recommendation systems, as widely implemented nowadays on various platforms, recommend relevant items to users based on their preferences.","The classical methods which rely on user-item interaction matrices has limitations, especially in scenarios where there is a lack of interaction data for new items.","Knowledge graph (KG)-based recommendation systems have emerged as a promising solution.","However, most KG-based methods adopt node embeddings, which do not provide personalized recommendations for different users and cannot generalize well to the new items.","To address these limitations, we propose Knowledge-enhanced User-Centric subgraph Network (KUCNet), a subgraph learning approach with graph neural network (GNN) for effective recommendation.","KUCNet constructs a U-I subgraph for each user-item pair that captures both the historical information of user-item interactions and the side information provided in KG.","An attention-based GNN is designed to encode the U-I subgraphs for recommendation.","Considering efficiency, the pruned user-centric computation graph is further introduced such that multiple U-I subgraphs can be simultaneously computed and that the size can be pruned by Personalized PageRank.","Our proposed method achieves accurate, efficient, and interpretable recommendations especially for new items.","Experimental results demonstrate the superiority of KUCNet over state-of-the-art KG-based and collaborative filtering (CF)-based methods."],"url":"http://arxiv.org/abs/2403.14377v1"}
{"created":"2024-03-21 13:06:57","title":"InfNeRF: Towards Infinite Scale NeRF Rendering with O(log n) Space Complexity","abstract":"The conventional mesh-based Level of Detail (LoD) technique, exemplified by applications such as Google Earth and many game engines, exhibits the capability to holistically represent a large scene even the Earth, and achieves rendering with a space complexity of O(log n). This constrained data requirement not only enhances rendering efficiency but also facilitates dynamic data fetching, thereby enabling a seamless 3D navigation experience for users. In this work, we extend this proven LoD technique to Neural Radiance Fields (NeRF) by introducing an octree structure to represent the scenes in different scales. This innovative approach provides a mathematically simple and elegant representation with a rendering space complexity of O(log n), aligned with the efficiency of mesh-based LoD techniques. We also present a novel training strategy that maintains a complexity of O(n). This strategy allows for parallel training with minimal overhead, ensuring the scalability and efficiency of our proposed method. Our contribution is not only in extending the capabilities of existing techniques but also in establishing a foundation for scalable and efficient large-scale scene representation using NeRF and octree structures.","sentences":["The conventional mesh-based Level of Detail (LoD) technique, exemplified by applications such as Google Earth and many game engines, exhibits the capability to holistically represent a large scene even the Earth, and achieves rendering with a space complexity of O(log n).","This constrained data requirement not only enhances rendering efficiency but also facilitates dynamic data fetching, thereby enabling a seamless 3D navigation experience for users.","In this work, we extend this proven LoD technique to Neural Radiance Fields (NeRF) by introducing an octree structure to represent the scenes in different scales.","This innovative approach provides a mathematically simple and elegant representation with a rendering space complexity of O(log n), aligned with the efficiency of mesh-based LoD techniques.","We also present a novel training strategy that maintains a complexity of O(n).","This strategy allows for parallel training with minimal overhead, ensuring the scalability and efficiency of our proposed method.","Our contribution is not only in extending the capabilities of existing techniques but also in establishing a foundation for scalable and efficient large-scale scene representation using NeRF and octree structures."],"url":"http://arxiv.org/abs/2403.14376v1"}
{"created":"2024-03-21 12:59:24","title":"Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server","abstract":"In federated learning, data heterogeneity significantly impacts performance. A typical solution involves segregating these parameters into shared and personalized components, a concept also relevant in multi-task learning. Addressing this, we propose \"Loop Improvement\" (LI), a novel method enhancing this separation and feature extraction without necessitating a central server or data interchange among participants. Our experiments reveal LI's superiority in several aspects: In personalized federated learning environments, LI consistently outperforms the advanced FedALA algorithm in accuracy across diverse scenarios. Additionally, LI's feature extractor closely matches the performance achieved when aggregating data from all clients. In global model contexts, employing LI with stacked personalized layers and an additional network also yields comparable results to combined client data scenarios. Furthermore, LI's adaptability extends to multi-task learning, streamlining the extraction of common features across tasks and obviating the need for simultaneous training. This approach not only enhances individual task performance but also achieves accuracy levels on par with classic multi-task learning methods where all tasks are trained simultaneously. LI integrates a loop topology with layer-wise and end-to-end training, compatible with various neural network models. This paper also delves into the theoretical underpinnings of LI's effectiveness, offering insights into its potential applications. The code is on https://github.com/axedge1983/LI","sentences":["In federated learning, data heterogeneity significantly impacts performance.","A typical solution involves segregating these parameters into shared and personalized components, a concept also relevant in multi-task learning.","Addressing this, we propose \"Loop Improvement\" (LI), a novel method enhancing this separation and feature extraction without necessitating a central server or data interchange among participants.","Our experiments reveal LI's superiority in several aspects: In personalized federated learning environments, LI consistently outperforms the advanced FedALA algorithm in accuracy across diverse scenarios.","Additionally, LI's feature extractor closely matches the performance achieved when aggregating data from all clients.","In global model contexts, employing LI with stacked personalized layers and an additional network also yields comparable results to combined client data scenarios.","Furthermore, LI's adaptability extends to multi-task learning, streamlining the extraction of common features across tasks and obviating the need for simultaneous training.","This approach not only enhances individual task performance but also achieves accuracy levels on par with classic multi-task learning methods where all tasks are trained simultaneously.","LI integrates a loop topology with layer-wise and end-to-end training, compatible with various neural network models.","This paper also delves into the theoretical underpinnings of LI's effectiveness, offering insights into its potential applications.","The code is on https://github.com/axedge1983/LI"],"url":"http://arxiv.org/abs/2403.14371v1"}
{"created":"2024-03-21 12:45:01","title":"Less but Better: Enabling Generalized Zero-shot Learning Towards Unseen Domains by Intrinsic Learning from Redundant LLM Semantics","abstract":"Generalized zero-shot learning (GZSL) focuses on recognizing seen and unseen classes against domain shift problem (DSP) where data of unseen classes may be misclassified as seen classes. However, existing GZSL is still limited to seen domains. In the current work, we pioneer cross-domain GZSL (CDGZSL) which addresses GZSL towards unseen domains. Different from existing GZSL methods which alleviate DSP by generating features of unseen classes with semantics, CDGZSL needs to construct a common feature space across domains and acquire the corresponding intrinsic semantics shared among domains to transfer from seen to unseen domains. Considering the information asymmetry problem caused by redundant class semantics annotated with large language models (LLMs), we present Meta Domain Alignment Semantic Refinement (MDASR). Technically, MDASR consists of two parts: Inter-class Similarity Alignment (ISA), which eliminates the non-intrinsic semantics not shared across all domains under the guidance of inter-class feature relationships, and Unseen-class Meta Generation (UMG), which preserves intrinsic semantics to maintain connectivity between seen and unseen classes by simulating feature generation. MDASR effectively aligns the redundant semantic space with the common feature space, mitigating the information asymmetry in CDGZSL. The effectiveness of MDASR is demonstrated on the Office-Home and Mini-DomainNet, and we have shared the LLM-based semantics for these datasets as the benchmark.","sentences":["Generalized zero-shot learning (GZSL) focuses on recognizing seen and unseen classes against domain shift problem (DSP) where data of unseen classes may be misclassified as seen classes.","However, existing GZSL is still limited to seen domains.","In the current work, we pioneer cross-domain GZSL (CDGZSL) which addresses GZSL towards unseen domains.","Different from existing GZSL methods which alleviate DSP by generating features of unseen classes with semantics, CDGZSL needs to construct a common feature space across domains and acquire the corresponding intrinsic semantics shared among domains to transfer from seen to unseen domains.","Considering the information asymmetry problem caused by redundant class semantics annotated with large language models (LLMs), we present Meta Domain Alignment Semantic Refinement (MDASR).","Technically, MDASR consists of two parts: Inter-class Similarity Alignment (ISA), which eliminates the non-intrinsic semantics not shared across all domains under the guidance of inter-class feature relationships, and Unseen-class Meta Generation (UMG), which preserves intrinsic semantics to maintain connectivity between seen and unseen classes by simulating feature generation.","MDASR effectively aligns the redundant semantic space with the common feature space, mitigating the information asymmetry in CDGZSL.","The effectiveness of MDASR is demonstrated on the Office-Home and Mini-DomainNet, and we have shared the LLM-based semantics for these datasets as the benchmark."],"url":"http://arxiv.org/abs/2403.14362v1"}
{"created":"2024-03-21 12:35:46","title":"DomainLab: A modular Python package for domain generalization in deep learning","abstract":"Poor generalization performance caused by distribution shifts in unseen domains often hinders the trustworthy deployment of deep neural networks. Many domain generalization techniques address this problem by adding a domain invariant regularization loss terms during training. However, there is a lack of modular software that allows users to combine the advantages of different methods with minimal effort for reproducibility. DomainLab is a modular Python package for training user specified neural networks with composable regularization loss terms. Its decoupled design allows the separation of neural networks from regularization loss construction. Hierarchical combinations of neural networks, different domain generalization methods, and associated hyperparameters, can all be specified together with other experimental setup in a single configuration file. Hierarchical combinations of neural networks, different domain generalization methods, and associated hyperparameters, can all be specified together with other experimental setup in a single configuration file. In addition, DomainLab offers powerful benchmarking functionality to evaluate the generalization performance of neural networks in out-of-distribution data. The package supports running the specified benchmark on an HPC cluster or on a standalone machine. The package is well tested with over 95 percent coverage and well documented. From the user perspective, it is closed to modification but open to extension. The package is under the MIT license, and its source code, tutorial and documentation can be found at https://github.com/marrlab/DomainLab.","sentences":["Poor generalization performance caused by distribution shifts in unseen domains often hinders the trustworthy deployment of deep neural networks.","Many domain generalization techniques address this problem by adding a domain invariant regularization loss terms during training.","However, there is a lack of modular software that allows users to combine the advantages of different methods with minimal effort for reproducibility.","DomainLab is a modular Python package for training user specified neural networks with composable regularization loss terms.","Its decoupled design allows the separation of neural networks from regularization loss construction.","Hierarchical combinations of neural networks, different domain generalization methods, and associated hyperparameters, can all be specified together with other experimental setup in a single configuration file.","Hierarchical combinations of neural networks, different domain generalization methods, and associated hyperparameters, can all be specified together with other experimental setup in a single configuration file.","In addition, DomainLab offers powerful benchmarking functionality to evaluate the generalization performance of neural networks in out-of-distribution data.","The package supports running the specified benchmark on an HPC cluster or on a standalone machine.","The package is well tested with over 95 percent coverage and well documented.","From the user perspective, it is closed to modification but open to extension.","The package is under the MIT license, and its source code, tutorial and documentation can be found at https://github.com/marrlab/DomainLab."],"url":"http://arxiv.org/abs/2403.14356v1"}
{"created":"2024-03-21 12:28:44","title":"DaCapo: Accelerating Continuous Learning in Autonomous Systems for Video Analytics","abstract":"Deep neural network (DNN) video analytics is crucial for autonomous systems such as self-driving vehicles, unmanned aerial vehicles (UAVs), and security robots. However, real-world deployment faces challenges due to their limited computational resources and battery power. To tackle these challenges, continuous learning exploits a lightweight \"student\" model at deployment (inference), leverages a larger \"teacher\" model for labeling sampled data (labeling), and continuously retrains the student model to adapt to changing scenarios (retraining). This paper highlights the limitations in state-of-the-art continuous learning systems: (1) they focus on computations for retraining, while overlooking the compute needs for inference and labeling, (2) they rely on power-hungry GPUs, unsuitable for battery-operated autonomous systems, and (3) they are located on a remote centralized server, intended for multi-tenant scenarios, again unsuitable for autonomous systems due to privacy, network availability, and latency concerns. We propose a hardware-algorithm co-designed solution for continuous learning, DaCapo, that enables autonomous systems to perform concurrent executions of inference, labeling, and training in a performant and energy-efficient manner. DaCapo comprises (1) a spatially-partitionable and precision-flexible accelerator enabling parallel execution of kernels on sub-accelerators at their respective precisions, and (2) a spatiotemporal resource allocation algorithm that strategically navigates the resource-accuracy tradeoff space, facilitating optimal decisions for resource allocation to achieve maximal accuracy. Our evaluation shows that DaCapo achieves 6.5% and 5.5% higher accuracy than a state-of-the-art GPU-based continuous learning systems, Ekya and EOMU, respectively, while consuming 254x less power.","sentences":["Deep neural network (DNN) video analytics is crucial for autonomous systems such as self-driving vehicles, unmanned aerial vehicles (UAVs), and security robots.","However, real-world deployment faces challenges due to their limited computational resources and battery power.","To tackle these challenges, continuous learning exploits a lightweight \"student\" model at deployment (inference), leverages a larger \"teacher\" model for labeling sampled data (labeling), and continuously retrains the student model to adapt to changing scenarios (retraining).","This paper highlights the limitations in state-of-the-art continuous learning systems: (1) they focus on computations for retraining, while overlooking the compute needs for inference and labeling, (2) they rely on power-hungry GPUs, unsuitable for battery-operated autonomous systems, and (3) they are located on a remote centralized server, intended for multi-tenant scenarios, again unsuitable for autonomous systems due to privacy, network availability, and latency concerns.","We propose a hardware-algorithm co-designed solution for continuous learning, DaCapo, that enables autonomous systems to perform concurrent executions of inference, labeling, and training in a performant and energy-efficient manner.","DaCapo comprises (1) a spatially-partitionable and precision-flexible accelerator enabling parallel execution of kernels on sub-accelerators at their respective precisions, and (2) a spatiotemporal resource allocation algorithm that strategically navigates the resource-accuracy tradeoff space, facilitating optimal decisions for resource allocation to achieve maximal accuracy.","Our evaluation shows that DaCapo achieves 6.5% and 5.5% higher accuracy than a state-of-the-art GPU-based continuous learning systems, Ekya and EOMU, respectively, while consuming 254x less power."],"url":"http://arxiv.org/abs/2403.14353v1"}
{"created":"2024-03-21 12:28:24","title":"Accelerating Time-to-Science by Streaming Detector Data Directly into Perlmutter Compute Nodes","abstract":"Recent advancements in detector technology have significantly increased the size and complexity of experimental data, and high-performance computing (HPC) provides a path towards more efficient and timely data processing. However, movement of large data sets from acquisition systems to HPC centers introduces bottlenecks owing to storage I/O at both ends. This manuscript introduces a streaming workflow designed for an high data rate electron detector that streams data directly to compute node memory at the National Energy Research Scientific Computing Center (NERSC), thereby avoiding storage I/O. The new workflow deploys ZeroMQ-based services for data production, aggregation, and distribution for on-the-fly processing, all coordinated through a distributed key-value store. The system is integrated with the detector's science gateway and utilizes the NERSC Superfacility API to initiate streaming jobs through a web-based frontend. Our approach achieves up to a 14-fold increase in data throughput and enhances predictability and reliability compared to a I/O-heavy file-based transfer workflow. Our work highlights the transformative potential of streaming workflows to expedite data analysis for time-sensitive experiments.","sentences":["Recent advancements in detector technology have significantly increased the size and complexity of experimental data, and high-performance computing (HPC) provides a path towards more efficient and timely data processing.","However, movement of large data sets from acquisition systems to HPC centers introduces bottlenecks owing to storage I/O at both ends.","This manuscript introduces a streaming workflow designed for an high data rate electron detector that streams data directly to compute node memory at the National Energy Research Scientific Computing Center (NERSC), thereby avoiding storage I/O.","The new workflow deploys ZeroMQ-based services for data production, aggregation, and distribution for on-the-fly processing, all coordinated through a distributed key-value store.","The system is integrated with the detector's science gateway and utilizes the NERSC Superfacility API to initiate streaming jobs through a web-based frontend.","Our approach achieves up to a 14-fold increase in data throughput and enhances predictability and reliability compared to a I/O-heavy file-based transfer workflow.","Our work highlights the transformative potential of streaming workflows to expedite data analysis for time-sensitive experiments."],"url":"http://arxiv.org/abs/2403.14352v1"}
{"created":"2024-03-21 12:26:24","title":"Collecting Influencers: A Comparative Study of Online Network Crawlers","abstract":"Online network crawling tasks require a lot of efforts for the researchers to collect the data. One of them is identification of important nodes, which has many applications starting from viral marketing to the prevention of disease spread. Various crawling algorithms has been suggested but their efficiency is not studied well. In this paper we compared six known crawlers on the task of collecting the fraction of the most influential nodes of graph.   We analyzed crawlers behavior for four measures of node influence: node degree, k-coreness, betweenness centrality, and eccentricity. The experiments confirmed that greedy methods perform the best in many settings, but the cases exist when they are very inefficient.","sentences":["Online network crawling tasks require a lot of efforts for the researchers to collect the data.","One of them is identification of important nodes, which has many applications starting from viral marketing to the prevention of disease spread.","Various crawling algorithms has been suggested but their efficiency is not studied well.","In this paper we compared six known crawlers on the task of collecting the fraction of the most influential nodes of graph.   ","We analyzed crawlers behavior for four measures of node influence: node degree, k-coreness, betweenness centrality, and eccentricity.","The experiments confirmed that greedy methods perform the best in many settings, but the cases exist when they are very inefficient."],"url":"http://arxiv.org/abs/2403.14351v1"}
{"created":"2024-03-21 12:25:17","title":"Annotation-Efficient Polyp Segmentation via Active Learning","abstract":"Deep learning-based techniques have proven effective in polyp segmentation tasks when provided with sufficient pixel-wise labeled data. However, the high cost of manual annotation has created a bottleneck for model generalization. To minimize annotation costs, we propose a deep active learning framework for annotation-efficient polyp segmentation. In practice, we measure the uncertainty of each sample by examining the similarity between features masked by the prediction map of the polyp and the background area. Since the segmentation model tends to perform weak in samples with indistinguishable features of foreground and background areas, uncertainty sampling facilitates the fitting of under-learning data. Furthermore, clustering image-level features weighted by uncertainty identify samples that are both uncertain and representative. To enhance the selectivity of the active selection strategy, we propose a novel unsupervised feature discrepancy learning mechanism. The selection strategy and feature optimization work in tandem to achieve optimal performance with a limited annotation budget. Extensive experimental results have demonstrated that our proposed method achieved state-of-the-art performance compared to other competitors on both a public dataset and a large-scale in-house dataset.","sentences":["Deep learning-based techniques have proven effective in polyp segmentation tasks when provided with sufficient pixel-wise labeled data.","However, the high cost of manual annotation has created a bottleneck for model generalization.","To minimize annotation costs, we propose a deep active learning framework for annotation-efficient polyp segmentation.","In practice, we measure the uncertainty of each sample by examining the similarity between features masked by the prediction map of the polyp and the background area.","Since the segmentation model tends to perform weak in samples with indistinguishable features of foreground and background areas, uncertainty sampling facilitates the fitting of under-learning data.","Furthermore, clustering image-level features weighted by uncertainty identify samples that are both uncertain and representative.","To enhance the selectivity of the active selection strategy, we propose a novel unsupervised feature discrepancy learning mechanism.","The selection strategy and feature optimization work in tandem to achieve optimal performance with a limited annotation budget.","Extensive experimental results have demonstrated that our proposed method achieved state-of-the-art performance compared to other competitors on both a public dataset and a large-scale in-house dataset."],"url":"http://arxiv.org/abs/2403.14350v1"}
{"created":"2024-03-21 12:23:29","title":"Towards Efficient Information Fusion: Concentric Dual Fusion Attention Based Multiple Instance Learning for Whole Slide Images","abstract":"In the realm of digital pathology, multi-magnification Multiple Instance Learning (multi-mag MIL) has proven effective in leveraging the hierarchical structure of Whole Slide Images (WSIs) to reduce information loss and redundant data. However, current methods fall short in bridging the domain gap between pretrained models and medical imaging, and often fail to account for spatial relationships across different magnifications. Addressing these challenges, we introduce the Concentric Dual Fusion Attention-MIL (CDFA-MIL) framework,which innovatively combines point-to-area feature-colum attention and point-to-point concentric-row attention using concentric patch. This approach is designed to effectively fuse correlated information, enhancing feature representation and providing stronger correlation guidance for WSI analysis. CDFA-MIL distinguishes itself by offering a robust fusion strategy that leads to superior WSI recognition. Its application has demonstrated exceptional performance, significantly surpassing existing MIL methods in accuracy and F1 scores on prominent datasets like Camelyon16 and TCGA-NSCLC. Specifically, CDFA-MIL achieved an average accuracy and F1-score of 93.7\\% and 94.1\\% respectively on these datasets, marking a notable advancement over traditional MIL approaches.","sentences":["In the realm of digital pathology, multi-magnification Multiple Instance Learning (multi-mag MIL) has proven effective in leveraging the hierarchical structure of Whole Slide Images (WSIs) to reduce information loss and redundant data.","However, current methods fall short in bridging the domain gap between pretrained models and medical imaging, and often fail to account for spatial relationships across different magnifications.","Addressing these challenges, we introduce the Concentric Dual Fusion Attention-MIL (CDFA-MIL) framework,which innovatively combines point-to-area feature-colum attention and point-to-point concentric-row attention using concentric patch.","This approach is designed to effectively fuse correlated information, enhancing feature representation and providing stronger correlation guidance for WSI analysis.","CDFA-MIL distinguishes itself by offering a robust fusion strategy that leads to superior WSI recognition.","Its application has demonstrated exceptional performance, significantly surpassing existing MIL methods in accuracy and F1 scores on prominent datasets like Camelyon16 and TCGA-NSCLC.","Specifically, CDFA-MIL achieved an average accuracy and F1-score of 93.7\\% and 94.1\\% respectively on these datasets, marking a notable advancement over traditional MIL approaches."],"url":"http://arxiv.org/abs/2403.14346v1"}
{"created":"2024-03-21 12:14:02","title":"Exploring Task Unification in Graph Representation Learning via Generative Approach","abstract":"Graphs are ubiquitous in real-world scenarios and encompass a diverse range of tasks, from node-, edge-, and graph-level tasks to transfer learning. However, designing specific tasks for each type of graph data is often costly and lacks generalizability. Recent endeavors under the \"Pre-training + Fine-tuning\" or \"Pre-training + Prompt\" paradigms aim to design a unified framework capable of generalizing across multiple graph tasks. Among these, graph autoencoders (GAEs), generative self-supervised models, have demonstrated their potential in effectively addressing various graph tasks. Nevertheless, these methods typically employ multi-stage training and require adaptive designs, which on one hand make it difficult to be seamlessly applied to diverse graph tasks and on the other hand overlook the negative impact caused by discrepancies in task objectives between the different stages. To address these challenges, we propose GA^2E, a unified adversarially masked autoencoder capable of addressing the above challenges seamlessly. Specifically, GA^2E proposes to use the subgraph as the meta-structure, which remains consistent across all graph tasks (ranging from node-, edge-, and graph-level to transfer learning) and all stages (both during training and inference). Further, GA^2E operates in a \\textbf{\"Generate then Discriminate\"} manner. It leverages the masked GAE to reconstruct the input subgraph whilst treating it as a generator to compel the reconstructed graphs resemble the input subgraph. Furthermore, GA^2E introduces an auxiliary discriminator to discern the authenticity between the reconstructed (generated) subgraph and the input subgraph, thus ensuring the robustness of the graph representation through adversarial training mechanisms. We validate GA^2E's capabilities through extensive experiments on 21 datasets across four types of graph tasks.","sentences":["Graphs are ubiquitous in real-world scenarios and encompass a diverse range of tasks, from node-, edge-, and graph-level tasks to transfer learning.","However, designing specific tasks for each type of graph data is often costly and lacks generalizability.","Recent endeavors under the \"Pre-training + Fine-tuning\" or \"Pre-training + Prompt\" paradigms aim to design a unified framework capable of generalizing across multiple graph tasks.","Among these, graph autoencoders (GAEs), generative self-supervised models, have demonstrated their potential in effectively addressing various graph tasks.","Nevertheless, these methods typically employ multi-stage training and require adaptive designs, which on one hand make it difficult to be seamlessly applied to diverse graph tasks and on the other hand overlook the negative impact caused by discrepancies in task objectives between the different stages.","To address these challenges, we propose GA^2E, a unified adversarially masked autoencoder capable of addressing the above challenges seamlessly.","Specifically, GA^2E proposes to use the subgraph as the meta-structure, which remains consistent across all graph tasks (ranging from node-, edge-, and graph-level to transfer learning) and all stages (both during training and inference).","Further, GA^2E operates in a \\textbf{\"Generate then Discriminate\"} manner.","It leverages the masked GAE to reconstruct the input subgraph whilst treating it as a generator to compel the reconstructed graphs resemble the input subgraph.","Furthermore, GA^2E introduces an auxiliary discriminator to discern the authenticity between the reconstructed (generated) subgraph and the input subgraph, thus ensuring the robustness of the graph representation through adversarial training mechanisms.","We validate GA^2E's capabilities through extensive experiments on 21 datasets across four types of graph tasks."],"url":"http://arxiv.org/abs/2403.14340v1"}
{"created":"2024-03-21 12:11:26","title":"$\\nabla \u03c4$: Gradient-based and Task-Agnostic machine Unlearning","abstract":"Machine Unlearning, the process of selectively eliminating the influence of certain data examples used during a model's training, has gained significant attention as a means for practitioners to comply with recent data protection regulations. However, existing unlearning methods face critical drawbacks, including their prohibitively high cost, often associated with a large number of hyperparameters, and the limitation of forgetting only relatively small data portions. This often makes retraining the model from scratch a quicker and more effective solution. In this study, we introduce Gradient-based and Task-Agnostic machine Unlearning ($\\nabla \\tau$), an optimization framework designed to remove the influence of a subset of training data efficiently. It applies adaptive gradient ascent to the data to be forgotten while using standard gradient descent for the remaining data. $\\nabla \\tau$ offers multiple benefits over existing approaches. It enables the unlearning of large sections of the training dataset (up to 30%). It is versatile, supporting various unlearning tasks (such as subset forgetting or class removal) and applicable across different domains (images, text, etc.). Importantly, $\\nabla \\tau$ requires no hyperparameter adjustments, making it a more appealing option than retraining the model from scratch. We evaluate our framework's effectiveness using a set of well-established Membership Inference Attack metrics, demonstrating up to 10% enhancements in performance compared to state-of-the-art methods without compromising the original model's accuracy.","sentences":["Machine Unlearning, the process of selectively eliminating the influence of certain data examples used during a model's training, has gained significant attention as a means for practitioners to comply with recent data protection regulations.","However, existing unlearning methods face critical drawbacks, including their prohibitively high cost, often associated with a large number of hyperparameters, and the limitation of forgetting only relatively small data portions.","This often makes retraining the model from scratch a quicker and more effective solution.","In this study, we introduce Gradient-based and Task-Agnostic machine Unlearning ($\\nabla \\tau$), an optimization framework designed to remove the influence of a subset of training data efficiently.","It applies adaptive gradient ascent to the data to be forgotten while using standard gradient descent for the remaining data.","$\\nabla \\tau$ offers multiple benefits over existing approaches.","It enables the unlearning of large sections of the training dataset (up to 30%).","It is versatile, supporting various unlearning tasks (such as subset forgetting or class removal) and applicable across different domains (images, text, etc.).","Importantly, $\\nabla \\tau$ requires no hyperparameter adjustments, making it a more appealing option than retraining the model from scratch.","We evaluate our framework's effectiveness using a set of well-established Membership Inference Attack metrics, demonstrating up to 10% enhancements in performance compared to state-of-the-art methods without compromising the original model's accuracy."],"url":"http://arxiv.org/abs/2403.14339v1"}
{"created":"2024-03-21 11:57:16","title":"A Differentially Private Clustering Algorithm for Well-Clustered Graphs","abstract":"We study differentially private (DP) algorithms for recovering clusters in well-clustered graphs, which are graphs whose vertex set can be partitioned into a small number of sets, each inducing a subgraph of high inner conductance and small outer conductance. Such graphs have widespread application as a benchmark in the theoretical analysis of spectral clustering. We provide an efficient ($\\epsilon$,$\\delta$)-DP algorithm tailored specifically for such graphs. Our algorithm draws inspiration from the recent work of Chen et al., who developed DP algorithms for recovery of stochastic block models in cases where the graph comprises exactly two nearly-balanced clusters. Our algorithm works for well-clustered graphs with $k$ nearly-balanced clusters, and the misclassification ratio almost matches the one of the best-known non-private algorithms. We conduct experimental evaluations on datasets with known ground truth clusters to substantiate the prowess of our algorithm. We also show that any (pure) $\\epsilon$-DP algorithm would result in substantial error.","sentences":["We study differentially private (DP) algorithms for recovering clusters in well-clustered graphs, which are graphs whose vertex set can be partitioned into a small number of sets, each inducing a subgraph of high inner conductance and small outer conductance.","Such graphs have widespread application as a benchmark in the theoretical analysis of spectral clustering.","We provide an efficient ($\\epsilon$,$\\delta$)-DP algorithm tailored specifically for such graphs.","Our algorithm draws inspiration from the recent work of Chen et al., who developed DP algorithms for recovery of stochastic block models in cases where the graph comprises exactly two nearly-balanced clusters.","Our algorithm works for well-clustered graphs with $k$ nearly-balanced clusters, and the misclassification ratio almost matches the one of the best-known non-private algorithms.","We conduct experimental evaluations on datasets with known ground truth clusters to substantiate the prowess of our algorithm.","We also show that any (pure) $\\epsilon$-DP algorithm would result in substantial error."],"url":"http://arxiv.org/abs/2403.14332v1"}
{"created":"2024-03-21 11:51:42","title":"Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes","abstract":"Diabetes, a pervasive and enduring health challenge, imposes significant global implications on health, financial healthcare systems, and societal well-being. This study undertakes a comprehensive exploration of various structural learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression. The methodology involves the application of these algorithms to relevant diabetes data, followed by the conversion of their output graphs into Causal Bayesian Networks (CBNs), enabling predictive analysis and the evaluation of discrepancies in the effect of hypothetical interventions within our context-specific case study.   This study highlights the substantial impact of algorithm selection on intervention outcomes. To consolidate insights from diverse algorithms, we employ a model-averaging technique that helps us obtain a unique causal model for diabetes derived from a varied set of structural learning algorithms. We also investigate how each of those individual graphs, as well as the average graph, compare to the structures elicited by a domain expert who categorised graph edges into high confidence, moderate, and low confidence types, leading into three individual graphs corresponding to the three levels of confidence.   The resulting causal model and data are made available online, and serve as a valuable resource and a guide for informed decision-making by healthcare practitioners, offering a comprehensive understanding of the interactions between relevant risk factors and the effect of hypothetical interventions. Therefore, this research not only contributes to the academic discussion on diabetes, but also provides practical guidance for healthcare professionals in developing efficient intervention and risk management strategies.","sentences":["Diabetes, a pervasive and enduring health challenge, imposes significant global implications on health, financial healthcare systems, and societal well-being.","This study undertakes a comprehensive exploration of various structural learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression.","The methodology involves the application of these algorithms to relevant diabetes data, followed by the conversion of their output graphs into Causal Bayesian Networks (CBNs), enabling predictive analysis and the evaluation of discrepancies in the effect of hypothetical interventions within our context-specific case study.   ","This study highlights the substantial impact of algorithm selection on intervention outcomes.","To consolidate insights from diverse algorithms, we employ a model-averaging technique that helps us obtain a unique causal model for diabetes derived from a varied set of structural learning algorithms.","We also investigate how each of those individual graphs, as well as the average graph, compare to the structures elicited by a domain expert who categorised graph edges into high confidence, moderate, and low confidence types, leading into three individual graphs corresponding to the three levels of confidence.   ","The resulting causal model and data are made available online, and serve as a valuable resource and a guide for informed decision-making by healthcare practitioners, offering a comprehensive understanding of the interactions between relevant risk factors and the effect of hypothetical interventions.","Therefore, this research not only contributes to the academic discussion on diabetes, but also provides practical guidance for healthcare professionals in developing efficient intervention and risk management strategies."],"url":"http://arxiv.org/abs/2403.14327v1"}
{"created":"2024-03-21 11:50:00","title":"Evaluation and Deployment of LiDAR-based Place Recognition in Dense Forests","abstract":"Many LiDAR place recognition systems have been developed and tested specifically for urban driving scenarios. Their performance in natural environments such as forests and woodlands have been studied less closely. In this paper, we analyzed the capabilities of four different LiDAR place recognition systems, both handcrafted and learning-based methods, using LiDAR data collected with a handheld device and legged robot within dense forest environments. In particular, we focused on evaluating localization where there is significant translational and orientation difference between corresponding LiDAR scan pairs. This is particularly important for forest survey systems where the sensor or robot does not follow a defined road or path. Extending our analysis we then incorporated the best performing approach, Logg3dNet, into a full 6-DoF pose estimation system -- introducing several verification layers for precise registration. We demonstrated the performance of our methods in three operational modes: online SLAM, offline multi-mission SLAM map merging, and relocalization into a prior map. We evaluated these modes using data captured in forests from three different countries, achieving 80% of correct loop closures candidates with baseline distances up to 5m, and 60% up to 10m.","sentences":["Many LiDAR place recognition systems have been developed and tested specifically for urban driving scenarios.","Their performance in natural environments such as forests and woodlands have been studied less closely.","In this paper, we analyzed the capabilities of four different LiDAR place recognition systems, both handcrafted and learning-based methods, using LiDAR data collected with a handheld device and legged robot within dense forest environments.","In particular, we focused on evaluating localization where there is significant translational and orientation difference between corresponding LiDAR scan pairs.","This is particularly important for forest survey systems where the sensor or robot does not follow a defined road or path.","Extending our analysis we then incorporated the best performing approach, Logg3dNet, into a full 6-DoF pose estimation system -- introducing several verification layers for precise registration.","We demonstrated the performance of our methods in three operational modes: online SLAM, offline multi-mission SLAM map merging, and relocalization into a prior map.","We evaluated these modes using data captured in forests from three different countries, achieving 80% of correct loop closures candidates with baseline distances up to 5m, and 60% up to 10m."],"url":"http://arxiv.org/abs/2403.14326v1"}
{"created":"2024-03-21 11:34:26","title":"ChainLM: Empowering Large Language Models with Improved Chain-of-Thought Prompting","abstract":"Chain-of-Thought (CoT) prompting can enhance the reasoning capabilities of large language models (LLMs), establishing itself as a primary approach to solving complex reasoning tasks. Existing CoT synthesis approaches usually focus on simpler reasoning tasks and thus result in low-quality and inconsistent CoT prompts. In response to this challenge, we present an empirical investigation of CoT prompting and introduce CoTGenius, a novel framework designed for the automatic generation of superior CoT prompts. CoTGenius is developed based on three major evolution strategies, i.e., complicate, diversify, and specify-alongside two filtering mechanisms: evolutionary success judgement and correctness verification. We further employ CoTGenius to create an extensive CoT dataset, and subsequently fine-tune the Llama 2-Chat 7B and 13B models on this dataset. We call the resulting model ChainLM. To deal with the cumulative error issue in reasoning steps, we propose a step-level debating method, wherein multiple debaters discuss each reasoning step to arrive at the correct answer. Extensive experiments demonstrate that our ChainLM models exhibit enhanced proficiency in addressing a spectrum of complex reasoning problems compared to existing models. In addition, we conduct an in-depth analysis of the impact of data categories within CoTGenius on the model performance. We release our dataset and code at https://github.com/RUCAIBox/ChainLM.","sentences":["Chain-of-Thought (CoT) prompting can enhance the reasoning capabilities of large language models (LLMs), establishing itself as a primary approach to solving complex reasoning tasks.","Existing CoT synthesis approaches usually focus on simpler reasoning tasks and thus result in low-quality and inconsistent CoT prompts.","In response to this challenge, we present an empirical investigation of CoT prompting and introduce CoTGenius, a novel framework designed for the automatic generation of superior CoT prompts.","CoTGenius is developed based on three major evolution strategies, i.e., complicate, diversify, and specify-alongside two filtering mechanisms: evolutionary success judgement and correctness verification.","We further employ CoTGenius to create an extensive CoT dataset, and subsequently fine-tune the Llama 2-Chat 7B and 13B models on this dataset.","We call the resulting model ChainLM.","To deal with the cumulative error issue in reasoning steps, we propose a step-level debating method, wherein multiple debaters discuss each reasoning step to arrive at the correct answer.","Extensive experiments demonstrate that our ChainLM models exhibit enhanced proficiency in addressing a spectrum of complex reasoning problems compared to existing models.","In addition, we conduct an in-depth analysis of the impact of data categories within CoTGenius on the model performance.","We release our dataset and code at https://github.com/RUCAIBox/ChainLM."],"url":"http://arxiv.org/abs/2403.14312v1"}
{"created":"2024-03-21 11:21:17","title":"Bayesian Optimization for Sample-Efficient Policy Improvement in Robotic Manipulation","abstract":"Sample efficient learning of manipulation skills poses a major challenge in robotics. While recent approaches demonstrate impressive advances in the type of task that can be addressed and the sensing modalities that can be incorporated, they still require large amounts of training data. Especially with regard to learning actions on robots in the real world, this poses a major problem due to the high costs associated with both demonstrations and real-world robot interactions. To address this challenge, we introduce BOpt-GMM, a hybrid approach that combines imitation learning with own experience collection. We first learn a skill model as a dynamical system encoded in a Gaussian Mixture Model from a few demonstrations. We then improve this model with Bayesian optimization building on a small number of autonomous skill executions in a sparse reward setting. We demonstrate the sample efficiency of our approach on multiple complex manipulation skills in both simulations and real-world experiments. Furthermore, we make the code and pre-trained models publicly available at http://bopt-gmm. cs.uni-freiburg.de.","sentences":["Sample efficient learning of manipulation skills poses a major challenge in robotics.","While recent approaches demonstrate impressive advances in the type of task that can be addressed and the sensing modalities that can be incorporated, they still require large amounts of training data.","Especially with regard to learning actions on robots in the real world, this poses a major problem due to the high costs associated with both demonstrations and real-world robot interactions.","To address this challenge, we introduce BOpt-GMM, a hybrid approach that combines imitation learning with own experience collection.","We first learn a skill model as a dynamical system encoded in a Gaussian Mixture Model from a few demonstrations.","We then improve this model with Bayesian optimization building on a small number of autonomous skill executions in a sparse reward setting.","We demonstrate the sample efficiency of our approach on multiple complex manipulation skills in both simulations and real-world experiments.","Furthermore, we make the code and pre-trained models publicly available at http://bopt-gmm.","cs.uni-freiburg.de."],"url":"http://arxiv.org/abs/2403.14305v1"}
{"created":"2024-03-21 11:03:56","title":"Impact Assessment of Missing Data in Model Predictions for Earth Observation Applications","abstract":"Earth observation (EO) applications involving complex and heterogeneous data sources are commonly approached with machine learning models. However, there is a common assumption that data sources will be persistently available. Different situations could affect the availability of EO sources, like noise, clouds, or satellite mission failures. In this work, we assess the impact of missing temporal and static EO sources in trained models across four datasets with classification and regression tasks. We compare the predictive quality of different methods and find that some are naturally more robust to missing data. The Ensemble strategy, in particular, achieves a prediction robustness up to 100%. We evidence that missing scenarios are significantly more challenging in regression than classification tasks. Finally, we find that the optical view is the most critical view when it is missing individually.","sentences":["Earth observation (EO) applications involving complex and heterogeneous data sources are commonly approached with machine learning models.","However, there is a common assumption that data sources will be persistently available.","Different situations could affect the availability of EO sources, like noise, clouds, or satellite mission failures.","In this work, we assess the impact of missing temporal and static EO sources in trained models across four datasets with classification and regression tasks.","We compare the predictive quality of different methods and find that some are naturally more robust to missing data.","The Ensemble strategy, in particular, achieves a prediction robustness up to 100%.","We evidence that missing scenarios are significantly more challenging in regression than classification tasks.","Finally, we find that the optical view is the most critical view when it is missing individually."],"url":"http://arxiv.org/abs/2403.14297v1"}
{"created":"2024-03-21 11:00:11","title":"Human Reactions to Incorrect Answers from Robots","abstract":"As robots grow more and more integrated into numerous industries, it is critical to comprehend how humans respond to their failures. This paper systematically studies how trust dynamics and system design are affected by human responses to robot failures. The three-stage survey used in the study provides a thorough understanding of human-robot interactions. While the second stage concentrates on interaction details, such as robot precision and error acknowledgment, the first stage collects demographic data and initial levels of trust. In the last phase, participants' perceptions are examined after the encounter, and trust dynamics, forgiveness, and propensity to suggest robotic technologies are evaluated. Results show that participants' trust in robotic technologies increased significantly when robots acknowledged their errors or limitations to participants and their willingness to suggest robots for activities in the future points to a favorable change in perception, emphasizing the role that direct engagement has in influencing trust dynamics. By providing useful advice for creating more sympathetic, responsive, and reliable robotic systems, the study advances the science of human-robot interaction and promotes a wider adoption of robotic technologies.","sentences":["As robots grow more and more integrated into numerous industries, it is critical to comprehend how humans respond to their failures.","This paper systematically studies how trust dynamics and system design are affected by human responses to robot failures.","The three-stage survey used in the study provides a thorough understanding of human-robot interactions.","While the second stage concentrates on interaction details, such as robot precision and error acknowledgment, the first stage collects demographic data and initial levels of trust.","In the last phase, participants' perceptions are examined after the encounter, and trust dynamics, forgiveness, and propensity to suggest robotic technologies are evaluated.","Results show that participants' trust in robotic technologies increased significantly when robots acknowledged their errors or limitations to participants and their willingness to suggest robots for activities in the future points to a favorable change in perception, emphasizing the role that direct engagement has in influencing trust dynamics.","By providing useful advice for creating more sympathetic, responsive, and reliable robotic systems, the study advances the science of human-robot interaction and promotes a wider adoption of robotic technologies."],"url":"http://arxiv.org/abs/2403.14293v1"}
{"created":"2024-03-21 10:59:44","title":"HySim: An Efficient Hybrid Similarity Measure for Patch Matching in Image Inpainting","abstract":"Inpainting, for filling missing image regions, is a crucial task in various applications, such as medical imaging and remote sensing. Trending data-driven approaches efficiency, for image inpainting, often requires extensive data preprocessing. In this sense, there is still a need for model-driven approaches in case of application constrained with data availability and quality, especially for those related for time series forecasting using image inpainting techniques. This paper proposes an improved modeldriven approach relying on patch-based techniques. Our approach deviates from the standard Sum of Squared Differences (SSD) similarity measure by introducing a Hybrid Similarity (HySim), which combines both strengths of Chebychev and Minkowski distances. This hybridization enhances patch selection, leading to high-quality inpainting results with reduced mismatch errors. Experimental results proved the effectiveness of our approach against other model-driven techniques, such as diffusion or patch-based approaches, showcasing its effectiveness in achieving visually pleasing restorations.","sentences":["Inpainting, for filling missing image regions, is a crucial task in various applications, such as medical imaging and remote sensing.","Trending data-driven approaches efficiency, for image inpainting, often requires extensive data preprocessing.","In this sense, there is still a need for model-driven approaches in case of application constrained with data availability and quality, especially for those related for time series forecasting using image inpainting techniques.","This paper proposes an improved modeldriven approach relying on patch-based techniques.","Our approach deviates from the standard Sum of Squared Differences (SSD) similarity measure by introducing a Hybrid Similarity (HySim), which combines both strengths of Chebychev and Minkowski distances.","This hybridization enhances patch selection, leading to high-quality inpainting results with reduced mismatch errors.","Experimental results proved the effectiveness of our approach against other model-driven techniques, such as diffusion or patch-based approaches, showcasing its effectiveness in achieving visually pleasing restorations."],"url":"http://arxiv.org/abs/2403.14292v1"}
{"created":"2024-03-21 10:51:19","title":"Enhancing Historical Image Retrieval with Compositional Cues","abstract":"In analyzing vast amounts of digitally stored historical image data, existing content-based retrieval methods often overlook significant non-semantic information, limiting their effectiveness for flexible exploration across varied themes. To broaden the applicability of image retrieval methods for diverse purposes and uncover more general patterns, we innovatively introduce a crucial factor from computational aesthetics, namely image composition, into this topic. By explicitly integrating composition-related information extracted by CNN into the designed retrieval model, our method considers both the image's composition rules and semantic information. Qualitative and quantitative experiments demonstrate that the image retrieval network guided by composition information outperforms those relying solely on content information, facilitating the identification of images in databases closer to the target image in human perception. Please visit https://github.com/linty5/CCBIR to try our codes.","sentences":["In analyzing vast amounts of digitally stored historical image data, existing content-based retrieval methods often overlook significant non-semantic information, limiting their effectiveness for flexible exploration across varied themes.","To broaden the applicability of image retrieval methods for diverse purposes and uncover more general patterns, we innovatively introduce a crucial factor from computational aesthetics, namely image composition, into this topic.","By explicitly integrating composition-related information extracted by CNN into the designed retrieval model, our method considers both the image's composition rules and semantic information.","Qualitative and quantitative experiments demonstrate that the image retrieval network guided by composition information outperforms those relying solely on content information, facilitating the identification of images in databases closer to the target image in human perception.","Please visit https://github.com/linty5/CCBIR to try our codes."],"url":"http://arxiv.org/abs/2403.14287v1"}
{"created":"2024-03-21 10:49:54","title":"Assessing the Robustness of Spectral Clustering for Deep Speaker Diarization","abstract":"Clustering speaker embeddings is crucial in speaker diarization but hasn't received as much focus as other components. Moreover, the robustness of speaker diarization across various datasets hasn't been explored when the development and evaluation data are from different domains. To bridge this gap, this study thoroughly examines spectral clustering for both same-domain and cross-domain speaker diarization. Our extensive experiments on two widely used corpora, AMI and DIHARD, reveal the performance trend of speaker diarization in the presence of domain mismatch. We observe that the performance difference between two different domain conditions can be attributed to the role of spectral clustering. In particular, keeping other modules unchanged, we show that differences in optimal tuning parameters as well as speaker count estimation originates due to the mismatch. This study opens several future directions for speaker diarization research.","sentences":["Clustering speaker embeddings is crucial in speaker diarization but hasn't received as much focus as other components.","Moreover, the robustness of speaker diarization across various datasets hasn't been explored when the development and evaluation data are from different domains.","To bridge this gap, this study thoroughly examines spectral clustering for both same-domain and cross-domain speaker diarization.","Our extensive experiments on two widely used corpora, AMI and DIHARD, reveal the performance trend of speaker diarization in the presence of domain mismatch.","We observe that the performance difference between two different domain conditions can be attributed to the role of spectral clustering.","In particular, keeping other modules unchanged, we show that differences in optimal tuning parameters as well as speaker count estimation originates due to the mismatch.","This study opens several future directions for speaker diarization research."],"url":"http://arxiv.org/abs/2403.14286v1"}
{"created":"2024-03-21 10:43:55","title":"How to be fair? A study of label and selection bias","abstract":"It is widely accepted that biased data leads to biased and thus potentially unfair models. Therefore, several measures for bias in data and model predictions have been proposed, as well as bias mitigation techniques whose aim is to learn models that are fair by design. Despite the myriad of mitigation techniques developed in the past decade, however, it is still poorly understood under what circumstances which methods work. Recently, Wick et al. showed, with experiments on synthetic data, that there exist situations in which bias mitigation techniques lead to more accurate models when measured on unbiased data. Nevertheless, in the absence of a thorough mathematical analysis, it remains unclear which techniques are effective under what circumstances. We propose to address this problem by establishing relationships between the type of bias and the effectiveness of a mitigation technique, where we categorize the mitigation techniques by the bias measure they optimize. In this paper we illustrate this principle for label and selection bias on the one hand, and demographic parity and ``We're All Equal'' on the other hand. Our theoretical analysis allows to explain the results of Wick et al. and we also show that there are situations where minimizing fairness measures does not result in the fairest possible distribution.","sentences":["It is widely accepted that biased data leads to biased and thus potentially unfair models.","Therefore, several measures for bias in data and model predictions have been proposed, as well as bias mitigation techniques whose aim is to learn models that are fair by design.","Despite the myriad of mitigation techniques developed in the past decade, however, it is still poorly understood under what circumstances which methods work.","Recently, Wick et al. showed, with experiments on synthetic data, that there exist situations in which bias mitigation techniques lead to more accurate models when measured on unbiased data.","Nevertheless, in the absence of a thorough mathematical analysis, it remains unclear which techniques are effective under what circumstances.","We propose to address this problem by establishing relationships between the type of bias and the effectiveness of a mitigation technique, where we categorize the mitigation techniques by the bias measure they optimize.","In this paper we illustrate this principle for label and selection bias on the one hand, and demographic parity and ``We're All Equal'' on the other hand.","Our theoretical analysis allows to explain the results of Wick et al.","and we also show that there are situations where minimizing fairness measures does not result in the fairest possible distribution."],"url":"http://arxiv.org/abs/2403.14282v1"}
{"created":"2024-03-21 10:38:18","title":"Zero123-6D: Zero-shot Novel View Synthesis for RGB Category-level 6D Pose Estimation","abstract":"Estimating the pose of objects through vision is essential to make robotic platforms interact with the environment. Yet, it presents many challenges, often related to the lack of flexibility and generalizability of state-of-the-art solutions. Diffusion models are a cutting-edge neural architecture transforming 2D and 3D computer vision, outlining remarkable performances in zero-shot novel-view synthesis. Such a use case is particularly intriguing for reconstructing 3D objects. However, localizing objects in unstructured environments is rather unexplored. To this end, this work presents Zero123-6D to demonstrate the utility of Diffusion Model-based novel-view-synthesizers in enhancing RGB 6D pose estimation at category-level by integrating them with feature extraction techniques. The outlined method exploits such a novel view synthesizer to expand a sparse set of RGB-only reference views for the zero-shot 6D pose estimation task. Experiments are quantitatively analyzed on the CO3D dataset, showcasing increased performance over baselines, a substantial reduction in data requirements, and the removal of the necessity of depth information.","sentences":["Estimating the pose of objects through vision is essential to make robotic platforms interact with the environment.","Yet, it presents many challenges, often related to the lack of flexibility and generalizability of state-of-the-art solutions.","Diffusion models are a cutting-edge neural architecture transforming 2D and 3D computer vision, outlining remarkable performances in zero-shot novel-view synthesis.","Such a use case is particularly intriguing for reconstructing 3D objects.","However, localizing objects in unstructured environments is rather unexplored.","To this end, this work presents Zero123-6D to demonstrate the utility of Diffusion Model-based novel-view-synthesizers in enhancing RGB 6D pose estimation at category-level by integrating them with feature extraction techniques.","The outlined method exploits such a novel view synthesizer to expand a sparse set of RGB-only reference views for the zero-shot 6D pose estimation task.","Experiments are quantitatively analyzed on the CO3D dataset, showcasing increased performance over baselines, a substantial reduction in data requirements, and the removal of the necessity of depth information."],"url":"http://arxiv.org/abs/2403.14279v1"}
{"created":"2024-03-21 10:15:57","title":"Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection","abstract":"Visual relationship detection aims to identify objects and their relationships in images. Prior methods approach this task by adding separate relationship modules or decoders to existing object detection architectures. This separation increases complexity and hinders end-to-end training, which limits performance. We propose a simple and highly efficient decoder-free architecture for open-vocabulary visual relationship detection. Our model consists of a Transformer-based image encoder that represents objects as tokens and models their relationships implicitly. To extract relationship information, we introduce an attention mechanism that selects object pairs likely to form a relationship. We provide a single-stage recipe to train this model on a mixture of object and relationship detection data. Our approach achieves state-of-the-art relationship detection performance on Visual Genome and on the large-vocabulary GQA benchmark at real-time inference speeds. We provide analyses of zero-shot performance, ablations, and real-world qualitative examples.","sentences":["Visual relationship detection aims to identify objects and their relationships in images.","Prior methods approach this task by adding separate relationship modules or decoders to existing object detection architectures.","This separation increases complexity and hinders end-to-end training, which limits performance.","We propose a simple and highly efficient decoder-free architecture for open-vocabulary visual relationship detection.","Our model consists of a Transformer-based image encoder that represents objects as tokens and models their relationships implicitly.","To extract relationship information, we introduce an attention mechanism that selects object pairs likely to form a relationship.","We provide a single-stage recipe to train this model on a mixture of object and relationship detection data.","Our approach achieves state-of-the-art relationship detection performance on Visual Genome and on the large-vocabulary GQA benchmark at real-time inference speeds.","We provide analyses of zero-shot performance, ablations, and real-world qualitative examples."],"url":"http://arxiv.org/abs/2403.14270v1"}
{"created":"2024-03-21 09:29:18","title":"Space-Efficient Indexes for Uncertain Strings","abstract":"Strings in the real world are often encoded with some level of uncertainty. In the character-level uncertainty model, an uncertain string $X$ of length $n$ on an alphabet $\\Sigma$ is a sequence of $n$ probability distributions over $\\Sigma$. Given an uncertain string $X$ and a weight threshold $\\frac{1}{z}\\in(0,1]$, we say that pattern $P$ occurs in $X$ at position $i$, if the product of probabilities of the letters of $P$ at positions $i,\\ldots,i+|P|-1$ is at least $\\frac{1}{z}$. While indexing standard strings for online pattern searches can be performed in linear time and space, indexing uncertain strings is much more challenging. Specifically, the state-of-the-art index for uncertain strings has $\\mathcal{O}(nz)$ size, requires $\\mathcal{O}(nz)$ time and $\\mathcal{O}(nz)$ space to be constructed, and answers pattern matching queries in the optimal $\\mathcal{O}(m+|\\text{Occ}|)$ time, where $m$ is the length of $P$ and $|\\text{Occ}|$ is the total number of occurrences of $P$ in $X$. For large $n$ and (moderate) $z$ values, this index is completely impractical to construct, which outweighs the benefit of the supported optimal pattern matching queries. We were thus motivated to design a space-efficient index at the expense of slower yet competitive pattern matching queries. We propose an index of $\\mathcal{O}(\\frac{nz}{\\ell}\\log z)$ expected size, which can be constructed using $\\mathcal{O}(\\frac{nz}{\\ell}\\log z)$ expected space, and supports very fast pattern matching queries in expectation, for patterns of length $m\\geq \\ell$. We have implemented and evaluated several versions of our index. The best-performing version of our index is up to two orders of magnitude smaller than the state of the art in terms of both index size and construction space, while offering faster or very competitive query and construction times.","sentences":["Strings in the real world are often encoded with some level of uncertainty.","In the character-level uncertainty model, an uncertain string $X$ of length $n$ on an alphabet $\\Sigma$ is a sequence of $n$ probability distributions over $\\Sigma$. Given an uncertain string $X$ and a weight threshold $\\frac{1}{z}\\in(0,1]$, we say that pattern $P$ occurs in $X$ at position $i$, if the product of probabilities of the letters of $P$ at positions $i,\\ldots,i+|P|-1$ is at least $\\frac{1}{z}$. While indexing standard strings for online pattern searches can be performed in linear time and space, indexing uncertain strings is much more challenging.","Specifically, the state-of-the-art index for uncertain strings has $\\mathcal{O}(nz)$ size, requires $\\mathcal{O}(nz)$ time and $\\mathcal{O}(nz)$ space to be constructed, and answers pattern matching queries in the optimal $\\mathcal{O}(m+|\\text{Occ}|)$ time, where $m$ is the length of $P$ and $|\\text{Occ}|$ is the total number of occurrences of $P$ in $X$. For large $n$ and (moderate) $z$ values, this index is completely impractical to construct, which outweighs the benefit of the supported optimal pattern matching queries.","We were thus motivated to design a space-efficient index at the expense of slower yet competitive pattern matching queries.","We propose an index of $\\mathcal{O}(\\frac{nz}{\\ell}\\log z)$ expected size, which can be constructed using $\\mathcal{O}(\\frac{nz}{\\ell}\\log z)$ expected space, and supports very fast pattern matching queries in expectation, for patterns of length $m\\geq \\ell$. We have implemented and evaluated several versions of our index.","The best-performing version of our index is up to two orders of magnitude smaller than the state of the art in terms of both index size and construction space, while offering faster or very competitive query and construction times."],"url":"http://arxiv.org/abs/2403.14256v1"}
{"created":"2024-03-21 08:49:34","title":"SoftPatch: Unsupervised Anomaly Detection with Noisy Data","abstract":"Although mainstream unsupervised anomaly detection (AD) algorithms perform well in academic datasets, their performance is limited in practical application due to the ideal experimental setting of clean training data. Training with noisy data is an inevitable problem in real-world anomaly detection but is seldom discussed. This paper considers label-level noise in image sensory anomaly detection for the first time. To solve this problem, we proposed a memory-based unsupervised AD method, SoftPatch, which efficiently denoises the data at the patch level. Noise discriminators are utilized to generate outlier scores for patch-level noise elimination before coreset construction. The scores are then stored in the memory bank to soften the anomaly detection boundary. Compared with existing methods, SoftPatch maintains a strong modeling ability of normal data and alleviates the overconfidence problem in coreset. Comprehensive experiments in various noise scenes demonstrate that SoftPatch outperforms the state-of-the-art AD methods on the MVTecAD and BTAD benchmarks and is comparable to those methods under the setting without noise.","sentences":["Although mainstream unsupervised anomaly detection (AD) algorithms perform well in academic datasets, their performance is limited in practical application due to the ideal experimental setting of clean training data.","Training with noisy data is an inevitable problem in real-world anomaly detection but is seldom discussed.","This paper considers label-level noise in image sensory anomaly detection for the first time.","To solve this problem, we proposed a memory-based unsupervised AD method, SoftPatch, which efficiently denoises the data at the patch level.","Noise discriminators are utilized to generate outlier scores for patch-level noise elimination before coreset construction.","The scores are then stored in the memory bank to soften the anomaly detection boundary.","Compared with existing methods, SoftPatch maintains a strong modeling ability of normal data and alleviates the overconfidence problem in coreset.","Comprehensive experiments in various noise scenes demonstrate that SoftPatch outperforms the state-of-the-art AD methods on the MVTecAD and BTAD benchmarks and is comparable to those methods under the setting without noise."],"url":"http://arxiv.org/abs/2403.14233v1"}
{"created":"2024-03-21 08:30:44","title":"Stitching for Neuroevolution: Recombining Deep Neural Networks without Breaking Them","abstract":"Traditional approaches to neuroevolution often start from scratch. This becomes prohibitively expensive in terms of computational and data requirements when targeting modern, deep neural networks. Using a warm start could be highly advantageous, e.g., using previously trained networks, potentially from different sources. This moreover enables leveraging the benefits of transfer learning (in particular vastly reduced training effort). However, recombining trained networks is non-trivial because architectures and feature representations typically differ. Consequently, a straightforward exchange of layers tends to lead to a performance breakdown. We overcome this by matching the layers of parent networks based on their connectivity, identifying potential crossover points. To correct for differing feature representations between these layers we employ stitching, which merges the networks by introducing new layers at crossover points. To train the merged network, only stitching layers need to be considered. New networks can then be created by selecting a subnetwork by choosing which stitching layers to (not) use. Assessing their performance is efficient as only their evaluation on data is required. We experimentally show that our approach enables finding networks that represent novel trade-offs between performance and computational cost, with some even dominating the original networks.","sentences":["Traditional approaches to neuroevolution often start from scratch.","This becomes prohibitively expensive in terms of computational and data requirements when targeting modern, deep neural networks.","Using a warm start could be highly advantageous, e.g., using previously trained networks, potentially from different sources.","This moreover enables leveraging the benefits of transfer learning (in particular vastly reduced training effort).","However, recombining trained networks is non-trivial because architectures and feature representations typically differ.","Consequently, a straightforward exchange of layers tends to lead to a performance breakdown.","We overcome this by matching the layers of parent networks based on their connectivity, identifying potential crossover points.","To correct for differing feature representations between these layers we employ stitching, which merges the networks by introducing new layers at crossover points.","To train the merged network, only stitching layers need to be considered.","New networks can then be created by selecting a subnetwork by choosing which stitching layers to (not) use.","Assessing their performance is efficient as only their evaluation on data is required.","We experimentally show that our approach enables finding networks that represent novel trade-offs between performance and computational cost, with some even dominating the original networks."],"url":"http://arxiv.org/abs/2403.14224v1"}
{"created":"2024-03-21 08:22:44","title":"Large-Scale Label Interpretation Learning for Few-Shot Named Entity Recognition","abstract":"Few-shot named entity recognition (NER) detects named entities within text using only a few annotated examples. One promising line of research is to leverage natural language descriptions of each entity type: the common label PER might, for example, be verbalized as ''person entity.'' In an initial label interpretation learning phase, the model learns to interpret such verbalized descriptions of entity types. In a subsequent few-shot tagset extension phase, this model is then given a description of a previously unseen entity type (such as ''music album'') and optionally a few training examples to perform few-shot NER for this type. In this paper, we systematically explore the impact of a strong semantic prior to interpret verbalizations of new entity types by massively scaling up the number and granularity of entity types used for label interpretation learning. To this end, we leverage an entity linking benchmark to create a dataset with orders of magnitude of more distinct entity types and descriptions as currently used datasets. We find that this increased signal yields strong results in zero- and few-shot NER in in-domain, cross-domain, and even cross-lingual settings. Our findings indicate significant potential for improving few-shot NER through heuristical data-based optimization.","sentences":["Few-shot named entity recognition (NER) detects named entities within text using only a few annotated examples.","One promising line of research is to leverage natural language descriptions of each entity type: the common label PER might, for example, be verbalized as ''person entity.''","In an initial label interpretation learning phase, the model learns to interpret such verbalized descriptions of entity types.","In a subsequent few-shot tagset extension phase, this model is then given a description of a previously unseen entity type (such as ''music album'') and optionally a few training examples to perform few-shot NER for this type.","In this paper, we systematically explore the impact of a strong semantic prior to interpret verbalizations of new entity types by massively scaling up the number and granularity of entity types used for label interpretation learning.","To this end, we leverage an entity linking benchmark to create a dataset with orders of magnitude of more distinct entity types and descriptions as currently used datasets.","We find that this increased signal yields strong results in zero- and few-shot NER in in-domain, cross-domain, and even cross-lingual settings.","Our findings indicate significant potential for improving few-shot NER through heuristical data-based optimization."],"url":"http://arxiv.org/abs/2403.14222v1"}
{"created":"2024-03-21 08:00:05","title":"Automatic Annotation of Grammaticality in Child-Caregiver Conversations","abstract":"The acquisition of grammar has been a central question to adjudicate between theories of language acquisition. In order to conduct faster, more reproducible, and larger-scale corpus studies on grammaticality in child-caregiver conversations, tools for automatic annotation can offer an effective alternative to tedious manual annotation. We propose a coding scheme for context-dependent grammaticality in child-caregiver conversations and annotate more than 4,000 utterances from a large corpus of transcribed conversations. Based on these annotations, we train and evaluate a range of NLP models. Our results show that fine-tuned Transformer-based models perform best, achieving human inter-annotation agreement levels.As a first application and sanity check of this tool, we use the trained models to annotate a corpus almost two orders of magnitude larger than the manually annotated data and verify that children's grammaticality shows a steady increase with age.This work contributes to the growing literature on applying state-of-the-art NLP methods to help study child language acquisition at scale.","sentences":["The acquisition of grammar has been a central question to adjudicate between theories of language acquisition.","In order to conduct faster, more reproducible, and larger-scale corpus studies on grammaticality in child-caregiver conversations, tools for automatic annotation can offer an effective alternative to tedious manual annotation.","We propose a coding scheme for context-dependent grammaticality in child-caregiver conversations and annotate more than 4,000 utterances from a large corpus of transcribed conversations.","Based on these annotations, we train and evaluate a range of NLP models.","Our results show that fine-tuned Transformer-based models perform best, achieving human inter-annotation agreement levels.","As a first application and sanity check of this tool, we use the trained models to annotate a corpus almost two orders of magnitude larger than the manually annotated data and verify that children's grammaticality shows a steady increase with age.","This work contributes to the growing literature on applying state-of-the-art NLP methods to help study child language acquisition at scale."],"url":"http://arxiv.org/abs/2403.14208v1"}
{"created":"2024-03-21 07:57:28","title":"VL-DNA: Enhance DNA Storage Capacity with Variable Payload (Strand) Lengths","abstract":"DNA storage is a promising archival data storage solution to today's big data problem. A DNA storage system encodes and stores digital data with synthetic DNA sequences and decodes DNA sequences back to digital data via sequencing. For efficient target data retrieving, existing Polymerase Chain Reaction PCR based DNA storage systems apply primers as specific identifier to tag different set of DNA strands. However, the PCR based DNA storage system suffers from primer-payload collisions, causing a significant reduction of storage capacity. This paper proposes using variable strand length, which takes advantage of the inherent payload-cutting process, to split collisions and recover primers. The executing time of our scheme is linear to the number of primer-payload collisions. The scheme serves as a post-processing method to any DNA encoding scheme. The evaluation of three state-of-the-art encoding schemes shows that the scheme can recover thousands of usable primers and improve tube capacity ranging from 18.27% to 19x.","sentences":["DNA storage is a promising archival data storage solution to today's big data problem.","A DNA storage system encodes and stores digital data with synthetic DNA sequences and decodes DNA sequences back to digital data via sequencing.","For efficient target data retrieving, existing Polymerase Chain Reaction PCR based DNA storage systems apply primers as specific identifier to tag different set of DNA strands.","However, the PCR based DNA storage system suffers from primer-payload collisions, causing a significant reduction of storage capacity.","This paper proposes using variable strand length, which takes advantage of the inherent payload-cutting process, to split collisions and recover primers.","The executing time of our scheme is linear to the number of primer-payload collisions.","The scheme serves as a post-processing method to any DNA encoding scheme.","The evaluation of three state-of-the-art encoding schemes shows that the scheme can recover thousands of usable primers and improve tube capacity ranging from 18.27% to 19x."],"url":"http://arxiv.org/abs/2403.14204v1"}
{"created":"2024-03-21 07:48:35","title":"Unleashing Unlabeled Data: A Paradigm for Cross-View Geo-Localization","abstract":"This paper investigates the effective utilization of unlabeled data for large-area cross-view geo-localization (CVGL), encompassing both unsupervised and semi-supervised settings. Common approaches to CVGL rely on ground-satellite image pairs and employ label-driven supervised training. However, the cost of collecting precise cross-view image pairs hinders the deployment of CVGL in real-life scenarios. Without the pairs, CVGL will be more challenging to handle the significant imaging and spatial gaps between ground and satellite images. To this end, we propose an unsupervised framework including a cross-view projection to guide the model for retrieving initial pseudo-labels and a fast re-ranking mechanism to refine the pseudo-labels by leveraging the fact that ``the perfectly paired ground-satellite image is located in a unique and identical scene\". The framework exhibits competitive performance compared with supervised works on three open-source benchmarks. Our code and models will be released on https://github.com/liguopeng0923/UCVGL.","sentences":["This paper investigates the effective utilization of unlabeled data for large-area cross-view geo-localization (CVGL), encompassing both unsupervised and semi-supervised settings.","Common approaches to CVGL rely on ground-satellite image pairs and employ label-driven supervised training.","However, the cost of collecting precise cross-view image pairs hinders the deployment of CVGL in real-life scenarios.","Without the pairs, CVGL will be more challenging to handle the significant imaging and spatial gaps between ground and satellite images.","To this end, we propose an unsupervised framework including a cross-view projection to guide the model for retrieving initial pseudo-labels and a fast re-ranking mechanism to refine the pseudo-labels by leveraging the fact that ``the perfectly paired ground-satellite image is located in a unique and identical scene\".","The framework exhibits competitive performance compared with supervised works on three open-source benchmarks.","Our code and models will be released on https://github.com/liguopeng0923/UCVGL."],"url":"http://arxiv.org/abs/2403.14198v1"}
{"created":"2024-03-21 06:47:28","title":"MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation","abstract":"Automatic detection of multimodal misinformation has gained a widespread attention recently. However, the potential of powerful Large Language Models (LLMs) for multimodal misinformation detection remains underexplored. Besides, how to teach LLMs to interpret multimodal misinformation in cost-effective and accessible way is still an open question. To address that, we propose MMIDR, a framework designed to teach LLMs in providing fluent and high-quality textual explanations for their decision-making process of multimodal misinformation. To convert multimodal misinformation into an appropriate instruction-following format, we present a data augmentation perspective and pipeline. This pipeline consists of a visual information processing module and an evidence retrieval module. Subsequently, we prompt the proprietary LLMs with processed contents to extract rationales for interpreting the authenticity of multimodal misinformation. Furthermore, we design an efficient knowledge distillation approach to distill the capability of proprietary LLMs in explaining multimodal misinformation into open-source LLMs. To explore several research questions regarding the performance of LLMs in multimodal misinformation detection tasks, we construct an instruction-following multimodal misinformation dataset and conduct comprehensive experiments. The experimental findings reveal that our MMIDR exhibits sufficient detection performance and possesses the capacity to provide compelling rationales to support its assessments.","sentences":["Automatic detection of multimodal misinformation has gained a widespread attention recently.","However, the potential of powerful Large Language Models (LLMs) for multimodal misinformation detection remains underexplored.","Besides, how to teach LLMs to interpret multimodal misinformation in cost-effective and accessible way is still an open question.","To address that, we propose MMIDR, a framework designed to teach LLMs in providing fluent and high-quality textual explanations for their decision-making process of multimodal misinformation.","To convert multimodal misinformation into an appropriate instruction-following format, we present a data augmentation perspective and pipeline.","This pipeline consists of a visual information processing module and an evidence retrieval module.","Subsequently, we prompt the proprietary LLMs with processed contents to extract rationales for interpreting the authenticity of multimodal misinformation.","Furthermore, we design an efficient knowledge distillation approach to distill the capability of proprietary LLMs in explaining multimodal misinformation into open-source LLMs.","To explore several research questions regarding the performance of LLMs in multimodal misinformation detection tasks, we construct an instruction-following multimodal misinformation dataset and conduct comprehensive experiments.","The experimental findings reveal that our MMIDR exhibits sufficient detection performance and possesses the capacity to provide compelling rationales to support its assessments."],"url":"http://arxiv.org/abs/2403.14171v1"}
{"created":"2024-03-21 06:32:36","title":"Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation","abstract":"Object-goal navigation is a crucial engineering task for the community of embodied navigation; it involves navigating to an instance of a specified object category within unseen environments. Although extensive investigations have been conducted on both end-to-end and modular-based, data-driven approaches, fully enabling an agent to comprehend the environment through perceptual knowledge and perform object-goal navigation as efficiently as humans remains a significant challenge. Recently, large language models have shown potential in this task, thanks to their powerful capabilities for knowledge extraction and integration. In this study, we propose a data-driven, modular-based approach, trained on a dataset that incorporates common-sense knowledge of object-to-room relationships extracted from a large language model. We utilize the multi-channel Swin-Unet architecture to conduct multi-task learning incorporating with multimodal inputs. The results in the Habitat simulator demonstrate that our framework outperforms the baseline by an average of 10.6% in the efficiency metric, Success weighted by Path Length (SPL). The real-world demonstration shows that the proposed approach can efficiently conduct this task by traversing several rooms. For more details and real-world demonstrations, please check our project webpage (https://sunleyuan.github.io/ObjectNav).","sentences":["Object-goal navigation is a crucial engineering task for the community of embodied navigation; it involves navigating to an instance of a specified object category within unseen environments.","Although extensive investigations have been conducted on both end-to-end and modular-based, data-driven approaches, fully enabling an agent to comprehend the environment through perceptual knowledge and perform object-goal navigation as efficiently as humans remains a significant challenge.","Recently, large language models have shown potential in this task, thanks to their powerful capabilities for knowledge extraction and integration.","In this study, we propose a data-driven, modular-based approach, trained on a dataset that incorporates common-sense knowledge of object-to-room relationships extracted from a large language model.","We utilize the multi-channel Swin-Unet architecture to conduct multi-task learning incorporating with multimodal inputs.","The results in the Habitat simulator demonstrate that our framework outperforms the baseline by an average of 10.6% in the efficiency metric, Success weighted by Path Length (SPL).","The real-world demonstration shows that the proposed approach can efficiently conduct this task by traversing several rooms.","For more details and real-world demonstrations, please check our project webpage (https://sunleyuan.github.io/ObjectNav)."],"url":"http://arxiv.org/abs/2403.14163v1"}
{"created":"2024-03-21 05:57:27","title":"Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond","abstract":"Trajectory computing is a pivotal domain encompassing trajectory data management and mining, garnering widespread attention due to its crucial role in various practical applications such as location services, urban traffic, and public safety. Traditional methods, focusing on simplistic spatio-temporal features, face challenges of complex calculations, limited scalability, and inadequate adaptability to real-world complexities. In this paper, we present a comprehensive review of the development and recent advances in deep learning for trajectory computing (DL4Traj). We first define trajectory data and provide a brief overview of widely-used deep learning models. Systematically, we explore deep learning applications in trajectory management (pre-processing, storage, analysis, and visualization) and mining (trajectory-related forecasting, trajectory-related recommendation, trajectory classification, travel time estimation, anomaly detection, and mobility generation). Notably, we encapsulate recent advancements in Large Language Models (LLMs) that hold the potential to augment trajectory computing. Additionally, we summarize application scenarios, public datasets, and toolkits. Finally, we outline current challenges in DL4Traj research and propose future directions. Relevant papers and open-source resources have been collated and are continuously updated at: \\href{https://github.com/yoshall/Awesome-Trajectory-Computing}{DL4Traj Repo}.","sentences":["Trajectory computing is a pivotal domain encompassing trajectory data management and mining, garnering widespread attention due to its crucial role in various practical applications such as location services, urban traffic, and public safety.","Traditional methods, focusing on simplistic spatio-temporal features, face challenges of complex calculations, limited scalability, and inadequate adaptability to real-world complexities.","In this paper, we present a comprehensive review of the development and recent advances in deep learning for trajectory computing (DL4Traj).","We first define trajectory data and provide a brief overview of widely-used deep learning models.","Systematically, we explore deep learning applications in trajectory management (pre-processing, storage, analysis, and visualization) and mining (trajectory-related forecasting, trajectory-related recommendation, trajectory classification, travel time estimation, anomaly detection, and mobility generation).","Notably, we encapsulate recent advancements in Large Language Models (LLMs) that hold the potential to augment trajectory computing.","Additionally, we summarize application scenarios, public datasets, and toolkits.","Finally, we outline current challenges in DL4Traj research and propose future directions.","Relevant papers and open-source resources have been collated and are continuously updated at: \\href{https://github.com/yoshall/Awesome-Trajectory-Computing}{DL4Traj Repo}."],"url":"http://arxiv.org/abs/2403.14151v1"}
{"created":"2024-03-21 05:17:22","title":"Genetic Programming for Explainable Manifold Learning","abstract":"Manifold learning techniques play a pivotal role in machine learning by revealing lower-dimensional embeddings within high-dimensional data, thus enhancing both the efficiency and interpretability of data analysis by transforming the data into a lower-dimensional representation. However, a notable challenge with current manifold learning methods is their lack of explicit functional mappings, crucial for explainability in many real-world applications. Genetic programming, known for its interpretable functional tree-based models, has emerged as a promising approach to address this challenge. Previous research leveraged multi-objective GP to balance manifold quality against embedding dimensionality, producing functional mappings across a range of embedding sizes. Yet, these mapping trees often became complex, hindering explainability. In response, in this paper, we introduce Genetic Programming for Explainable Manifold Learning (GP-EMaL), a novel approach that directly penalises tree complexity. Our new method is able to maintain high manifold quality while significantly enhancing explainability and also allows customisation of complexity measures, such as symmetry balancing, scaling, and node complexity, catering to diverse application needs. Our experimental analysis demonstrates that GP-EMaL is able to match the performance of the existing approach in most cases, while using simpler, smaller, and more interpretable tree structures. This advancement marks a significant step towards achieving interpretable manifold learning.","sentences":["Manifold learning techniques play a pivotal role in machine learning by revealing lower-dimensional embeddings within high-dimensional data, thus enhancing both the efficiency and interpretability of data analysis by transforming the data into a lower-dimensional representation.","However, a notable challenge with current manifold learning methods is their lack of explicit functional mappings, crucial for explainability in many real-world applications.","Genetic programming, known for its interpretable functional tree-based models, has emerged as a promising approach to address this challenge.","Previous research leveraged multi-objective GP to balance manifold quality against embedding dimensionality, producing functional mappings across a range of embedding sizes.","Yet, these mapping trees often became complex, hindering explainability.","In response, in this paper, we introduce Genetic Programming for Explainable Manifold Learning (GP-EMaL), a novel approach that directly penalises tree complexity.","Our new method is able to maintain high manifold quality while significantly enhancing explainability and also allows customisation of complexity measures, such as symmetry balancing, scaling, and node complexity, catering to diverse application needs.","Our experimental analysis demonstrates that GP-EMaL is able to match the performance of the existing approach in most cases, while using simpler, smaller, and more interpretable tree structures.","This advancement marks a significant step towards achieving interpretable manifold learning."],"url":"http://arxiv.org/abs/2403.14139v1"}
{"created":"2024-03-21 04:48:08","title":"Gen-T: Table Reclamation in Data Lakes","abstract":"We introduce the problem of Table Reclamation. Given a Source Table and a large table repository, reclamation finds a set of tables that, when integrated, reproduce the source table as closely as possible. Unlike query discovery problems like Query-by-Example or by-Target, Table Reclamation focuses on reclaiming the data in the Source Table as fully as possible using real tables that may be incomplete or inconsistent. To do this, we define a new measure of table similarity, called error-aware instance similarity, to measure how close a reclaimed table is to a Source Table, a measure grounded in instance similarity used in data exchange. Our search covers not only SELECT-PROJECT- JOIN queries, but integration queries with unions, outerjoins, and the unary operators subsumption and complementation that have been shown to be important in data integration and fusion. Using reclamation, a data scientist can understand if any tables in a repository can be used to exactly reclaim a tuple in the Source. If not, one can understand if this is due to differences in values or to incompleteness in the data. Our solution, Gen-T, performs table discovery to retrieve a set of candidate tables from the table repository, filters these down to a set of originating tables, then integrates these tables to reclaim the Source as closely as possible. We show that our solution, while approximate, is accurate, efficient and scalable in the size of the table repository with experiments on real data lakes containing up to 15K tables, where the average number of tuples varies from small (web tables) to extremely large (open data tables) up to 1M tuples.","sentences":["We introduce the problem of Table Reclamation.","Given a Source Table and a large table repository, reclamation finds a set of tables that, when integrated, reproduce the source table as closely as possible.","Unlike query discovery problems like Query-by-Example or by-Target, Table Reclamation focuses on reclaiming the data in the Source Table as fully as possible using real tables that may be incomplete or inconsistent.","To do this, we define a new measure of table similarity, called error-aware instance similarity, to measure how close a reclaimed table is to a Source Table, a measure grounded in instance similarity used in data exchange.","Our search covers not only SELECT-PROJECT- JOIN queries, but integration queries with unions, outerjoins, and the unary operators subsumption and complementation that have been shown to be important in data integration and fusion.","Using reclamation, a data scientist can understand if any tables in a repository can be used to exactly reclaim a tuple in the Source.","If not, one can understand if this is due to differences in values or to incompleteness in the data.","Our solution, Gen-T, performs table discovery to retrieve a set of candidate tables from the table repository, filters these down to a set of originating tables, then integrates these tables to reclaim the Source as closely as possible.","We show that our solution, while approximate, is accurate, efficient and scalable in the size of the table repository with experiments on real data lakes containing up to 15K tables, where the average number of tuples varies from small (web tables) to extremely large (open data tables) up to 1M tuples."],"url":"http://arxiv.org/abs/2403.14128v1"}
{"created":"2024-03-21 04:31:59","title":"AI and Memory Wall","abstract":"The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training LLMs. However, the main performance bottleneck is increasingly shifting to memory bandwidth. Over the past 20 years, peak server hardware FLOPS has been scaling at 3.0x/2yrs, outpacing the growth of DRAM and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every 2 years, respectively. This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving. Here, we analyze encoder and decoder Transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models. We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation.","sentences":["The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training LLMs.","However, the main performance bottleneck is increasingly shifting to memory bandwidth.","Over the past 20 years, peak server hardware FLOPS has been scaling at 3.0x/2yrs, outpacing the growth of DRAM and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every 2 years, respectively.","This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving.","Here, we analyze encoder and decoder Transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models.","We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation."],"url":"http://arxiv.org/abs/2403.14123v1"}
{"created":"2024-03-21 04:15:56","title":"Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning","abstract":"The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of interconnected smart devices where data-driven insights and machine learning (ML) fuse to revolutionize manufacturing. A noteworthy development in IIoT is the integration of federated learning (FL), which addresses data privacy and security among devices. FL enables edge sensors, also known as peripheral intelligence units (PIUs) to learn and adapt using their data locally, without explicit sharing of confidential data, to facilitate a collaborative yet confidential learning process. However, the lower memory footprint and computational power of PIUs inherently require deep neural network (DNN) models that have a very compact size. Model compression techniques such as pruning can be used to reduce the size of DNN models by removing unnecessary connections that have little impact on the model's performance, thus making the models more suitable for the limited resources of PIUs. Targeting the notion of compact yet robust DNN models, we propose the integration of iterative magnitude pruning (IMP) of the DNN model being trained in an over-the-air FL (OTA-FL) environment for IIoT. We provide a tutorial overview and also present a case study of the effectiveness of IMP in OTA-FL for an IIoT environment. Finally, we present future directions for enhancing and optimizing these deep compression techniques further, aiming to push the boundaries of IIoT capabilities in acquiring compact yet robust and high-performing DNN models.","sentences":["The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of interconnected smart devices where data-driven insights and machine learning (ML) fuse to revolutionize manufacturing.","A noteworthy development in IIoT is the integration of federated learning (FL), which addresses data privacy and security among devices.","FL enables edge sensors, also known as peripheral intelligence units (PIUs) to learn and adapt using their data locally, without explicit sharing of confidential data, to facilitate a collaborative yet confidential learning process.","However, the lower memory footprint and computational power of PIUs inherently require deep neural network (DNN) models that have a very compact size.","Model compression techniques such as pruning can be used to reduce the size of DNN models by removing unnecessary connections that have little impact on the model's performance, thus making the models more suitable for the limited resources of PIUs.","Targeting the notion of compact yet robust DNN models, we propose the integration of iterative magnitude pruning (IMP) of the DNN model being trained in an over-the-air FL (OTA-FL) environment for IIoT. We provide a tutorial overview and also present a case study of the effectiveness of IMP in OTA-FL for an IIoT environment.","Finally, we present future directions for enhancing and optimizing these deep compression techniques further, aiming to push the boundaries of IIoT capabilities in acquiring compact yet robust and high-performing DNN models."],"url":"http://arxiv.org/abs/2403.14120v1"}
{"created":"2024-03-21 04:08:29","title":"C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion","abstract":"In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration-a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion (ATFD), we establish its relationship with calibration error and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT), for optimizing prompts during test-time with enhanced calibration. Through extensive experiments on different CLIP architectures and datasets, we show that C-TPT can effectively improve the calibration of test-time prompt tuning without needing labeled data.","sentences":["In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data.","A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP.","Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration-a crucial aspect for quantifying prediction uncertainty.","However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios.","To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP.","Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions.","Introducing the Average Text Feature Dispersion (ATFD), we establish its relationship with calibration error and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT), for optimizing prompts during test-time with enhanced calibration.","Through extensive experiments on different CLIP architectures and datasets, we show that C-TPT can effectively improve the calibration of test-time prompt tuning without needing labeled data."],"url":"http://arxiv.org/abs/2403.14119v1"}
{"created":"2024-03-21 04:01:26","title":"Training point-based deep learning networks for forest segmentation with synthetic data","abstract":"Remote sensing through unmanned aerial systems (UAS) has been increasing in forestry in recent years, along with using machine learning for data processing. Deep learning architectures, extensively applied in natural language and image processing, have recently been extended to the point cloud domain. However, the availability of point cloud datasets for training and testing remains limited. Creating forested environment point cloud datasets is expensive, requires high-precision sensors, and is time-consuming as manual point classification is required. Moreover, forest areas could be inaccessible or dangerous for humans, further complicating data collection. Then, a question arises whether it is possible to use synthetic data to train deep learning networks without the need to rely on large volumes of real forest data. To answer this question, we developed a realistic simulator that procedurally generates synthetic forest scenes. Thanks to this, we have conducted a comparative study of different state-of-the-art point-based deep learning networks for forest segmentation. Using created datasets, we determined the feasibility of using synthetic data to train deep learning networks to classify point clouds from real forest datasets. Both the simulator and the datasets are released as part of this work.","sentences":["Remote sensing through unmanned aerial systems (UAS) has been increasing in forestry in recent years, along with using machine learning for data processing.","Deep learning architectures, extensively applied in natural language and image processing, have recently been extended to the point cloud domain.","However, the availability of point cloud datasets for training and testing remains limited.","Creating forested environment point cloud datasets is expensive, requires high-precision sensors, and is time-consuming as manual point classification is required.","Moreover, forest areas could be inaccessible or dangerous for humans, further complicating data collection.","Then, a question arises whether it is possible to use synthetic data to train deep learning networks without the need to rely on large volumes of real forest data.","To answer this question, we developed a realistic simulator that procedurally generates synthetic forest scenes.","Thanks to this, we have conducted a comparative study of different state-of-the-art point-based deep learning networks for forest segmentation.","Using created datasets, we determined the feasibility of using synthetic data to train deep learning networks to classify point clouds from real forest datasets.","Both the simulator and the datasets are released as part of this work."],"url":"http://arxiv.org/abs/2403.14115v1"}
{"created":"2024-03-21 03:58:27","title":"Test-time Similarity Modification for Person Re-identification toward Temporal Distribution Shift","abstract":"Person re-identification (re-id), which aims to retrieve images of the same person in a given image from a database, is one of the most practical image recognition applications. In the real world, however, the environments that the images are taken from change over time. This causes a distribution shift between training and testing and degrades the performance of re-id. To maintain re-id performance, models should continue adapting to the test environment's temporal changes. Test-time adaptation (TTA), which aims to adapt models to the test environment with only unlabeled test data, is a promising way to handle this problem because TTA can adapt models instantly in the test environment. However, the previous TTA methods are designed for classification and cannot be directly applied to re-id. This is because the set of people's identities in the dataset differs between training and testing in re-id, whereas the set of classes is fixed in the current TTA methods designed for classification. To improve re-id performance in changing test environments, we propose TEst-time similarity Modification for Person re-identification (TEMP), a novel TTA method for re-id. TEMP is the first fully TTA method for re-id, which does not require any modification to pre-training. Inspired by TTA methods that refine the prediction uncertainty in classification, we aim to refine the uncertainty in re-id. However, the uncertainty cannot be computed in the same way as classification in re-id since it is an open-set task, which does not share person labels between training and testing. Hence, we propose re-id entropy, an alternative uncertainty measure for re-id computed based on the similarity between the feature vectors. Experiments show that the re-id entropy can measure the uncertainty on re-id and TEMP improves the performance of re-id in online settings where the distribution changes over time.","sentences":["Person re-identification (re-id), which aims to retrieve images of the same person in a given image from a database, is one of the most practical image recognition applications.","In the real world, however, the environments that the images are taken from change over time.","This causes a distribution shift between training and testing and degrades the performance of re-id.","To maintain re-id performance, models should continue adapting to the test environment's temporal changes.","Test-time adaptation (TTA), which aims to adapt models to the test environment with only unlabeled test data, is a promising way to handle this problem because TTA can adapt models instantly in the test environment.","However, the previous TTA methods are designed for classification and cannot be directly applied to re-id.","This is because the set of people's identities in the dataset differs between training and testing in re-id, whereas the set of classes is fixed in the current TTA methods designed for classification.","To improve re-id performance in changing test environments, we propose TEst-time similarity Modification for Person re-identification (TEMP), a novel TTA method for re-id.","TEMP is the first fully TTA method for re-id, which does not require any modification to pre-training.","Inspired by TTA methods that refine the prediction uncertainty in classification, we aim to refine the uncertainty in re-id.","However, the uncertainty cannot be computed in the same way as classification in re-id since it is an open-set task, which does not share person labels between training and testing.","Hence, we propose re-id entropy, an alternative uncertainty measure for re-id computed based on the similarity between the feature vectors.","Experiments show that the re-id entropy can measure the uncertainty on re-id and TEMP improves the performance of re-id in online settings where the distribution changes over time."],"url":"http://arxiv.org/abs/2403.14114v1"}
{"created":"2024-03-21 03:47:26","title":"HETAL: Efficient Privacy-preserving Transfer Learning with Homomorphic Encryption","abstract":"Transfer learning is a de facto standard method for efficiently training machine learning models for data-scarce problems by adding and fine-tuning new classification layers to a model pre-trained on large datasets. Although numerous previous studies proposed to use homomorphic encryption to resolve the data privacy issue in transfer learning in the machine learning as a service setting, most of them only focused on encrypted inference. In this study, we present HETAL, an efficient Homomorphic Encryption based Transfer Learning algorithm, that protects the client's privacy in training tasks by encrypting the client data using the CKKS homomorphic encryption scheme. HETAL is the first practical scheme that strictly provides encrypted training, adopting validation-based early stopping and achieving the accuracy of nonencrypted training. We propose an efficient encrypted matrix multiplication algorithm, which is 1.8 to 323 times faster than prior methods, and a highly precise softmax approximation algorithm with increased coverage. The experimental results for five well-known benchmark datasets show total training times of 567-3442 seconds, which is less than an hour.","sentences":["Transfer learning is a de facto standard method for efficiently training machine learning models for data-scarce problems by adding and fine-tuning new classification layers to a model pre-trained on large datasets.","Although numerous previous studies proposed to use homomorphic encryption to resolve the data privacy issue in transfer learning in the machine learning as a service setting, most of them only focused on encrypted inference.","In this study, we present HETAL, an efficient Homomorphic Encryption based Transfer Learning algorithm, that protects the client's privacy in training tasks by encrypting the client data using the CKKS homomorphic encryption scheme.","HETAL is the first practical scheme that strictly provides encrypted training, adopting validation-based early stopping and achieving the accuracy of nonencrypted training.","We propose an efficient encrypted matrix multiplication algorithm, which is 1.8 to 323 times faster than prior methods, and a highly precise softmax approximation algorithm with increased coverage.","The experimental results for five well-known benchmark datasets show total training times of 567-3442 seconds, which is less than an hour."],"url":"http://arxiv.org/abs/2403.14111v1"}
{"created":"2024-03-21 03:34:18","title":"Existence Is Chaos: Enhancing 3D Human Motion Prediction with Uncertainty Consideration","abstract":"Human motion prediction is consisting in forecasting future body poses from historically observed sequences. It is a longstanding challenge due to motion's complex dynamics and uncertainty. Existing methods focus on building up complicated neural networks to model the motion dynamics. The predicted results are required to be strictly similar to the training samples with L2 loss in current training pipeline. However, little attention has been paid to the uncertainty property which is crucial to the prediction task. We argue that the recorded motion in training data could be an observation of possible future, rather than a predetermined result. In addition, existing works calculate the predicted error on each future frame equally during training, while recent work indicated that different frames could play different roles. In this work, a novel computationally efficient encoder-decoder model with uncertainty consideration is proposed, which could learn proper characteristics for future frames by a dynamic function. Experimental results on benchmark datasets demonstrate that our uncertainty consideration approach has obvious advantages both in quantity and quality. Moreover, the proposed method could produce motion sequences with much better quality that avoids the intractable shaking artefacts. We believe our work could provide a novel perspective to consider the uncertainty quality for the general motion prediction task and encourage the studies in this field. The code will be available in https://github.com/Motionpre/Adaptive-Salient-Loss-SAGGB.","sentences":["Human motion prediction is consisting in forecasting future body poses from historically observed sequences.","It is a longstanding challenge due to motion's complex dynamics and uncertainty.","Existing methods focus on building up complicated neural networks to model the motion dynamics.","The predicted results are required to be strictly similar to the training samples with L2 loss in current training pipeline.","However, little attention has been paid to the uncertainty property which is crucial to the prediction task.","We argue that the recorded motion in training data could be an observation of possible future, rather than a predetermined result.","In addition, existing works calculate the predicted error on each future frame equally during training, while recent work indicated that different frames could play different roles.","In this work, a novel computationally efficient encoder-decoder model with uncertainty consideration is proposed, which could learn proper characteristics for future frames by a dynamic function.","Experimental results on benchmark datasets demonstrate that our uncertainty consideration approach has obvious advantages both in quantity and quality.","Moreover, the proposed method could produce motion sequences with much better quality that avoids the intractable shaking artefacts.","We believe our work could provide a novel perspective to consider the uncertainty quality for the general motion prediction task and encourage the studies in this field.","The code will be available in https://github.com/Motionpre/Adaptive-Salient-Loss-SAGGB."],"url":"http://arxiv.org/abs/2403.14104v1"}
{"created":"2024-03-21 03:24:01","title":"Text-Enhanced Data-free Approach for Federated Class-Incremental Learning","abstract":"Federated Class-Incremental Learning (FCIL) is an underexplored yet pivotal issue, involving the dynamic addition of new classes in the context of federated learning. In this field, Data-Free Knowledge Transfer (DFKT) plays a crucial role in addressing catastrophic forgetting and data privacy problems. However, prior approaches lack the crucial synergy between DFKT and the model training phases, causing DFKT to encounter difficulties in generating high-quality data from a non-anchored latent space of the old task model. In this paper, we introduce LANDER (Label Text Centered Data-Free Knowledge Transfer) to address this issue by utilizing label text embeddings (LTE) produced by pretrained language models. Specifically, during the model training phase, our approach treats LTE as anchor points and constrains the feature embeddings of corresponding training samples around them, enriching the surrounding area with more meaningful information. In the DFKT phase, by using these LTE anchors, LANDER can synthesize more meaningful samples, thereby effectively addressing the forgetting problem. Additionally, instead of tightly constraining embeddings toward the anchor, the Bounding Loss is introduced to encourage sample embeddings to remain flexible within a defined radius. This approach preserves the natural differences in sample embeddings and mitigates the embedding overlap caused by heterogeneous federated settings. Extensive experiments conducted on CIFAR100, Tiny-ImageNet, and ImageNet demonstrate that LANDER significantly outperforms previous methods and achieves state-of-the-art performance in FCIL. The code is available at https://github.com/tmtuan1307/lander.","sentences":["Federated Class-Incremental Learning (FCIL) is an underexplored yet pivotal issue, involving the dynamic addition of new classes in the context of federated learning.","In this field, Data-Free Knowledge Transfer (DFKT) plays a crucial role in addressing catastrophic forgetting and data privacy problems.","However, prior approaches lack the crucial synergy between DFKT and the model training phases, causing DFKT to encounter difficulties in generating high-quality data from a non-anchored latent space of the old task model.","In this paper, we introduce LANDER (Label Text Centered Data-Free Knowledge Transfer) to address this issue by utilizing label text embeddings (LTE) produced by pretrained language models.","Specifically, during the model training phase, our approach treats LTE as anchor points and constrains the feature embeddings of corresponding training samples around them, enriching the surrounding area with more meaningful information.","In the DFKT phase, by using these LTE anchors, LANDER can synthesize more meaningful samples, thereby effectively addressing the forgetting problem.","Additionally, instead of tightly constraining embeddings toward the anchor, the Bounding Loss is introduced to encourage sample embeddings to remain flexible within a defined radius.","This approach preserves the natural differences in sample embeddings and mitigates the embedding overlap caused by heterogeneous federated settings.","Extensive experiments conducted on CIFAR100, Tiny-ImageNet, and ImageNet demonstrate that LANDER significantly outperforms previous methods and achieves state-of-the-art performance in FCIL.","The code is available at https://github.com/tmtuan1307/lander."],"url":"http://arxiv.org/abs/2403.14101v1"}
{"created":"2024-03-21 03:23:34","title":"Causal knowledge engineering: A case study from COVID-19","abstract":"COVID-19 appeared abruptly in early 2020, requiring a rapid response amid a context of great uncertainty. Good quality data and knowledge was initially lacking, and many early models had to be developed with causal assumptions and estimations built in to supplement limited data, often with no reliable approach for identifying, validating and documenting these causal assumptions. Our team embarked on a knowledge engineering process to develop a causal knowledge base consisting of several causal BNs for diverse aspects of COVID-19. The unique challenges of the setting lead to experiments with the elicitation approach, and what emerged was a knowledge engineering method we call Causal Knowledge Engineering (CKE). The CKE provides a structured approach for building a causal knowledge base that can support the development of a variety of application-specific models. Here we describe the CKE method, and use our COVID-19 work as a case study to provide a detailed discussion and analysis of the method.","sentences":["COVID-19 appeared abruptly in early 2020, requiring a rapid response amid a context of great uncertainty.","Good quality data and knowledge was initially lacking, and many early models had to be developed with causal assumptions and estimations built in to supplement limited data, often with no reliable approach for identifying, validating and documenting these causal assumptions.","Our team embarked on a knowledge engineering process to develop a causal knowledge base consisting of several causal BNs for diverse aspects of COVID-19.","The unique challenges of the setting lead to experiments with the elicitation approach, and what emerged was a knowledge engineering method we call Causal Knowledge Engineering (CKE).","The CKE provides a structured approach for building a causal knowledge base that can support the development of a variety of application-specific models.","Here we describe the CKE method, and use our COVID-19 work as a case study to provide a detailed discussion and analysis of the method."],"url":"http://arxiv.org/abs/2403.14100v1"}
{"created":"2024-03-21 03:01:25","title":"Science based AI model certification for untrained operational environments with application in traffic state estimation","abstract":"The expanding role of Artificial Intelligence (AI) in diverse engineering domains highlights the challenges associated with deploying AI models in new operational environments, involving substantial investments in data collection and model training. Rapid application of AI necessitates evaluating the feasibility of utilizing pre-trained models in unobserved operational settings with minimal or no additional data. However, interpreting the opaque nature of AI's black-box models remains a persistent challenge. Addressing this issue, this paper proposes a science-based certification methodology to assess the viability of employing pre-trained data-driven models in untrained operational environments. The methodology advocates a profound integration of domain knowledge, leveraging theoretical and analytical models from physics and related disciplines, with data-driven AI models. This novel approach introduces tools to facilitate the development of secure engineering systems, providing decision-makers with confidence in the trustworthiness and safety of AI-based models across diverse environments characterized by limited training data and dynamic, uncertain conditions. The paper demonstrates the efficacy of this methodology in real-world safety-critical scenarios, particularly in the context of traffic state estimation. Through simulation results, the study illustrates how the proposed methodology efficiently quantifies physical inconsistencies exhibited by pre-trained AI models. By utilizing analytical models, the methodology offers a means to gauge the applicability of pre-trained AI models in new operational environments. This research contributes to advancing the understanding and deployment of AI models, offering a robust certification framework that enhances confidence in their reliability and safety across a spectrum of operational conditions.","sentences":["The expanding role of Artificial Intelligence (AI) in diverse engineering domains highlights the challenges associated with deploying AI models in new operational environments, involving substantial investments in data collection and model training.","Rapid application of AI necessitates evaluating the feasibility of utilizing pre-trained models in unobserved operational settings with minimal or no additional data.","However, interpreting the opaque nature of AI's black-box models remains a persistent challenge.","Addressing this issue, this paper proposes a science-based certification methodology to assess the viability of employing pre-trained data-driven models in untrained operational environments.","The methodology advocates a profound integration of domain knowledge, leveraging theoretical and analytical models from physics and related disciplines, with data-driven AI models.","This novel approach introduces tools to facilitate the development of secure engineering systems, providing decision-makers with confidence in the trustworthiness and safety of AI-based models across diverse environments characterized by limited training data and dynamic, uncertain conditions.","The paper demonstrates the efficacy of this methodology in real-world safety-critical scenarios, particularly in the context of traffic state estimation.","Through simulation results, the study illustrates how the proposed methodology efficiently quantifies physical inconsistencies exhibited by pre-trained AI models.","By utilizing analytical models, the methodology offers a means to gauge the applicability of pre-trained AI models in new operational environments.","This research contributes to advancing the understanding and deployment of AI models, offering a robust certification framework that enhances confidence in their reliability and safety across a spectrum of operational conditions."],"url":"http://arxiv.org/abs/2403.14093v1"}
{"created":"2024-03-21 02:59:56","title":"Carbon Footprint Reduction for Sustainable Data Centers in Real-Time","abstract":"As machine learning workloads significantly increase energy consumption, sustainable data centers with low carbon emissions are becoming a top priority for governments and corporations worldwide. This requires a paradigm shift in optimizing power consumption in cooling and IT loads, shifting flexible loads based on the availability of renewable energy in the power grid, and leveraging battery storage from the uninterrupted power supply in data centers, using collaborative agents. The complex association between these optimization strategies and their dependencies on variable external factors like weather and the power grid carbon intensity makes this a hard problem. Currently, a real-time controller to optimize all these goals simultaneously in a dynamic real-world setting is lacking. We propose a Data Center Carbon Footprint Reduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that optimizes data centers for the multiple objectives of carbon footprint reduction, energy consumption, and energy cost. The results show that the DC-CFR MARL agents effectively resolved the complex interdependencies in optimizing cooling, load shifting, and energy storage in real-time for various locations under real-world dynamic weather and grid carbon intensity conditions. DC-CFR significantly outperformed the industry standard ASHRAE controller with a considerable reduction in carbon emissions (14.5%), energy usage (14.4%), and energy cost (13.7%) when evaluated over one year across multiple geographical regions.","sentences":["As machine learning workloads significantly increase energy consumption, sustainable data centers with low carbon emissions are becoming a top priority for governments and corporations worldwide.","This requires a paradigm shift in optimizing power consumption in cooling and IT loads, shifting flexible loads based on the availability of renewable energy in the power grid, and leveraging battery storage from the uninterrupted power supply in data centers, using collaborative agents.","The complex association between these optimization strategies and their dependencies on variable external factors like weather and the power grid carbon intensity makes this a hard problem.","Currently, a real-time controller to optimize all these goals simultaneously in a dynamic real-world setting is lacking.","We propose a Data Center Carbon Footprint Reduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that optimizes data centers for the multiple objectives of carbon footprint reduction, energy consumption, and energy cost.","The results show that the DC-CFR MARL agents effectively resolved the complex interdependencies in optimizing cooling, load shifting, and energy storage in real-time for various locations under real-world dynamic weather and grid carbon intensity conditions.","DC-CFR significantly outperformed the industry standard ASHRAE controller with a considerable reduction in carbon emissions (14.5%), energy usage (14.4%), and energy cost (13.7%) when evaluated over one year across multiple geographical regions."],"url":"http://arxiv.org/abs/2403.14092v1"}
{"created":"2024-03-21 02:43:37","title":"Improved Algorithms for Maximum Coverage in Dynamic and Random Order Streams","abstract":"The maximum coverage problem is to select $k$ sets from a collection of sets such that the cardinality of the union of the selected sets is maximized. We consider $(1-1/e-\\epsilon)$-approximation algorithms for this NP-hard problem in three standard data stream models.   1. {\\em Dynamic Model.} The stream consists of a sequence of sets being inserted and deleted. Our multi-pass algorithm uses $\\epsilon^{-2} k \\cdot \\text{polylog}(n,m)$ space. The best previous result (Assadi and Khanna, SODA 2018) used $(n +\\epsilon^{-4} k) \\text{polylog}(n,m)$ space. While both algorithms use $O(\\epsilon^{-1} \\log n)$ passes, our analysis shows that when $\\epsilon$ is a constant, it is possible to reduce the number of passes by a $1/\\log \\log n$ factor without incurring additional space.   2. {\\em Random Order Model.} In this model, there are no deletions and the sets forming the instance are uniformly randomly permuted to form the input stream. We show that a single pass and $k \\text{polylog}(n,m)$ space suffices for arbitrary small constant $\\epsilon$. The best previous result, by Warneke et al.~(ESA 2023), used $k^2 \\text{polylog}(n,m)$ space.   3. {\\em Insert-Only Model.} Lastly, our results, along with numerous previous results, use a sub-sampling technique introduced by McGregor and Vu (ICDT 2017) to sparsify the input instance. We explain how this technique and others used in the paper can be implemented such that the amortized update time of our algorithm is polylogarithmic. This also implies an improvement of the state-of-the-art insert only algorithms in terms of the update time: $\\text{polylog}(m,n)$ update time suffices whereas the best previous result by Jaud et al.~(SEA 2023) required update time that was linear in $k$.","sentences":["The maximum coverage problem is to select $k$ sets from a collection of sets such that the cardinality of the union of the selected sets is maximized.","We consider $(1-1/e-\\epsilon)$-approximation algorithms for this NP-hard problem in three standard data stream models.   ","1.","{\\em Dynamic Model.}","The stream consists of a sequence of sets being inserted and deleted.","Our multi-pass algorithm uses $\\epsilon^{-2} k \\cdot \\text{polylog}(n,m)$ space.","The best previous result (Assadi and Khanna, SODA 2018) used $(n +\\epsilon^{-4} k) \\text{polylog}(n,m)$ space.","While both algorithms use $O(\\epsilon^{-1} \\log n)$ passes, our analysis shows that when $\\epsilon$ is a constant, it is possible to reduce the number of passes by a $1/\\log \\log n$ factor without incurring additional space.   ","2. {\\em Random Order Model.}","In this model, there are no deletions and the sets forming the instance are uniformly randomly permuted to form the input stream.","We show that a single pass and $k \\text{polylog}(n,m)$ space suffices for arbitrary small constant $\\epsilon$. The best previous result, by Warneke et al.~(ESA 2023), used $k^2 \\text{polylog}(n,m)$ space.   ","3. {\\em Insert-Only Model.}","Lastly, our results, along with numerous previous results, use a sub-sampling technique introduced by McGregor and Vu (ICDT 2017) to sparsify the input instance.","We explain how this technique and others used in the paper can be implemented such that the amortized update time of our algorithm is polylogarithmic.","This also implies an improvement of the state-of-the-art insert only algorithms in terms of the update time: $\\text{polylog}(m,n)$ update time suffices whereas the best previous result by Jaud et al.~(SEA 2023) required update time that was linear in $k$."],"url":"http://arxiv.org/abs/2403.14087v1"}
{"created":"2024-03-21 02:19:54","title":"EventDance: Unsupervised Source-free Cross-modal Adaptation for Event-based Object Recognition","abstract":"In this paper, we make the first attempt at achieving the cross-modal (i.e., image-to-events) adaptation for event-based object recognition without accessing any labeled source image data owning to privacy and commercial issues. Tackling this novel problem is non-trivial due to the novelty of event cameras and the distinct modality gap between images and events. In particular, as only the source model is available, a hurdle is how to extract the knowledge from the source model by only using the unlabeled target event data while achieving knowledge transfer. To this end, we propose a novel framework, dubbed EventDance for this unsupervised source-free cross-modal adaptation problem. Importantly, inspired by event-to-video reconstruction methods, we propose a reconstruction-based modality bridging (RMB) module, which reconstructs intensity frames from events in a self-supervised manner. This makes it possible to build up the surrogate images to extract the knowledge (i.e., labels) from the source model. We then propose a multi-representation knowledge adaptation (MKA) module that transfers the knowledge to target models learning events with multiple representation types for fully exploring the spatiotemporal information of events. The two modules connecting the source and target models are mutually updated so as to achieve the best performance. Experiments on three benchmark datasets with two adaption settings show that EventDance is on par with prior methods utilizing the source data.","sentences":["In this paper, we make the first attempt at achieving the cross-modal (i.e., image-to-events) adaptation for event-based object recognition without accessing any labeled source image data owning to privacy and commercial issues.","Tackling this novel problem is non-trivial due to the novelty of event cameras and the distinct modality gap between images and events.","In particular, as only the source model is available, a hurdle is how to extract the knowledge from the source model by only using the unlabeled target event data while achieving knowledge transfer.","To this end, we propose a novel framework, dubbed EventDance for this unsupervised source-free cross-modal adaptation problem.","Importantly, inspired by event-to-video reconstruction methods, we propose a reconstruction-based modality bridging (RMB) module, which reconstructs intensity frames from events in a self-supervised manner.","This makes it possible to build up the surrogate images to extract the knowledge (i.e., labels) from the source model.","We then propose a multi-representation knowledge adaptation (MKA) module that transfers the knowledge to target models learning events with multiple representation types for fully exploring the spatiotemporal information of events.","The two modules connecting the source and target models are mutually updated so as to achieve the best performance.","Experiments on three benchmark datasets with two adaption settings show that EventDance is on par with prior methods utilizing the source data."],"url":"http://arxiv.org/abs/2403.14082v1"}
{"created":"2024-03-21 01:52:07","title":"M3: A Multi-Task Mixed-Objective Learning Framework for Open-Domain Multi-Hop Dense Sentence Retrieval","abstract":"In recent research, contrastive learning has proven to be a highly effective method for representation learning and is widely used for dense retrieval. However, we identify that relying solely on contrastive learning can lead to suboptimal retrieval performance. On the other hand, despite many retrieval datasets supporting various learning objectives beyond contrastive learning, combining them efficiently in multi-task learning scenarios can be challenging. In this paper, we introduce M3, an advanced recursive Multi-hop dense sentence retrieval system built upon a novel Multi-task Mixed-objective approach for dense text representation learning, addressing the aforementioned challenges. Our approach yields state-of-the-art performance on a large-scale open-domain fact verification benchmark dataset, FEVER. Code and data are available at: https://github.com/TonyBY/M3","sentences":["In recent research, contrastive learning has proven to be a highly effective method for representation learning and is widely used for dense retrieval.","However, we identify that relying solely on contrastive learning can lead to suboptimal retrieval performance.","On the other hand, despite many retrieval datasets supporting various learning objectives beyond contrastive learning, combining them efficiently in multi-task learning scenarios can be challenging.","In this paper, we introduce M3, an advanced recursive Multi-hop dense sentence retrieval system built upon a novel Multi-task Mixed-objective approach for dense text representation learning, addressing the aforementioned challenges.","Our approach yields state-of-the-art performance on a large-scale open-domain fact verification benchmark dataset, FEVER.","Code and data are available at: https://github.com/TonyBY/M3"],"url":"http://arxiv.org/abs/2403.14074v1"}
{"created":"2024-03-21 01:47:22","title":"A Taxonomy of Ambiguity Types for NLP","abstract":"Ambiguity is an critical component of language that allows for more effective communication between speakers, but is often ignored in NLP. Recent work suggests that NLP systems may struggle to grasp certain elements of human language understanding because they may not handle ambiguities at the level that humans naturally do in communication. Additionally, different types of ambiguity may serve different purposes and require different approaches for resolution, and we aim to investigate how language models' abilities vary across types. We propose a taxonomy of ambiguity types as seen in English to facilitate NLP analysis. Our taxonomy can help make meaningful splits in language ambiguity data, allowing for more fine-grained assessments of both datasets and model performance.","sentences":["Ambiguity is an critical component of language that allows for more effective communication between speakers, but is often ignored in NLP.","Recent work suggests that NLP systems may struggle to grasp certain elements of human language understanding because they may not handle ambiguities at the level that humans naturally do in communication.","Additionally, different types of ambiguity may serve different purposes and require different approaches for resolution, and we aim to investigate how language models' abilities vary across types.","We propose a taxonomy of ambiguity types as seen in English to facilitate NLP analysis.","Our taxonomy can help make meaningful splits in language ambiguity data, allowing for more fine-grained assessments of both datasets and model performance."],"url":"http://arxiv.org/abs/2403.14072v1"}
{"created":"2024-03-21 01:35:03","title":"Sampling Audit Evidence Using a Naive Bayes Classifier","abstract":"Taiwan's auditors have suffered from processing excessive audit data, including drawing audit evidence. This study advances sampling techniques by integrating machine learning with sampling. This machine learning integration helps avoid sampling bias, keep randomness and variability, and target risker samples. We first classify data using a Naive Bayes classifier into some classes. Next, a user-based, item-based, or hybrid approach is employed to draw audit evidence. The representativeness index is the primary metric for measuring its representativeness. The user-based approach samples data symmetric around the median of a class as audit evidence. It may be equivalent to a combination of monetary and variable samplings. The item-based approach represents asymmetric sampling based on posterior probabilities for obtaining risky samples as audit evidence. It may be identical to a combination of non-statistical and monetary samplings. Auditors can hybridize those user-based and item-based approaches to balance representativeness and riskiness in selecting audit evidence. Three experiments show that sampling using machine learning integration has the benefits of drawing unbiased samples, handling complex patterns, correlations, and unstructured data, and improving efficiency in sampling big data. However, the limitations are the classification accuracy output by machine learning algorithms and the range of prior probabilities.","sentences":["Taiwan's auditors have suffered from processing excessive audit data, including drawing audit evidence.","This study advances sampling techniques by integrating machine learning with sampling.","This machine learning integration helps avoid sampling bias, keep randomness and variability, and target risker samples.","We first classify data using a Naive Bayes classifier into some classes.","Next, a user-based, item-based, or hybrid approach is employed to draw audit evidence.","The representativeness index is the primary metric for measuring its representativeness.","The user-based approach samples data symmetric around the median of a class as audit evidence.","It may be equivalent to a combination of monetary and variable samplings.","The item-based approach represents asymmetric sampling based on posterior probabilities for obtaining risky samples as audit evidence.","It may be identical to a combination of non-statistical and monetary samplings.","Auditors can hybridize those user-based and item-based approaches to balance representativeness and riskiness in selecting audit evidence.","Three experiments show that sampling using machine learning integration has the benefits of drawing unbiased samples, handling complex patterns, correlations, and unstructured data, and improving efficiency in sampling big data.","However, the limitations are the classification accuracy output by machine learning algorithms and the range of prior probabilities."],"url":"http://arxiv.org/abs/2403.14069v1"}
{"created":"2024-03-21 01:20:32","title":"DiffSTOCK: Probabilistic relational Stock Market Predictions using Diffusion Models","abstract":"In this work, we propose an approach to generalize denoising diffusion probabilistic models for stock market predictions and portfolio management. Present works have demonstrated the efficacy of modeling interstock relations for market time-series forecasting and utilized Graph-based learning models for value prediction and portfolio management. Though convincing, these deterministic approaches still fall short of handling uncertainties i.e., due to the low signal-to-noise ratio of the financial data, it is quite challenging to learn effective deterministic models. Since the probabilistic methods have shown to effectively emulate higher uncertainties for time-series predictions. To this end, we showcase effective utilisation of Denoising Diffusion Probabilistic Models (DDPM), to develop an architecture for providing better market predictions conditioned on the historical financial indicators and inter-stock relations. Additionally, we also provide a novel deterministic architecture MaTCHS which uses Masked Relational Transformer(MRT) to exploit inter-stock relations along with historical stock features. We demonstrate that our model achieves SOTA performance for movement predication and Portfolio management.","sentences":["In this work, we propose an approach to generalize denoising diffusion probabilistic models for stock market predictions and portfolio management.","Present works have demonstrated the efficacy of modeling interstock relations for market time-series forecasting and utilized Graph-based learning models for value prediction and portfolio management.","Though convincing, these deterministic approaches still fall short of handling uncertainties i.e., due to the low signal-to-noise ratio of the financial data, it is quite challenging to learn effective deterministic models.","Since the probabilistic methods have shown to effectively emulate higher uncertainties for time-series predictions.","To this end, we showcase effective utilisation of Denoising Diffusion Probabilistic Models (DDPM), to develop an architecture for providing better market predictions conditioned on the historical financial indicators and inter-stock relations.","Additionally, we also provide a novel deterministic architecture MaTCHS which uses Masked Relational Transformer(MRT) to exploit inter-stock relations along with historical stock features.","We demonstrate that our model achieves SOTA performance for movement predication and Portfolio management."],"url":"http://arxiv.org/abs/2403.14063v1"}
{"created":"2024-03-21 01:06:47","title":"Hypothesis-Driven Deep Learning for Out of Distribution Detection","abstract":"Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare. For such applications, it is crucial to assess how models handle samples beyond the domain of training data. While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use. In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD. Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses. We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothesis. We adapt our method to detect an unseen sample of bacteria to a trained deep learning model, and show that it reveals interpretable differences between InD and OoD latent responses. Our work has implications for systematic novelty detection and informed decision-making from classifiers trained on a subset of labels.","sentences":["Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare.","For such applications, it is crucial to assess how models handle samples beyond the domain of training data.","While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use.","In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD.","Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses.","We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothesis.","We adapt our method to detect an unseen sample of bacteria to a trained deep learning model, and show that it reveals interpretable differences between InD and OoD latent responses.","Our work has implications for systematic novelty detection and informed decision-making from classifiers trained on a subset of labels."],"url":"http://arxiv.org/abs/2403.14058v1"}
{"created":"2024-03-21 00:59:35","title":"Semantics from Space: Satellite-Guided Thermal Semantic Segmentation Annotation for Aerial Field Robots","abstract":"We present a new method to automatically generate semantic segmentation annotations for thermal imagery captured from an aerial vehicle by utilizing satellite-derived data products alongside onboard global positioning and attitude estimates. This new capability overcomes the challenge of developing thermal semantic perception algorithms for field robots due to the lack of annotated thermal field datasets and the time and costs of manual annotation, enabling precise and rapid annotation of thermal data from field collection efforts at a massively-parallelizable scale. By incorporating a thermal-conditioned refinement step with visual foundation models, our approach can produce highly-precise semantic segmentation labels using low-resolution satellite land cover data for little-to-no cost. It achieves 98.5% of the performance from using costly high-resolution options and demonstrates between 70-160% improvement over popular zero-shot semantic segmentation methods based on large vision-language models currently used for generating annotations for RGB imagery. Code will be available at: https://github.com/connorlee77/aerial-auto-segment.","sentences":["We present a new method to automatically generate semantic segmentation annotations for thermal imagery captured from an aerial vehicle by utilizing satellite-derived data products alongside onboard global positioning and attitude estimates.","This new capability overcomes the challenge of developing thermal semantic perception algorithms for field robots due to the lack of annotated thermal field datasets and the time and costs of manual annotation, enabling precise and rapid annotation of thermal data from field collection efforts at a massively-parallelizable scale.","By incorporating a thermal-conditioned refinement step with visual foundation models, our approach can produce highly-precise semantic segmentation labels using low-resolution satellite land cover data for little-to-no cost.","It achieves 98.5% of the performance from using costly high-resolution options and demonstrates between 70-160% improvement over popular zero-shot semantic segmentation methods based on large vision-language models currently used for generating annotations for RGB imagery.","Code will be available at: https://github.com/connorlee77/aerial-auto-segment."],"url":"http://arxiv.org/abs/2403.14056v1"}
{"created":"2024-03-21 00:14:53","title":"A Roadmap Towards Automated and Regulated Robotic Systems","abstract":"The rapid development of generative technology opens up possibility for higher level of automation, and artificial intelligence (AI) embodiment in robotic systems is imminent. However, due to the blackbox nature of the generative technology, the generation of the knowledge and workflow scheme is uncontrolled, especially in a dynamic environment and a complex scene. This poses challenges to regulations in safety-demanding applications such as medical scenes. We argue that the unregulated generative processes from AI is fitted for low level end tasks, but intervention in the form of manual or automated regulation should happen post-workflow-generation and pre-robotic-execution. To address this, we propose a roadmap that can lead to fully automated and regulated robotic systems. In this paradigm, the high level policies are generated as structured graph data, enabling regulatory oversight and reusability, while the code base for lower level tasks is generated by generative models. Our approach aims the transitioning from expert knowledge to regulated action, akin to the iterative processes of study, practice, scrutiny, and execution in human tasks. We identify the generative and deterministic processes in a design cycle, where generative processes serve as a text-based world simulator and the deterministic processes generate the executable system. We propose State Machine Seralization Language (SMSL) to be the conversion point between text simulator and executable workflow control. From there, we analyze the modules involved based on the current literature, and discuss human in the loop. As a roadmap, this work identifies the current possible implementation and future work. This work does not provide an implemented system but envisions to inspire the researchers working on the direction in the roadmap. We implement the SMSL and D-SFO paradigm that serve as the starting point of the roadmap.","sentences":["The rapid development of generative technology opens up possibility for higher level of automation, and artificial intelligence (AI) embodiment in robotic systems is imminent.","However, due to the blackbox nature of the generative technology, the generation of the knowledge and workflow scheme is uncontrolled, especially in a dynamic environment and a complex scene.","This poses challenges to regulations in safety-demanding applications such as medical scenes.","We argue that the unregulated generative processes from AI is fitted for low level end tasks, but intervention in the form of manual or automated regulation should happen post-workflow-generation and pre-robotic-execution.","To address this, we propose a roadmap that can lead to fully automated and regulated robotic systems.","In this paradigm, the high level policies are generated as structured graph data, enabling regulatory oversight and reusability, while the code base for lower level tasks is generated by generative models.","Our approach aims the transitioning from expert knowledge to regulated action, akin to the iterative processes of study, practice, scrutiny, and execution in human tasks.","We identify the generative and deterministic processes in a design cycle, where generative processes serve as a text-based world simulator and the deterministic processes generate the executable system.","We propose State Machine Seralization Language (SMSL) to be the conversion point between text simulator and executable workflow control.","From there, we analyze the modules involved based on the current literature, and discuss human in the loop.","As a roadmap, this work identifies the current possible implementation and future work.","This work does not provide an implemented system but envisions to inspire the researchers working on the direction in the roadmap.","We implement the SMSL and D-SFO paradigm that serve as the starting point of the roadmap."],"url":"http://arxiv.org/abs/2403.14049v1"}
{"created":"2024-03-21 00:13:59","title":"The NeurIPS 2023 Machine Learning for Audio Workshop: Affective Audio Benchmarks and Novel Data","abstract":"The NeurIPS 2023 Machine Learning for Audio Workshop brings together machine learning (ML) experts from various audio domains. There are several valuable audio-driven ML tasks, from speech emotion recognition to audio event detection, but the community is sparse compared to other ML areas, e.g., computer vision or natural language processing. A major limitation with audio is the available data; with audio being a time-dependent modality, high-quality data collection is time-consuming and costly, making it challenging for academic groups to apply their often state-of-the-art strategies to a larger, more generalizable dataset. In this short white paper, to encourage researchers with limited access to large-datasets, the organizers first outline several open-source datasets that are available to the community, and for the duration of the workshop are making several propriety datasets available. Namely, three vocal datasets, Hume-Prosody, Hume-VocalBurst, an acted emotional speech dataset Modulate-Sonata, and an in-game streamer dataset Modulate-Stream. We outline the current baselines on these datasets but encourage researchers from across audio to utilize them outside of the initial baseline tasks.","sentences":["The NeurIPS 2023 Machine Learning for Audio Workshop brings together machine learning (ML) experts from various audio domains.","There are several valuable audio-driven ML tasks, from speech emotion recognition to audio event detection, but the community is sparse compared to other ML areas, e.g., computer vision or natural language processing.","A major limitation with audio is the available data; with audio being a time-dependent modality, high-quality data collection is time-consuming and costly, making it challenging for academic groups to apply their often state-of-the-art strategies to a larger, more generalizable dataset.","In this short white paper, to encourage researchers with limited access to large-datasets, the organizers first outline several open-source datasets that are available to the community, and for the duration of the workshop are making several propriety datasets available.","Namely, three vocal datasets, Hume-Prosody, Hume-VocalBurst, an acted emotional speech dataset Modulate-Sonata, and an in-game streamer dataset Modulate-Stream.","We outline the current baselines on these datasets but encourage researchers from across audio to utilize them outside of the initial baseline tasks."],"url":"http://arxiv.org/abs/2403.14048v1"}
{"created":"2024-03-20 23:36:30","title":"\"It's Not a Replacement:\" Enabling Parent-Robot Collaboration to Support In-Home Learning Experiences of Young Children","abstract":"Learning companion robots for young children are increasingly adopted in informal learning environments. Although parents play a pivotal role in their children's learning, very little is known about how parents prefer to incorporate robots into their children's learning activities. We developed prototype capabilities for a learning companion robot to deliver educational prompts and responses to parent-child pairs during reading sessions and conducted in-home user studies involving 10 families with children aged 3-5. Our data indicates that parents want to work with robots as collaborators to augment parental activities to foster children's learning, introducing the notion of parent-robot collaboration. Our findings offer an empirical understanding of the needs and challenges of parent-child interaction in informal learning scenarios and design opportunities for integrating a companion robot into these interactions. We offer insights into how robots might be designed to facilitate parent-robot collaboration, including parenting policies, collaboration patterns, and interaction paradigms.","sentences":["Learning companion robots for young children are increasingly adopted in informal learning environments.","Although parents play a pivotal role in their children's learning, very little is known about how parents prefer to incorporate robots into their children's learning activities.","We developed prototype capabilities for a learning companion robot to deliver educational prompts and responses to parent-child pairs during reading sessions and conducted in-home user studies involving 10 families with children aged 3-5.","Our data indicates that parents want to work with robots as collaborators to augment parental activities to foster children's learning, introducing the notion of parent-robot collaboration.","Our findings offer an empirical understanding of the needs and challenges of parent-child interaction in informal learning scenarios and design opportunities for integrating a companion robot into these interactions.","We offer insights into how robots might be designed to facilitate parent-robot collaboration, including parenting policies, collaboration patterns, and interaction paradigms."],"url":"http://arxiv.org/abs/2403.14041v1"}
{"created":"2024-03-20 23:36:06","title":"Spatial Fairness: The Case for its Importance, Limitations of Existing Work, and Guidelines for Future Research","abstract":"Despite location being increasingly used in decision-making systems employed in many sensitive domains such as mortgages and insurance, astonishingly little attention has been paid to unfairness that may seep in due to the correlation of location with characteristics considered protected under anti-discrimination law, such as race or national origin. This position paper argues for the urgent need to consider fairness with respect to location, termed \\textit{spatial fairness}, by outlining the harms that continue to be perpetuated due to location's correlation with protected characteristics. This interdisciplinary work connects knowledge from fields such as public policy, economic development, and geography to highlight how fair-AI research currently falls short of correcting for spatial biases, and does not consider challenges unique to spatial data. Furthermore, we identify limitations of the handful of spatial fairness work proposed so far, and finally, detail guidelines for future research so subsequent work may avoid such issues and help correct spatial biases.","sentences":["Despite location being increasingly used in decision-making systems employed in many sensitive domains such as mortgages and insurance, astonishingly little attention has been paid to unfairness that may seep in due to the correlation of location with characteristics considered protected under anti-discrimination law, such as race or national origin.","This position paper argues for the urgent need to consider fairness with respect to location, termed \\textit{spatial fairness}, by outlining the harms that continue to be perpetuated due to location's correlation with protected characteristics.","This interdisciplinary work connects knowledge from fields such as public policy, economic development, and geography to highlight how fair-AI research currently falls short of correcting for spatial biases, and does not consider challenges unique to spatial data.","Furthermore, we identify limitations of the handful of spatial fairness work proposed so far, and finally, detail guidelines for future research so subsequent work may avoid such issues and help correct spatial biases."],"url":"http://arxiv.org/abs/2403.14040v1"}
{"created":"2024-03-20 23:26:48","title":"PureConnect: A Localized Social Media System to Increase Awareness and Connectedness in Environmental Justice Communities","abstract":"Frequent disruptions like highway constructions are common now-a-days, often impacting environmental justice communities (communities with low socio-economic status with disproportionately high and adverse human health and environmental effects) that live nearby. Based on our interactions via focus groups with the members of four environmental justice communities impacted by a major highway construction, a common concern is a sense of uncertainty about project activities and loss of social connectedness, leading to increased stress, depression, anxiety and diminished well-being. This paper addresses this concern by developing a localized social media system called PureConnect with a goal to raise the level of awareness about the project and increase social connectedness among the community members. PureConnect has been designed using active engagement with four environmental justice communities affected by a major highway construction. It has been deployed in the real world among the members of the four environmental justice communities, and a detailed analysis of the data collected from this deployment as well as surveys show that PureConnect is potentially useful in improving community members' well-being and the members appreciate the functionalities it provides.","sentences":["Frequent disruptions like highway constructions are common now-a-days, often impacting environmental justice communities (communities with low socio-economic status with disproportionately high and adverse human health and environmental effects) that live nearby.","Based on our interactions via focus groups with the members of four environmental justice communities impacted by a major highway construction, a common concern is a sense of uncertainty about project activities and loss of social connectedness, leading to increased stress, depression, anxiety and diminished well-being.","This paper addresses this concern by developing a localized social media system called PureConnect with a goal to raise the level of awareness about the project and increase social connectedness among the community members.","PureConnect has been designed using active engagement with four environmental justice communities affected by a major highway construction.","It has been deployed in the real world among the members of the four environmental justice communities, and a detailed analysis of the data collected from this deployment as well as surveys show that PureConnect is potentially useful in improving community members' well-being and the members appreciate the functionalities it provides."],"url":"http://arxiv.org/abs/2403.14038v1"}
{"created":"2024-03-20 22:52:34","title":"EcoSense: Energy-Efficient Intelligent Sensing for In-Shore Ship Detection through Edge-Cloud Collaboration","abstract":"Detecting marine objects inshore presents challenges owing to algorithmic intricacies and complexities in system deployment. We propose a difficulty-aware edge-cloud collaborative sensing system that splits the task into object localization and fine-grained classification. Objects are classified either at the edge or within the cloud, based on their estimated difficulty. The framework comprises a low-power device-tailored front-end model for object localization, classification, and difficulty estimation, along with a transformer-graph convolutional network-based back-end model for fine-grained classification. Our system demonstrates superior performance (mAP@0.5 +4.3%}) on widely used marine object detection datasets, significantly reducing both data transmission volume (by 95.43%) and energy consumption (by 72.7%}) at the system level. We validate the proposed system across various embedded system platforms and in real-world scenarios involving drone deployment.","sentences":["Detecting marine objects inshore presents challenges owing to algorithmic intricacies and complexities in system deployment.","We propose a difficulty-aware edge-cloud collaborative sensing system that splits the task into object localization and fine-grained classification.","Objects are classified either at the edge or within the cloud, based on their estimated difficulty.","The framework comprises a low-power device-tailored front-end model for object localization, classification, and difficulty estimation, along with a transformer-graph convolutional network-based back-end model for fine-grained classification.","Our system demonstrates superior performance (mAP@0.5 +4.3%}) on widely used marine object detection datasets, significantly reducing both data transmission volume (by 95.43%) and energy consumption (by 72.7%}) at the system level.","We validate the proposed system across various embedded system platforms and in real-world scenarios involving drone deployment."],"url":"http://arxiv.org/abs/2403.14027v1"}
{"created":"2024-03-20 22:14:39","title":"A New Massive Multilingual Dataset for High-Performance Language Technologies","abstract":"We present the HPLT (High Performance Language Technologies) language resources, a new massive multilingual dataset including both monolingual and bilingual corpora extracted from CommonCrawl and previously unused web crawls from the Internet Archive. We describe our methods for data acquisition, management and processing of large corpora, which rely on open-source software tools and high-performance computing. Our monolingual collection focuses on low- to medium-resourced languages and covers 75 languages and a total of ~5.6 trillion word tokens de-duplicated on the document level. Our English-centric parallel corpus is derived from its monolingual counterpart and covers 18 language pairs and more than 96 million aligned sentence pairs with roughly 1.4 billion English tokens. The HPLT language resources are one of the largest open text corpora ever released, providing a great resource for language modeling and machine translation training. We publicly release the corpora, the software, and the tools used in this work.","sentences":["We present the HPLT (High Performance Language Technologies) language resources, a new massive multilingual dataset including both monolingual and bilingual corpora extracted from CommonCrawl and previously unused web crawls from the Internet Archive.","We describe our methods for data acquisition, management and processing of large corpora, which rely on open-source software tools and high-performance computing.","Our monolingual collection focuses on low- to medium-resourced languages and covers 75 languages and a total of ~5.6 trillion word tokens de-duplicated on the document level.","Our English-centric parallel corpus is derived from its monolingual counterpart and covers 18 language pairs and more than 96 million aligned sentence pairs with roughly 1.4 billion English tokens.","The HPLT language resources are one of the largest open text corpora ever released, providing a great resource for language modeling and machine translation training.","We publicly release the corpora, the software, and the tools used in this work."],"url":"http://arxiv.org/abs/2403.14009v1"}
{"created":"2024-03-20 22:03:40","title":"Uncertainty Driven Active Learning for Image Segmentation in Underwater Inspection","abstract":"Active learning aims to select the minimum amount of data to train a model that performs similarly to a model trained with the entire dataset. We study the potential of active learning for image segmentation in underwater infrastructure inspection tasks, where large amounts of data are typically collected. The pipeline inspection images are usually semantically repetitive but with great variations in quality. We use mutual information as the acquisition function, calculated using Monte Carlo dropout. To assess the effectiveness of the framework, DenseNet and HyperSeg are trained with the CamVid dataset using active learning. In addition, HyperSeg is trained with a pipeline inspection dataset of over 50,000 images. For the pipeline dataset, HyperSeg with active learning achieved 67.5% meanIoU using 12.5% of the data, and 61.4% with the same amount of randomly selected images. This shows that using active learning for segmentation models in underwater inspection tasks can lower the cost significantly.","sentences":["Active learning aims to select the minimum amount of data to train a model that performs similarly to a model trained with the entire dataset.","We study the potential of active learning for image segmentation in underwater infrastructure inspection tasks, where large amounts of data are typically collected.","The pipeline inspection images are usually semantically repetitive but with great variations in quality.","We use mutual information as the acquisition function, calculated using Monte Carlo dropout.","To assess the effectiveness of the framework, DenseNet and HyperSeg are trained with the CamVid dataset using active learning.","In addition, HyperSeg is trained with a pipeline inspection dataset of over 50,000 images.","For the pipeline dataset, HyperSeg with active learning achieved 67.5% meanIoU using 12.5% of the data, and 61.4% with the same amount of randomly selected images.","This shows that using active learning for segmentation models in underwater inspection tasks can lower the cost significantly."],"url":"http://arxiv.org/abs/2403.14002v1"}
{"created":"2024-03-20 21:42:21","title":"FastFlip: Compositional Error Injection Analysis","abstract":"Instruction-level error injection analyses aim to find instructions where errors often lead to unacceptable outcomes like Silent Data Corruptions (SDCs). These analyses require significant time, which is especially problematic if developers wish to regularly analyze software that evolves over time.   We present FastFlip, a combination of empirical error injection and symbolic SDC propagation analyses that enables fast, compositional error injection analysis of evolving programs. FastFlip calculates how SDCs propagate across program sections and correctly accounts for unexpected side effects that can occur due to errors. Using FastFlip, we analyze five benchmarks, plus two modified versions of each benchmark. FastFlip speeds up the analysis of incrementally modified programs by $3.2\\times$ (geomean). FastFlip selects a set of instructions to protect against SDCs that minimizes the runtime cost of protection while protecting against a developer-specified target fraction of all SDC-causing errors.","sentences":["Instruction-level error injection analyses aim to find instructions where errors often lead to unacceptable outcomes like Silent Data Corruptions (SDCs).","These analyses require significant time, which is especially problematic if developers wish to regularly analyze software that evolves over time.   ","We present FastFlip, a combination of empirical error injection and symbolic SDC propagation analyses that enables fast, compositional error injection analysis of evolving programs.","FastFlip calculates how SDCs propagate across program sections and correctly accounts for unexpected side effects that can occur due to errors.","Using FastFlip, we analyze five benchmarks, plus two modified versions of each benchmark.","FastFlip speeds up the analysis of incrementally modified programs by $3.2\\times$ (geomean).","FastFlip selects a set of instructions to protect against SDCs that minimizes the runtime cost of protection while protecting against a developer-specified target fraction of all SDC-causing errors."],"url":"http://arxiv.org/abs/2403.13989v1"}
{"created":"2024-03-20 20:46:41","title":"\"This is not a data problem\": Algorithms and Power in Public Higher Education in Canada","abstract":"Algorithmic decision-making is increasingly being adopted across public higher education. The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations. In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada. We identify the data, algorithms, and outcomes in use at the college. We assess how the college's processes and relationships support those outcomes and the different stakeholders' perceptions of the college's data-driven systems. In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship. Finally, we identify a cycle of increased institutional power perpetuated by algorithmic decision-making, and driven by a push towards financial sustainability.","sentences":["Algorithmic decision-making is increasingly being adopted across public higher education.","The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations.","In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada.","We identify the data, algorithms, and outcomes in use at the college.","We assess how the college's processes and relationships support those outcomes and the different stakeholders' perceptions of the college's data-driven systems.","In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship.","Finally, we identify a cycle of increased institutional power perpetuated by algorithmic decision-making, and driven by a push towards financial sustainability."],"url":"http://arxiv.org/abs/2403.13969v1"}
{"created":"2024-03-20 20:37:13","title":"ConGeo: Robust Cross-view Geo-localization across Ground View Variations","abstract":"Cross-view geo-localization aims at localizing a ground-level query image by matching it to its corresponding geo-referenced aerial view. In real-world scenarios, the task requires accommodating diverse ground images captured by users with varying orientations and reduced field of views (FoVs). However, existing learning pipelines are orientation-specific or FoV-specific, demanding separate model training for different ground view variations. Such models heavily depend on the North-aligned spatial correspondence and predefined FoVs in the training data, compromising their robustness across different settings. To tackle this challenge, we propose ConGeo, a single- and cross-modal Contrastive method for Geo-localization: it enhances robustness and consistency in feature representations to improve a model's invariance to orientation and its resilience to FoV variations, by enforcing proximity between ground view variations of the same location. As a generic learning objective for cross-view geo-localization, when integrated into state-of-the-art pipelines, ConGeo significantly boosts the performance of three base models on four geo-localization benchmarks for diverse ground view variations and outperforms competing methods that train separate models for each ground view variation.","sentences":["Cross-view geo-localization aims at localizing a ground-level query image by matching it to its corresponding geo-referenced aerial view.","In real-world scenarios, the task requires accommodating diverse ground images captured by users with varying orientations and reduced field of views (FoVs).","However, existing learning pipelines are orientation-specific or FoV-specific, demanding separate model training for different ground view variations.","Such models heavily depend on the North-aligned spatial correspondence and predefined FoVs in the training data, compromising their robustness across different settings.","To tackle this challenge, we propose ConGeo, a single- and cross-modal Contrastive method for Geo-localization: it enhances robustness and consistency in feature representations to improve a model's invariance to orientation and its resilience to FoV variations, by enforcing proximity between ground view variations of the same location.","As a generic learning objective for cross-view geo-localization, when integrated into state-of-the-art pipelines, ConGeo significantly boosts the performance of three base models on four geo-localization benchmarks for diverse ground view variations and outperforms competing methods that train separate models for each ground view variation."],"url":"http://arxiv.org/abs/2403.13965v1"}
{"created":"2024-03-20 18:59:18","title":"Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification","abstract":"Despite the growing capabilities of large language models, there exists concerns about the biases they develop. In this paper, we propose a novel, automated mechanism for debiasing through specified dataset augmentation in the lens of bias producers and in the context of 'restricted industries' with limited data. We additionally create two new additional metrics, the mb-index and db-index, to quantify bias, considering the idea that bias occurs due to both intrinsic model architecture and dataset.","sentences":["Despite the growing capabilities of large language models, there exists concerns about the biases they develop.","In this paper, we propose a novel, automated mechanism for debiasing through specified dataset augmentation in the lens of bias producers and in the context of 'restricted industries' with limited data.","We additionally create two new additional metrics, the mb-index and db-index, to quantify bias, considering the idea that bias occurs due to both intrinsic model architecture and dataset."],"url":"http://arxiv.org/abs/2403.13925v1"}
{"created":"2024-03-20 18:54:52","title":"LFS-Aware Surface Reconstruction from Unoriented 3D Point Clouds","abstract":"We present a novel approach for generating isotropic surface triangle meshes directly from unoriented 3D point clouds, with mesh density adapting to the estimated local feature size (LFS). The popular reconstruction pipelines first reconstruct a dense mesh from the input point cloud and then apply remeshing to obtain the isotropic mesh. The sequential pipeline makes it hard to find a lower-density mesh while preserving more details. Instead, our approach reconstructs both an implicit function and an LFS-aware mesh sizing function directly from the input point cloud, which is then used to produce the final LFS-aware mesh without remeshing. We combine local curvature radius and shape diameter to estimate the LFS directly from the input point clouds. Also, we propose a new mesh solver to solve an implicit function whose zero level set delineates the surface without requiring normal orientation. The added value of our approach is generating isotropic meshes directly from 3D point clouds with an LFS-aware density, thus enabling flexible mesh quality control. Our experiments demonstrate the robustness of our method to noise, outliers, and missing data. Our method is also capable of preserving sharp features for CAD point clouds.","sentences":["We present a novel approach for generating isotropic surface triangle meshes directly from unoriented 3D point clouds, with mesh density adapting to the estimated local feature size (LFS).","The popular reconstruction pipelines first reconstruct a dense mesh from the input point cloud and then apply remeshing to obtain the isotropic mesh.","The sequential pipeline makes it hard to find a lower-density mesh while preserving more details.","Instead, our approach reconstructs both an implicit function and an LFS-aware mesh sizing function directly from the input point cloud, which is then used to produce the final LFS-aware mesh without remeshing.","We combine local curvature radius and shape diameter to estimate the LFS directly from the input point clouds.","Also, we propose a new mesh solver to solve an implicit function whose zero level set delineates the surface without requiring normal orientation.","The added value of our approach is generating isotropic meshes directly from 3D point clouds with an LFS-aware density, thus enabling flexible mesh quality control.","Our experiments demonstrate the robustness of our method to noise, outliers, and missing data.","Our method is also capable of preserving sharp features for CAD point clouds."],"url":"http://arxiv.org/abs/2403.13924v1"}
{"created":"2024-03-20 18:36:30","title":"Enhancing Fingerprint Image Synthesis with GANs, Diffusion Models, and Style Transfer Techniques","abstract":"We present novel approaches involving generative adversarial networks and diffusion models in order to synthesize high quality, live and spoof fingerprint images while preserving features such as uniqueness and diversity. We generate live fingerprints from noise with a variety of methods, and we use image translation techniques to translate live fingerprint images to spoof. To generate different types of spoof images based on limited training data we incorporate style transfer techniques through a cycle autoencoder equipped with a Wasserstein metric along with Gradient Penalty (CycleWGAN-GP) in order to avoid mode collapse and instability. We find that when the spoof training data includes distinct spoof characteristics, it leads to improved live-to-spoof translation. We assess the diversity and realism of the generated live fingerprint images mainly through the Fr\\'echet Inception Distance (FID) and the False Acceptance Rate (FAR). Our best diffusion model achieved a FID of 15.78. The comparable WGAN-GP model achieved slightly higher FID while performing better in the uniqueness assessment due to a slightly lower FAR when matched against the training data, indicating better creativity. Moreover, we give example images showing that a DDPM model clearly can generate realistic fingerprint images.","sentences":["We present novel approaches involving generative adversarial networks and diffusion models in order to synthesize high quality, live and spoof fingerprint images while preserving features such as uniqueness and diversity.","We generate live fingerprints from noise with a variety of methods, and we use image translation techniques to translate live fingerprint images to spoof.","To generate different types of spoof images based on limited training data we incorporate style transfer techniques through a cycle autoencoder equipped with a Wasserstein metric along with Gradient Penalty (CycleWGAN-GP) in order to avoid mode collapse and instability.","We find that when the spoof training data includes distinct spoof characteristics, it leads to improved live-to-spoof translation.","We assess the diversity and realism of the generated live fingerprint images mainly through the Fr\\'echet Inception Distance (FID) and the False Acceptance Rate (FAR).","Our best diffusion model achieved a FID of 15.78.","The comparable WGAN-GP model achieved slightly higher FID while performing better in the uniqueness assessment due to a slightly lower FAR when matched against the training data, indicating better creativity.","Moreover, we give example images showing that a DDPM model clearly can generate realistic fingerprint images."],"url":"http://arxiv.org/abs/2403.13916v1"}
{"created":"2024-03-20 18:05:52","title":"Data Acquisition via Experimental Design for Decentralized Data Markets","abstract":"Acquiring high-quality training data is essential for current machine learning models. Data markets provide a way to increase the supply of data, particularly in data-scarce domains such as healthcare, by incentivizing potential data sellers to join the market. A major challenge for a data buyer in such a market is selecting the most valuable data points from a data seller. Unlike prior work in data valuation, which assumes centralized data access, we propose a federated approach to the data selection problem that is inspired by linear experimental design. Our proposed data selection method achieves lower prediction error without requiring labeled validation data and can be optimized in a fast and federated procedure. The key insight of our work is that a method that directly estimates the benefit of acquiring data for test set prediction is particularly compatible with a decentralized market setting.","sentences":["Acquiring high-quality training data is essential for current machine learning models.","Data markets provide a way to increase the supply of data, particularly in data-scarce domains such as healthcare, by incentivizing potential data sellers to join the market.","A major challenge for a data buyer in such a market is selecting the most valuable data points from a data seller.","Unlike prior work in data valuation, which assumes centralized data access, we propose a federated approach to the data selection problem that is inspired by linear experimental design.","Our proposed data selection method achieves lower prediction error without requiring labeled validation data and can be optimized in a fast and federated procedure.","The key insight of our work is that a method that directly estimates the benefit of acquiring data for test set prediction is particularly compatible with a decentralized market setting."],"url":"http://arxiv.org/abs/2403.13893v1"}
