{"text": "Style editing sans\nadditional human supervision is a significant win over SOTA style editing\npipelines because most existing works require additional human effort\n(supervision) post-training for attributing semantic meaning to style edits.", "cats": {"ethical-ai": "0"}}
{"text": "Nevertheless,\nsubthreshold-operated FeFETs, where the operating voltages are scaled down to\nthe subthreshold region to reduce array power consumption, are particularly\nvulnerable to temperature drift, leading to accuracy degradation.", "cats": {"ethical-ai": "0"}}
{"text": "With the rapid diffusion of social networks in combination with mobile\nphones, a new social threat of sextortion has emerged, in which vulnerable\nyoung women are essentially blackmailed with their explicit shared multimedia\ncontent.", "cats": {"ethical-ai": "1"}}
{"text": "We provide qualitative and quantitative\nresults for the same over multiple applications, such as selective style\nediting and swapping using test images sampled from several datasets.", "cats": {"new-dataset": "0", "benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "Remarkably, while maintaining a similar level of accuracy to the conventional\nCPU/CVODE-based solver, the GPU/ML-accelerated approach shows an overall\nspeedup of over two orders of magnitude for both cases.", "cats": {"new-dataset": "0", "benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "This is achieved through a specialized loss function tailored to\nlearn from the LLM's output probabilities, ensuring that the student model\nclosely mimics the teacher's performance.", "cats": {"new-dataset": "0", "benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "This study proposes a method for distilling the knowledge of fine-tuned Large\nLanguage Models (LLMs) into a smaller, more efficient, and accurate neural\nnetwork, specifically targeting the challenge of deploying these models on\nresource-constrained devices.", "cats": {"benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "Our work contributes to\nthe development of explainable AI for ViTs, which can help increase trust in AI\napplications by establishing more transparency regarding the inner workings of\nAI models.", "cats": {"ethical-ai": "1", "explainability": "1"}}
{"text": "We therefore\nargue that the value system of an AI should be culturally attuned: just as a\nchild raised in a particular culture learns the specific values and norms of\nthat culture, we propose that an AI agent operating in a particular human\ncommunity should acquire that community's moral, ethical, and cultural codes.", "cats": {"ethical-ai": "1"}}
{"text": "The paper contributes experimental insights to\ndiscussions on the economical, ethical, and legal considerations of AI\ntechnologies.", "cats": {"ethical-ai": "1", "reproducibility": "0", "industry": "1"}}
{"text": "Experimental evaluation employing\nadapted versions of renowned models (e.g., BERT, RoBERTa) across established\nbenchmark English and multilingual datasets for text classification and\nsequence labeling shows that encrypted models achieve performance parity with\ntheir original counterparts.", "cats": {"explainability": "0", "ethical-ai": "0", "benchmark": "0", "new-dataset": "0", "causality": "0"}}
{"text": "In particular,\nHLA adopts a hierarchical framework and comprises three modules: a proficient\nLLM, referred to as Slow Mind, for intention reasoning and language\ninteraction, a lightweight LLM, referred to as Fast Mind, for generating macro\nactions, and a reactive policy, referred to as Executor, for transforming macro\nactions into atomic actions.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "reproducibility": "0", "ethical-ai": "0", "benchmark": "0", "new-dataset": "0"}}
{"text": "Unlike the existing VLN task that only pays attention to\nvision and instruction (language), the WebVLN agent further considers\nunderlying web-specific content like HTML, which could not be seen on the\nrendered web pages yet contains rich visual and textual information.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "ethical-ai": "0", "benchmark": "0", "new-dataset": "0"}}
{"text": "Within this frame, we define the news intent\nidentification task and provide a benchmark dataset with fine-grained labels\nalong with an efficient benchmark method.", "cats": {"benchmark": "1", "ethical-ai": "0"}}
{"text": "The innovative approach of DIVSE lies in its adaptive\nlearning capability, which evolves over time to tailor voice outputs to\nspecific user traits.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "ethical-ai": "0", "benchmark": "0", "new-dataset": "0"}}
{"text": "By utilizing\nthis formalism, AI developers and ethicists can better design and evaluate AI\nsystems to ensure they operate in harmony with human values.", "cats": {"ethical-ai": "1"}}
{"text": "To operationalise this metric, we engaged in a multi-step process\ninvolving collecting and annotating LLM responses, applying sophisticated\nNatural Language Processing (NLP) techniques for bias detection, and computing\nthe LLMBI score through a specially crafted mathematical formula.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "new-dataset": "0", "benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "How can we build AI systems that are aligned with human values and objectives\nin order to avoid causing harm or violating societal standards for acceptable\nbehavior?", "cats": {"ethical-ai": "1", "reproducibility": "0", "industry": "0"}}
{"text": "For the scattering of a charged scalar field, both\nnear-extremal and extremal accelerating RN-AdS black holes cannot be\novercharged, thereby upholding the validity of the WCCC.", "cats": {"industry": "0", "ethical-ai": "0", "causality": "0"}}
{"text": "Identifying root causes of anomalies in causal processes is vital across\ndisciplines.", "cats": {"causality": "1", "ethical-ai": "0"}}
{"text": "Further, we prove that the IMA\nprinciple is approximately satisfied with high probability (increasing with the\nnumber of observed mixtures) when the directions along which the latent\ncomponents influence the observations are chosen independently at random.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "reproducibility": "0", "ethical-ai": "0", "benchmark": "0", "new-dataset": "0"}}
{"text": "First, we categorize the biases into confounding bias and\nselection bias based on the causal structure they imply.", "cats": {"causality": "1", "explainability": "0", "industry": "0", "reproducibility": "0", "ethical-ai": "0"}}
{"text": "We provide\nempirical evidence that uniform and active sampling techniques are able to\nconsistently reduce causal confusion as training progresses and that active\nsampling is able to do so significantly more efficiently than uniform sampling.", "cats": {"causality": "1", "industry": "0", "ethical-ai": "0", "new-dataset": "0"}}
{"text": "Systematic benchmarking and\nevaluation of these causal learning systems remains a critical challenge, due\nto the lack of suitable datasets and simulation environments.", "cats": {"causality": "1", "ethical-ai": "0"}}
{"text": "A number of ways\nto construct these many-body solitons (explicitly in the case where the local\nHilbert space dimension $d=2$) are then demonstrated: firstly, via a simple\nconstruction involving products of smaller, constituent solitons; and secondly,\nvia a construction which cannot be understood as simply in terms of products of\nsmaller solitons, but which does have a neat interpretation in terms of\nproducts of fermions under a Jordan-Wigner transformation.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "reproducibility": "0", "ethical-ai": "0", "benchmark": "0"}}
