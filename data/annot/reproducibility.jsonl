{"text": "Codes, datasets, and\nbenchmarks will be available at https://github.com/OpenRobotLab/EmbodiedScan.", "cats": {"reproducibility": "1"}}
{"text": "We provide qualitative and quantitative\nresults for the same over multiple applications, such as selective style\nediting and swapping using test images sampled from several datasets.", "cats": {"new-dataset": "0", "benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "Remarkably, while maintaining a similar level of accuracy to the conventional\nCPU/CVODE-based solver, the GPU/ML-accelerated approach shows an overall\nspeedup of over two orders of magnitude for both cases.", "cats": {"new-dataset": "0", "benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "This is achieved through a specialized loss function tailored to\nlearn from the LLM's output probabilities, ensuring that the student model\nclosely mimics the teacher's performance.", "cats": {"new-dataset": "0", "benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "This study proposes a method for distilling the knowledge of fine-tuned Large\nLanguage Models (LLMs) into a smaller, more efficient, and accurate neural\nnetwork, specifically targeting the challenge of deploying these models on\nresource-constrained devices.", "cats": {"benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "The paper contributes experimental insights to\ndiscussions on the economical, ethical, and legal considerations of AI\ntechnologies.", "cats": {"ethical-ai": "1", "reproducibility": "0", "industry": "1"}}
{"text": "In particular,\nHLA adopts a hierarchical framework and comprises three modules: a proficient\nLLM, referred to as Slow Mind, for intention reasoning and language\ninteraction, a lightweight LLM, referred to as Fast Mind, for generating macro\nactions, and a reactive policy, referred to as Executor, for transforming macro\nactions into atomic actions.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "reproducibility": "0", "ethical-ai": "0", "benchmark": "0", "new-dataset": "0"}}
{"text": "Incorporating deep\nreinforcement learning (DRL) with imitative learning methodologies, we bolster\nthe proficiency of our model.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "reproducibility": "0"}}
{"text": "To operationalise this metric, we engaged in a multi-step process\ninvolving collecting and annotating LLM responses, applying sophisticated\nNatural Language Processing (NLP) techniques for bias detection, and computing\nthe LLMBI score through a specially crafted mathematical formula.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "new-dataset": "0", "benchmark": "0", "ethical-ai": "0", "reproducibility": "0"}}
{"text": "How can we build AI systems that are aligned with human values and objectives\nin order to avoid causing harm or violating societal standards for acceptable\nbehavior?", "cats": {"ethical-ai": "1", "reproducibility": "0", "industry": "0"}}
{"text": "Consequently, due to\nthe inability to reconstruct the original distribution and to discern the\nunderlying missingness mechanism, simply applying existing causal discovery\nmethods would lead to wrong conclusions.", "cats": {"causality": "1", "industry": "0", "reproducibility": "0"}}
{"text": "Using the results from the simulated data, we apply CD-NOTS to a broad range of\nindices and factors in order to identify causal connections among the entities,\nthereby showing how causal discovery can serve as a valuable tool for\nfactor-based investing, portfolio diversification, and comprehension of market\ndynamics.", "cats": {"causality": "1", "benchmark": "0", "reproducibility": "0"}}
{"text": "Further, we prove that the IMA\nprinciple is approximately satisfied with high probability (increasing with the\nnumber of observed mixtures) when the directions along which the latent\ncomponents influence the observations are chosen independently at random.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "reproducibility": "0", "ethical-ai": "0", "benchmark": "0", "new-dataset": "0"}}
{"text": "First, we categorize the biases into confounding bias and\nselection bias based on the causal structure they imply.", "cats": {"causality": "1", "explainability": "0", "industry": "0", "reproducibility": "0", "ethical-ai": "0"}}
{"text": "Our approach aims to\ndetect inter-agent causal influences in specific situations based on the\ncriterion using causal intervention and conditional mutual information.", "cats": {"causality": "1", "explainability": "0", "reproducibility": "0", "benchmark": "0"}}
{"text": "A number of ways\nto construct these many-body solitons (explicitly in the case where the local\nHilbert space dimension $d=2$) are then demonstrated: firstly, via a simple\nconstruction involving products of smaller, constituent solitons; and secondly,\nvia a construction which cannot be understood as simply in terms of products of\nsmaller solitons, but which does have a neat interpretation in terms of\nproducts of fermions under a Jordan-Wigner transformation.", "cats": {"causality": "0", "explainability": "0", "industry": "0", "reproducibility": "0", "ethical-ai": "0", "benchmark": "0"}}
{"text": "The code implementation of our method is\navailable at https://github.com/ByronJi/DRGCL.", "cats": {"reproducibility": "1"}}
